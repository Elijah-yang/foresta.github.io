<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>C/C++漏洞数据集</title>
      <link href="/2024/04/18/Security/C_C++%E6%BC%8F%E6%B4%9E%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
      <url>/2024/04/18/Security/C_C++%E6%BC%8F%E6%B4%9E%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/qq_44370676/article/details/118198912#2_136">C/C++漏洞数据集-CSDN博客</a></p><h4 id="漏洞数据集"><a class="markdownIt-Anchor" href="#漏洞数据集"></a> 漏洞数据集</h4><ul><li>[1.常用数据集]</li><li><ul><li>[1.1.Big-Vul]</li><li>[1.2.Reveal]</li><li>[1.3.FFMPeg+Qemu]</li><li>[1.4.D2A]</li></ul></li><li>[2.数据集质量研究]</li></ul><h2 id="1常用数据集"><a class="markdownIt-Anchor" href="#1常用数据集"></a> 1.常用数据集</h2><h3 id="11big-vul"><a class="markdownIt-Anchor" href="#11big-vul"></a> 1.1.Big-Vul</h3><p>论文地址：<a href="https://dl.acm.org/doi/10.1145/3379597.3387501">A C/C++ Code Vulnerability Dataset with Code Changes and CVE Summaries</a></p><p><a href="https://github.com/ZeoVan/MSR_20_Code_vulnerability_CSV_Dataset">github地址</a></p><p>该数据集存储为csv格式。包含了漏洞行号信息，详细参考github地址。</p><p><a href="https://github.com/ZeoVan/MSR_20_Code_vulnerability_CSV_Dataset">https://github.com/ZeoVan/MSR_20_Code_vulnerability_CSV_Dataset</a></p><h3 id="12reveal"><a class="markdownIt-Anchor" href="#12reveal"></a> 1.2.Reveal</h3><p>Reveal本为一个DLVD（Deep Learning Vulnerbility Detection）方法，可以参考<a href="https://blog.csdn.net/qq_44370676/article/details/118223852">Reveal</a>。而作者收集了一个数据集。从Linux <a href="https://so.csdn.net/so/search?q=Debian&amp;spm=1001.2101.3001.7020">Debian</a> Kernel 和Chromium的vulnerabilitiy fixed patches中构造。</p><p>论文地址：<a href="https://arxiv.org/abs/2009.07235">Deep Learning based Vulnerability Detection:Are We There Yet?</a></p><p><a href="https://drive.google.com/drive/folders/1KuIYgFcvWUXheDhT--cBALsfy1I4utOy">数据集下载地址</a></p><p>包含2个json，vulnerables.json和non-vulnerables.json。json的key包括</p><ul><li>code:源代码内容</li><li>hash</li><li>project</li><li>size</li></ul><p>遗憾的是，该数据集不包括漏洞行号信息。</p><h3 id="13ffmpegqemu"><a class="markdownIt-Anchor" href="#13ffmpegqemu"></a> 1.3.FFMPeg+Qemu</h3><p>又称Devign数据集</p><p><a href="https://drive.google.com/file/d/1x6hoF7G-tSYxg8AFybggypLZgMGDNHfF/edit">数据集下载地址</a></p><p>数据集为一个function.json，包括4个key。</p><ul><li>project：FFmpeg或者Qemu</li><li>commit_id</li><li>target：0或者1，是否有漏洞</li><li>func：一个函数的代码内容，包括函数定义那一行</li></ul><p>遗憾的是，该数据集也不包括漏洞行号信息。</p><h3 id="14d2a"><a class="markdownIt-Anchor" href="#14d2a"></a> 1.4.D2A</h3><p>论文地址：<a href="https://arxiv.org/pdf/2102.07995.pdf">D2A: A Dataset Built for AI-Based Vulnerability<br />Detection Methods Using Differential Analysis</a></p><p>github地址：<a href="https://github.com/ibm/D2A">D2A</a></p><p><a href="https://developer.ibm.com/exchanges/data/all/d2a/">数据集下载地址</a></p><p>数据集下下来为pickle文件，需要注意的是，这里的标记并不是简单的将一个function标为0或1，而是有一个trace，记录bug触发的路径，会涉及到多个function。</p><p>以libtiff Sample Dataset为例，加载2020-09-10_libtiff_labeler_1.pickle文件，打开发现是一个dict，有下面几个key</p><ul><li>id：值为libtiff_d888dddf8807829fc0f9f3bbdb0a64871c29b05b_1</li><li>label：值为1，该文件全是标记为1的数据</li><li>label_source：auto_labeler</li><li>bug_type：PULSE_MEMORY_LEAK</li><li>project：libtiff</li><li>bug_info：为1个dict，key包括<ul><li>qualifier：bug信息</li><li>file：源文件</li><li>procedure</li><li>line</li><li>column</li><li>url</li></ul></li><li>adjusted_bug_loc</li><li>bug_loc_trace_index</li><li>versions</li><li>sample_type：before_fix</li><li>trace：为1个list，记录该fix涉及到的function行号</li><li>functions：记录bug trace的function完整的代码</li><li>commit</li><li>compiler_args：为dict，记录每个文件用什么编译器编译</li><li>zipped_bug_report：由Infer产生的原始bug报告。</li></ul><p>论文给出的示例如下：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;   </span><br><span class="line">   <span class="attr">&quot;id&quot;:</span> <span class="string">&quot;httpd_9b3a5f0ffd8ec787cf645f97902582acb3234d96_1&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;label&quot;:</span> <span class="number">1</span>,   </span><br><span class="line">   <span class="attr">&quot;label_source&quot;:</span> <span class="string">&quot;auto_labeler&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;bug_type&quot;:</span> <span class="string">&quot;BUFFER_OVERRUN_U5&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;project&quot;:</span> <span class="string">&quot;httpd&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;bug_info&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;qualifier&quot;:</span> <span class="string">&quot;Offset: [0, +oo] Size: 10 by call to ...&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;loc&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c:178:31&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;url&quot;:</span> <span class="string">&quot;https://github.com/apache/httpd/blob/...&quot;</span>   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;versions&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;before&quot;:</span> <span class="string">&quot;545d85acdaa384a25ee5184a8ee671a18ef5582f&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;after&quot;:</span> <span class="string">&quot;2c70ed756286b2adf81c55473077698d6d6d16a1&quot;</span>   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;trace&quot;:</span> [   </span><br><span class="line">     &#123;   </span><br><span class="line">       <span class="attr">&quot;description&quot;:</span> <span class="string">&quot;Array declaration&quot;</span>,   </span><br><span class="line">       <span class="attr">&quot;loc&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c:178:31&quot;</span>,   </span><br><span class="line">       <span class="attr">&quot;func_key&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c@167:1-203:2&quot;</span>,   </span><br><span class="line">     &#125;   </span><br><span class="line">   ],   </span><br><span class="line">   <span class="attr">&quot;functions&quot;:</span> &#123;   </span><br><span class="line">     <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c@167:1-203:2&quot;</span><span class="string">:</span> &#123;   </span><br><span class="line">       <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;fix_cgivars&quot;</span>,   </span><br><span class="line">       <span class="attr">&quot;touched_by_commit&quot;:</span> <span class="literal">true</span>,   </span><br><span class="line">       <span class="attr">&quot;code&quot;:</span> <span class="string">&quot;static void fix_cgivars(request_rec *r, ...&quot;</span>   </span><br><span class="line">     &#125;   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;commit&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;url&quot;:</span> <span class="string">&quot;https://github.com/apache/httpd/commit/2c70ed7&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;changes&quot;:</span> [   </span><br><span class="line">       &#123;   </span><br><span class="line">         <span class="attr">&quot;before&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c&quot;</span>,   </span><br><span class="line">         <span class="attr">&quot;after&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c&quot;</span>,   </span><br><span class="line">         <span class="attr">&quot;changes&quot;:</span> [<span class="string">&quot;177,1^^177,5&quot;</span>]   </span><br><span class="line">       &#125;   </span><br><span class="line">     ]   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;compiler_args&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;modules/proxy/mod_proxy_fcgi.c&quot;:</span> <span class="string">&quot;-D_REENTRANT -I./server ...&quot;</span>,   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;zipped_bug_report&quot;:</span> <span class="string">&quot;...&quot;</span>   </span><br><span class="line">&#125; </span><br><span class="line"><span class="number">1234567891011121314151617181920212223242526272829303132333435363738394041424344</span></span><br></pre></td></tr></table></figure><h2 id="2数据集质量研究"><a class="markdownIt-Anchor" href="#2数据集质量研究"></a> 2.数据集质量研究</h2><p>在ICSE 23关于漏洞数据集的paper <a href="https://arxiv.org/pdf/2301.05456.pdf">Data Quality for Software Vulnerability Datasets</a>中，调研的数据集如下表所示：</p><table><thead><tr><th>数据集</th><th>标注来源</th><th>function数量</th><th>漏洞function占比</th></tr></thead><tbody><tr><td>Big-Vul</td><td>CVE databas</td><td>188636</td><td>5.78%</td></tr><tr><td>Devign</td><td>开发者标注</td><td>27318</td><td>45.61%</td></tr><tr><td>D2A</td><td>工具标注</td><td>1295623</td><td>1.44%</td></tr><tr><td>Juliet</td><td>合成</td><td>253002</td><td>36.77%</td></tr></tbody></table><p>作者统计了可能导致标注不准确的原因：</p><ul><li>Irrelevant code change: 数据集标注器假设漏洞修复（vulnerability-fix）所涉及的代码是易受攻击的代码（function）。然而，漏洞修复commit可能不一定只包括修复补丁。可能还存在非功能性更改，如样式更改、重构和代码迁移，可能会混淆数据标记过程。比如FFMpeg中<a href="https://github.com/FFmpeg/FFmpeg/commit/8b2fce0d3f5a56c40c28899c9237210ca8f9cf75#diff73395d3a1e02aad201d2af860c5bf0fc9cb6a68c9c711ff226eeb24ea0d409a5L400">libswscale/swscale.c</a>的commit仅仅是将常量变成定义的宏。</li><li>Cleanup changes: 漏洞修复可能包括增加、删除或者修改变量，这些是与漏洞修复相关的功能更改，但是它们并没有指示触发行的位置。</li><li>Inaccurate vulnerability fix identification: 如果标注器无法识别漏洞修复，那么随后的代码片段自然不会是漏洞。像Big Vul这样从外部漏洞报告中跟踪漏洞修复的数据集可能会在这个过程中引入错误。比如<ul><li>作者发现<a href="https://so.csdn.net/so/search?q=Chromium&amp;spm=1001.2101.3001.7020">Chromium</a>项目的大多数漏洞报告都被不正确地跟踪，因为这个存储库不是通过GitHub自然托管的。</li><li>而此外，有些标注器（Devign和D2A）试图直接从提交commit历史记录中识别漏洞修复的数据集，这个过程同样可能导致错误标注。D2A用静态分析工具Infer标注数据集同样可能引入错误。</li></ul></li></ul><p>对于来源自真实环境的数据集，作者的分析结果如下：</p><table><thead><tr><th>数据集</th><th>Irrelevant</th><th>Cleanup</th><th>Inaccurate</th></tr></thead><tbody><tr><td>Big-Vul</td><td>25%</td><td>28.1%</td><td>46.9%</td></tr><tr><td>Devign</td><td>42.9%</td><td>21.4%</td><td>35.7%</td></tr><tr><td>D2A</td><td>0</td><td>0</td><td>100%</td></tr></tbody></table><ul><li>Devign由于引入人工校验，所以不准确度相对低，但是其数据量也很小。</li><li>Big-Vul的主要问题是从commit中提取了不相关的code change，尤其是来自Chromium的commit，36%的entry都来自Chromium。</li><li>D2A所标注的commit大部分都不是真正的漏洞commit。</li></ul><p>除了对数据集的准确性评估，作者还评估了数据集独特性（存不存在重复样本）、一致性（存不存在标签冲突的样本）、完整性问题。</p>]]></content>
      
      
      <categories>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cross-domain vulnerability detection using graph embedding and domain adaptation</title>
      <link href="/2023/12/19/Papers/Vul/Cross-domain%20vulnerability%20detection%20using%20graph%20embedding%20and%20domain%20adaptation/"/>
      <url>/2023/12/19/Papers/Vul/Cross-domain%20vulnerability%20detection%20using%20graph%20embedding%20and%20domain%20adaptation/</url>
      
        <content type="html"><![CDATA[<p>a山东省计算机网络重点实验室，山东省计算机科学中心（济南国家超级计算机中心），齐鲁工业大学（山东科学院），济南250014，中国b北京邮电大学网络空间安全学院，北京100876，中国c公共大数据国家重点实验室，贵州大学计算机科学与技术学院，贵阳550025</p><h1 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h1><p>漏洞检测是维护网络空间安全的有效手段。机器学习方法由于其准确性和自动化的优势，在软件安全领域引起了人们的广泛关注。<strong>然而，目前的研究主要集中在训练数据和测试数据属于同一域的域内漏洞检测上。<strong>由于应用场景、编码习惯等因素，不同软件项目中的漏洞可能服从不同的概率分布。当机器学习方法应用于一个全新的项目时，这种差异会影响它们的性能。为了解决这个冷启动问题，我们</strong>提出了一个使用图嵌入和深度域自适应（VulGDA）的跨域漏洞检测框架。<strong>它以多种跨域方式工作，包括</strong>零样本方式</strong>，即目标域中没有标记数据可用于训练。将VulGDA分解为图嵌入和域自适应。在图嵌入阶段，我们将源代码中的样本转换为图表示，其中元素根据其语法和语义关系直接连接。然后，我们将来自图中定义的邻居和边的信息聚合为实值向量。通过图形嵌入，VulGDA提取了全面的漏洞特征，并解决了长期依赖性的挑战。针对训练数据和测试数据之间的差异，使用域自适应来训练特征生成器。该特征生成器将嵌入的图映射到一个“深层”特征，该特征对漏洞检测具有鉴别性，并且对域之间的移动保持不变。我们进行了一项系统实验来验证VulGDA的有效性。结果表明，将图嵌入和深域自适应相结合，提高了VulGDA在跨域漏洞检测中的性能。与最先进的方法相比，我们的方法在冷启动条件下具有更好的性能。</p><h1 id="1-contributions"><a class="markdownIt-Anchor" href="#1-contributions"></a> 1 Contributions</h1><p>主要问题就是目前的研究针对某一数据集或是某些特定的漏洞，没有在跨域问题上提出适当的解决方法；</p><ul><li><p>提出了一个结合了图嵌入和域自适应的跨域漏洞检测框架VulGDA，VulGDA以ZeroShot方式工作，这是跨域检测中最严格的方式。VulGDA通过将目标域中的监督信息添加到训练数据中，也适用于few-shot和域内方式。</p></li><li><p>提出了一种提取综合漏洞特征的图嵌入方法；减少噪声对漏洞特征的影响</p></li><li><p>提出了一种神经网络来学习特征生成器。该特征生成器通过减少分类损失和域差异来进行优化。最后，该特征生成器将学习到的源域中的漏洞模式传输到目标域。</p></li><li><p>实现了一个原型并进行了系统的实验。结果表明，图嵌入和域自适应的应用提高了VulGDA的性能。与现有方法相比，VulGDA在跨域漏洞检测方面取得了更好的性能。</p></li></ul><h1 id="2-method"><a class="markdownIt-Anchor" href="#2-method"></a> 2 Method</h1><p>VulGDA旨在检测现实世界软件中的漏洞。为了实用，本文考虑了最严格的条件。也就是说，应用在源域中训练的检测模型来检测目标域中的漏洞，并且该模型在训练期间无法从目标域获得任何监督信息（零样本）。这一假设使VulGDA具有良好的泛化能力，并易于应用于其他跨域检测情况，例如历史漏洞数据很少（很少发生）或丰富（Indomain）的项目。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191701536.png" alt="image-20231219170117488" /></p><p>问题定义：假设我们的检测架构可以访问源域中的标记数据集<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo><msubsup><mo stretchy="false">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo>∼</mo><mo stretchy="false">(</mo><msub><mi>D</mi><mi>s</mi></msub><msup><mo stretchy="false">)</mo><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">S=\{(x_{i},y_{i})\}_{i=1}^{n}\sim(D_{s})^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.008664em;vertical-align:-0.258664em;"></span><span class="mopen">{</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>  和目标域中的未标记数据集 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><msubsup><mo stretchy="false">}</mo><mrow><mi>i</mi><mo>=</mo><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mo>∼</mo><mo stretchy="false">(</mo><msubsup><mi>D</mi><mi>T</mi><mi>X</mi></msubsup><msup><mo stretchy="false">)</mo><mrow><mi>N</mi><mo>−</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">T=\{({x}_{i})\}_{i=n+1}^{N}\sim(D_{T}^{X})^{N-n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.158326em;vertical-align:-0.316995em;"></span><span class="mopen">{</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathdefault">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.316995em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1166619999999998em;vertical-align:-0.275331em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.424669em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">X</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.275331em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>是训练样本的总数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>D</mi><mi>T</mi><mi>X</mi></msubsup></mrow><annotation encoding="application/x-tex">D_T^X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1166619999999998em;vertical-align:-0.275331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.424669em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">X</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.275331em;"><span></span></span></span></span></span></span></span></span></span>是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">D_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span>上的边缘分布。</p><p>最终目标是建立一个预测<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>η</mi><mo>:</mo><mi>X</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">η:X→Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>：最小<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><msub><mi>D</mi><mi>T</mi></msub></msub><mo stretchy="false">(</mo><mi>η</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">*</mi><mo>⁡</mo><msub><mrow><mi>P</mi><mi>r</mi></mrow><mrow><mo stretchy="false">(</mo><mi>x</mi><mi>y</mi><mo stretchy="false">)</mo><mo>∼</mo><msub><mi>D</mi><mi>T</mi></msub></mrow></msub><mo stretchy="false">(</mo><mi>η</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">≠</mi><mi>y</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">R_{D_T}(η)=\operatorname*{Pr}_{(x y)\sim D_{T}}(\eta(x)\neq y),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.000305em;vertical-align:-0.250305em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.250305em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mop"><span class="mord mathrm">*</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span>，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">D_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中没有监督信息。</p><p><strong>VuLGDA有两个阶段组成：</strong></p><p><strong>图嵌入：</strong></p><p>图嵌入阶段的目的是将源代码中的漏洞样本转换为可由机器学习模型处理的实值向量。因此，通过句法和语义分析，图嵌入阶段首先将样本转换为CPG，即图结构中的中间表示。在CPG中，语法和语义相关的元素被直接连接在一起，这缓解了长期的依赖问题和域之间的分歧。然后，利用预训练的单词嵌入生成标记嵌入和节点嵌入。最后，我们使用GGNN通过传播和聚合来自CPG中定义的邻居的信息来获得嵌入向量。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191747401.png" alt="image-20231219174742348" /></p><p><strong>域自适应：</strong></p><p>域自适应阶段旨在学习在域之间转换分布的特征生成器。提出了一种由特征生成器、分类器和瓶颈组成的神经网络来学习该特征生成器。将源域中的特征作为输入的分类器产生分类损失。瓶颈度量源域和目标域中的特征之间的差异。通过最小化分类损失和领域差异来优化特征生成器。检测结果由生成的“深层”特征训练的分类器报告。经过上述阶段后，VulGDA可以在目标域中检测跨域漏洞，而无需标记数据。</p><p>本文的创新点主要在于领域自适应：</p><p>传统的机器学习方法假设训练数据和测试数据服从相同的特征分布。然而，由于编程风格和应用场景的不同，不同领域的漏洞特征可能服从不同的分布，从而影响模型的检测性能。在本节中，使用来自源域和目标域的数据，我们构建了一个特征生成器G f:XG→XF。G f将嵌入XG的图转换为“深度”特征向量XF，该向量对漏洞检测具有判别性，并且随着域之间的移动而不变。因此，目标函数定义为：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>f</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><mi mathvariant="normal">*</mi><mo>⁡</mo><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mfrac><mn>1</mn><mi>B</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>λ</mi><mi>R</mi><mo stretchy="false">(</mo><msub><mi>B</mi><mi>S</mi></msub><mo separator="true">,</mo><msub><mi>B</mi><mi>T</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f^{*}=\arg\operatorname*{min}\frac{1}{B}\sum_{i=1}^{B}\ell(f(x_{i}),y_{i})+\lambda R(B_{S},B_{T})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.933136em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mord mathrm">*</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">λ</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>其中B表示批次大小，（f（xi），yi）表示分类损失，BS和BT分别在源域和目标域中为2个批次，R（∗，∗）测量域差异。λ用于调整分类损失和域差异的权重。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312192225166.png" alt="image-20231219222546132" /></p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Conv2d</title>
      <link href="/2023/12/19/AILearning/pytorch/conv2d/"/>
      <url>/2023/12/19/AILearning/pytorch/conv2d/</url>
      
        <content type="html"><![CDATA[<h4 id="1-用法"><a class="markdownIt-Anchor" href="#1-用法"></a> 1 用法</h4><ul><li>Conv2d(in_channels, out_channels, kernel_size, stride=1,padding=0, dilation=1, groups=1,bias=True, padding_mode=‘zeros’)</li></ul><h4 id="2-参数"><a class="markdownIt-Anchor" href="#2-参数"></a> 2 参数</h4><ul><li><p>in_channels：输入的通道数目 【必选】</p></li><li><p>out_channels： 输出的通道数目 【必选】</p></li><li><p>kernel_size：卷积核的大小，类型为int 或者元组，当卷积是方形的时候，只需要一个整数边长即可，卷积不是方形，要输入一个元组表示 高和宽。【必选】</p></li><li><p>stride： 卷积每次滑动的步长为多少，默认是 1 【可选】</p></li><li><p>padding： 设置在所有边界增加 值为 0 的边距的大小（也就是在feature map 外围增加几圈 0 ），例如当 padding =1 的时候，如果原来大小为 3 × 3 ，那么之后的大小为 5 × 5 。即在外围加了一圈 0 。【可选】</p></li><li><p>dilation：控制卷积核之间的间距（什么玩意？请看例子）【可选】</p></li><li><p>groups：控制输入和输出之间的连接。（不常用）【可选】</p><p>举例来说：<br />比如 groups 为1，那么所有的输入都会连接到所有输出<br />当 groups 为 2的时候，相当于将输入分为两组，并排放置两层，每层看到一半的输入通道并产生一半的输出通道，并且两者都是串联在一起的。这也是参数字面的意思：“组” 的含义。<br />需要注意的是，in_channels 和 out_channels 必须都可以整除 groups，否则会报错（因为要分成这么多组啊，除不开你让人家程序怎么办？）</p></li><li><p>bias： 是否将一个 学习到的 bias 增加输出中，默认是 True 。【可选】</p></li><li><p>padding_mode ： 字符串类型，接收的字符串只有 “zeros” 和 “circular”。【可选】</p></li></ul><h4 id="3-相关形状"><a class="markdownIt-Anchor" href="#3-相关形状"></a> 3 相关形状</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191632440.png" alt="image-20231219163239412" /></p>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch入门</title>
      <link href="/2023/12/19/AILearning/pytorch/pytorch/"/>
      <url>/2023/12/19/AILearning/pytorch/pytorch/</url>
      
        <content type="html"><![CDATA[<h1 id="1torchnn简介"><a class="markdownIt-Anchor" href="#1torchnn简介"></a> 1.torch.nn简介</h1><p>1.1torch.nn相关库的导入</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#环境准备</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np              <span class="comment"># numpy数组库</span></span><br><span class="line"><span class="keyword">import</span> math                     <span class="comment"># 数学运算库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 画图库</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> torch             <span class="comment"># torch基础库</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn    <span class="comment"># torch神经网络库</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure><h3 id="12-torchnn概述"><a class="markdownIt-Anchor" href="#12-torchnn概述"></a> 1.2 torch.nn概述</h3><blockquote><p>Pytorch提供了几个设计得非常棒的模块和类，比如 torch.nn，torch.optim，Dataset 以及 DataLoader，来帮助程序员设计和训练神经网络。</p></blockquote><p>nn是Neural Network的简称，帮助程序员方便执行如下的与神经网络相关的行为：</p><ul><li><p>创建神经网络</p></li><li><p>训练神经网络</p></li><li><p>保存神经网络</p></li><li><p>恢复神经网络</p></li></ul><p>包括五大基本功能模块</p><ul><li>torch.nn是专门为神经网络设计的模块化接口</li><li>nn构建于autograd之上，可以用来定义和运行神经网络<ul><li>nn.Parameter</li><li>nn.Linear</li><li>nn.functional</li><li>nn.Module</li><li>nn.Sequential</li></ul></li></ul><h1 id="2nnlinear类全连接层"><a class="markdownIt-Anchor" href="#2nnlinear类全连接层"></a> 2.nn.Linear类（全连接层）</h1><h3 id="21函数功能"><a class="markdownIt-Anchor" href="#21函数功能"></a> 2.1函数功能</h3><p>用于创建一个多输入、多输出的全连接层。</p><p>nn.Linear本身并不包含激活函数（Functional）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635002.png" alt="image-20231219163552911" /></p><h3 id="22函数说明"><a class="markdownIt-Anchor" href="#22函数说明"></a> 2.2函数说明</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629041.png" alt="image-20211203155643310" /></p><ul><li>in_featrues：<ul><li>指输入的二维张量的大小，即输入的[batch_size, size]中的size</li><li>in_features的数量，决定的参数的个数Y=WX+b，X的维度就是in_features，X的维度决定W的维度，总参数的个数 = in_features + 1</li></ul></li><li>out_featrues<ul><li>指的是输出的二维张量的大小，<mark>即输出的二维张量的形状为[batch_size output_size].</mark></li><li>out_features的数量，决定了全连接层中神经元的个数，因为每个神经元只有一个输出。<strong>多少个输出，就需要多少个神经元</strong>。</li><li><mark>从输入输出的张量的shape角度来理解，相当于一个输入为[batch_size, in_features]的张量变换成了[batch_size, out_features]的输出张量。</mark></li></ul></li></ul><h3 id="23多个全连接层构建全连接网络"><a class="markdownIt-Anchor" href="#23多个全连接层构建全连接网络"></a> 2.3多个全连接层构建全连接网络</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629046.png" alt="image-20211203160715687" /></p><ul><li>使用nn.Linear类创建全连接层</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nn.Linear</span></span><br><span class="line"><span class="comment"># 建立单层的多输入、多输出全连接层</span></span><br><span class="line"><span class="comment"># in_features由输入张量的形状决定，out_features则决定了输出张量的形状 </span></span><br><span class="line">full_connect_layer = nn.Linear(in_features = <span class="number">28</span> * <span class="number">28</span> * <span class="number">1</span>, out_features = <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;full_connect_layer:&quot;</span>, full_connect_layer)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;parameters        :&quot;</span>, full_connect_layer.parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假定输入的图像形状为[28,28,1]</span></span><br><span class="line">x_input = torch.randn(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将四维张量转换为二维张量之后，才能作为全连接层的输入</span></span><br><span class="line">x_input = x_input.view(<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span> * <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_input.shape:&quot;</span>, x_input.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用全连接层</span></span><br><span class="line">y_output = full_connect_layer(x_input) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_output.shape:&quot;</span>, y_output.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_output:&quot;</span>, y_output)</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629071.png" alt="image-20211203163313390" /></p><h2 id="3-nnfunctional常见函数"><a class="markdownIt-Anchor" href="#3-nnfunctional常见函数"></a> 3 nn.functional（常见函数）</h2><h3 id="31-nnfunctional概述"><a class="markdownIt-Anchor" href="#31-nnfunctional概述"></a> 3.1 nn.functional概述</h3><blockquote><p>nn.functional定义了创建神经网络所需要的一些常见的处理函数。如没有激活函数的神经元，各种激活函数等。</p></blockquote><ul><li>包含torch.nn库中所有函数，包含大量loss和activation function<ul><li>torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)</li><li>nn.functional.xxx是函数接口</li><li>nn.functional.xxx无法与nn.Sequential结合使用</li><li>没有学习参数的(eg. maxpool, loss_ func, activation func)<a href="http://xn--nn-gy2c4vz4a856fs0ap4ztl4ad2mv07c.functional.xn--xxxnn-zm6j.Xxx">等根据个人选择使用nn.functional.xxx或nn.Xxx</a></li><li>需要特别注意dropout层</li></ul></li></ul><h3 id="32-nnfunctional函数分类"><a class="markdownIt-Anchor" href="#32-nnfunctional函数分类"></a> 3.2 nn.functional函数分类</h3><p>nn.functional包括神经网络前向和后向处理所需要到的常见函数</p><ul><li>神经元处理函数</li><li>激活函数</li></ul><h3 id="33-激活函数案例"><a class="markdownIt-Anchor" href="#33-激活函数案例"></a> 3.3 激活函数案例</h3><ul><li>relu案例</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nn.functional.relu( )</span></span><br><span class="line"><span class="built_in">print</span>(y_output)</span><br><span class="line">out = nn.functional.relu(y_output)</span><br><span class="line"><span class="built_in">print</span>(out.shape)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br></pre></td></tr></table></figure><h2 id="4-nnxxx和nnfunctionalxxx比较"><a class="markdownIt-Anchor" href="#4-nnxxx和nnfunctionalxxx比较"></a> 4 nn.xxx和nn.functional.xxx比较</h2><h3 id="41-相同点"><a class="markdownIt-Anchor" href="#41-相同点"></a> 4.1 相同点</h3><ul><li><code>nn.Xxx</code>和<code>nn.functional.xxx</code>的实际功能是相同的，即<code>nn.Conv2d</code>和<code>nn.functional.conv2d</code> 都是进行卷积，<code>nn.Dropout</code> 和<code>nn.functional.dropout</code>都是进行dropout，。。。。。；</li><li>运行效率也是近乎相同。</li></ul><h3 id="42-不同点"><a class="markdownIt-Anchor" href="#42-不同点"></a> 4.2 不同点</h3><ul><li><code>nn.functional.xxx</code>是API函数接口，而<code>nn.Xxx</code>是对原始API函数<code>nn.functional.xxx</code>的类封装。</li><li>所有<code>nn.Xxx</code>都继承于于共同祖先<code>nn.Module</code>。这一点导致<code>nn.Xxx</code>除了具有<code>nn.functional.xxx</code>功能之外，内部附带了<code>nn.Module</code>相关的属性和方法，例如<code>train(), eval(),load_state_dict, state_dict</code> 等。</li><li><code>nn.Xxx</code>继承于<code>nn.Module</code>， 能够很好的与<code>nn.Sequential</code>结合使用， 而<code>nn.functional.xxx</code>无法与<code>nn.Sequential</code>结合使用。</li><li><code>nn.Xxx</code> 需要先实例化并传入参数，然后以函数调用的方式调用实例化的对象并传入输入数据。<code>nn.functional.xxx</code>同时传入输入数据和<code>weight, bias</code>等其他参数 。</li><li><code>nn.Xxx</code>不需要你自己定义和管理weight；而<code>nn.functional.xxx</code>需要你自己定义weight，每次调用的时候都需要手动传入weight, 不利于代码复用。</li></ul><h2 id="5-nnparameter类"><a class="markdownIt-Anchor" href="#5-nnparameter类"></a> 5 nn.Parameter类</h2><h3 id="51-nnparameter概述"><a class="markdownIt-Anchor" href="#51-nnparameter概述"></a> 5.1 nn.Parameter概述</h3><blockquote><p>Parameter实际上也是tensor，也就是说是一个多维矩阵，是Variable类的一个特殊类。</p><p>当我们创建一个model时，nn会自动创建相应的参数parameter，并会自动累加到模型的Parameter 成员列表中。</p></blockquote><h3 id="52-单个全连接层中参数的个数"><a class="markdownIt-Anchor" href="#52-单个全连接层中参数的个数"></a> 5.2 单个全连接层中参数的个数</h3><p>in_features的数量，决定的参数的个数   Y = WX + b,  X的维度就是in_features，X的维度决定的W的维度， 总的参数个数 = in_features + 1</p><p>out_features的数量，决定了全连接层中神经元的个数，因为每个神经元只有一个输出。</p><p>多少个输出，就需要多少个神经元。</p><p>总的W参数的个数=  in_features * out_features</p><p>总的b参数的个数=  1 * out_features</p><p>总的参数（W和B）的个数=  (in_features + 1) * out_features</p><h3 id="53-使用参数创建全连接层"><a class="markdownIt-Anchor" href="#53-使用参数创建全连接层"></a> 5.3 使用参数创建全连接层</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nn.functional.linear( )</span></span><br><span class="line">x_input = torch.Tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_input.shape:&quot;</span>, x_input.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_input      :&quot;</span>, x_input)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line">Weights1 = nn.Parameter(torch.rand(<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights.shape:&quot;</span>, Weights1.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights      :&quot;</span>, Weights1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line">Bias1 = nn.Parameter(torch.rand(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Bias.shape:&quot;</span>, Bias1.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Bias      :&quot;</span>, Bias1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line">Weights2 = nn.Parameter(torch.Tensor(<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights.shape:&quot;</span>, Weights2.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights      :&quot;</span>, Weights2)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nfull_connect_layer&quot;</span>)</span><br><span class="line">full_connect_layer = nn.functional.linear(x_input, Weights1)</span><br><span class="line"><span class="built_in">print</span>(full_connect_layer)</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629076.png" alt="image-20211203165921227" /></p><h2 id="6-nnmodule类"><a class="markdownIt-Anchor" href="#6-nnmodule类"></a> 6 nn.Module类</h2><ul><li>抽象概念，既可以表示神经网络中的某个层layer，也可以表示一个包含很多层的神经网络</li><li>modle.parameters()</li><li>modle.buffers()</li><li>modle.state_dict()</li><li>modle.modules()</li><li>forward(),to()</li></ul><h2 id="7-利用nnsequential类创建神经网络继承与nnmodule类"><a class="markdownIt-Anchor" href="#7-利用nnsequential类创建神经网络继承与nnmodule类"></a> 7 利用nn.Sequential类创建神经网络（继承与nn.Module类）</h2><blockquote><p>nn.Sequential是一个有序的容器，该类将按照传入构造器的顺序，依次创建相应的函数，并记录在Sequential类对象的数据结构中，同时以神经网络模块为元素的有序字典也可以作为传入参数。</p><p>因此，Sequential可以看成是有多个函数运算对象，串联成的神经网络，其返回的是Module类型的神经网络对象。</p></blockquote><h2 id="8自定义神经网络模型类继承于module类"><a class="markdownIt-Anchor" href="#8自定义神经网络模型类继承于module类"></a> 8.自定义神经网络模型类（继承于Module类）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义网络模型：带relu的两层全连接神经网络</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自定义新的神经网络模型的类&quot;</span>)</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NetC</span>(torch.nn.Module):</span><br><span class="line">    <span class="comment"># 定义神经网络</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_feature, n_hidden, n_output</span>):</span><br><span class="line">        <span class="built_in">super</span>(NetC, self).__init__()</span><br><span class="line">        self.h1 = nn.Linear(n_feature, n_hidden)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.out = nn.Linear(n_hidden, n_output)</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#定义前向运算</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 得到的数据格式torch.Size([64, 1, 28, 28])需要转变为（64,784）</span></span><br><span class="line">        x = x.view(x.size()[<span class="number">0</span>],-<span class="number">1</span>) <span class="comment"># -1表示自动匹配</span></span><br><span class="line">        h1 = self.h1(x)</span><br><span class="line">        a1 =  self.relu1(h1)</span><br><span class="line">        out = self.out(a1)</span><br><span class="line">        a_out = self.softmax(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n实例化神经网络模型对象&quot;</span>)</span><br><span class="line">model = NetC(<span class="number">28</span>*<span class="number">28</span>, <span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n显示网络模型参数&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model.parameters)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n定义神经网络样本输入&quot;</span>)</span><br><span class="line">x_input = torch.randn(<span class="number">2</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x_input.shape)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n使用神经网络进行预测&quot;</span>)</span><br><span class="line">y_pred = model.forward(x_input)</span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>torch tensor操作</title>
      <link href="/2023/12/19/AILearning/pytorch/tensor%E6%93%8D%E4%BD%9C/"/>
      <url>/2023/12/19/AILearning/pytorch/tensor%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="一-张量的基本操作"><a class="markdownIt-Anchor" href="#一-张量的基本操作"></a> 一、张量的基本操作</h1><p>Pytorch 中，张量的操作分为<strong>结构操作和数学运算</strong>，其理解就如字面意思。结构操作就是改变张量本身的结构，数学运算就是对张量的元素值完成数学运算。</p><ul><li>常使用的张量结构操作：维度变换（tranpose、view 等）、合并分割（split、chunk等）、索引切片（index_select、gather 等）。</li><li>常使用的张量数学运算：标量运算、向量运算、矩阵运算。</li></ul><h1 id="二-维度变换"><a class="markdownIt-Anchor" href="#二-维度变换"></a> 二、维度变换</h1><h2 id="21-squeeze-vs-unsqueeze-维度增减"><a class="markdownIt-Anchor" href="#21-squeeze-vs-unsqueeze-维度增减"></a> <strong>2.1 squeeze vs unsqueeze 维度增减</strong></h2><ul><li><strong>squeeze()</strong>：对 tensor 进行维度的压缩，去掉维数为 1 的维度。用法：torch.squeeze(a) 将 a 中所有为 1 的维度都删除，或者 a.squeeze(1) 是去掉 a中指定的维数为 1 的维度。</li><li><strong>unsqueeze()</strong>：对数据维度进行扩充，给指定位置加上维数为 1 的维度。用法：torch.unsqueeze(a, N)，或者 a.unsqueeze(N)，在 a 中指定位置 N 加上一个维数为 1 的维度。</li></ul><p>squeeze 用例程序如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.squeeze(a)</span><br><span class="line">c = a.squeeze(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(b.shape)</span><br><span class="line"><span class="built_in">print</span>(c.shape)</span><br></pre></td></tr></table></figure><p>程序输出结果如下：</p><blockquote><p>torch.Size([3, 3]) torch.Size([1, 3, 3])</p></blockquote><p>unsqueeze 用例程序如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.rand(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">y1 = torch.unsqueeze(x, <span class="number">0</span>)</span><br><span class="line">y2 = x.unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(y1.shape)</span><br><span class="line"><span class="built_in">print</span>(y2.shape)</span><br></pre></td></tr></table></figure><p>程序输出结果如下：</p><blockquote><p>torch.Size([1, 3, 3]) torch.Size([1, 3, 3])</p></blockquote><h2 id="22-transpose-vs-permute-维度交换"><a class="markdownIt-Anchor" href="#22-transpose-vs-permute-维度交换"></a> <strong>2.2 transpose vs permute 维度交换</strong></h2><p>torch.transpose() 只能交换两个维度，而 .permute() 可以自由交换任意位置。函数定义如下：</p><ul><li>transpose(dim0, dim1) → Tensor # See torch.transpose()</li><li>permute(*dims) → Tensor # dim(int). Returns a view of the original tensor with its dimensions permuted.</li></ul><p>在 CNN 模型中，我们经常遇到交换维度的问题，举例：四个维度表示的 tensor：[batch, channel, h, w]（nchw），如果想把 channel 放到最后去，形成[batch, h, w, channel]（nhwc），如果使用 torch.transpose() 方法，至少要交换两次（先 1 3 交换再 1 2 交换），而使用 .permute() 方法只需一次操作，更加方便。例子程序如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">b = torch.rand(<span class="number">1</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">32</span>)</span><br><span class="line"><span class="comment"># torch.Size([1, 3, 28, 32]</span></span><br><span class="line"><span class="built_in">print</span>(b.transpose(<span class="number">1</span>, <span class="number">3</span>).shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 32, 28, 3])</span></span><br><span class="line"><span class="built_in">print</span>(b.transpose(<span class="number">1</span>, <span class="number">3</span>).transpose(<span class="number">1</span>, <span class="number">2</span>).shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 28, 32, 3])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(b.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 28, 32, 3]</span></span><br></pre></td></tr></table></figure><h2 id="23-reshape-vs-view"><a class="markdownIt-Anchor" href="#23-reshape-vs-view"></a> <strong>2.3 reshape vs view</strong></h2><blockquote><p>view只适合对满足连续性条件（contiguous）的tensor进行操作，而reshape同时还可以对不满足连续性条件的tensor进行操作，具有更好的鲁棒性。view能干的reshape都能干，如果view不能干就可以用reshape来处理。更多可看[1]</p></blockquote><h2 id="24-einsum"><a class="markdownIt-Anchor" href="#24-einsum"></a> <strong>2.4 einsum</strong></h2><p>首先看下 einsum 实现矩阵乘法的例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 语义解析：</span></span><br><span class="line"><span class="comment"># 输入a：2阶张量，下标为ik</span></span><br><span class="line"><span class="comment"># 输入b: 2阶张量，下标为kj</span></span><br><span class="line"><span class="comment"># 输出o: 2阶张量，下标为i和j</span></span><br><span class="line">c = torch.einsum(<span class="string">&quot;ik,kj-&gt;ij&quot;</span>, [a, b])</span><br><span class="line"><span class="comment"># 等价操作 torch.mm(a, b)</span></span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="number">60.</span>).reshape(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">b = np.arange(<span class="number">24.</span>).reshape(<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 语义解析：</span></span><br><span class="line"><span class="comment"># 输入a：3阶张量，下标为ijk</span></span><br><span class="line"><span class="comment"># 输入b: 3阶张量，下标为jil</span></span><br><span class="line"><span class="comment"># 输出o: 2阶张量，下标为k和l</span></span><br><span class="line">c = np.einsum(<span class="string">&#x27;ijk,jil-&gt;kl&#x27;</span>, a, b)</span><br></pre></td></tr></table></figure><p>这个方法可以实现矩阵乘法，但是也可以用来更换维度</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 语义解析:</span></span><br><span class="line"><span class="comment"># 当后面只有一个张量时，就是对自己维度进行变换</span></span><br><span class="line"><span class="comment"># 比较常用的就是将chanel换到最后</span></span><br><span class="line">x = torch.einsum(<span class="string">&#x27;nchw-&gt;nhwc&#x27;</span>, x)</span><br></pre></td></tr></table></figure><blockquote><p>更多可看[2]</p></blockquote><h1 id="三-索引切片"><a class="markdownIt-Anchor" href="#三-索引切片"></a> 三、索引切片</h1><h2 id="31-规则索引切片方式"><a class="markdownIt-Anchor" href="#31-规则索引切片方式"></a> <strong>3.1 规则索引切片方式</strong></h2><p>张量的索引切片方式和 numpy、python 多维列表几乎一致，都可以通过索引和切片对部分元素进行修改。切片时支持缺省参数和省略号。实例代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.randint(<span class="number">1</span>,<span class="number">10</span>,[<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t</span><br><span class="line">tensor([[<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">5</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">9</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>] <span class="comment"># 第 1 行数据</span></span><br><span class="line">tensor([<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">2</span>][<span class="number">2</span>]</span><br><span class="line">tensor(<span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>:<span class="number">3</span>,:]  <span class="comment"># 第1至第3行，全部列</span></span><br><span class="line">tensor([[<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">5</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">9</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>:<span class="number">2</span>,:]  <span class="comment"># 第1行至第2行</span></span><br><span class="line">tensor([[<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">5</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">1</span>:,-<span class="number">1</span>]  <span class="comment"># 第2行至最后行，最后一列</span></span><br><span class="line">tensor([<span class="number">9</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">1</span>:,::<span class="number">2</span>] <span class="comment"># 第1行至最后行，第0列到最后一列每隔两列取一列</span></span><br><span class="line">tensor([[<span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">9</span>]])</span><br></pre></td></tr></table></figure><p>以上切片方式相对规则，对于不规则的切片提取,可以使用 torch.index_select, torch.take, torch.gather, torch.masked_select。</p><h2 id="32-gather-和-torchindex_select-算子"><a class="markdownIt-Anchor" href="#32-gather-和-torchindex_select-算子"></a> <strong>3.2 gather 和 torch.index_select 算子</strong></h2><blockquote><p>gather 算子的用法比较难以理解，在翻阅了官方文档和网上资料后，我有了一些自己的理解。</p></blockquote><p>1，gather 是不规则的切片提取算子（Gathers values along an axis specified by dim. 在指定维度上根据索引 index 来选取数据）。函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.gather(<span class="built_in">input</span>, dim, index, *, sparse_grad=<span class="literal">False</span>, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p><strong>参数解释：</strong></p><ul><li>input (Tensor) – the source tensor.</li><li>dim (int) – the axis along which to index.</li><li>index (LongTensor) – the indices of elements to gather.</li></ul><p>对于 3D tensor，output 值的定义如下： gather 的官方定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out[i][j][k] = <span class="built_in">input</span>[index[i][j][k]][j][k]  <span class="comment"># if dim == 0</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][index[i][j][k]][k]  <span class="comment"># if dim == 1</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][j][index[i][j][k]]   <span class="comment"># if dim == 2</span></span><br></pre></td></tr></table></figure><p>下面结合 2D 和 3D tensor 的用例来直观理解算子用法。<br />（1）对于 2D tensor 的例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">0</span>, <span class="number">16</span>).view(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">        [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">        [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]])  <span class="comment"># 选取对角线元素</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.gather(a, <span class="number">0</span>, index)</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>]])</span><br></pre></td></tr></table></figure><p>output 值定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 按照 index = tensor([[0, 1, 2, 3]])顺序作用在行上索引依次为0,1,2,3</span></span><br><span class="line">a[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">a[<span class="number">1</span>][<span class="number">1</span>] = <span class="number">5</span></span><br><span class="line">a[<span class="number">2</span>][<span class="number">2</span>] = <span class="number">10</span></span><br><span class="line">a[<span class="number">3</span>][<span class="number">3</span>] = <span class="number">15</span></span><br></pre></td></tr></table></figure><p>（2）索引更复杂的 2D tensor 例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.gather(t, <span class="number">1</span>, torch.tensor([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>]]))</span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">3</span>]])</span><br></pre></td></tr></table></figure><p>output 值的计算如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">output[i][j] = <span class="built_in">input</span>[i][index[i][j]]  <span class="comment"># if dim = 1</span></span><br><span class="line">output[<span class="number">0</span>][<span class="number">0</span>] = <span class="built_in">input</span>[<span class="number">0</span>][index[<span class="number">0</span>][<span class="number">0</span>]] = <span class="built_in">input</span>[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">output[<span class="number">0</span>][<span class="number">1</span>] = <span class="built_in">input</span>[<span class="number">0</span>][index[<span class="number">0</span>][<span class="number">1</span>]] = <span class="built_in">input</span>[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">output[<span class="number">1</span>][<span class="number">0</span>] = <span class="built_in">input</span>[<span class="number">1</span>][index[<span class="number">1</span>][<span class="number">0</span>]] = <span class="built_in">input</span>[<span class="number">1</span>][<span class="number">1</span>] = <span class="number">4</span></span><br><span class="line">output[<span class="number">1</span>][<span class="number">1</span>] = <span class="built_in">input</span>[<span class="number">1</span>][index[<span class="number">1</span>][<span class="number">1</span>]] = <span class="built_in">input</span>[<span class="number">1</span>][<span class="number">0</span>] = <span class="number">3</span></span><br></pre></td></tr></table></figure><p>总结：<strong>可以看到 gather 是通过将索引在指定维度 dim 上的值替换为 index 的值，但是其他维度索引不变的情况下获取 tensor 数据</strong>。直观上可以理解为对矩阵进行重排，比如对每一行(dim=1)的元素进行变换，比如 torch.gather(a, 1, torch.tensor([[1,2,0], [1,2,0]])) 的作用就是对 矩阵 a 每一行的元素，进行 permtute(1,2,0) 操作。</p><p>2，理解了 gather 再看 index_select 就很简单，函数作用是返回沿着输入张量的指定维度的指定索引号进行索引的张量子集。函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.index_select(<span class="built_in">input</span>, dim, index, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p>函数返回一个新的张量，它使用数据类型为 LongTensor 的 index 中的条目沿维度 dim 索引输入张量。返回的张量具有与原始张量（输入）相同的维数。 维度尺寸与索引长度相同； 其他尺寸与原始张量中的尺寸相同。实例代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">        [-<span class="number">0.4664</span>,  <span class="number">0.2647</span>, -<span class="number">0.1228</span>, -<span class="number">1.1068</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>indices = torch.tensor([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">0</span>, indices)</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">1</span>, indices)</span><br><span class="line">tensor([[ <span class="number">0.1427</span>, -<span class="number">0.5414</span>],</span><br><span class="line">        [-<span class="number">0.4664</span>, -<span class="number">0.1228</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>,  <span class="number">0.7230</span>]])</span><br></pre></td></tr></table></figure><h1 id="四-合并分割"><a class="markdownIt-Anchor" href="#四-合并分割"></a> 四、合并分割</h1><h2 id="41-torchcat-和-torchstack"><a class="markdownIt-Anchor" href="#41-torchcat-和-torchstack"></a> <strong>4.1 torch.cat 和 torch.stack</strong></h2><p>可以用 torch.cat 方法和 torch.stack 方法将多个张量合并，也可以用 torch.split方法把一个张量分割成多个张量。torch.cat 和 torch.stack 有略微的区别，torch.cat 是连接，不会增加维度，而 torch.stack 是堆叠，会增加一个维度。两者函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.</span></span><br><span class="line">torch.cat(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br><span class="line"><span class="comment"># Concatenates a sequence of tensors along **a new** dimension. All tensors need to be of the same size.</span></span><br><span class="line">torch.stack(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p>torch.cat 和 torch.stack 用法实例代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">0</span>,<span class="number">9</span>).view(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.arange(<span class="number">10</span>,<span class="number">19</span>).view(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = torch.arange(<span class="number">20</span>,<span class="number">29</span>).view(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cat_abc = torch.cat([a,b,c], dim=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(cat_abc.shape)</span><br><span class="line">torch.Size([<span class="number">9</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(cat_abc)</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">        [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line">        [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">        [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">        [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>],</span><br><span class="line">        [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">        [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>stack_abc = torch.stack([a,b,c], axis=<span class="number">0</span>)  <span class="comment"># torch中dim和axis参数名可以混用</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(stack_abc.shape)</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(stack_abc)</span><br><span class="line">tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">         [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">         [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>],</span><br><span class="line">         [<span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">         [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>chunk_abc = torch.chunk(cat_abc, <span class="number">3</span>, dim=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>chunk_abc</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">         [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">         [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]]),</span><br><span class="line"> tensor([[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>]]),</span><br><span class="line"> tensor([[<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>],</span><br><span class="line">         [<span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">         [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]]))</span><br></pre></td></tr></table></figure><h2 id="42-torchsplit-和-torchchunk"><a class="markdownIt-Anchor" href="#42-torchsplit-和-torchchunk"></a> <strong>4.2 torch.split 和 torch.chunk</strong></h2><p>torch.split() 和 torch.chunk() 可以看作是 torch.cat() 的逆运算。split() 作用是将张量拆分为多个块，每个块都是原始张量的视图。split() 函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Splits the tensor into chunks. Each chunk is a view of the original tensor.</span></span><br><span class="line"><span class="string">If split_size_or_sections is an integer type, then tensor will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by split_size.</span></span><br><span class="line"><span class="string">If split_size_or_sections is a list, then tensor will be split into len(split_size_or_sections) chunks with sizes in dim according to split_size_or_sections.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">torch.split(tensor, split_size_or_sections, dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>chunk() 作用是将 tensor 按 dim（行或列）分割成 chunks 个 tensor 块，返回的是一个元组。chunk() 函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.chunk(<span class="built_in">input</span>, chunks, dim=<span class="number">0</span>) → <span class="type">List</span> of Tensors</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Splits a tensor into a specific number of chunks. Each chunk is a view of the input tensor.</span></span><br><span class="line"><span class="string">Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by chunks.</span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    input (Tensor) – the tensor to split</span></span><br><span class="line"><span class="string">    chunks (int) – number of chunks to return</span></span><br><span class="line"><span class="string">    dim (int) – dimension along which to split the tensor</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>实例代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">10</span>).reshape(<span class="number">5</span>,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">        [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">        [<span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.split(a, <span class="number">2</span>)</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">3</span>]]),</span><br><span class="line"> tensor([[<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">          [<span class="number">6</span>, <span class="number">7</span>]]),</span><br><span class="line"> tensor([[<span class="number">8</span>, <span class="number">9</span>]]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.split(a, [<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>]]),</span><br><span class="line"> tensor([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">         [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">         [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">         [<span class="number">8</span>, <span class="number">9</span>]]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.chunk(a, <span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">(tensor([[<span class="number">0</span>],</span><br><span class="line">        [<span class="number">2</span>],</span><br><span class="line">        [<span class="number">4</span>],</span><br><span class="line">        [<span class="number">6</span>],</span><br><span class="line">        [<span class="number">8</span>]]), </span><br><span class="line">tensor([[<span class="number">1</span>],</span><br><span class="line">        [<span class="number">3</span>],</span><br><span class="line">        [<span class="number">5</span>],</span><br><span class="line">        [<span class="number">7</span>],</span><br><span class="line">        [<span class="number">9</span>]]))</span><br></pre></td></tr></table></figure><h1 id="五-卷积相关算子"><a class="markdownIt-Anchor" href="#五-卷积相关算子"></a> 五、卷积相关算子</h1><h2 id="51-上采样方法总结"><a class="markdownIt-Anchor" href="#51-上采样方法总结"></a> <strong>5.1 上采样方法总结</strong></h2><p>上采样大致被总结成了三个类别：</p><ol><li>基于线性插值的上采样：最近邻算法（nearest）、双线性插值算法（bilinear）、双三次插值算法（bicubic）等，这是传统图像处理方法。</li><li>基于深度学习的上采样（转置卷积，也叫反卷积 Conv2dTranspose2d等）</li><li>Unpooling 的方法（简单的补零或者扩充操作）<br />计算效果：最近邻插值算法 &lt; 双线性插值 &lt; 双三次插值。计算速度：最近邻插值算法 &gt; 双线性插值 &gt; 双三次插值。</li></ol><h2 id="52-finterpolate-采样函数"><a class="markdownIt-Anchor" href="#52-finterpolate-采样函数"></a> <strong>5.2 F.interpolate 采样函数</strong></h2><blockquote><p>Pytorch 老版本有 nn.Upsample 函数，新版本建议用 torch.nn.functional.interpolate，一个函数可实现定制化需求的上采样或者下采样功能，。</p></blockquote><p>F.interpolate() 函数全称是 torch.nn.functional.interpolate()，函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">interpolate</span>(<span class="params"><span class="built_in">input</span>, size=<span class="literal">None</span>, scale_factor=<span class="literal">None</span>, mode=<span class="string">&#x27;nearest&#x27;</span>, align_corners=<span class="literal">None</span>, recompute_scale_factor=<span class="literal">None</span></span>):  <span class="comment"># noqa: F811</span></span><br><span class="line">    <span class="comment"># type: (Tensor, <span class="type">Optional</span>[<span class="built_in">int</span>], <span class="type">Optional</span>[<span class="type">List</span>[<span class="built_in">float</span>]], <span class="built_in">str</span>, <span class="type">Optional</span>[<span class="built_in">bool</span>], <span class="type">Optional</span>[<span class="built_in">bool</span>]) -&gt; Tensor</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>参数解释如下：</p><ul><li>input(Tensor)：输入张量数据；</li><li>size： 输出的尺寸，数据类型为 tuple： ([optional D_out], [optional H_out], W_out)，和 scale_factor 二选一；</li><li>scale_factor：在高度、宽度和深度上面的放大倍数。数据类型既可以是 int——表明高度、宽度、深度都扩大同一倍数；也可是tuple——指定高度、宽度、深度等维度的扩大倍数；</li><li>mode： 上采样的方法，包括最近邻（nearest），线性插值（linear），双线性插值（bilinear），三次线性插值（trilinear），默认是最近邻（nearest）；</li><li>align_corners： 如果设为True，输入图像和输出图像角点的像素将会被对齐（aligned），这只在mode = linear, bilinear, or trilinear才有效，默认为False。</li></ul><p>例子程序如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x = torch.rand(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">y = F.interpolate(x * <span class="number">2</span>, scale_factor=(<span class="number">2</span>, <span class="number">2</span>), mode=<span class="string">&#x27;bilinear&#x27;</span>).squeeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(y.shape)   <span class="comment"># torch.Size([3, 224, 224])</span></span><br></pre></td></tr></table></figure><h2 id="53-nnconvtranspose2d-反卷积"><a class="markdownIt-Anchor" href="#53-nnconvtranspose2d-反卷积"></a> <strong>5.3 nn.ConvTranspose2d 反卷积</strong></h2><p>转置卷积（有时候也称为反卷积，个人觉得这种叫法不是很规范），它是一种特殊的卷积，先 padding 来扩大图像尺寸，紧接着跟正向卷积一样，旋转卷积核 180 度，再进行卷积计算。</p><h1 id="引用"><a class="markdownIt-Anchor" href="#引用"></a> 引用</h1><p>[0] <a href="http://zhuanlan.zhihu.com/p/">zhuanlan.zhihu.com/p/</a><br />[1] <a href="https://blog.csdn.net/Flag_ing/article/details/109129752">https://blog.csdn.net/Flag_ing/article/details/109129752</a><br />[2] <a href="https://zhuanlan.zhihu.com/p/361209187">https://zhuanlan.zhihu.com/p/361209187</a></p>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> tensor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>torch tensor 计算</title>
      <link href="/2023/12/19/AILearning/pytorch/tensor%E8%AE%A1%E7%AE%97/"/>
      <url>/2023/12/19/AILearning/pytorch/tensor%E8%AE%A1%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<h4 id="torchmean"><a class="markdownIt-Anchor" href="#torchmean"></a> torch.mean()</h4><blockquote><p>mean()函数的参数：dim=0,按行求平均值，返回的形状是（1，列数）；dim=1,按列求平均值，返回的形状是（行数，1）,默认不设置dim的时候，返回的是所有元素的平均值。</p></blockquote><h4 id="torchpow"><a class="markdownIt-Anchor" href="#torchpow"></a> torch.pow()</h4><blockquote><p>功能: 实现张量和标量之间逐元素求指数操作, 或者在可广播的张量之间逐元素求指数操作.</p></blockquote><h4 id="torchstack"><a class="markdownIt-Anchor" href="#torchstack"></a> torch.stack()</h4><blockquote><p>官方解释：沿着一个新维度对输入张量序列进行连接。 序列中所有的张量都应该为相同形状。</p><p>注：<code>python</code>的序列数据只有<code>list</code>和<code>tuple</code>。</p><p>浅显说法：把多个2维的张量凑成一个3维的张量；多个3维的凑成一个4维的张量…以此类推，也就是在增加新的维度进行堆叠。</p><p>outputs = torch.stack(inputs, dim=?) → Tensor</p></blockquote><h4 id="torchclamp"><a class="markdownIt-Anchor" href="#torchclamp"></a> torch.clamp()</h4><blockquote><p>torch.clamp(input, min, max, out=None) → Tensor</p><p>将输入<code>input</code>张量每个元素的夹紧到区间 [min,max][min,max]，并返回结果到一个新张量。</p></blockquote><h4 id="torchbmm"><a class="markdownIt-Anchor" href="#torchbmm"></a> torch.bmm()</h4><blockquote><p>计算两个tensor的矩阵乘法，torch.bmm(a,b),tensor a 的size为(b,h,w),tensor b的size为(b,w,m) 也就是说两个tensor的第一维是相等的，然后第一个数组的第三维和第二个数组的第二维度要求一样，对于剩下的则不做要求，输出维度 （b,h,m）;</p></blockquote><h4 id="torchsqueeze函数"><a class="markdownIt-Anchor" href="#torchsqueeze函数"></a> torch.squeeze()函数</h4><blockquote><p>torch.squeeze(input, dim=None, out=None)</p><p>squeeze()函数的功能是维度压缩。返回一个tensor（张量），其中 input 中大小为1的所有维都已删除。</p><p>举个例子：如果 input 的形状为 (A×1×B×C×1×D)，那么返回的tensor的形状则为 (A×B×C×D)</p><p>当给定 dim 时，那么只在给定的维度（dimension）上进行压缩操作。</p><p>举个例子：如果 input 的形状为 (A×1×B)，squeeze(input, 0)后，返回的tensor不变；squeeze(input, 1)后，返回的tensor将被压缩为 (A×B)</p></blockquote><h4 id="torchunsqueeze"><a class="markdownIt-Anchor" href="#torchunsqueeze"></a> torch.unsqueeze()</h4><blockquote></blockquote><h4 id="torchspmm"><a class="markdownIt-Anchor" href="#torchspmm"></a> torch.spmm</h4><blockquote><p>torch.spmm只支持 sparse 在前，dense 在后的矩阵乘法，两个sparse相乘或者dense在前的乘法不支持，当然两个dense矩阵相乘是支持的。</p></blockquote><h4 id="torchsum"><a class="markdownIt-Anchor" href="#torchsum"></a> torch.sum</h4><blockquote><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191625912.png" alt="img" /></p><p>在dim这个维度上，对里面的tesnor 进行加和，如果keepdim=False，返回结果会删去dim这个维度。因为在dim上加和之后，dim=1，所以可以直接删去。</p></blockquote><h4 id="torchdiag"><a class="markdownIt-Anchor" href="#torchdiag"></a> torch.diag</h4><blockquote><p>对角矩阵</p></blockquote><h4 id="torchconcat"><a class="markdownIt-Anchor" href="#torchconcat"></a> torch.concat</h4><blockquote><p>torch.cat ( (A, B), dim=0)接受一个由两个（或多个）tensor组成的元组，按行拼接，所以两个（多个）tensor的列数要相同。</p><p>torch.cat ( (A, B), dim=1)是按列拼接，所以两个tensor的行数要相同。</p></blockquote><h4 id="torchview"><a class="markdownIt-Anchor" href="#torchview"></a> torch.view</h4><blockquote><p>在PyTorch中<strong>view</strong>函数作用为重构张量的维度，相当于numpy中的resize()的功能，但是用法不太一样;</p><p>torch.view(参数a,参数b,…)，其中参数a=3,参数b=2决定了将一维的tt1重构成3*2维的张量。<br />有时候会出现torch.view(-1)或者torch.view(参数a,-1)这种情况。则-1参数是需要估算的。</p><p><strong>view()函数的功能与reshape类似，用来转换size大小。x = x.view(batchsize, -1)中batchsize指转换后有几行，而-1指在不告诉函数有多少列的情况下，根据原tensor数据和batchsize自动分配列数。</strong></p><p>之前对于pytorch的网络编程学习都是大致理解每一层的概念，有些语法语句没有从原理上弄清楚，就比如标题的x = x.view(x.size(0), -1)  。</p><p>这句话一般出现在model类的forward函数中，具体位置一般都是在调用分类器之前。分类器是一个简单的nn.Linear()结构，输入输出都是维度为一的值，x = x.view(x.size(0), -1)  这句话的出现就是为了将前面多维度的tensor展平成一维。</p></blockquote><h4 id="torchpermute"><a class="markdownIt-Anchor" href="#torchpermute"></a> torch.permute</h4><blockquote><p>permute（dims）<br />参数dims用矩阵的维数代入，一般默认从0开始。即第0维，第1维等等<br />也可以理解为，第0块，第1块等等。当然矩阵最少是两维才能使用permute<br />如是两维，dims分别为是0和1<br />可以写成permute（0,1）这里不做任何变化，维数与之前相同<br />如果写成permute（1,0）得到的就是矩阵的转置<br />如果三维是permute(0,1,2)<br />0代表共有几块维度：本例中0对应着3块矩阵<br />1代表每一块中有多少行：本例中1对应着每块有2行<br />2代表每一块中有多少列：本例中2对应着每块有5列<br />所以是3块2行5列的三维矩阵</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> tensor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习率衰减方法</title>
      <link href="/2023/12/19/AILearning/pytorch/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/"/>
      <url>/2023/12/19/AILearning/pytorch/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="pytorch"><a class="markdownIt-Anchor" href="#pytorch"></a> <a href="https://so.csdn.net/so/search?q=Pytorch&amp;spm=1001.2101.3001.7020">Pytorch</a> 学习率衰减方法</h3><h1 id="1什么是学习率衰减"><a class="markdownIt-Anchor" href="#1什么是学习率衰减"></a> 1.什么是学习率衰减</h1><p><a href="https://so.csdn.net/so/search?q=%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D&amp;spm=1001.2101.3001.7020">梯度下降</a>算法需要我们指定一个学习率作为权重更新步幅的控制因子，常用的学习率有0.01、0.001以及0.0001等，学习率越大则权重更新。一般来说，<strong>我们希望在训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些，使得网络更好的收敛到最优解。</strong><br />Pytorch中有两种学习率调整(衰减)方法：<br />（1）使用<a href="https://so.csdn.net/so/search?q=%E5%BA%93%E5%87%BD%E6%95%B0&amp;spm=1001.2101.3001.7020">库函数</a>进行调整；<br />（2）手动调整。</p><h1 id="2使用库函数进行调整"><a class="markdownIt-Anchor" href="#2使用库函数进行调整"></a> 2.使用库函数进行调整</h1><p>Pytorch学习率调整策略通过 <a href="https://so.csdn.net/so/search?q=torch&amp;spm=1001.2101.3001.7020">torch</a>.optim.lr_sheduler 接口实现。pytorch提供的学习率调整策略分为三大类，分别是：<br />（1）有序调整：等间隔调整(Step)，多间隔调整(MultiStep)，指数衰减(Exponential)，余弦退火(CosineAnnealing);<br />（2）自适应调整：依训练状况伺机而变，通过监测某个指标的变化情况(loss、accuracy)，当该指标不怎么变化时，就是调整学习率的时机(ReduceLROnPlateau);<br />（3）自定义调整：通过自定义关于epoch的lambda函数调整学习率(LambdaLR)。<br />在每个epoch的训练中，使用scheduler.step()语句进行学习率更新</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=<span class="number">30</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        ......</span><br><span class="line">        y_ = model(x)</span><br><span class="line">        loss = criterion(y_,y)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        ......</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    train(...)</span><br><span class="line">    test(...)</span><br><span class="line">    scheduler.step()</span><br><span class="line"><span class="number">12345678910111213141516</span></span><br></pre></td></tr></table></figure><h2 id="21有序调整"><a class="markdownIt-Anchor" href="#21有序调整"></a> 2.1.有序调整</h2><h3 id="211等间隔调整学习率"><a class="markdownIt-Anchor" href="#211等间隔调整学习率"></a> 2.1.1等间隔调整学习率</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=<span class="number">0.1</span>, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>每训练step_size个epoch，学习率调整为lr=lr*gamma.<br />以下内容中都将epoch和step对等，因为每个epoch中只进行一次scheduler.step()，实则该step指scheduler.step()中的step, 即step_size指scheduler.step()进行的次数。<br />参数</p><ul><li>optimizer: 神经网络训练中使用的优化器，如optimizer=torch.optim.SGD(…)</li><li>step_size(int): 学习率下降间隔数，单位是epoch，而不是iteration.</li><li>gamma(float):学习率调整倍数，默认为0.1</li><li>last_epoch(int)：上一个epoch数，这个变量用来指示学习率是否需要调整。当last_epoch符合设定的间隔时，就会对学习率进行调整；当为-1时，学习率设置为初始值。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635978.png" alt="img" /></li></ul><h3 id="212多间隔调整学习率"><a class="markdownIt-Anchor" href="#212多间隔调整学习率"></a> 2.1.2.多间隔调整学习率</h3><p>跟2.1类似，但学习率调整的间隔并不是相等的，如epoch=10时调整一次，epoch=30时调整一次，epoch=80时调整一次…</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_shceduler.MultiStepLR(optimizer, milestones, gamma=<span class="number">0.1</span>, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>milestone(list): 一个列表参数，表示多个学习率需要调整的epoch值，如milestones=[10, 30, 80].</li><li>其它参数同(1)。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635994.png" alt="img" /></li></ul><h3 id="213指数衰减调整学习率-exponentiallr"><a class="markdownIt-Anchor" href="#213指数衰减调整学习率-exponentiallr"></a> 2.1.3.指数衰减调整学习率 ExponentialLR</h3><p>学习率呈指数型衰减，每训练一个epoch，lr=lr×γepoch</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>gamma(float)：学习率调整倍数的底数，指数为epoch，初始值我lr, 倍数为γepoch</li><li>其它参数同上。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635065.png" alt="img" /></li></ul><h3 id="214余弦退火函数调整学习率"><a class="markdownIt-Anchor" href="#214余弦退火函数调整学习率"></a> 2.1.4.余弦退火函数调整学习率</h3><p>学习率呈余弦函数型衰减，并以2×Tmax为余弦函数周期，epoch=0对应余弦型学习率调整曲线的x=0，ymax=lr，epoch=Tmax对应余弦型学习率调整曲线的x=Π，ymin=etamin处，随着epoch&gt;Tmax，学习率随epoch增加逐渐上升，整个走势同cos(x)。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=<span class="number">0</span>, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>Tmax(int):学习率下降到最小值时的epoch数，即当epoch=T_max时，学习率下降到余弦函数最小值，当epoch&gt;T_max时，学习率将增大；</li><li>etamin: 学习率调整的最小值，即epoch=Tmax时，lrmin=etamin, 默认为0.</li><li>其它参数同上。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635073.png" alt="img" /></li></ul><h2 id="22根据指标调整学习率reducelronplateau"><a class="markdownIt-Anchor" href="#22根据指标调整学习率reducelronplateau"></a> 2.2.根据指标调整学习率ReduceLROnPlateau</h2><p>当<strong>某指标(loss或accuracy)在最近几个epoch中都没有变化(下降或升高超过给定阈值)时</strong>，调整学习率。<br />如当验证集的loss不再下降是，调整学习率；或监察验证集的accuracy不再升高时，调整学习率。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">&#x27;min&#x27;</span>, factor=<span class="number">0.1</span>,</span><br><span class="line"> patience=<span class="number">10</span>,verbose=<span class="literal">False</span>, threshold=<span class="number">0.0001</span>, threshold_mode=<span class="string">&#x27;rel&#x27;</span>, cooldown=<span class="number">0</span>, </span><br><span class="line"> min_lr=<span class="number">0</span>, eps=<span class="number">1e-08</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>mode(str): 模式选择，有min和max两种模式，min表示当指标不再降低(如监测loss)，max表示当指标不再升高(如监测accuracy)。</li><li>factor(float): 学习率调整倍数，同前面的gamma，当监测指标达到要求时，lr=lr×factor。</li><li>patience(int): 忍受该指标多少个epoch不变化，当忍无可忍时，调整学习率。</li><li>verbose(bool): 是否打印学习率信息，print( ‘Epoch {:5d} reducing learning rate of group {} to {:.4e}.’.format(epoch, i, new_lr), 默认为False, 即不打印该信息。</li><li>threshold_mode (str): 选择判断指标是否达最优的模式，有两种模式：rel 和 abs.<br />当threshold_mode == rel, 并且 mode == max时，dynamic_threshold = best * (1 + threshold);<br />当threshold_mode == rel, 并且 mode == min时，dynamic_threshold = best * (1 - threshold);<br />当threshold_mode == abs, 并且 mode == max时，dynamic_threshold = best + threshold;<br />当threshold_mode == abs, 并且 mode == min时，dynamic_threshold = best - threshold;<br />threshold(float): 配合threshold_mode使用。</li><li>cooldown(int): “冷却时间”，当调整学习率之后，让学习率调整策略冷静一下，让模型在训练一段时间，再重启监测模式</li><li>min_lr(float or list): 学习率下限，可为float，或者list，当有多个参数组时，可用list进行设置。</li><li>eps(float): 学习率衰减的最小值，当学习率的变化值小于eps时，则不调整学习率。</li></ul><h2 id="23自定义调整学习率"><a class="markdownIt-Anchor" href="#23自定义调整学习率"></a> 2.3.自定义调整学习率</h2><p>为不同参数组设定不同学习率调整策略。调整规则为：<br />lr = base_lr * lambda(self.last_epoch)<br />在fine-tune中特别有用，<strong>我们不仅可以为不同层设置不同的学习率，还可以为不同层设置不同的学习率调整策略。</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>lr_lambda(function or list): 自定义计算学习率调整倍数的函数，通常时epoch的函数，当有多个参数组时，设为list.</li><li>其它参数同上。</li></ul><h1 id="3手动调整学习率"><a class="markdownIt-Anchor" href="#3手动调整学习率"></a> 3.手动调整学习率</h1><p>手动调整学习率，通常可以定义如下函数：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adjust_learning_rate</span>(<span class="params">optimizer, epoch</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Sets the learning rate to the initial LR decayed by 10 every 30 epochs&quot;&quot;&quot;</span></span><br><span class="line">    lr = args.lr * (<span class="number">0.1</span> ** (epoch // <span class="number">30</span>))</span><br><span class="line">    <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">        param_group[<span class="string">&#x27;lr&#x27;</span>] = lr</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>又如：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adjust_learning_rate</span>(<span class="params">epoch, lr</span>):</span><br><span class="line">    <span class="keyword">if</span> epoch &lt;= <span class="number">81</span>:  <span class="comment"># 32k iterations</span></span><br><span class="line">      <span class="keyword">return</span> lr</span><br><span class="line">    <span class="keyword">elif</span> epoch &lt;= <span class="number">122</span>:  <span class="comment"># 48k iterations</span></span><br><span class="line">      <span class="keyword">return</span> lr/<span class="number">10</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">return</span> lr/<span class="number">100</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>该函数通过修改每个epoch下，各参数组中的lr来进行学习率手动调整，用法如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    lr = adjust_learning_rate(optimizer, epoch)  <span class="comment"># 调整学习率</span></span><br><span class="line">    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">5e-4</span>)</span><br><span class="line">    ......</span><br><span class="line">    optimizer.step()  <span class="comment"># 采用新的学习率进行参数更新</span></span><br></pre></td></tr></table></figure><p>梯度下降算法需要我们指定一个学习率作为权重更新步幅的控制因子，常用的学习率有0.01、0.001以及0.0001等，学习率越大则权重更新。一般来说，<strong>我们希望在训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些</strong>，使得网络更好的收敛到最优解。下图展示了随着迭代的进行动态调整学习率的4种策略曲线：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635068.jpg" alt="img" /></p><p>上述4种策略为自己根据资料整理得到的衰减类型：指数衰减、固定步长的衰减、多步长衰、余弦退火衰减。下面逐一介绍其性质，及pytorch对应的使用方式，需要注意学习率衰减策略很大程度上是<strong>依赖于经验与具体问题的</strong>，不能照搬参数。</p><p>*<strong>1、指数衰减*</strong></p><p>学习率按照指数的形式衰减是比较常用的策略，我们首先需要确定需要针对哪个优化器执行学习率动态调整策略，也就是首先定义一个优化器：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">optimizer_ExpLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br></pre></td></tr></table></figure><p>定义好优化器以后，就可以给这个优化器绑定一个指数衰减学习率控制器：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ExpLR = torch.optim.lr_scheduler.ExponentialLR(optimizer_ExpLR, gamma=0.98)</span><br></pre></td></tr></table></figure><p>其中<strong>参数gamma表示衰减的底数，选择不同的gamma值可以获得幅度不同的衰减曲线</strong>，如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635071.jpg" alt="img" /></p><p>*<strong>2、固定步长衰减*</strong></p><p>有时我们希望学习率每隔一定步数（或者epoch）就减少为原来的gamma分之一，使用固定步长衰减依旧先定义优化器，再给优化器绑定StepLR对象：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">optimizer_StepLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br><span class="line">StepLR = torch.optim.lr_scheduler.StepLR(optimizer_StepLR, step_size=step_size, gamma=0.65)</span><br></pre></td></tr></table></figure><p>其中gamma参数表示衰减的程度，step_size参数表示每隔多少个step进行一次学习率调整，下面对比了不同gamma值下的学习率变化情况：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635399.jpg" alt="img" /></p><p>*<strong>3、多步长衰减*</strong></p><p>上述固定步长的衰减的虽然能够按照固定的区间长度进行学习率更新**，但是有时我们希望不同的区间采用不同的更新频率，或者是有的区间更新学习率，有的区间不更新学习率**，这就需要使用MultiStepLR来实现动态区间长度控制：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">optimizer_MultiStepLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br><span class="line">torch.optim.lr_scheduler.MultiStepLR(optimizer_MultiStepLR,</span><br><span class="line">                    milestones=[200, 300, 320, 340, 200], gamma=0.8)</span><br></pre></td></tr></table></figure><p>其中milestones参数为表示学习率更新的起止区间，在区间[0. 200]内学习率不更新，而在[200, 300]、[300, 320]…[340, 400]的右侧值都进行一次更新；gamma参数表示学习率衰减为上次的gamma分之一。其图示如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635419.jpg" alt="img" /></p><p>从图中可以看出，学习率在区间[200， 400]内快速的下降，这就是milestones参数所控制的，在milestones以外的区间学习率始终保持不变。</p><p>*<strong>4、余弦退火衰减*</strong></p><p>严格的说，余弦退火策略不应该算是学习率衰减策略，因为它使得学习率按照周期变化，其定义方式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">optimizer_CosineLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br><span class="line">CosineLR = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_CosineLR, T_max=150, eta_min=0)</span><br></pre></td></tr></table></figure><p>其包含的参数和余弦知识一致，参数T_max表示余弦函数周期；eta_min表示学习率的最小值，默认它是0表示学习率至少为正值。确定一个余弦函数需要知道最值和周期，其中周期就是T_max，最值是初试学习率。下图展示了不同周期下的余弦学习率更新曲线：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635437.jpg" alt="img" /></p><p>*<strong>5、上述4种学习率动态更新策略的说明*</strong></p><p>4个负责学习率调整的类：StepLR、ExponentialLR、MultiStepLR和CosineAnnealingLR，其完整对学习率的更新都是在其step()函数被调用以后完成的，这个step表达的含义可以是一次迭代，当然更多情况下应该是一个epoch以后进行一次scheduler.step()，这根据具体问题来确定。此外，根据pytorch官网上给出的说明，scheduler.step()函数的调用应该在训练代码以后：</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">scheduler = ...</span><br><span class="line">&gt;&gt;&gt; for epoch in range(100):</span><br><span class="line">&gt;&gt;&gt;     train(...)</span><br><span class="line">&gt;&gt;&gt;     validate(...)</span><br><span class="line">&gt;&gt;&gt;     scheduler.step()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 学习率 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>torch环境</title>
      <link href="/2023/12/19/Programmer/python/torch%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"/>
      <url>/2023/12/19/Programmer/python/torch%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191226420.png" alt="image-20231219122612389" /></p><h1 id="1安装对应的torch-torchvision"><a class="markdownIt-Anchor" href="#1安装对应的torch-torchvision"></a> 1.安装对应的torch、torchvision</h1><p>网址：<a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a></p><p>搜索对应CUDA版本的安装命令（cu110代表CUDA11.0），在终端中复制命令安装。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191135284.png" alt="image-20231219113547226" /></p><p>查看是否安装成功</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.__version__) </span><br><span class="line"><span class="built_in">print</span>(torch.version.cuda) </span><br></pre></td></tr></table></figure><h1 id="2安装torch-geometric"><a class="markdownIt-Anchor" href="#2安装torch-geometric"></a> 2.安装torch-geometric</h1><p>网址：<a href="https://pytorch-geometric.com/whl/">https://pytorch-geometric.com/whl/</a></p><p>找到对应pytorch版本：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191137168.png" alt="image-20231219113754141" /></p><p>四个库（cluster,scatter,sparse,spline-conv）分别：wget 网页中对应的链接并 pip install 下载好的whl包，即完成安装：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191139386.png" alt="image-20231219113927345" /></p><p>注意自己环境的python版本以及linux/win就行</p><p>安装完上面四个库后执行 pip install torch-geometric</p><p>以上安装完成。</p><p>完成之后 import torch-geometric 发现报错，报错信息：<strong>“No module named 'torch.profiler”</strong></p><p>原因是torch1.10以上的版本才有<strong>torch.profiler</strong>这个库，但是Torch网址CUDA11.0兼容的选项没有torch1.10以上，那怎么办呢？</p><p>解决：</p><p>找到报错路径里的文件<strong><a href="http://profile.py">profile.py</a></strong></p><p>作如下修改：（原文件是第八行，改成了第九行）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191140609.png" alt="image-20231219114012578" /></p><h1 id="3-dgl安装"><a class="markdownIt-Anchor" href="#3-dgl安装"></a> 3 DGL安装</h1><p>安装DGL无需安装torch-geometric，需要安装那四个依赖库</p><p><a href="https://www.dgl.ai/pages/start.html">Deep Graph Library (dgl.ai)</a></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n mVul python=3.7</span><br><span class="line"></span><br><span class="line">pip install torch==1.5.0+cu102 torchvision==0.6.0+cu102 torchaudio==0.5.0 -f https://download.pytorch.org/whl/cu102/torch_stable.html</span><br><span class="line"></span><br><span class="line">torch 1.5.0</span><br><span class="line">torchgeometric</span><br><span class="line">pip install networkx==2.5</span><br><span class="line">pip install dgl -f https://data.dgl.ai/wheels/cu102/repo.html</span><br><span class="line">https://data.dgl.ai/wheels/cu113/repo.html</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 环境 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python环境</title>
      <link href="/2023/12/19/Programmer/python/python%E7%8E%AF%E5%A2%83/"/>
      <url>/2023/12/19/Programmer/python/python%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h1 id="1-conda虚拟环境"><a class="markdownIt-Anchor" href="#1-conda虚拟环境"></a> 1 conda虚拟环境</h1><h4 id="conda常用命令"><a class="markdownIt-Anchor" href="#conda常用命令"></a> conda常用命令</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda list # 查看当前虚拟环境已经安装的包（激活虚拟环境后使用）</span><br><span class="line">conda env list # 查看当前存在哪些虚拟环境</span><br><span class="line">conda update # conda 检查更新当前conda</span><br></pre></td></tr></table></figure><h4 id="conda创建虚拟环境"><a class="markdownIt-Anchor" href="#conda创建虚拟环境"></a> conda创建虚拟环境</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda create -n xxx python=3.6</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">xxx为所创建虚拟环境的名字</span></span><br></pre></td></tr></table></figure><h4 id="conda激活和退出虚拟环境windows"><a class="markdownIt-Anchor" href="#conda激活和退出虚拟环境windows"></a> conda激活和退出虚拟环境（windows）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda activate xx # (虚拟环境名称）</span><br><span class="line"></span><br><span class="line">conda deactivate</span><br></pre></td></tr></table></figure><h4 id="conda为当前虚拟环境安装新的包"><a class="markdownIt-Anchor" href="#conda为当前虚拟环境安装新的包"></a> conda为当前虚拟环境安装新的包</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda install -n package_name==所需版本 #（版本不指定则默认最新版）</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可使用临时镜像安装加快速度，例如安装numpy：</span></span><br><span class="line"></span><br><span class="line">conda install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy</span><br></pre></td></tr></table></figure><h4 id="conda删除虚拟环境或者虚拟环境中的某个包"><a class="markdownIt-Anchor" href="#conda删除虚拟环境或者虚拟环境中的某个包"></a> conda删除虚拟环境或者虚拟环境中的某个包</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda remove -n name --all</span><br><span class="line">conda remove --name env_name package_name </span><br></pre></td></tr></table></figure><h4 id="conda环境复制"><a class="markdownIt-Anchor" href="#conda环境复制"></a> conda环境复制</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda create -n new_name --clone path</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">path为所需要复制的环境路径，可根据conda <span class="built_in">env</span> list查看路径</span></span><br></pre></td></tr></table></figure><h1 id="2-安装依赖库"><a class="markdownIt-Anchor" href="#2-安装依赖库"></a> 2 安装依赖库</h1><h2 id="pip"><a class="markdownIt-Anchor" href="#pip"></a> pip</h2><p>pip 是最为广泛使用的 Python 包管理器，可以帮助我们获得最新的 Python 包并进行管理。常用命令如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install [package-name]              # 安装名为[package-name]的包</span><br><span class="line">pip install [package-name]==X.X         # 安装名为[package-name]的包并指定版本X.X</span><br><span class="line">pip install [package-name] --proxy=代理服务器IP:端口号         # 使用代理服务器安装</span><br><span class="line">pip install [package-name] --upgrade    # 更新名为[package-name]的包</span><br><span class="line">pip uninstall [package-name]            # 删除名为[package-name]的包</span><br><span class="line">pip list                                # 列出当前环境下已安装的所有包</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">代码示例：</span></span><br><span class="line">pip install spyder -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line">-i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下面介绍常见的国内源镜像：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清华：https://pypi.tuna.tsinghua.edu.cn/simple</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">阿里云：http://mirrors.aliyun.com/pypi/simple/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">华中理工大学：http://pypi.hustunique.com/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">山东理工大学：http://pypi.sdutlinux.org/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">豆瓣：http://pypi.douban.com/simple/</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="conda"><a class="markdownIt-Anchor" href="#conda"></a> conda</h2><p>conda 包管理器是 Anaconda 自带的包管理器，可以帮助我们在 conda 环境下轻松地安装各种包。相较于 pip 而言，conda 的通用性更强（不仅是 Python 包，其他包如 CUDA Toolkit 和 cuDNN 也可以安装），但 conda 源的版本更新往往较慢。常用命令如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda install [package-name]        # 安装名为[package-name]的包</span><br><span class="line">conda install [package-name]=X.X    # 安装名为[package-name]的包并指定版本X.X</span><br><span class="line">conda update [package-name]         # 更新名为[package-name]的包</span><br><span class="line">conda remove [package-name]         # 删除名为[package-name]的包</span><br><span class="line">conda list                          # 列出当前环境下已安装的所有包</span><br><span class="line">conda search [package-name]         # 列出名为[package-name]的包在conda源中的所有可用版本</span><br></pre></td></tr></table></figure><p><strong>conda镜像</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看conda当前设置</span></span><br><span class="line">conda config --show channels</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重置默认镜像源</span></span><br><span class="line">conda config --remove-key channels</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除单个镜像源</span></span><br><span class="line">conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/peterjc123/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">国内镜像</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清华大学镜像</span></span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">中科大镜像</span></span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/menpo/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">阿里镜像</span></span><br><span class="line">conda config --add channels http://mirrors.aliyun.com/pypi/simple/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 环境 </tag>
            
            <tag> pip </tag>
            
            <tag> conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Latex OCR</title>
      <link href="/2023/12/18/Tools/Latex-OCR/"/>
      <url>/2023/12/18/Tools/Latex-OCR/</url>
      
        <content type="html"><![CDATA[<blockquote><p>LaTeX-OCR 是一个开源的光学字符识别（OCR）软件，专为 LaTeX 文档提供支持。其主要目的是帮助用户将扫描的文档转换为 LaTeX 编辑器可以使用的可编辑文本，从而方便进行修改、编辑和排版。</p></blockquote><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206456.png" alt="image-20231219121553484" /></p><h1 id="1安装"><a class="markdownIt-Anchor" href="#1安装"></a> 1.安装</h1><p>LaTeX-OCR可以从源码进行安装，也可以直接用pip来安装，源码地址：<a href="https://github.com/lukas-blecher/LaTeX-OCR">https://github.com/lukas-blecher/LaTeX-OCR</a> ，这里直接使用pip安装，为了方便管理环境，使用conda创建虚拟环境。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n latex python=3.10</span><br><span class="line">conda activate latex</span><br><span class="line">pip install &quot;pix2tex[gui]&quot;</span><br><span class="line">pip install &quot;pix2tex[gui]&quot; -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>注：使用pip清华镜像源更快哦~</p><h1 id="2启动与使用"><a class="markdownIt-Anchor" href="#2启动与使用"></a> 2.启动与使用</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在虚拟环境下执行</span><br><span class="line">pix2tex</span><br></pre></td></tr></table></figure><p>首次执行会下载依赖模型；</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206433.png" alt="image-20231219000535903" /></p><p>期间可能报错，连接断开，尝试重试；</p><p>使用：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206418.png" alt="image-20231219000831872" /></p><p>输入h 回车查看帮助：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206473.png" alt="image-20231219000913782" /></p><p>可以看到windows或macos下可以非常丝滑地使用，只需要：</p><ul><li>截图或复制一个图片到memory，可以理解为复制到剪贴板；</li><li>回到终端按回车，即可看到公式：<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206447.png" alt="image-20231219001159694" /></li><li>复制内容到LaTex块即可；</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>G</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>Y</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">m i n\sum_{i=1}^{n}{\mathcal{L}}(f(G_{i},Y_{i}|V_{i}))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Ω</mi><mi>j</mi></msub><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">W</mi><mi>h</mi></msub><mrow><mo fence="true">(</mo><msub><mi mathvariant="bold">r</mi><mi>j</mi></msub><mo>⊙</mo><msub><mi mathvariant="normal">Ω</mi><mi>S</mi></msub><mo fence="true">)</mo></mrow><mo>+</mo><mrow><mo fence="true">[</mo><msub><mi mathvariant="normal">∇</mi><mi>h</mi></msub><msub><mi mathvariant="normal">e</mi><mi>j</mi></msub><mo>+</mo><msub><mi mathvariant="normal">b</mi><mi>h</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Omega_{j}=tanh({\bf W}_{h}\left({\bf r}_{j}\odot\Omega_{S}\right)+\left[\nabla_{h}\mathrm{e}_{j}+\mathrm{b}_{h}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">r</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathrm">e</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">b</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p><p>工具很好用，无限制，非常良心，简直是福祉。</p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LaTex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git修改remote地址</title>
      <link href="/2023/12/18/Programmer/git/git%E4%BF%AE%E6%94%B9remote%E5%9C%B0%E5%9D%80/"/>
      <url>/2023/12/18/Programmer/git/git%E4%BF%AE%E6%94%B9remote%E5%9C%B0%E5%9D%80/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202212006.png" alt="image-20231220221159980" /></p><h1 id="git修改remote地址"><a class="markdownIt-Anchor" href="#git修改remote地址"></a> git修改remote地址</h1><p>方式1、直接修改：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git remote set-url origin xxxxx.git</span><br></pre></td></tr></table></figure><p>方式2、先删后加 ：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git remote rm origin</span><br><span class="line">git remote add origin xxxxx.git</span><br></pre></td></tr></table></figure><p>修改默认pull和push分支：</p><p>git branch --set-upstream-to=origin/develop develop<br /><code>origin/develop develop</code>为要设置的默认分支</p><h4 id="给本地和远程仓库重命名"><a class="markdownIt-Anchor" href="#给本地和远程仓库重命名"></a> 给本地和远程仓库重命名</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">### 1.重命名本地分支</span><br><span class="line">git branch -m new-name  #如果当前在要重命名的分支</span><br><span class="line">git branch -m old-name new-name #如果当前不在要重命名的分支</span><br><span class="line"></span><br><span class="line">### 2.删除远程旧名称分支并且push新名称分支</span><br><span class="line">git push origin :old-name new-name</span><br><span class="line"></span><br><span class="line">### 3.关联新名称的本地分支和远程分支</span><br><span class="line"> git push origin -u new-name123456789</span><br></pre></td></tr></table></figure><h3 id="修改远程仓库地址"><a class="markdownIt-Anchor" href="#修改远程仓库地址"></a> 修改远程仓库地址</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git remote set-url origin [url]1</span><br></pre></td></tr></table></figure><h4 id="分别查看仓库-local-global-system-的配置信息"><a class="markdownIt-Anchor" href="#分别查看仓库-local-global-system-的配置信息"></a> 分别查看仓库 local global system 的配置信息</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --local --list</span><br><span class="line">git config --global --list</span><br><span class="line">git config --system --list123</span><br></pre></td></tr></table></figure><h4 id="仓库配置增加用户"><a class="markdownIt-Anchor" href="#仓库配置增加用户"></a> 仓库配置增加用户</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --local --add user.name yourname</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决“无法加载文件&#92;WindowsPowerShell&#92;profile.ps1，因为在此系统上禁止运行脚本”</title>
      <link href="/2023/12/18/issues/powershell/"/>
      <url>/2023/12/18/issues/powershell/</url>
      
        <content type="html"><![CDATA[<h3 id="解决无法加载文件-windowspowershellprofileps1因为在此系统上禁止运行脚本"><a class="markdownIt-Anchor" href="#解决无法加载文件-windowspowershellprofileps1因为在此系统上禁止运行脚本"></a> 解决“无法加载文件 ***\WindowsPowerShell\profile.ps1，因为在此系统上禁止运行脚本”</h3><p>在VScode使用anaconda时，提示</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">. : 无法加载文件 C:\Users\47370\Documents\WindowsPowerShell\profile.ps1，因为在此系统上禁止运行脚本。有关详</span><br><span class="line">细信息，请参阅 https:/go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies。</span><br></pre></td></tr></table></figure><p>想了解计算机上的现用执行策略，打开 PowerShell 然后输入：</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">&gt;&gt; get-executionpolicy</span><br><span class="line">Restricted</span><br></pre></td></tr></table></figure><p>更改执行策略，以管理员身份打开 PowerShell 输入：</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">&gt;&gt; set-executionpolicy remotesigned</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404031041877.webp" alt="img" /></p><p>选择“是”，即可。</p><p>如果要更改回Windows 客户端计算机的默认执行策略，则设置为restricted：</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">set-executionpolicy restricted</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> windows </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PowerShell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>没有思考过Embedding，不足以谈 AI</title>
      <link href="/2023/12/18/AILearning/DL/%E6%B2%A1%E6%9C%89%E6%80%9D%E8%80%83%E8%BF%87%20Embedding%EF%BC%8C%E4%B8%8D%E8%B6%B3%E4%BB%A5%E8%B0%88%20AI/"/>
      <url>/2023/12/18/AILearning/DL/%E6%B2%A1%E6%9C%89%E6%80%9D%E8%80%83%E8%BF%87%20Embedding%EF%BC%8C%E4%B8%8D%E8%B6%B3%E4%BB%A5%E8%B0%88%20AI/</url>
      
        <content type="html"><![CDATA[<p>和大部分人一样，我对自然语言处理和语言模型的了解从ChatGPT开始。也和大部分人一样，第一次接触就被ChatGPT的能力所震惊 —— 硅基智能确实做到了理解人类的语言。</p><p>我也产生了几乎人人都会有的疑问：怎么做到的？硅基智能潜力是否会远胜于碳基智能？</p><p>在这篇文章中，我并不试图去解释ChatGPT的一切，而是将从原理出发，思考计算机理解语言的关键要素，这些思考落到了一个具体的切入点 —— embedding —— 一个第一眼难以理解但极为关键的东西。</p><p>文章是一个门外汉通过业余的研究和碎片的思考所完成，谬误之处难以避免，欢迎专业的研究人员指正。</p><h3 id="1-编码文字的数字化"><a class="markdownIt-Anchor" href="#1-编码文字的数字化"></a> 1 编码：文字的数字化</h3><p>Embedding 这个词直译为中文是：嵌入，这是让人头秃的两个字 —— 啥是嵌入？嵌入了啥？跟自然语言又有啥关系？</p><p>嵌入的体现形式是一组具有固定长度的数组，或者叫做向量，但它究竟是什么？为什么需要它？它在计算机理解自然语言的过程中扮演的是怎样的角色呢？</p><p>要回答这些问题，不妨先思考：让计算机理解自然语言，我们需要做什么？</p><p>计算的基础是数，而自然语言是文字，因此很容易想到要做的第一步是让文字数字化，为行文方便，我们将这个过程叫做编码。要设计编码的方法，自然需要思考的问题是：哪些性质是编码规则必须要满足的？</p><p>有一条是显然可以给出的：</p><p><strong>性质一：每一个词具有唯一量化值，不同词需要具有不同的量化值</strong></p><p>背后的逻辑不言自明：一词多数，或是多词一数，都会增加计算机理解语言的难度，这种难度就如同多音字或是多义词给人类造成的困难，尽管人类的智慧让我们可以克服这些障碍，但对于仍然处于培育智能阶段的计算机，为它降低一些难度显然是必要的。</p><p>满足性质一的方法非常容易设计，例如：首先穷举出人类所有的文字或词组 —— 这个集合必定是有限集，例如汉字有10万个，辞海收录的词大概60万个，字母有26个，英语单词数小于100万个 ——— 由于是有限集，我们可以给每一个词分配一个固定的数字。</p><p>例如打开一个词典，将遇到的单词依次赋予一个不同的数值：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A --&gt; 1</span><br><span class="line">Abandon --&gt; 2</span><br><span class="line">Abnormal --&gt; 3</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这便完成了符合性质一的编码。例如 “Hello World” 这句话就可以作为 ”3942 98783“ 这样的数字序列输入，从而可以被计算机处理。</p><p>但这一方法存在的问题是显然的：</p><p><strong>数的值与词的义是割裂的。</strong></p><p>这种割裂会产生什么问题？可以通过一个简单的例子来思考：在英语中，a 和 an 是完全同质的词，而 a 和 abnormal 则是差异极大的词。如果按照上述编码方式， a 可能会被赋予数值1，abnormal会被赋予数值2，an 会被赋值赋予数值 123 ，这个时候我们可能会发现 a 和 abnormal 似乎在数值上更加靠近，而 a 和 an 这两个同质的词却隔得非常远。这时容易想到要添加一条性质，来确保数字化后的数值与词义之间的关联：</p><p><strong>性质二：词义相近词需要有&quot;相近&quot;的量化值；词义不相近的词量化值需要尽量“远离”。</strong></p><h3 id="2-基于词义的编码"><a class="markdownIt-Anchor" href="#2-基于词义的编码"></a> 2 基于词义的编码</h3><p>上面的例子中虽然提到了字典编码法会割裂数值和词义，却未能解释为什么数值和词义应该关联 —— 基于直觉的思考会认为这一点是显然的，但模糊的显然容易掩埋值得被清晰梳理的逻辑。我能够想到的原因有两个：</p><ol><li>可以帮助更加高效理解语义；</li><li>允许计算模型的设计有更大的自由度。</li></ol><p>第1条怎么理解？如果说词的数值分布与词义无关，这会使得文本的序列变得过于随机，例如：</p><blockquote><p>句子一：张三在讲话。<br />句子二：李四在发言。</p></blockquote><p>这两句话有着非常强的同质性，但如果对于字/词的编码不符合性质二，这就会使得以上两句话的序列特征会有非常大的差异。以下的例子或许足够直观：</p><p>如果近义词具有相近的量化值，词和值之间的关系或许会是这样，看起来就是相似的形状：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">张 --&gt; 105, 李 --&gt; 99</span><br><span class="line">三 --&gt; 3, 四 --&gt; 4</span><br><span class="line">在 --&gt; 200,</span><br><span class="line">讲话 --&gt; 300, 发言 --&gt; 295</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151285.jpeg" alt="图片" /></p><p>而如果近义词具有不相近的量化值，词和值之间的关系或许会是这样，一眼看上去似乎没什么关系：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">张 --&gt; 33, 李 --&gt; 1</span><br><span class="line">三 --&gt; 5, 四 --&gt; 200</span><br><span class="line">在 --&gt; 45,</span><br><span class="line">讲话 --&gt; 2, 发言 --&gt; 42</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151296.jpeg" alt="图片" /></p><p>换言之，当性质二得到满足时，同义的句子在序列特征上会更加接近，这将有利于计算机而言更高效地理解共性、区分特性；反之则会给计算机制造非常多的困难。难以捕捉同质内容之间的共性，就意味着模型需要更多的参数才能描述同等的信息量，学习的过程显然困难也会更大。OpenAI 的 Jack Rae 在 Standford 的分享 中提到了一个很深刻的理解语言模型的视角：</p><ul><li><strong>语言模型就是一个压缩器。</strong></li></ul><p>这个观点已有不少文章都做了阐释。</p><p>**所有的压缩，大抵都能被概括在以下框架内：提取共性，保留个性，过滤噪声。**带着这个视角去看，就更加容易认识到性质二的必要性。不同词所编码的数值，是否基于词义本身的相似性形成高区分度的聚类，会直接影响到语言模型对于输入数据的压缩效率。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151288.jpeg" alt="图片" /></p><p>编码值未基于词义形成聚类</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151238.jpeg" alt="图片" /></p><p>编码值基于词义形成聚类</p><p>第2条怎么理解？</p><p>因为词是离散分布的，而计算模型的输出 —— 除非只使用非常简单的运算并且约束参数的权重 —— 很难恰好落在定义好的量化值中。</p><p>对于神经网络模型，每一个节点、每一层都必须是连续的，否则便无法计算梯度从而无法应用反向传播算法。这两个事实放在一起可能会出现的情况是：词的量化值可以全部是整数，但是语言模型的输出不一定。例如当模型输出 1.5，词表只定义了 1 和 2，这时该如何处理呢？</p><p>我们会希望 1 和 2 都可以，甚至 3 可能也不会太离谱，因此 1 和 2 所代表的词在词义上最好有某种共性，而不是像 “a” 和 “abandon” 一样，几乎找不到词义上的关联。当相近的词聚集到一起，推断出有效输出的概率就会更高。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151301.jpeg" alt="图片" /></p><p>图片来源：<a href="https://en.wikipedia.org/wiki/Generative_pre-trained_transformer">https://en.wikipedia.org/wiki/Generative_pre-trained_transformer</a></p><p>—— 理解了这一点，GPT模型的最后一层就非常容易理解了。在最后一层之前，推理的对象是以向量形式表征的语义，输出的是代表语义的一个“模糊”的向量。此处“模糊”指的是，这一向量或许并不对应任何一个已知的词。</p><p>因此，整个模型最后需要再做一个推测，基于这个“模糊”的向量所包含的语义信息，在词表中寻找最符合这些特征的词，来作为真正的输出。在 transformer 中，最后的输出是一个概率分布，表示每一个词匹配这一“模糊”向量的概率。</p><p>现在我们知道了性质二是必要的，在考虑这一点的基础上是否有可能再抢救一下字典编码法？比如… 找一本近义词字典，针对相近的词赋予相近的数？</p><p>问题很快也就出现了：A 和 B 词义相似，B 和 C 词义相似，似乎并不意味着 A 和 C 词义也相近。</p><p>例如：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A = ”Love“，B = ”Passion“，C = &quot;Rage&quot;</span><br><span class="line">A = ”Comedy“，B = ”Play“，C = &quot;Game&quot;</span><br></pre></td></tr></table></figure><p>在这两个案例中，A 和 B 都是接近的，B 和 C 也是接近，但 A 和 C 却不是。问题在哪呢？</p><ul><li><strong>词义的多维性。</strong></li></ul><p>当用一个标量来表示一个词时，词和词之间的关系只能基于两个标量间的差值得到，从而只有“远”和“近”两种状态；但实际情况可能是：两个词只在某些维度上接近。“Love” 和 “Passion” 接近的地方是：情感浓度，都表示存在强烈的情感，但是在情感色彩方面 —— 也就是消极还是积极 —— passion 具有更加中性的色彩，于是同样具有浓烈情感的 “Rage” 也与 “Passion” 相近，但是 “Rage” 的情感色彩却是消极的。</p><p>于是我们需要一个多维的数字形态，很自然会想到使用向量 ——— 对于每一个词，我们可以表达为一组数，而非一个数；这样一来，就可以在不同的维度上定义远近，词与词之间复杂的关系便能在这一高维的空间中得到表达 —— 这，就是 embedding，它的意义也就不言自明了。“嵌入”这个名字太糟糕了，不如叫它“词义向量” 吧；而词义向量所处的空间，可以称为“词义空间”。</p><h3 id="3-如何设计编码器"><a class="markdownIt-Anchor" href="#3-如何设计编码器"></a> 3 如何设计编码器</h3><p>目前为止，我们已经找到了可以用于表达词义的数字化形式 —— 向量，也知道了一个好的编码方式应当满足的性质。如何设计一套方法，来完成我们所期望的编码，就成了最后的问题。</p><p>一个比较容易想到的方法是，令词义的不同维度和向量不同维度进行关联。例如，对词义的维度进行全面的拆分：名词性、动词性、形容词性、数量特征、人物、主动、被动、情感色彩、情感强度、空间上下、空间前后、空间内外、颜色特征、… 只要维度的数量足够多，一定是可以把词义所包含的信息全都囊括在内；一旦我们给出每一个维度的定义，就可以给出每个词在相应维度上的数值，从而完成词的向量化，并且完美地符合以上给出的两点性质。但这个看似可行的设计，并不具备可实现性。</p><p>首先是要能够囊括所有词义的不同维度，需要维度数量必然是极高的，而要对词义进行这么精细的切分，就非常困难，其次即使切分出来了，要将每个词不同维度的意义赋予有效的数值，哪怕是资深的语言学家恐怕也会难以感到棘手。今天大家所熟知的语言模型中，并没有一个是用这一方式对词进行向量化的。但是这个思想方案却是有意义的，词义向量的不同维度之于计算机，就如同上面我们列举的维度 —— 词性、数量、时间、空间等等 —— 之于人类。</p><p>纯构建的方式不可行，今天我们也已经知道了一套有效的解决办法：神经网络加大数据暴力出奇迹。这套范式的起源于是：Word2Vec。今天语言模型，无一不是基于词义向量，而词义向量真正开始有效，正是从Word2Vec开始。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403051151233.jpeg" alt="图片" /></p><p>Word2Vec 的关键是一个重要的洞察、一个极具启发性的角度：</p><p><strong>一个词的意义，可以被它所出现的上下文定义。</strong></p><p>这句话换一种说法又可以表述为：**上下文相似的词在词义上也一定存在相似性。**想一想是不是很有道理？这个观点是语言学家 Zellig Harris 在1954 提出的“Distribution Hypothesis”，随后被广泛接受。Word2Vec 的两类做法分别是：</p><p>中心词 --&gt; 神经网络 --&gt; 上下文</p><p>上下文 --&gt; 神经网络 --&gt; 中心词</p><p>今天回头看，这个工作从一开始就注定了成功：原理上，是基于广泛接受的“Distribution Hypothesis”；方法上，使用了拟合能力强大的神经网络模型；最重要的，数据要多少有多少。</p><p>这个方法当然不是终点，它的局限性是明显的 —— 但开创性已经足够了 —— 只是利用和挖掘了“Distribution Hypothesis”的浅层结构。怎么理解这句话呢？</p><p>本质上是因为Word2Vec并没有尝试去理解句子内的语义。因此对于完全相同的上下文，不同的中心词的词义相似性是容易捕捉的；当词义向量的聚类逐渐形成，由近义词构成的上下文，也一定程度上能够标记词义相近的中心词。但人类的语言结构非常复杂，当相同语义通过不同句式、语态、修辞进行表达时，某些近义词对的关系就会可能被深埋。</p><p>看看ChatGPT举的这个例子：</p><blockquote><p>句子1：Driven by an insatiable thirst for knowledge, she stayed late every night, her eyes dancing across the pages of books as if they were starry skies.<br />句子2：Isn’t it unusual, that she, prompted by an unquenchable intellectual curiosity, burns the midnight oil, pouring over pages as though navigating constellations?</p></blockquote><p>两个句子都在描述一个女性深夜仍在阅读，驱使她的是对知识的无尽渴望，两句话也存在非常多意义相近的词对，在不理解语义的情况下，这些词对之间的相似性是难以被辨识的。</p><p>接下来我们可以讨论 GPT 了。</p><p>它是一个有能力理解句子的模型。如果说此前讨论的Word2Vec这类构建词义向量的模型是教计算机“认字”的过程，那么GPT模型的训练，则是一个“认字”+“背书”的过程。老师最后只考书背的好不好，但为了把书背好，GPT 也被动地强化了其认字能力。</p><p><strong>推理的核心是transformer，transformer的核心是attention机制，attention机制是什么？</strong></p><p>一言以蔽之：计算词义向量之间的“距离”后 ，对距离近的词投向更多注意力，而收到高注意力的词义则获得更高的激活值，当预测完成后，通过反向传播算法：当特定的激活帮助了最终的预测，对应词之间关联将被强化，反之则被弱化，模型便是通过这一方式学到了词之间的关系。而在“Distribution Hypothesis”这一视角下，“认字”的实质就是认识一个词和其它词之间的关系。于是就形成了认字为了背书，背书帮助认字的结构。这里提炼一个我个人的观点：</p><p><strong>attention 机制之所以重要和好用，原因之一是可以有效帮助词义向量（embedding）聚类。</strong></p><p>GPT的例子想想其实很有趣，一般的工程思维是将大的问题拆成多个小的问题然后一个一个解决，正如文中开始说的那句：</p><p>让计算机理解自然语言，我们需要做什么？</p><p>计算的基础是数，而自然语言是文字，因此很容易想到要做的第一步是让文字数字化…</p><p>这个表述隐含了一个解决问题的路径：先将文字数字化后，考虑理解句子的问题。有趣的地方是：对词进行向量化编码的最好方法，是直接训练一个理解句子的语言模型；这就像为了让婴儿学会走路，我们直接从跑步开始训练。人类会摔跤会受伤，但机器不会 —— 至少在embodied之前不会，因此人类为了降低代价所建立的步骤化学习过程或许并不适合人工智能 —— 也不难发现，深度学习中，许多好的解决方案往往都是一步到位的。</p><h3 id="4-总结"><a class="markdownIt-Anchor" href="#4-总结"></a> 4 总结</h3><p>这篇文章把我关于语言模型中embedding的理解都介绍完了。但embedding 还不止这些。</p><p>图像可以有embedding，句子和段落也可以有 embedding —— 本质都是通过一组数来表达意义。段落的 embedding 可以作为基于语义搜索的高效索引，AI 绘画技术的背后，有着这两种 embedding 的互动 —— 未来如果有一个大一统的多模态模型，embedding 必然是其中的基石和桥梁 。</p><p>由 AI 掀起的时代浪潮毫无疑问地要来了，今天是一个还难以看清未来的节点。当下能做的为数不多的事情之一还是保持学习。希望这篇文章可以帮到正在学习的你。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Latent Space - 理解深度学习中的潜在空间</title>
      <link href="/2023/12/18/AILearning/DL/%E7%90%86%E8%A7%A3latent%20space/"/>
      <url>/2023/12/18/AILearning/DL/%E7%90%86%E8%A7%A3latent%20space/</url>
      
        <content type="html"><![CDATA[<h1 id="latent-space理解深度学习中的潜在空间"><a class="markdownIt-Anchor" href="#latent-space理解深度学习中的潜在空间"></a> （Latent Space）理解深度学习中的潜在空间</h1><h2 id="什么是潜在空间"><a class="markdownIt-Anchor" href="#什么是潜在空间"></a> 什么是潜在空间？</h2><blockquote><p>If I have to describe latent space in one sentence, it simply means a representation of compressed data.</p></blockquote><blockquote><p>[!NOTE]</p><p>想象一个大的手写数字数据集（0–9），就像上面显示的那样。 与其他不同编号（即3s与7s）的图像相比，相同编号的手写图像（即3的图像）彼此最相似。 但是我们可以训练一种算法来识别这些相似之处吗？ 如何进行？如果您已经训练了一个模型来对数字进行分类，那么您也已经训练了该模型来学习图像之间的“结构相似性”。 实际上，这就是模型能够通过学习每个数字的特征而首先对数字进行分类的方式。这个过程似乎对您“隐藏”了，那根据定义，潜在性即是指“隐藏”。</p></blockquote><p><mark>“潜在空间”的概念很重要，因为<strong>它的用途是“深度学习”的核心-学习数据的特征并简化数据表示形式以寻找模式</strong>。</mark></p><p><strong>其实，Latent Variable这个概念在统计机器学习中并不陌生，概率图模型里从GMM (<strong>高斯混合模型</strong>), HMM(<strong>隐马尔科夫模型</strong>), 到PPCA (<strong>概率PCA</strong>) 和 LDS(<strong>线性动态系统，也叫卡曼滤波</strong>)， 都有Latent Variable的身影。<strong>在这些模型中</strong>，我们用Latent Variable来描述模型对于分布的certainty与uncertainty。因为我们在概率图的框架下用一些分布来拟合给定数据分布时需要这样一个未知变量（Latent Variable）来对拟合函数(用来拟合数据的分布函数， 如高斯分布)们进行一种有效“组合”, 这样的组合可以是线性的，如GMM， 也可以是非线性的，如PPCA，如果我们把时序也考虑进来，就分别有了HMM与LDS。</strong></p><p>**那么以上几种概率图模型中我们其实是在通过学习Latent Variable (Latent Space)来展开学习进程的。**那么深度神经网络呢？ <strong>Latent Space对于深度神经网络的意义在何？</strong></p><p>深度神经网络即深度学习是一种Representation Learning, 表征学习**。顾名思义，学习数据表征。我们的学习过程已经不是靠一些分布来拟合给定数据的分布, 而是通过空间转换来学习数据特征。**</p><p>从什么空间到什么空间呢？ <strong>从数据分布空间到任务的目标分布空间。</strong></p><blockquote><p>[!Note]</p><p>数字识别分类任务，原始数据分布是图片的像素的数值和位置分布空间， 任务目标分布空间是0-9这10个数字对应的离散概率质量分布。 我们在每一层使用向量的线性变换 + 非线性变换的方式将原始分布 (即一个高维向量) 映射到另一个目标分布(即另一个相对低维向量)。 线性变换用到了矩阵变换，batch gradient descent 和 mini-batch gradient descent更新矩阵参数时考虑到了一个 batch(或mini-batch)中所有的映射对， 即<strong>每一次更新参数时考虑了一个 batch(或mini-batch)中所有的映射对</strong>，所以<strong>我们可不可以感性的理解矩阵的参数在经过多次迭代更新后具有了这个分布空间转换的分布特性</strong>。</p></blockquote><p>在inference时我们把每个数据一个一个的放进模型 (深度神经网络)， 经过层层转换，我们得到每个数据的特定特征， 即，稍微不同于其他数据的特征，但还与他们存在某种关系或关联。 这个特征 (向量) 体现在哪儿呢？</p><p><strong>我们为什么要在ML中压缩数据？</strong></p><p>数据压缩定义为使用比原始表示更少的比特对信息进行编码的过程。 这就像获取一个19D数据点（需要19个值来定义唯一点）并将所有这些信息压缩到9D数据点中一样。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191342635.png" alt="image-20240419134254543" /></p><p>通常，在机器学习中对数据进行压缩以学习有关数据点的重要信息。 让我用一个例子来解释。</p><p>假设我们想训练一个使用全卷积神经网络（FCN）对图像进行分类的模型。 （即，给定数字图像后输出数字位数）。 <strong><mark>作为模型“学习”，它只是简单地学习每一层的特征（边缘，角度等），并将特征的组合归因于特定的输出。但是，每次模型通过数据点学习时，图像的维数都会先减小，然后才最终增大。 （请参见下面的编码器和瓶颈）。</mark></strong> 当降维时，我们认为这是有损压缩的一种形式。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191343971.webp" alt="img" /></p><p>因为需要模型来重建压缩数据（请参见解码器），所以它必须学会存储所有相关信息并忽略噪声。 这就是压缩的价值，它使我们能够摆脱任何无关的信息，而只关注最重要的功能。</p><p><strong>这种“压缩状态”是数据的潜在空间表示。我们所说的空间是什么？</strong></p><p>您可能想知道为什么我们将其称为潜在空间。 毕竟，乍一看，压缩数据可能不会引起任何形式的“空间”。但是，这是平行的。在这个非常简单的示例中，假设我们的原始数据集是尺寸为5 x 5 x 1的图像。我们将潜在空间尺寸设置为3 x 1，这意味着压缩数据点是一个3维向量。</p><blockquote><p>Whenever we graph points or think of points in latent space, we can imagine them as coordinates in space in which points that are “similar” are closer together on the graph</p></blockquote><p>随之而来的自然问题是，我们将如何想象4D点或n维点或什至非矢量的空间（因为不需要将潜在空间表示为2维或3维矢量，而且通常不需要太多） 信息将会丢失）。不能令人满意的答案是，我们不能。 我们是无法理解n维空间（例如n&gt; 3）的3维生物。 但是，有些工具（例如t-SNE）可以将我们的高维潜在空间表示转换为可以可视化的表示（2D或3D）。 （请参阅下面的“可视化潜在空间”一节。）但是您可能想知道什么是“相似”图像，为什么减少数据的维数会使相似图像在空间上“更紧密”在一起？</p><p>相似是什么意思？</p><p>如果我们查看三个图像，其中两个是椅子，一个是桌子，我们很容易地说这两个椅子图像最相似，而桌子与任何一个椅子图像的区别最大。</p><p>但是，什么使这两个椅子图像“更相似”？椅子具有明显的特征（即靠背，无抽屉，两腿之间的连接）。通过学习边缘，角度等的图案，这些都可以被我们的模型“理解”。如所解释的，这样的特征被包装在数据的潜在空间表示中。因此，随着维数的减少，与每个图像截然不同的“外部”信息（即椅子颜色）从我们的潜在空间表示中被“去除”，因为只有每个图像的最重要特征都存储在潜在空间表示中。 结果，随着我们减小尺寸，两把椅子的表示变得越来越不清晰，越来越相似。如果我们想象它们在空间中，它们将“紧密”在一起。请注意，我在<strong>整篇文章中提到的“接近度”指标是一个歧义术语，而不是确定的欧几里得距离，因为空间中存在多种距离定义</strong>。<strong>因为机器“看到的”数据表征形式和我们人用肉眼看和思维理解到的是不一样的！在理解特征向量的时候，我们不能用人类的思维去考量。在概率图里，我们还能把latent variable当作分布出现的似然性，但是在深度神经网络里这样思考feature vector就行不通了。因为它在某种意义上代表了空间转换的特征。</strong></p><h2 id="为什么潜在空间很重要"><a class="markdownIt-Anchor" href="#为什么潜在空间很重要"></a> 为什么潜在空间很重要？</h2><p>潜在的空间概念绝对令人着迷。 但是如何使用呢？ 我们什么时候使用它？ 最重要的是，为什么？我们会发现，在我们最喜欢的图像处理网络，生成模型等中，潜在空间是“隐藏的”。尽管潜在空间对大多数人来说是隐藏的，但是在某些任务中，了解潜在空间不仅有帮助，而且是必要的。</p><p><strong>表征学习</strong></p><p>数据的潜在空间表示包含表示原始数据点所需的所有重要信息。然后，该表示必须表示原始数据的特征。换句话说，该模型学习数据特征并简化其表示，从而使其更易于分析。这是称为表示学习（Representation Learning）的概念的核心，该概念定义为允许系统从原始数据中发现特征检测或分类所需的表示的一组技术。在这种用例中，我们的潜在空间表示用于将更复杂的原始数据形式（即图像，视频）转换为更“易于处理”和分析的简单表示。</p><p>下面列出了代表性学习的具体实例。</p><p><strong>Manifolds</strong></p><p>潜在空间是流形学习（表示学习的一个子领域）中必不可少的概念。数据科学中的流形可以理解为在某种程度上“相似”的数据组或子集。一旦我们的数据已在潜在空间中表示出来，就可以发现这些相似性，通常在高维空间中是难以察觉的或模糊不清的。</p><p>以瑞士卷为例</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191421283.png" alt="image-20240419142143218" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191424238.webp" alt="img" /></p><p>在3D中，我们知道存在类似数据点的组，但是用更高维度的数据来描绘此类组要困难得多。</p><blockquote><p>通过将数据的维数减少为2D（在这种情况下可以视为“潜在空间”表示），我们可以更轻松地区分数据集中的流形（相似数据组）。</p></blockquote><h2 id="自编码器和生成模型"><a class="markdownIt-Anchor" href="#自编码器和生成模型"></a> 自编码器和生成模型</h2><p>自编码器是操纵潜在空间中数据“紧密度”的一种常见类型的深度学习模型，它是一种充当身份函数的神经网络。 换句话说，自动编码器会学习输出任何输入的内容。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191424856.webp" alt="img" /></p><p>你可能会想知道，为什么在世界上我们需要一个能够做到这一点的模型？ 如果它输出的只是它自己，那似乎就没用了……尽管这种推论是正确的，但我们并不太在乎模型的输出。 <strong>我们更关心模型在此过程中学到的内容</strong>。<strong>当我们强制模型成为身份函数时，我们将其强制以压缩的表示形式存储所有数据的相关特征</strong>，以便以压缩的形式提供足够的信息，以使模型可以“准确地”重建模型。 听起来有点熟？ 应该这样做，因为此压缩表示形式是我们的潜在空间表示形式（上图中的红色块）。</p><p><strong>“压缩”这里听起来有点主成分分析 (PCA) 那意思， 比如PCA里的SVD分解，通过提取数据矩阵在“向量外积合成时”的重要表征 (谁的奇异值大谁就是重要表征) 来实现数据存储的压缩。但是这里的压缩是向量空间转换意义上的维度压缩，和PCA里的“压缩”不一样。前者代表数据本身的特征压缩，而后者代表两个空间进行相互转换时的中介空间的重要特征“压缩”。</strong></p><p>我们已经看到了如何在潜在空间中更容易发现模式，因为相似的数据点将趋于聚集在一起，但是我们还没有看到如何从该潜在空间中采样点以产生“新”数据。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191424892.webp" alt="img" /></p><p>在上面的示例中，我们可以<strong>通过在潜在空间上进行插值</strong>，并<strong>使用模型解码器将潜在空间表示重构为二维图像</strong>，并以<strong>与原始输入相同的尺寸来生成不同的面部结构</strong>。</p><p><strong>在潜在空间上插值是什么意思？</strong></p><p>假设我已将上一节中的椅子图像压缩为以下2D向量[0.4，0.5]和[0.45，0.45]。 假设办公桌被压缩为[0.6，0.75]。 如果要在潜在空间上进行插值，则需要对“椅子”群集和“办公桌”群集之间的潜在空间中的点进行采样。我们可以将这些采样的2D向量输入模型的解码器，瞧！ 我们得到的“新”图像看起来像是椅子和桌子之间的变体。 * new用引号引起来，因为这些生成的图像在技术上并不独立于原始数据样本。</p><p>以下是潜在空间中两种椅子之间的线性插值示例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191424949.jpeg" alt="动图封面" /></p><p>图像生成仍然是研究的活跃领域，<strong>而潜在空间是必须理解的基本概念</strong>。 有关生成模型的更多用例，请参见以下文章，以及使用GAN（生成对抗网络）的潜在空间插值的动手示例，GAN是使用潜在空间表示形式的另一种生成模型。</p><h2 id="可视化潜在空间"><a class="markdownIt-Anchor" href="#可视化潜在空间"></a> 可视化潜在空间</h2><p>有关潜在空间可视化的更多信息，我推荐Hackernoon的文章，该文章提供了一个动手实例，可使用t-SNE算法可视化2D空间中数字图像之间的相似性。</p><h2 id="重要要点"><a class="markdownIt-Anchor" href="#重要要点"></a> 重要要点</h2><ul><li>潜在空间只是压缩数据的表示，其中相似的数据点在空间上更靠近在一起。</li><li>潜在空间对于学习数据功能和查找更简单的数据表示形式以进行分析很有用。</li><li>我们可以通过分析潜在空间中的数据（通过流形，聚类等）来了解数据点之间的模式或结构相似性。</li><li>我们可以在潜在空间内插值数据，并使用模型的解码器来“生成”数据样本。</li><li>我们可以使用t-SNE和LLE之类的算法来可视化潜在空间，该算法将我们的潜在空间表示形式转换为2D或3D。</li></ul><p>在学习潜在空间时，我对这个“隐藏但必不可少的概念”着迷。 我希望本文能消除潜在空间表示的神秘性，并提供我作为新手所渴望的对深度学习的“更深入的理解”</p>]]></content>
      
      
      <categories>
          
          <category> AILearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CEVulDet A Code Edge Representation Learnable Vulnerability Detector</title>
      <link href="/2023/12/18/Papers/Vul/CEVulDet/"/>
      <url>/2023/12/18/Papers/Vul/CEVulDet/</url>
      
        <content type="html"><![CDATA[<h1 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h1><p>许多研究者已开始应用深度学习算法来检测源代码的漏洞。然而，现有方法的检测结果仍然不够准确。大多数这些方法将程序源代码直接视为自然语言。这些方法可能会忽略特定于程序代码的结构信息，而这些信息是代码构成语义的关键部分。在本文中，我们提出了一种名为CEVulDet的新型漏洞检测方法。**首先，我们采用中心性分析来从PDG中去除不重要的节点，以获得保留程序重要部分的新图。其次，我们提出了一种新的程序语义提取方法，该方法获取特征向量以表示程序代码和图边信息的语义信息。它可以借助模型解释技术定位漏洞触发路径。**最后，我们的方法提取的向量被输入到CNN中训练漏洞检测器。在我们的实验中，我们评价了CEVulDet在一个包含33,360个函数的数据集上的性能，其中包括12,303个有漏洞的函数和21,057个无漏洞的函数。实验结果表明，CEVulDet远远优于基于规则的检测器，并超越了最先进的基于深度学习的检测器。CEVulDet在准确率、精确度、召回率和F1指标方面分别提高了3.2%、3.4%、5.1%和4.2%。</p><h1 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h1><h2 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h2><h2 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h2><p>我们的主要目标是准确地将一个函数代码标记为易受攻击或不易受攻击。为了做到这一点，我们以两种方式提高模型的准确性。一方面，我们需要使模型能够专注于函数的重要部分。另一方面，必须以适当的方式从源代码中提取丰富的语义。</p><p>为了让模型关注函数的重要部分。我们使用中心性分析来计算函数代码中每行代码的重要性，然后提取重要的代码行。函数代码中的不同代码行具有不同级别的语义重要性。例如，有些代码仅仅声明或定义变量，而其他代码实现了函数的核心算法。显然，后者对函数更重要，因为它们是函数语义的主要部分。获取这些关键代码（即高重要性代码）有助于模型做出更准确的判断。中心性分析计算图中节点的中心性值，这些值反映了图中节点的重要性。我们对函数进行静态分析，获取相应的PDG，然后使用中心性分析计算图中每个节点的中心性值。PDG中的每个节点对应函数中的一行代码，因此我们得到每行代码的重要性。</p><p>在这里，我们将度值视为度中心性，并计算其度中心性值，以弱点函数为示例。如图1所示，PDG中每个节点的内容是一行代码，在图中的实线和虚线表示代码之间的控制流和数据流。我们计算了图中每个节点的入度、出度和度，得到了表I。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221508383.png" alt="image-20240422150829338" style="zoom:50%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221508930.png" alt="image-20240422150839897" style="zoom:50%;" /><p>从表格I中，我们可以看到不同代码行的度基本不同，因为代码行之间有不同的关系（即控制流和数据流），这在一定程度上可以反映出代码行的重要性。为了更全面地考虑每行代码的重要性，我们使用三种不同的中心性分析（即度中心性[8]、接近中心性[8]和PageRank中心性[9]）。</p><p>从源代码中提取丰富的语义。我们提出了一个新颖的想法，可以从源代码中提取更丰富的语义意义。我们观察到，大多数先前的方法只是简单地堆叠代码行，然后将它们馈送到神经网络模型中。它们忽略了函数中的一些逻辑结构，特别是函数代码中的控制流和数据流，函数中的漏洞是基于这些流触发的。这些结构（即控制流边和数据流边）存在于与函数对应的PDG中。因此，我们提出了代码边，其中代码边对应于PDG中的一条边，由该边的两个节点组成。通过这种方式，我们可以将函数转换为代码边列表并获得语义丰富的数据。我们已经结合了这两个方面，并实施了CEVulDet，这使得能够更准确地检测函数（即易受攻击或不易受攻击）。</p><h2 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h2><p>我们使用中心性分析来拦截函数中的重要代码行，让神经网络模型专注于函数的重要部分。</p><p>我们提出了一种新颖的特征提取方法，能够从PDG中提取更丰富的语义（即控制流和数据流），并将函数转换为代码边缘列表。可解释的分析能帮助我们在一定程度上发现漏洞触发的路径。</p><p>我们实现了我们的漏洞检测器并将其与其他几种先进的检测方案进行比较。我们的方法在SARD [10]上取得了最佳结果。</p><h1 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h1><h2 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221519579.png" alt="image-20240422151938485" /></p><ul><li><p>获取代码的PDG：我们对每个函数的源代码进行规范化，然后进行静态分析以提取该函数的程序相关图。</p></li><li><p>生成中心图：PDG使用图的中心性值来删除程序相关图中的不重要节点，从而获得中心图。</p></li><li><p>生成代码边列表：我们使用中心图生成代码边缘列表，列表的每一行包含图中一个有向边的两个节点。</p></li><li><p>将代码边列表转换为向量列表：我们将一行代码视为一个句子，并遵循将句子嵌入向量的方法，同时将代码边嵌入向量中。</p></li><li><p>分类：最后，我们选择使用CNN模型构建我们的分类器，并将其用于检测漏洞。</p></li></ul><h2 id="22-method"><a class="markdownIt-Anchor" href="#22-method"></a> 2.2 Method</h2><p>代码边定义：</p><p>函数的程序依赖图包含其控制流和数据流，函数内代码行之间的逻辑关系嵌入在这两种流中。这些流（即控制流和数据流）在程序依赖图中被具体表示为有向边（例如，图1中的实线和虚线）。</p><p>考虑一个函数 f 的 PDG G = (V, E)，其中 V = {n1, …, nk} 是一组节点。一个节点对应于函数中的一行代码。E = {e1, …, ek} 是一组有向边，每条边代表一对节点之间的数据或控制依赖关系。使用代码边来表示PDG中的有向边，并且我们将有向边看作是两个节点之间的方向关系。因此，在PDG的Eei中，代码边缘ei = [nis，nie]由ei的起始节点和结束节点组成。因此，代码边在PDG中包含两个节点（即两行代码），这两个代码节点可能存在数据依赖性、控制依赖性，或者两者兼有。每个节点都包含函数中相应的代码行。请注意，这些边是有向边，这意味着节点“a”指向“b”的语义与节点“b”指向“a”的语义完全不同</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221547446.png" alt="image-20240422154739402" style="zoom:50%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221552952.png" alt="image-20240422155240908" style="zoom:50%;" /><h1 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h1><h2 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h2><h2 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h2><h1 id="4-discusion"><a class="markdownIt-Anchor" href="#4-discusion"></a> 4 Discusion</h1><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CPVD Cross Project Vulnerability Detection Based on Graph Attention Network and Domain Adaptation</title>
      <link href="/2023/12/18/Papers/Vul/CPVD%20Cross%20Project%20Vulnerability%20Detection%20Based%20on%20Graph%20Attention%20Network%20and%20Domain%20Adaptation/"/>
      <url>/2023/12/18/Papers/Vul/CPVD%20Cross%20Project%20Vulnerability%20Detection%20Based%20on%20Graph%20Attention%20Network%20and%20Domain%20Adaptation/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>代码漏洞检测对于软件安全预防至关重要。大规模软件代码中的漏洞注释非常繁琐且具有挑战性，这需要领域专家花费大量时间进行注释。这项工作提供了CPVD，这是一种跨域漏洞检测方法**，基于“学习使用一个具有丰富漏洞标签的项目快速预测另一个项目的漏洞标签”的挑战CPVD使用代码属性图来表示代码，并使用图注意力网络和卷积池网络来提取图特征向量。**在跨域漏洞检测的域自适应表示学习阶段，它减少了源域和目标域数据之间的分布。在本文中，我们在不同的真实世界项目代码上相互测试。与没有域自适应的方法和基于自然语言处理的域自适应方法相比，CPVD更通用，在跨域漏洞检测任务中表现更好。具体而言，对于chr_deb、qemu、libav和sard这四个数据集，它们的F1得分分别为70.2%、81.1%、59.7%和78.1%，AUC分别为88.4%、86.3%、85.2%和88.6%。</p><p>代码属性图，跨域漏洞检测，域自适应表示学习，图注意力网络。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><p>在代码漏洞检测任务中，VulDeePecker、μVulDeePecker、SySeVR、Vuldeeplocator、Devign、BGNN4VD、Reveal和Ivdetect已经表明，使用神经网络进行自动特征提取比专家制作的特征具有更好的性能。VulDeePecker、μVulDeePecker、SySeVR和Vuldeeplocator将代码函数处理为标记序列，标记序列被处理为自然语言文本。然而，Devgin、BGNN4VD、Reveal和Ivdetect体现了通过图神经网络（以下简称GNN）提取代码函数的图结构特征。这些方法已被证明优于特征提取方法，如递归神经网络、Bi-LSTM和GRU。</p><p>然而，前面的技术都导致了漏洞识别问题中的另一个重要问题：项目中缺乏易感代码标签。数据集及其标签用于推动当前的深度学习模型。深度学习模型的预测性能由数据集的数量和质量以及它们的标记决定。由于漏洞标签的稀缺性，历史漏洞不足以训练和验证神经网络模型，尤其是对处于休眠状态的开源项目。</p><p>Vulnerability detection in large-scale software code is timeconsuming, complicated, and error-prone;</p><p>尽管源域和目标属于不同项目的漏洞代码集，但它们在相同的特征提取器后具有相似的特征空间和标签分布。尽管如此，它们的概率联合分布在跨域漏洞检测问题上更进一步。源域和目标域数据集用于漏洞分类任务，因此最终的分类目标是相同的。基于上述前提条件，可以在跨域漏洞识别中使用域自适应方法。</p><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><p>总之，本文的贡献如下：本文提出了一种将图注意力网络和域自适应表示学习相结合的跨域漏洞检测方法CPVD。这是图神经网络与领域自适应相结合进行跨领域漏洞检测的开端。基于这一想法，研究人员可以提出不同的方法来提高漏洞检测性能。本文验证了域自适应方法更适合于未标记的漏洞检测任务。本文验证了在跨域漏洞检测任务中，代码的图形表示优于令牌序列处理。本文验证了只有对源域进行重新采样才能提高漏洞检测性能。</p><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403131546258.png" alt="image-20240313154641145" /></p><h4 id="问题定义"><a class="markdownIt-Anchor" href="#问题定义"></a> 问题定义</h4><p>跨域漏洞代码检测是一个二进制分类问题，旨在将目标域代码分为易受攻击和不易受攻击。跨域漏洞代码检测有两种域分布，即源域代码分布S（C，y）和目标域代码分布T（C，？），其中C是代码函数；y表示漏洞分类标签，y∈{0,1}，0表示没有漏洞，1表示有漏洞，“？”表示未知标签。此外，这两个域分布都有域标签，d∈{S，T}，如果d=S，则xG～S（xG）；else xG～T（xG），其中xG是样本的图特征向量。跨域漏洞检测的目标是训练一个神经网络Nf（C），以不断减少源域漏洞分类损失和域分类损失，最终实现对目标域中的代码漏洞进行准确分类的目标。上述损失可以正式定义为</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403131559058.png" alt="image-20240313155919021" style="zoom:67%;" /><p>其中，L是源域漏洞分类损失，y是漏洞分类标签，Ld是域分类损失，d是域标签。</p><h4 id="代码预处理"><a class="markdownIt-Anchor" href="#代码预处理"></a> 代码预处理</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142126819.png" alt="image-20240314212644742" /></p><p>每个节点都包含一个键、代码语句和属性元素（例如Identifier、AssignmentExpression、ParameterType、ExpressionStatement），边表示节点之间的关系，边类型是对它们关系的描述，类型为IS_AST_PARENT、FLOWS_TO、DEF、USE、CONTROLS等。注意，每个函数都有不同的CPG，因为它们的语义和句法结构不同，所以函数的代码属性图不一定包含所有的边类型。改论文中使用了10种类型的边。</p><p>节点和边的类型分别用one-hot表示，语句用词嵌入技术进行表示。</p><h4 id="图特征提取"><a class="markdownIt-Anchor" href="#图特征提取"></a> 图特征提取</h4><p>图特征提取阶段的输入是标记的源域节点向量和未标记的目标域节点向量；对于标记的源域图，在预训练后输出图的特征向量，而对于未标记的目标域图，使用在源域中训练的模型来提取目标域图的向量特征。</p><p>代码预处理阶段输出的节点特征向量是独立于其他节点获得的，因此节点信息较差。代码属性图是根据代码之间的句法和语义结构构建的，每个节点都有一个语句片段，相邻节点之间存在很大的相关性和依赖性。为了最佳地表示节点特征，有必要将其相邻节点的信息映射到自身。因此使用具有双头注意力机制的图注意力网络。</p><p>由于源域代码具有标签，我们可以根据漏洞分类任务进行预训练，以获得源域图特征向量和训练后的模型。目标域图特征向量可以从训练的模型中获得。预训练损失函数是一个二分类交叉熵损失函数。</p><h4 id="领域自适应表示学习阶段"><a class="markdownIt-Anchor" href="#领域自适应表示学习阶段"></a> 领域自适应表示学习阶段</h4><p>领域自适应表示学习阶段由四个部分组成：重采样和特征映射、源领域漏洞分类器和领域分类器。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142151983.png" alt="image-20240314215125905" /></p><p><strong>Resampling and Feature Mapping</strong></p><p>重采样方法使用SMOTETopek，它是过采样和欠采样的组合。重新采样后的源域平衡数据集和目标域不平衡数据集将进入表示学习网络。</p><p><strong>Source Domain Vulnerability Classifier</strong></p><p>漏洞分类器Cy（xL，yi）的输入是源域代码和源域漏洞标签的特征向量。我们使用完全连接层作为源域漏洞分类器。在每个完全连接的层之后，Relu被用作激活函数，Dropout被用于防止过拟合。为了使目标域样本接近源域样本，除了使用分类损失函数外，我们还设计了域自适应损失函数LST，以不断减少源域和目标域之间的分布差异。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142224423.png" alt="image-20240314222420388" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142225697.png" alt="image-20240314222501665" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142226622.png" alt="image-20240314222647564" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142227904.png" alt="image-20240314222753871" /></p><p><strong>Domain Classifier</strong></p><p>在域分类器中，源域代码的标签为S，目标域代码的标记为T。因此，为了混淆源域和目标域，我们需要最大化域分类误差。域分类器Cd（xG，di）的输入是源或目标域码及其域标签，也就是说，xL∈SõT。我们使用全连接层作为域分类器，在每个全连接层之后使用Relu作为激活函数，并使用Dropout来防止过拟合。DANN[42]设计了一个梯度反转层，确保在反向传播过程中梯度方向自动反转，并在正向传播中进行身份转换。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142228944.png" alt="image-20240314222811899" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142228852.png" alt="image-20240314222820817" /></p><p>领域自适应表示学习阶段利用领域数据分布自适应的思想，在训练过程中训练整个领域表示学习网络。因此，模型训练有两个目标：第一是减少代码漏洞分类错误，以确保源域数据的正确分类；第二是增加域分类错误，混淆两个域的代码输入。因此，这一阶段的总损失函数包括两个部分：源域漏洞分类损失和域分类损失。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><p>与没有域自适应的漏洞检测方法相比，CPVD在漏洞检测任务中的表现如何？</p><p>与适用于领域的漏洞检测方法相比，CPVD在漏洞检测任务中的表现如何？</p><p>本文中的图特征向量提取阶段的设计如何影响漏洞检测的性能？</p><p>对源域数据重新采样如何影响目标域中的漏洞检测性能？</p><p>与最先进的领域自适应方法相比，我们采用的领域自适应表示学习方法如何影响漏洞检测任务？</p><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr /><p><strong>Cross-Domain Vulnerability Detection</strong></p><p>跨域漏洞检测问题可以看作是一个训练模型并学习通过使用具有大量标签的源域代码来预测目标域代码的漏洞标签问题的问题。因为标签只有两种（漏洞或非漏洞），所以它也可以被视为二分类的问题。==跨域漏洞检测以源域和目标域的代码函数为输入。它使用距离或对抗性网络来测量源域和目标之间的相似性。==它学习目标域的漏洞预测函数F:Xt→ yt，连续训练F使其具有最小的预测误差，然后在目标域中正确地预测输入代码的漏洞分类标签。</p><p><strong>Graph-Based Code Representation</strong></p><p>图的节点表示表达式或代码语句，基于图的表示的边反映节点之间的关系，如控制流、控制依赖关系和数据依赖关系。</p><p>语法树（以下简称AST）是一种特殊类型的图结构。AST是代码解析器理解程序基本结构并检查语法错误的第一步。它可以用于将源代码表示为树。关于语法CD VulD[19]、code2vec[22]和Infercode[23]的结构的信息是以AST结构表达源代码的作品的示例。</p><p>控制流图（以下简称CFG）是一种有向图，它描述了程序中进程的所有可能的实时执行流。条件语句控制执行路径，CFG的节点是单个语句。Cheng等人[24]、Zhuang等人[25]和Yu等人[26]以CFG的形式表示源代码。代码属性图（以下简称CPG）[27]由AST、数据流图、CFG和程序依赖图组成。代码属性图的每个元素都提供了关于源代码整体语义结构的附加上下文。总之，代码属性图是有向的、边类型的属性多重图，至少有一个属性指示每个节点的类型。Devign[13]、BGNN4VD[14]和VulSnipper[28]是由CPG表示为源代码的作品的示例。</p><p><strong>Word Vector Embedding</strong></p><p>Word2vec[29]是一种将语言文本中的每个单词转换为向量的编码方法，然后可以表示单词之间的关系。skip gram模型和CBOW模型包含在Word2vec中。漏洞发现作业中最常用的单词嵌入方法是Word2vec[10]、[11]、[13]、[14]、[30]、[31]。Glove的主要想法是通过统计语料库中同时出现的单词的数量来收集有关全局单词的统计信息[32]。它是一个全局无监督对数双线性回归模型，用于描述无监督学习中的单词表示。Glove还用于表示具有代码函数[16]、[33]的单词嵌入。除了上述两个用于处理图[35]、[36]中节点中代码语句的单词嵌入之外，Doc2vec[34]还被用作程序表示的单词嵌入。研究[35]还发现，在JAVA语言漏洞检测工作中，TF-IDF[37]词向量嵌入方法的性能优于Doc2vec。</p><p><strong>Graph Neural Networks</strong></p><p>由于其卓越的性能和可解释性，图神经网络被广泛应用于推荐系统、知识图分类、文本分类等领域。由于表示学习和单词嵌入的成功，图嵌入和图神经网络已被应用于静态代码漏洞检测任务。图卷积神经网络、[38]门控图神经网络（以下简称GGNN[39]）和GAT是图神经网络的例子。GCN在图神经网络中加入了卷积层的概念，GGNN在图神经网中加入了门控递归单元，GAT在图神经网上加入了注意机制；GAT也是卷积图神经网络的一种。GGNN是一种广泛用于漏洞检测的图神经网络模型，用于提取图特征向量[13]，[14]，[15]，[40]。</p><p><strong>Domain Adaptation</strong></p><p>源域是描述领域自适应中当前先验知识的数据集，而目标域是需要算法学习新知识的数据集[41]。==域自适应的本质是源域和目标域之间的数据分布差异；==因此，数据特征分布自适应将是一个挑战。为了完成从源域到目标域的迁移操作，我们需要设计一种适当的测量方法，该方法能够自适应地估计数据分布的多样性，并不断缩小它们之间的差距。当标签明显缺失时，现在解决不同数据集之间的模型转移是一个关键概念。领域对抗性神经网络（以下简称DANN）[42]是一种领域自适应，它将对抗性机制添加到神经网络的训练中，由三部分组成：特征提取器、分类器和领域鉴别器。特征提取器，通常是神经网络模型，从源域和目标中的数据中提取特征向量；该分类器接受特征向量并将其用于下游分类任务。领域鉴别器决定输入图特征属于哪个领域。DANN有两个目标：一是减少代码分类器的分类误差，二是增加领域的分类误差。DANN被认为是在数据分布自适应的背景下进行边缘分布自适应的一种对抗性策略。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepVD Toward Class-Separation Features for Neural Network Vulnerability Detection</title>
      <link href="/2023/12/18/Papers/Vul/DeepVD%20Toward%20Class-Separation%20Features%20for%20Neural%20Network%20Vulnerability%20Detection/"/>
      <url>/2023/12/18/Papers/Vul/DeepVD%20Toward%20Class-Separation%20Features%20for%20Neural%20Network%20Vulnerability%20Detection/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>包括深度学习（DL）在内的机器学习（ML）的进步使几种方法能够隐式学习易受攻击的代码模式，从而自动检测软件漏洞。最近的一项研究表明，尽管取得了成功，但现有的基于ML/DL的漏洞检测（VD）模型在区分两类漏洞和良性代码方面的能力有限。我们提出了DEEPVD，这是一种基于图的神经网络VD模型，强调漏洞和良性代码之间的类分离特征。DEEPVD在不同的抽象级别上利用了三种类型的类分离功能：**语句类型（类似于词性标记）、后支配树（涵盖常规执行流）和异常流图（涵盖异常和错误处理流）。**我们使用13130种易受攻击的方法，在303个项目的真实世界漏洞数据集中进行了几个实验来评估DEEPVD。我们的研究结果表明，与最先进的基于ML/DL的VD相比，DEEPVD的准确率相对提高了13%–29.6%，召回率为15.6%–28.9%，F评分为16.4%–25.8%。我们的消融研究证实，我们设计的功能和组件有助于DEEPVD实现漏洞和良性代码的高度可分离性。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><p>提出了DEEPVD，这是一种基于图的神经网络VD模型，其目标是利用强调脆弱性和良性类别之间的类分离的特征。我们以以下见解设计DEEPVD。首先，当程序通过一个方法执行时，执行可以以两种方式进行：1）从方法m的开始到m的出口点的规则流，以及2）从m开始到异常/错误处理点的异常/错误操作流。漏洞的主要原因之一是对异常和错误案例的处理不当。例如，程序可能会在输入的数据验证中遗漏一个案例，从而导致通过精心编制的输入进行注入攻击（第二节）。因此，对于方法m，我们捕获从m的输入到异常/错误处理点的程序切片。这些切片被组合成一个数据结构，称为异常流图（EFG）[20]。EFG预计由关键程序元素及其依赖项组成，这些元素与异常/错误的错误处理有关，从而导致漏洞。</p><p>其次，在使用EFG来处理程序中的异常流时，我们还考虑了规则流的每个方法的后支配树（PDT）[21]。<mark>PDT是一个树，其中每个节点表示一个语句，每个边表示后优势关系。如果从s开始到方法出口点的所有路径都必须经过d，则语句d被视为另一个语句s的后支配者。虽然PDT比CFG更简单，但它可以帮助模型学习在通往出口点的规则流中s和d的执行之间的关联。如果d崩溃，s的执行路径将永远不会到达出口点。</mark></p><p>第三，根据Checkmarx[22]的漏洞分析，漏洞代码通常涉及特定的语法类型。因此，我们用一种相当于自然语言处理（NLP）中的词性（POS）标记的技术来增强EFG。POS标记已被证明可以提高下游NLP任务（文本到语音转换[23]、名称实体识别[24]等）的性能。这种标记也应用于代码补全，以实现高精度[25]。对于图表示中的每个语句节点，我们将其与一个语句类型相关联，<strong><mark>因为漏洞通常与特定的语句类型相关，例如数组声明/引用、指针声明/引用，赋值和表达式</mark></strong>[14]，[22]。语句类型补充了EFG和PDT捕获的语义依赖关系，并改进了类分离。EFG和PDT被编码并馈送到VD的标签图卷积网络（标签GCN）[26]和树LSTM[27]中。</p><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403212102060.png" alt="image-20240321210200935" /></p><p>1） 代码序列：方法M的代码标记序列在VD中很重要，因为它包含具体的词法值。我们使用lexer来解析和收集给定方法中的所有词法代码标记。我们将语句视为句子，将代码标记视为单词，并使用嵌入模型来生成所有代码标记的向量表示。在获得所有令牌的嵌入后，我们使用门控递归单元（GRU）[29]来生成整个序列的向量。然后，我们应用空间金字塔池（SPP）[30]来逐步减小GRU产生的向量的空间大小。最后，我们在给定的方法M中获得了表示代码序列的特征向量FCS。</p><p>2） AST上的长路径：作为源代码的重要组成部分，抽象语法树（AST）承载着结构和句法信息。直接使用基于树的嵌入模型的AST结构可能会产生较高的计算成本。相反，我们选择长路径而不是从方法体构建的AST。长路径是指从一个叶节点开始，到另一个叶结点结束，并通过AST的根节点的路径。如先前的工作[31]、[32]所示，可以通过AST节点上具有特定长度的路径来捕获和表示AST结构。以长路径中的节点为例，我们使用嵌入模型、基于注意力的GRU层[33]（对于AST结构），然后使用SPP[30]来构建表示给定方法的长路径的向量FLP（第IV节）。</p><p>3） 后支配树（PDT）：我们首先根据Ferrante等人[21]中的算法构建PDT。由于PDT是树形结构的，我们选择使用tree-LSTM[27]来执行PDT的表示学习，这是一种基于树的神经网络模型，已在源代码中表现良好。另一种设计是将支配后关系添加到EFG中，并使用基于图的神经网络模型来学习表示。我们不选择这种替代方案，因为基于图的模型必须学会区分PDT和EFG中的两种类型的关系。PDT中的每个节点都是一个语句。我们将标记视为单词，将语句视为句子，并使用嵌入模型来构建所有标记的向量。嵌入将经过SPP，然后使用树LSTM模型来生成该方法的特征向量FPDT（第五节）。</p><p>4） 异常流图（EFG）：我们遵循Allen和Horwitz[20]中的算法为给定的方法构建EFG。与PDT中一样，每个EFG节点代表一个语句，因此，我们使用单词嵌入模型和SPP层执行相同的过程来为每个语句生成向量。在这一步骤之后，我们获得了一个图结构，其中每个节点（语句）都由一个向量表示。最后，我们将该图结构作为LabelGCN模型的输入，以生成特征向量FEFG（第六节）。</p><p>5） 调用关系：对于方法M，我们考虑调用方/被调用方方法中的调用/被调用语句。与M中的调用/被调用语句和M的调用/被叫语句一起，我们构建了一个星形图。该图中的每个节点都表示一个语句，因此，对于节点内容，我们使用与上面相同的过程来构建语句的向量。我们还应用网络嵌入Node2Vec[34]对节点进行编码。将表示节点内容和调用结构的向量组合以产生特征向量FCR（第VII节）。最后，使用多层感知器对所有的特征向量进行分类。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403212107473.png" alt="image-20240321210748419" /></p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Devign基于GNN的源代码漏洞检测</title>
      <link href="/2023/12/18/Papers/Vul/Devign/"/>
      <url>/2023/12/18/Papers/Vul/Devign/</url>
      
        <content type="html"><![CDATA[<p>Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks：NIPS(A) 2019，Yaqin Zhou et al.</p><h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>本文提出了Devign模型，一个基于GNN的源代码漏洞检测模型，使用GNN学习丰富的代码语义信息。该模型包括一个Conv模块，其功能是提取有用的特征来进行graph-level的分类。该模型在4个大型开源C项目上进行训练和测试，结果表明Devign明显优于现有技术，平均提高了10.51%的准确率和8.68%的F1值。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><p>本文提出了一种基于复合代码表示的图神经网络模型Devign，可以对程序语义信息进行完整的提取，用以各种捕捉漏洞特征。在复合代码表示中，以AST为中心，将不同级别的数据依赖和控制依赖编码为联合图，其中不同类型的边代表不同的依赖特征。这种复合代码表征综合了各种信息，尽可能广泛的捕捉漏洞类型和漏洞模式，使得GNN能够更好的学习节点表征。</p><p>提取复合代码表征后，经过门控GNN模块，通过对邻接节点信息的聚合和传递来得到各个节点的表征。最后，经过Conv模块选择与当前任务相关的节点和特征集合，应用一维卷积和dense层来对节点特征进行提取从而实现图级别的分类。</p><p>另外，为了验证复合程序编码表征的作用，以及使用GNN进行漏洞检测的效果，本文从4个流行的C库中收集人工标记数据集来进行实验。实验结果表明，Devign比现有方法平均提高了10.51%的准确率和8.68%的F1值，而Conv模块带来了4.66%的精度和6.37%的F1值，将Devign应用到从4个项目中收集到的40个最新的CVE中，得到了74.11%的准确率，在发现新漏洞方面体现了该模型的可用性。</p><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062129788.png" alt="image-20240306212907717" /></p><p>上图是Devign的整体架构，包含三个顺序的部分，首先是复合代码语义embedding层，该层将源代码编码为具有多种代码语义的联合图结构；**第二部分是GNN层，该层通过聚集和传递图中相邻节点的信息来学习节点的特征；**第三部分是Conv模块，提取有意义的节点表征用于图级别的分类预测。</p><ul><li>复合代码表征</li></ul><p>程序分析中的各种程序表示被用来显示程序的内在信息，比如AST，CFG，DFG（数据流图）等等捕捉了源代码的语法和语义关系。很多漏洞不考虑复合代码语义就无法发现，比如有研究表明，仅仅使用AST可以查找不安全参数的漏洞，而将AST与CFG结合则可以查找资源泄露和释放后使用漏洞。进一步，将AST，CFG，DFG联合使用，则可以检测多种类型的漏洞。</p><p>除了以上的三种经典的代码结构，Devign还考虑了源代码序列本身，因为它的flatten结构能以一种“人类可读”的方式捕获代码token之间的联系。接下来分别介绍各种类型的代码表示，以及如何将个各种子图表示为一个联合图。下图(a)是整数溢出代码示例，(b)是图表示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062139644.png" alt="image-20240306213943562" /></p><ul><li>GNN层</li></ul><p>图神经网络的核心思想是通过对相邻节点的信息进行聚合来embedding节点表征，本文使用门控递归图网络来学习节点表征。和正常的GNN一样，通过邻接矩阵来对邻接节点的信息进行聚合，将聚合节点和当前节点一起经过GRU网络得到下一时刻的当前节点。以此类推，经过T时刻，生成所有节点的最终的节点表征。</p><ul><li>Conv层</li></ul><p>图分类的标准方法是将所有的节点特征线性的输入到MLP中然后通过softmax分类，这种方法没有注重重点。Conv模块用来选择与当前任务相关的节点和特征集合，应用一维卷积和dense层来对节点特征进行提取从而实现图级别的分类。</p><h3 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h3><ul><li>Q1：Devign相比其他源代码漏洞检测方法，效果如何？</li><li>Q2：Conv模块与普通的flatten的节点融合相比，有什么优势？</li><li>Q3：复合图特征学习相比单一图有哪些优势？</li><li>Q4：在真实场景中，相比于静态分析器，Devign是否有更好的性能？</li><li>Q5：在CVE公开报告的最新漏洞上，Devign的表现如何？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062148291.png" alt="image-20240306214821244" /></p><p>上图是本文使用的数据集示例，本文评估了从4个大型C语言开源项目中收集的手工标记的函数，这些项目在开发人员中很流行，并且功能多样，例如Linux Kernel, QEMU, Wireshark和FFmpeg。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062149478.png" alt="image-20240306214938378" /></p><p>本文利用基于代码属性图的C/C++开源代码分析平台Joern来提取数据集中所有函数的AST和CFG，上图中的Ggrn意思是普通的flatten的节点融合。将DFG图分为3个子图，DFG_C表示变量的定义，DFG_R表示变量的最近一次读，DFG_W表示变量的最后一次写。下图展示了Devign模型与BiLSTM，BiLSTM-Attention，CNN，以及两种静态方法进行比较的实验结果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062149491.png" alt="image-20240306214951439" /></p><p>下面回答之前提出的5个问题：</p><ul><li>Q1：可见Devign相比其他的模型，准确率和F1值都有明显的提高</li><li>Q2：Devign模型与Ggrn模型相比，准确率平均提高3.23%，F1值平均提高3.92%，说明Conv模块提取了更多相关节点和特征用于图级分类</li><li>Q3：对于Ggrn模型，复合图和单一图的区别不大，而对于Devign模型，复合图的效果优于单一图</li><li>Q4：本文创建了一个具有10%漏洞的不平衡数据集，将Devign与著名的开源静态分析工具Cppcheck、Flawfinder和商业工具CXXX进行比较，Devign的F1平均值显著提高，提升幅度达到了27.99%</li><li>Q5：本文分别提取了各个项目的最近的10个CVE漏洞来检查Devign是否可以识别0-day漏洞。通过对40个CVE漏洞的提交修复提取得到112个漏洞函数，将这些函数输入到经过训练的Devign模型中，平均准确率达到了74.11%，显示了Devign在实际应用中发现新漏洞的潜力。</li></ul><h3 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h3><p>本文提出了一种基于复合代码表示的图神经网络漏洞检测模型Devign, 该模型首先生成联合图提取图节点的复合代码表征，然后通过GNN对邻接节点的信息进行聚合来学习节点特征，最后通过Conv模块选择与当前任务相关的节点和特征集合，通过一维卷积和dense层来进行图级别的分类检测。以函数为检测粒度，针对C代码。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trvd Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding</title>
      <link href="/2023/12/18/Papers/Vul/Enhancing%20vulnerability%20detection%20via%20AST%20decomposition%20and%20neural%20sub-tree%20encoding/"/>
      <url>/2023/12/18/Papers/Vul/Enhancing%20vulnerability%20detection%20via%20AST%20decomposition%20and%20neural%20sub-tree%20encoding/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>软件漏洞的爆炸性增长对系统安全构成了严重威胁，已成为当今亟待解决的问题之一。然而，现有的漏洞检测方法在达到检测准确性、效率和适用性之间的平衡方面仍然面临局限性。遵循分而治之的策略，本文提出了TrVD（基于抽象语法树分解的漏洞检测器）来揭示源代码片段中隐含的指示语义，以实现准确高效的漏洞检测。为了便于捕捉细微的语义特征，TrVD使用一种新的分解算法将代码片段的AST转换为大小和深度受限的有序子树集。因此，通过精心设计的树结构神经网络，可以有效地收集每个子树的语义。最后，使用Transformer风格的编码器将所有子树的长程上下文语义聚合到一个特定于漏洞的向量中，以表示目标代码片段。在由不同的真实世界和合成漏洞样本组成的五个大型数据集上进行的广泛实验证明了TrVD在检测漏洞存在和确定漏洞类型方面相对于SOTA方法的性能优势。消融研究也证实了TrVD核心设计的有效性。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h3 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h3><h4 id="可用性"><a class="markdownIt-Anchor" href="#可用性"></a> 可用性</h4><p>其他被广泛采用的代码表示包括CFG、PDG和各种基于图形的变体。这些表示更明确地描述了代码元素之间的控制或数据依赖关系，然而，当面对不可执行或不完整的代码片段时，很难精确推导出这些依赖关系。因此，它们可能并不总是适用于漏洞检测。按照约定，AST可以很容易地为任何代码片段构建，例如文件、函数或单个语句。</p><h4 id="效率"><a class="markdownIt-Anchor" href="#效率"></a> 效率</h4><p>与需要相对复杂和耗时的控制或依赖性分析的代码表示（例如CFG、PDG和代码小工具）相比，从代码构建AST要简单得多，重量轻，从而有助于提高整个检测方法的效率。</p><h4 id="语义综合性"><a class="markdownIt-Anchor" href="#语义综合性"></a> 语义综合性</h4><p>那些人工创建的代码表示（例如，PDG和XFG）倾向于强调代码的特定方面，例如控制流或数据依赖关系。然而，它们经常在转换过程中丢失一些重要信息，这会导致语义损失，尤其是在表示不完整的代码片段时。不同的是，AST使源代码具有高度结构化的性质，其中关于语句和表达式的底层语法是直接可用的；也就是说，AST提供了更全面、更丰富、更精确的代码语义，使TrVD不遗漏任何可疑的漏洞含义，提高了检测的准确性。</p><h3 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h3><p>如前所述，为了充分利用AST的潜力并有效应对其使用带来的挑战（这对漏洞检测能力产生了重大影响），TrVD遵循了经典的分而治之策略。</p><p>Divide</p><p>使用基于图/树的神经网络编码整个AST，如GCN、GAT、tree LSTM和TBCNN，在处理大型/深层树结构时，使用过平滑嵌入捕获长程依赖性可能会大大降低。由于资源限制，这些耗费时间和内存的模型直接处理这样大/深的AST也是非常不可行的。在这方面，<mark>TrVD选择通过分解算法将整个AST划分为有序的子树集，每个子树对应于原始代码片段中的细粒度完整代码单元</mark>。这产生了两个优点：（1）每个子树包含有限（小得多）数量的节点和可控的树深度，并且可以由通用树或图神经网络以成本低廉的方式进行操作；以及（2）更重要的是，这提供了一个机会，通过关注大小受限的本地代码单元来更好地掌握指示漏洞信息的微妙语义，否则可能很容易被忽视。</p><p>Conquer</p><p>TrVD采用“先综合获取后关键点聚焦”的方案，实现对指示性和可疑漏洞语义的有效提取。具体来说，TrVD首先用新设计的树结构神经网络处理每个子树，将其对应代码单元的语义映射到数字向量中。基于所学习的子树嵌入，TrVD然后利用基于Transformer的主干来不同地关注越来越不重要的子树，以发现具有自注意机制的漏洞模式，并将所有子树的长程上下文语义融合到密集的、特定于漏洞的数字向量中，以表示目标代码片段。从这个意义上说，TrVD在代码表示学习中的方式类似于基于切片的方法，其中通过根据兴趣点对相关语句进行切片而生成的代码小工具（例如，库/API函数）通过常规NLP模型（例如LSTM）容纳有助于学习局部特征和帮助精确定位漏洞模式的信息。但是，在TrVD中细化的子树更结构化，不那么模糊，而为注意力增强子树聚合而设计的Transformer能够更好地嵌入上下文，以提高漏洞检测性能。</p><h3 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h3><ul><li>我们提出了一种新的漏洞检测方法，称为TrVD，在每个公式化阶段都经过精心设计，使其成为一种准确、高效、更实用的方法，适用于代码片段。具体而言，为了提高其检测隐藏良好的漏洞和特定漏洞类型的能力，它结合了新的AST分解、注意力增强子树编码和上下文感知语义聚合，从而能够从目标代码片段中提取微妙但特定于漏洞的语义，据我们所知，在基于DL的漏洞检测工作中尚属首次。</li><li>我们进行了大量的实验来评估TrVD的性能、不同组成模块的有效性以及运行时开销。实证研究表明，在大多数数据集上，TrVD在检测漏洞的存在或识别特定漏洞类型方面的准确性、F1和精度优于最先进的基于DL的方法。TrVD核心设计的优势，如AST分解和子树编码，也通过消融研究得到了证实。</li><li>我们提供了一个新的数据集来促进漏洞检测研究。该数据集包含264822个C/C++函数，每个函数都标有特定的CWE ID或非易受攻击的基本事实。TrVD实现的数据集和源代码已在https://github.com/XUPT-SSS/TrVD，以促进未来的基准测试或比较。</li></ul><p>AST分解，注意力增强子树编码，上下文感知语义聚合，</p><p>新数据集</p><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h3 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403042035978.png" alt="image-20240304203524892" /></p><p>目标源代码片段依次通过五个主要模块进行处理：</p><p>（1）AST生成器，它以语义保持的方式对代码片段进行规范化，并使用解析器构建其AST；</p><p>（2） AST分解器，使用分解算法将AST转换为有序的子树集；</p><p>（3） 综合语义收集器，通过树结构的神经编码器，将每个子树中传递的语义迭代提取为实值向量；</p><p>（4） 可疑语义焦点，它将所有收集到的子树语义聚合到一个上下文化的嵌入向量中，该嵌入向量通过基于Transformer的模型处理更具漏洞特定性的语义；</p><p>（5） 漏洞检测器，它实现了一个多层感知器（MLP），该感知器具有用交叉熵损失训练的softmax层来预测输出。</p><h4 id="ast-decomposer"><a class="markdownIt-Anchor" href="#ast-decomposer"></a> AST decomposer</h4><h4 id="单个令牌序列"><a class="markdownIt-Anchor" href="#单个令牌序列"></a> 单个令牌序列。</h4><p>遍历算法通常用于将AST展平为记号序列，包括前序遍历（Tang，Shen et al.，2022；Zhang，Wang，Zhang，Sun，&amp;Liu，2020）和中序遍历（Svyatkovskiy，赵，Fu，&amp;Sundaresan，2019）。为了避免信息丢失，SBT（Hu，Li，Xia，Lo，&amp;Jin，2018）和SPT（Niu et al.，2022）通过添加额外的符号来指示父子关系，进一步改进了这些方法，以确保线性化的序列可以明确地映射回AST，然而，这会使序列变得更大。另一种方法code2seq（Alon，Levy，&amp;Yahav，2019）将叶节点之间收集的采样路径连接起来，形成单个令牌序列，该序列通常太长，神经编码器无法有效处理语义提取，尤其是漏洞检测任务。</p><h4 id="令牌序列集"><a class="markdownIt-Anchor" href="#令牌序列集"></a> 令牌序列集。</h4><p>PathTrans（Kim，赵，Tian，&amp;Chandra，2021）将AST映射到一组根路径，每个根路径由通过从叶节点向上遍历根或从根向下遍历叶节点而获得的令牌组成（Jiang，Zheng，Lyu，Li，&amp;Lyu，2021），并指出特定代码元素（即叶节点）所在的纵向上下文。根路径可以用作学习令牌嵌入的输入；然而，由于每条路径只包含零碎的代码元素，从中学习到的不完整语义可能会降低训练和检测性能。</p><h4 id="子树"><a class="markdownIt-Anchor" href="#子树"></a> 子树。</h4><p>ASTNN（Zhang et al.，2019）和Infercode（Bui，Yu，&amp;Jiang，2021）等方法不是将AST线性化为标记序列，而是将其分解为一组子树，以利用句法结构。采用不同的粒度来分割AST，其中ASTNN生成与代码语句相对应的非重叠子树，而Infercode生成与表达式等较小代码元素相对应的具有重叠的子树。</p><p>该论文的分解器：</p><p>给定根节点，它通过访问者和构造函数递归地划分子树。访问者沿着AST执行先序遍历，将每个节点传递给构造函数，用于节点类型检查、复合语句分解和子树构建，其中构建的子树按顺序附加到集合中。这里，最终集合中每个子树的顺序由其对应代码在原始代码片段中的位置决定。图中给出了一个示例。3有助于理解我们的AST分解算法及其与ASTNN的区别。更具体地说，以图3（a）中的归一化代码为输入，我们的算法将其AST分解为12个子树，按其在代码中的出现顺序排列。与ASTNN相比，我们的算法的差异也得到了说明：对于代码中从第6行到第10行的if复合语句，我们的方法生成一个集成子树，而ASTNN将其拆分为三个子语句的平凡子树，如图中蓝色虚线所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403192205858.png" alt="image-20240319220539749" /></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404182057753.png" alt="image-20240418205716678" style="zoom: 50%;" /><h4 id="算法解释"><a class="markdownIt-Anchor" href="#算法解释"></a> 算法解释</h4><p><strong>输入参数：</strong></p><ul><li><p>T：输入的抽象语法树（AST）。</p></li><li><p>α：子树的最大深度限制。</p></li><li><p>β：子树中允许的最大节点数限制。</p></li><li><p>C：一个包含特定类型语句的列表，这些语句被认为是复合语句。</p></li></ul><p><strong>输出：</strong></p><ul><li>D：一个有序的子树集合。</li></ul><p>TREESPLITTING 函数：这是算法的核心函数，它递归地遍历AST，并根据给定的参数将树分解成子树。</p><p><strong>初始化：</strong></p><ul><li>node：从当前树 t 获取根节点。</li></ul><p><strong>处理语句节点：</strong></p><ul><li>如果 node 是一个语句节点（即不是复合语句），并且它不在复合语句类型列表 C 中：<ul><li>如果节点的大小（trSize(node)）小于 α 并且深度（trDepth(node)）小于 β：<ul><li>构造一个以 node 为根的子树，并将其添加到子树集合 D。</li><li>使用 subTreeConstructor 函数构造子树。</li></ul></li><li>否则：<ul><li>构造一个以 node.header 为根的子树，并将其添加到 D。</li></ul></li></ul></li></ul><p><strong>递归处理子节点：</strong></p><ul><li>对于 node 的每个子节点 child：<ul><li>递归调用 TreeSplitting 函数，将 child、D、α、β 和 C 作为参数。</li></ul></li></ul><p><strong>处理复合语句节点：</strong></p><ul><li>如果 node 是复合语句（即在列表 C 中）：<ul><li>对于 node 的每个子节点 child：<ul><li>递归调用 TreeSplitting 函数。</li></ul></li></ul></li></ul><p><strong>结束函数：</strong></p><ul><li>函数结束时返回子树集合 D。</li></ul><p><strong>复合语句类型列表</strong> C 包含了被认为是复合语句的类型，如函数定义、if、for、while、do-while、switch、try 和 catch。</p><p><strong>算法调用：</strong></p><p>最后，算法通过调用 TreeSplitting(T, D, α, β, C) 来启动，其中 T 是初始的AST。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HyVulDect A hybrid semantic vulnerability mining system based on graph neural network</title>
      <link href="/2023/12/18/Papers/Vul/HyVulDect%20A%20hybrid%20semantic%20vulnerability%20mining%20system%20based%20on%20graph%20neural%20network/"/>
      <url>/2023/12/18/Papers/Vul/HyVulDect%20A%20hybrid%20semantic%20vulnerability%20mining%20system%20based%20on%20graph%20neural%20network/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>提出了一个基于混合语义的图神经网络漏洞挖掘系统HyVulDect，该系统基于漏洞的原因构建了一个复合语义代码属性图用于代码表示。使用门控图神经网络来提取深层语义信息。由于大多数漏洞都与数据流相关，我们使用污点分析来提取污点传播链，使用BiLSTM模型来提取上下文的令牌级特征，最后使用分类器对融合特征进行分类。我们引入了一种双重关注机制，使模型能够专注于与漏洞相关的代码，使其更适合于漏洞挖掘任务。实验结果表明，HyVulDect优于现有的最先进的方法，在基准数据集上可以实现92%的准确率。与基于规则的静态挖掘工具Flawfinder、RATS和Cppcheck相比，它具有更好的性能，可以有效地检测实际的CVE源代码漏洞。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><p>现有的软件往往是大规模和复杂的，项目的代码量急剧增加。简单使用手动审计代码的成本非常高，而且很难发现触发条件复杂的漏洞。机器学习和深度学习的发展也被广泛用于软件漏洞挖掘。基于传统机器学习的方法需要手动提取漏洞的特征，并依赖于大量的专家知识。基于深度学习方法，将源代码视为一个自然语言序列，并使用现有的自然语言处理方法进行特征表示，总结漏洞的特征进行检测和分类。这些方法可以有效地捕获源代码中由漏洞触发的上下文信息。然而，**没有考虑源代码的结构特征，**此外，在代码表示中丢失了许多语义信息。尽管图神经网络可以处理代码图表示等非欧几里得数据，但现有的方法将源代码表示为AST和CFG，缺乏源代码的数据依赖性信息，不利于漏洞的检测。同时，直接使用程序源代码作为图神经网络的输入，引入了大量冗余代码，不利于模型的学习。</p><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><p>我们提出了一种基于混合语义的图神经网络漏洞挖掘系统，该系统利用门控图神经网络和具有双重注意力机制的BiLSTM网络来提取源代码图级和令牌级特征。融合两个维度的深层功能可以有效地用于检测漏洞。</p><p>我们改进了基于API调用的程序切片算法（Li et al.，2021），补充了程序切片的结构，在提取漏洞上下文信息的同时保留了代码的结构信息。</p><p>基于该设计方案的实验表明，HyVulDect的检测性能优于传统的静态扫描工具。与最先进的探测器相比，Devign、VUDDY和BGNN4VD的精度分别提高了27.6%、14.2%和4.9%。同时，它可以有效地检测现有的CVE漏洞。</p><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403052145289.png" alt="image-20240305214500170" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403052230552.png" alt="image-20240305223038459" /></p><p>图7（a）是该程序的源代码，它调用wcscpy函数将宽字符串从源复制到目标。首先，我们定位API函数wcscpy函数，它有两个参数数据和SOURCE_STRING。对于属于用户定义函数F ree_Pointer（）的参数数据，该函数的内部切片由五条语句组成，即程序的第17、18、20、21、23行。第23行的badSink（）函数是一个用户定义的函数，用于接收外部参数数据，该函数的内部切片由四行语句组成，即程序的第0、4、6和12行。对于参数SOURCE_STRING，相关联的语句是第15行、第21行。通过参数数据得到的最终切片序列为：17-&gt;18-&gt;20-&gt;21-&gt;23-&gt;0-&gt;4-&gt;6-&gt;12。通过参数SOURCE_STRING得到的最终切片序列为：15-&gt;21。将两个切片序列按照原来的代码顺序组合起来，去掉重复的代码行，基于API函数wcscpy（）的最终切片代码序列为：0-&gt;4-&gt;6-&gt;12-&gt;15&gt;17-&gt;18-&gt;20-&gt;21-&gt;21-&gt;23-&gt;23。图7（c）显示了基于API函数生成的代码切片，可以看出它有效地减少了代码行数。为了减少语料库的规模，我们一对一地替换用户定义的函数和变量（例如badSink（）-&gt;f unc_0（），data-&gt;var_0）。图7（d）显示了变量命名标准化后的程序切片，有效地减少了令牌的数量。尽管之前的操作有效地提取了与漏洞相关的代码行，并删除了不相关的代码，但源代码的结构不再完整。为了补充源代码的结构信息，我们补充了程序片的结构。我们根据程序源代码的结构来补充代码片的结构。算法1详细描述了程序片结构的补充过程。在解析源代码时，提取代码中用户定义的函数和控制块，以补充切片代码。完成切片后，首先从上到下扫描代码切片。如果这行代码是自定义函数，在这行代码下面加上结构代码“{”，继续向下扫描，直到遇到一行不属于自定义函数的代码，在它前面加上“}”，就完成了对函数结构的补充。对于控制结构，有四种主要结构：if条件语句、switch条件语句、For循环语句和while循环语句。补充逻辑与功能相同。在切片结构的补充过程中，我们遵循这样的原则：首先，完成结构的函数；然后，控制结构，因为控制结构通常包含在功能体中。如图7（e）所示，是最终生成的程序切片。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr /><p>污点分析是一种通过程序跟踪和分析污点信息流的技术（Zheng et al., 2019）。 污点是被污染的消息。 在程序分析中，来自外部和进入程序的信息被视为污染信息。 根据分析的需要，程序内部使用的数据也可以作为污点信息，并可以分析与其对应的信息流。 根据污点分析时程序是否运行，可分为静态污点分析和动态污点分析。</p><p>污点分析主要包括污点的来源、污点的汇聚点和消毒剂。污点源是指将污点数据引入到系统中； 污点聚合点是指系统将污点数据输出到敏感数据区或外界，导致敏感数据区被非法改写或隐私数据泄露； sanitizer是指数据传输不再通过数据加密或重新分配等操作损害系统的完整性和机密性。</p><p>污点分析的过程就是识别程序中污点信息的产生点，并对污点信息进行标记； 利用特定的规则来追踪和分析程序中污点信息的传播过程； 并检查关键操作是否会受到某些关键程序点的污点信息的影响。 污点信息的产生点称为源点，污点信息的检查点称为宿点。</p><p>在漏洞分析中，污点分析技术用于将感兴趣的数据（通常来自程序的外部输入，假设所有输入都是危险的）标记为污点数据。 然后通过跟踪与受污染数据相关的信息流，可以了解它们是否会影响某些关键程序操作并探索程序漏洞。 程序是否存在漏洞的问题转化为该操作是否会使用宿点上的污染信息。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IVDetect</title>
      <link href="/2023/12/18/Papers/Vul/IVDetect/"/>
      <url>/2023/12/18/Papers/Vul/IVDetect/</url>
      
        <content type="html"><![CDATA[<h2 id="一背景"><a class="markdownIt-Anchor" href="#一背景"></a> 一.背景</h2><p>现有的漏洞检测方法大部分只是根据给定代码片段，确认该片段是否包含漏洞（分类）。而并没有指出哪些statement有问题。因此作者提出了IVDetect。主要包括</p><ul><li>用一个新的代码表示方法。作者基于PDG对代码进行表示（源代码用图结构表示），并从PDG提取不同的信息将其向量化。并使用FA-GCN（Graph Convolution Network with feature-attention）对其进行分类。</li><li>用可解释方法（GNNExplainer）对FA-GCN的分类结果进行解释。GNNExplainer基于edge-mask对输入图选取子图进行解释。作者试图找出是哪些statement决定了分类结果。</li></ul><p>作者用三个数据集进行测试： Fan，Reveal，FFMPeg+Qemu</p><h2 id="二motivation"><a class="markdownIt-Anchor" href="#二motivation"></a> 二.motivation</h2><p>example：</p><p>下面展示了linux 4.6的<code>ec_device_ioctl_xcmd</code>方法。这个方法为CromeOS设备构造I/O控制命令。编号为CVE-2016-6156</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">long</span> <span class="title function_">ec_device_ioctl_xcmd</span><span class="params">(<span class="keyword">struct</span> cros_ec_dev *ec, <span class="type">void</span> __user *arg)</span>&#123;</span><br><span class="line"><span class="type">long</span> ret;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cros_ec_command</span> <span class="title">u_cmd</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cros_ec_command</span> *<span class="title">s_cmd</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (copy_from_user(&amp;u_cmd, arg, <span class="keyword">sizeof</span>(u_cmd)))</span><br><span class="line"><span class="keyword">return</span> -EFAULT;</span><br><span class="line"><span class="keyword">if</span> ((u_cmd.outsize &gt; EC_MAX_MSG_BYTES) || (u_cmd.insize &gt; EC_MAX_MSG_BYTES))</span><br><span class="line"><span class="keyword">return</span> -EINVAL;</span><br><span class="line">s_cmd = kmalloc(<span class="keyword">sizeof</span>(*s_cmd) + max(u_cmd.outsize, u_cmd.insize), GFP_KERNEL);</span><br><span class="line"><span class="keyword">if</span> (!s_cmd)</span><br><span class="line"><span class="keyword">return</span> -ENOMEM;</span><br><span class="line"><span class="keyword">if</span> (copy_from_user(s_cmd, arg, <span class="keyword">sizeof</span>(*s_cmd) + u_cmd.outsize)) &#123;</span><br><span class="line">ret = -EFAULT;</span><br><span class="line"><span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">&#125;</span><br><span class="line">+   <span class="keyword">if</span> (u_cmd.outsize != s_cmd-&gt;outsize ||u_cmd.insize != s_cmd-&gt;insize) &#123;</span><br><span class="line">+    ret = -EINVAL;</span><br><span class="line">+      <span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">+   &#125;</span><br><span class="line">s_cmd-&gt;command += ec-&gt;cmd_offset;</span><br><span class="line">ret = cros_ec_cmd_xfer(ec-&gt;ec_dev, s_cmd);</span><br><span class="line"><span class="comment">/* Only copy data to userland if data was received. */</span></span><br><span class="line"><span class="keyword">if</span> (ret &lt; <span class="number">0</span>)</span><br><span class="line"><span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">-   <span class="keyword">if</span> (copy_to_user(arg, s_cmd, <span class="keyword">sizeof</span>(*s_cmd) + u_cmd.insize))</span><br><span class="line">+   <span class="keyword">if</span> (copy_to_user(arg, s_cmd, <span class="keyword">sizeof</span>(*s_cmd) + s_cmd-&gt;insize))</span><br><span class="line"> ret = -EFAULT;</span><br><span class="line"><span class="built_in">exit</span>:</span><br><span class="line"> kfree(s_cmd);</span><br><span class="line"> <span class="keyword">return</span> ret;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>commit信息显示：At line 6 and line 13, the driver fetches user space data by pointer <code>arg</code> via <code>copy_from_user().</code> The first fetched value (stored in <code>u_cmd</code>) (line6) is used to get the <code>in_size</code> and <code>out_size</code> elements and allocation a buffer (<code>s_cmd</code>) at line 10 so as to copy the whole message to driver later at line 13, which means the copy size of the whole message(<code>s_cmd</code>) is based on the old value (<code>u_cmd.outsize</code>) from the first fetch. Besides, the whole message copied at the second fetch also contains the elements of <code>in_size</code> and <code>out_size</code>, which are the new values. The new values from the second fetch might be changed by another user thread under race condition, which will result in a double-fetch bug when the inconsistent values are used.（内核代码看不太懂，大家见谅，希望有大佬能补充下，大概意思就是可能造成double-fetch，一个fetch就是一次获取用户数据（<code>copy_from_user()</code>））</p><p>修复这个bug需要保证在这两次获取用户输入之间变量<code>u_cmd.outsize</code>和<code>u_cmd.insize</code>不会由于条件竞争而改变。</p><p>针对上述问题，DL-based方法可以将上述函数进行分类（是否包含漏洞），但不能定位到一个具体的行（statement），因此作者在这里用可解释的方法对分类结果进行解释。它会提供一个PDG的子图（几个重要的statement）来解释。</p><p>比如：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619008.png" alt="在这里插入图片描述" /></p><p>针对example代码，框出来的即为可解释方法选出的有问题的代码行。同时，针对没问题的代码，可解释方法也会提供相应的信息。</p><h2 id="三key-ideas-and-architecture-overview"><a class="markdownIt-Anchor" href="#三key-ideas-and-architecture-overview"></a> 三.Key Ideas and Architecture Overview</h2><p>IVDetect架构如下图所示：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619001.png" alt="在这里插入图片描述" /></p><p>作者用GNNExplainer作为其解释模型，GNNExplainer会选取关键的子图和子特征（比如一个结点特征向量100维，选取其中5维，不过这需要这个特征向量具备好的解释性，比如词袋向量比word2vec好解释）作为解释。</p><ul><li>对于子特征，如果mask掉node的某些特征会对分类结果造成明显影响，那么该这些特征应该包括在解释结果里</li><li>选取子图的选择是，mask掉子图会影响分类结果（有漏洞变没漏洞），子图由一些关键statement和相应控制依赖和数据依赖组成。</li></ul><h3 id="31-representation-learning"><a class="markdownIt-Anchor" href="#31-representation-learning"></a> 3.1 Representation Learning</h3><p>对于PDG结点（一个statement）的向量表示，作者设置了几组向量特征，一个图结点的最终向量表示由这几组拼接而成。</p><ul><li>Sequence of Sub-tokens of a Statement<br />这里将statement转化成sub-token序列，即将某些token再切分为sub-token，和BERT的tokenizer有些类似。这里作者在sub-token序列中只保存变量名（variables），函数名（method names）和类名（class names）。token会根据CamelCase或者Hungarian convention来进行sub-token，并删除单字符sub-token。比如，对于代码<code>if (copy_to_user(arg, s_cmd, sizeof(*s_cmd) + u_cmd.insize))</code>。sub-token序列为<code>copy, to, user, arg, etc</code>。可以看到并没有<code>if,_,(</code>等token。 之后，用glove来<a href="https://so.csdn.net/so/search?q=%E5%90%91%E9%87%8F%E5%8C%96&amp;spm=1001.2101.3001.7020">向量化</a>单个token，并用GRU将整个statement的序列向量化成向量 F 1 F_1F1​。</li><li>Code Structure of a Statement<br />从AST中捕获一个statement的AST子树，并用Tree-LSTM将其向量化为向量 F 2 F_2F2​。</li><li>Variables and Types<br />对于每个node（statement），收集其中的变量名和变量类型。并用和sub-token同样的向量化方式来进行向量化。比如<code>struct cros_ec_command *s_cmd;</code>中变量名<code>s_cmd</code>，类型<code>cros_ec_command</code>。（这块没太看懂，可能要看下代码了）。得到的向量记为 F 3 F_3F3​。</li><li>Surrounding Contexts<br />将跟该statement存在数据依赖和控制依赖的其它结点分别向量化，并用GRU和glove将这些向量统一计算成 F 4 F_4F4​ 和 F 5 F_5F5​（具体操作还得看代码）。</li><li>Attention-based Bidirectional GRU<br />最后，用Bi-GRU + attention模型将上面得到的 F 1 ， F 2 ， . . , F 5 F_1， F_2， … , F_5F1​，F2​，…,F5​ 转化成 最终结点向量（真的太复杂了）。流程如下图所示</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619044.png" alt="在这里插入图片描述" /></p><h3 id="32-vulnerability-detection-with-fa-gcn"><a class="markdownIt-Anchor" href="#32-vulnerability-detection-with-fa-gcn"></a> 3.2 Vulnerability Detection with FA-GCN</h3><p>下图展示了作者如何用FA-GCN来进行分类任务，FA-GCN在处理稀疏特征以及潜在噪声时非常好用。</p><p>下图中，join layer层之前的操作都是 3.1 中的内容，join layer将所有statement的向量拼成一个矩阵 Feature Matrix。之后就是卷积过程（数学不好没看懂），最终就是通过Classifier分类。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619063.png" alt="在这里插入图片描述" /></p><h3 id="33-graph-based-interpretation-model"><a class="markdownIt-Anchor" href="#33-graph-based-interpretation-model"></a> 3.3 Graph-Based Interpretation Model</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061620149.png" alt="image-20240406162046101" /></p><h2 id="四实验目标"><a class="markdownIt-Anchor" href="#四实验目标"></a> 四.实验目标</h2><p>作者的目标还挺多了，又分类又解释还要挖掘漏洞pattern。</p><h3 id="41-comparison-on-the-method-level-vulnerability-detection"><a class="markdownIt-Anchor" href="#41-comparison-on-the-method-level-vulnerability-detection"></a> 4.1 Comparison on the Method-Level Vulnerability Detection</h3><p>用IVDetect和其它漏洞分类方法进行比较，有VulDeepecker，SySeVR，Reveal，Devign还有token-based方法。作者这里还使用了AutoML来调参。</p><p>评估指标</p><ul><li>Precision ( P )</li><li>Recall ( R )</li><li>F score ( F )</li><li>Mean Average Precision ( MAP )<br />这个指标需要先理解PR曲线，这里有篇从PR-&gt;MAP都有的<a href="https://blog.csdn.net/xys430381_1/article/details/90770520?ops_request_misc=%7B%22request%5Fid%22%3A%22162643753116780269846149%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=162643753116780269846149&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-12-90770520.pc_search_result_cache&amp;utm_term=MAP+%E6%8C%87%E6%A0%87&amp;spm=1018.2226.3001.4187">讲解</a>。</li><li>Normalized DCG<br />貌似是推荐系统用的指标，不是很清楚</li><li>First Ranking ( FR )<br />我也没太看懂这个是用来衡量什么的</li><li>Accuracy under curve ( AUC )<br />AUC曲线，可以参考<a href="https://blog.csdn.net/liweibin1994/article/details/79462554?ops_request_misc=%7B%22request%5Fid%22%3A%22162643810616780255247871%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=162643810616780255247871&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-1-79462554.pc_search_result_cache&amp;utm_term=AUC&amp;spm=1018.2226.3001.4187">这篇</a></li></ul><h3 id="42-comparison-with-other-interpretation-models-for-fine-grained-vd-interpretation"><a class="markdownIt-Anchor" href="#42-comparison-with-other-interpretation-models-for-fine-grained-vd-interpretation"></a> 4.2 Comparison with other Interpretation Models for Fine-grained VD Interpretation</h3><p>这里作者拿GNNExplainer和其它解释方法进行了对比，对比的方法有</p><ul><li>ATT<br />用来衡量边的重要性的Graph attention机制</li><li>Grad<br />基于梯度的方法</li></ul><p>因为解释方法的对比需要有定位到漏洞行号的数据集，因此只有Fan数据集可以使用，其它两个只有哪些方法有漏洞的信息，并没有fix。这里，作者用在Reveal和FFMPeg+Qemu数据集上训练的FA-GCN模型来对Fan数据集分类。</p><p>对于错误分类（标签1，预测0）的作者不考虑进行解释。而同时，由于标签0的函数没有fix信息，解释出来也没法评估，所以作者只考虑标签1预测1的（TPR）。</p><p>Evaluation Metrics：</p><p>对于一个解释子图 G M G_MGM。S SS 为从vulnerable版本的代码中删除和修改的statement的集合。修改的目的是修复漏洞。如果 S ∈ G M S \in G_MS∈GM，那么解释结果算正确，否则错误。也就是所有的vul statement都要包括才行。</p><p>对于fixed版本，S ′ S^{’}S′ 为添加的statement的集合。而此时 G M G_MGM 包含任意一个 S ′ S^{’}S′ 中的statement，就算正确，否则失误。</p><p>作者还用了Mean First Ranking (MFR)和 Mean Average Ranking (MAR)来评估解释结果，不过没太看懂这两个指标。</p><p>需要注意的是作者并没有用fidelity和sparsity这2个指标，也许不符合人的直觉吧。</p><h3 id="43-vulnerable-code-patterns-and-fixing-patterns"><a class="markdownIt-Anchor" href="#43-vulnerable-code-patterns-and-fixing-patterns"></a> 4.3 Vulnerable Code Patterns and Fixing Patterns</h3><p>对于用GNNExplainer产生的一系列解释子图，作者用挖掘算法从这些子图中挖掘出漏洞pattern以及从fixed版本中挖掘fix pattern。这里并没有客观评价指标。</p><h3 id="44-sensitivity-analysis-for-internal-features"><a class="markdownIt-Anchor" href="#44-sensitivity-analysis-for-internal-features"></a> 4.4 Sensitivity Analysis for Internal Features</h3><p>作者在前面提到了对于图结点向量表示用了4种特征（token sequence, AST, type, 控制依赖和数据依赖算一种）。这里作者从只用其中一个特征（token）对statement向量化开始，一步一步添加特征，评估不同特征对结果的影响。</p><p>评估指标和4.1相同。</p><h3 id="45-sensitivity-analysis-on-training-data"><a class="markdownIt-Anchor" href="#45-sensitivity-analysis-on-training-data"></a> 4.5 Sensitivity Analysis on Training Data</h3><p>分别用(80%, 10%,10%), (70%, 15%, 15%), (60%, 20%, 20%)和(50%, 25%, 25%)的(training, tuning, testing)数据集划分比率来研究效果。</p><h3 id="46-time-complexity"><a class="markdownIt-Anchor" href="#46-time-complexity"></a> 4.6 Time Complexity</h3><p>评估实际训练和测试用时。</p><h2 id="五实验结果"><a class="markdownIt-Anchor" href="#五实验结果"></a> 五.实验结果</h2><h3 id="51-comparison-on-the-method-level-vulnerability-detection"><a class="markdownIt-Anchor" href="#51-comparison-on-the-method-level-vulnerability-detection"></a> 5.1 Comparison on the Method-Level Vulnerability Detection</h3><p>这里作者做的对比实验还挺多的，并且分别在FFMPeg+Qemu，Fan，Reveal数据集上分别测试的。</p><p>先看看precision, recall, F1 3个指标<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619015.png" alt="在这里插入图片描述" /></p><p>其它指标</p><p>FFMPeg+Qemu数据集<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619035.png" alt="在这里插入图片描述" /><br />Fan数据集<br /><img src="https://img-blog.csdnimg.cn/20210717150915119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" /><br />Reveal数据集<br /><img src="https://img-blog.csdnimg.cn/20210717150932483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" /></p><h3 id="52-comparison-with-other-interpretation-models-for-fine-grained-vd-interpretation"><a class="markdownIt-Anchor" href="#52-comparison-with-other-interpretation-models-for-fine-grained-vd-interpretation"></a> 5.2 Comparison with other Interpretation Models for Fine-grained VD Interpretation</h3><p>作者对比了3种解释方法的效果（GNNExplainer, Graph Attention, Grad）。用到的指标上面也提到了，accuracy是与分类的类似（correct or incorrect。correct定义上面说过）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619519.png" alt="在这里插入图片描述" /></p><h3 id="53-vulnerable-code-pattern-analysis"><a class="markdownIt-Anchor" href="#53-vulnerable-code-pattern-analysis"></a> 5.3 Vulnerable Code Pattern Analysis</h3><p>作者从前面的解释任务中收集了700+解释子图。作者先用与VulDeepecker和SySeVR相似的符号化（把变量名用VAR替代等待）方式预处理解释子图，然后用下面参考文献1提到的子图pattern挖掘算法配上不同的size限制来挖掘不同大小的子图pattern。</p><p>作者在此进行人工验证。不过没评估好坏，只是数个数。</p><p><img src="https://img-blog.csdnimg.cn/20210717152227969.png" alt="在这里插入图片描述" /><br />作者还贴上了2个example</p><p>下图展现了2个不同的漏洞pattern。第一个属于api误用，包括<code>is_link,exit,cop_file</code>，第二个调用了<code>udf_get_filename</code>这个有漏洞的函数，这个漏洞可以通过添加第5个参数得到修复。<br /><img src="https://img-blog.csdnimg.cn/20210717152339673.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" /></p><p>下图则是fixing pattern。第一个是为了修复多线程下数据加锁类问题，可以看到修复方式就是加锁。第二个图是为了修复一个缓冲区溢出漏洞。<br /><img src="https://img-blog.csdnimg.cn/20210717152359704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" /></p><h3 id="54-sensitivity-analysis-for-features"><a class="markdownIt-Anchor" href="#54-sensitivity-analysis-for-features"></a> 5.4 Sensitivity Analysis for Features</h3><p>下表展示了不同特征对漏洞分类的效果影响。涉及名词有</p><ul><li>sequence of sub-tokens (SST)</li><li>sequence of tokens (ST)</li><li>control dependency（CD）</li><li>data dependency（DD）<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619883.png" alt="在这里插入图片描述" /></li></ul><p>可以看到作者对比的特征是ST，ST+SST，ST+SST+AST等等。逐级递增，但并没有单独测试AST,VAR等等。</p><h3 id="55-sensitivity-analysis-on-training-data"><a class="markdownIt-Anchor" href="#55-sensitivity-analysis-on-training-data"></a> 5.5 Sensitivity Analysis on Training Data</h3><p>数据集切分方式的影响<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619877.png" alt="在这里插入图片描述" /></p><h2 id="六参考文献"><a class="markdownIt-Anchor" href="#六参考文献"></a> 六.参考文献</h2><blockquote><p>[<a href="https://dl.acm.org/doi/10.1145/1595696.1595767">1] Tung Thanh Nguyen, Hoan Anh Nguyen, Nam H. Pham, Jafar M. Al-Kofahi, and Tien N. Nguyen. 2009. Graph-Based Mining of Multiple Object Usage Patterns.</a><br />[<a href="https://arxiv.org/abs/2106.10478">2] Li Y , Wang S , Nguyen T N . Vulnerability Detection with Fine-grained Interpretations. 2021.</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LineVD_Statement-level Vulnerability Detection using Graph Neural Networks</title>
      <link href="/2023/12/18/Papers/Vul/LineVD-Statement-level-Vulnerability-Detection-using-Graph-Neural-Networks/"/>
      <url>/2023/12/18/Papers/Vul/LineVD-Statement-level-Vulnerability-Detection-using-Graph-Neural-Networks/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>当前基于机器学习的软件漏洞检测方法主要在功能级别进行。然而，这些方法的一个关键限制是，它们没有指示导致漏洞的特定代码行。这限制了开发人员有效检查和解释学习模型预测的能力，这对于将基于机器学习的工具集成到软件开发工作流中至关重要。基于图的模型在功能级漏洞检测方面表现出了良好的性能，但其在语句级漏洞检测中的能力尚未得到广泛探索。**虽然通过可解释的人工智能解释功能级预测是一个很有前途的方向，但我们在这里从完全监督学习的角度来考虑语句级软件漏洞检测任务。**我们提出了一种新的深度学习框架LineVD，它将语句级漏洞检测定义为节点分类任务。**LineVD利用图神经网络和基于转换器的模型对原始源代码标记进行编码，从而利用语句之间的控制和数据依赖性。**特别是，通过解决函数级和语句级信息之间的冲突输出，LineVD显著提高了函数代码在没有漏洞状态的情况下的预测性能。我们针对从多个真实世界项目中获得的大量真实世界C/C++漏洞进行了广泛的实验，并证明F1分数比当前最先进的技术提高了105%.</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><p>自动化SVD大致可分为两类：</p><p>（1）传统方法，包括静态和动态分析；</p><p>（2）数据驱动解决方案，利用数据挖掘和机器学习来预测软件漏洞；</p><p>尽管当前的数据驱动方法在识别软件漏洞方面取得了成功，但它们往往局限于粗粒度水平。模型输出通常为开发人员提供有限的预测结果验证和解释信息，导致在评估和缓解软件漏洞时付出额外努力。</p><p>许多SVD解决方案已经从文件级过渡到函数级或切片级预测，其他一些工作进一步利用补充信息，如提交级别的代码更改以及附带的日志消息，来构建预测模型。虽然目标是帮助从业者对有缺陷的代码进行优先级排序，但漏洞通常可以局限于几个关键行。因此，审查大型函数仍然可能是一个相当大的负担。</p><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312182057555.png" alt="image-20231218205705483" style="zoom:67%;" /><p>为了节省空间，我们从一个较小的函数中选择一个漏洞，该函数包含Linux内核（CVE-2018-12896）中的整数溢出漏洞，该漏洞最终可能被利用来导致拒绝服务。通过显式语句级别的预测，可以更容易地解释为什么函数被预测为易受攻击（或者，验证预测是否错误）。语句级SVD模型将第22行上的加法赋值操作标记为最可疑的，该操作包含易受攻击的整数强制转换操作，使开发人员能够更有效地验证和减轻该漏洞。</p><p>先前的工作利用GNNExplainer来导出易受攻击的语句作为模型的解释，以展示在语句级的工作。然而，在我们的工作中，我们发现在对潜在的脆弱性语句进行分类和排序时，性能是不充分和有效的。或者，我们旨在探索在语句级别直接训练和预测漏洞以进行SVD粒度细化的可行性和有效性，这将允许数据驱动的解决方案以完全监督的方式直接利用任何可用的语句级别信息。</p><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><ul><li>提出了一种新颖有效的语句级SVD方法，LineVD实现了显著的改进，F1得分增加了105%；</li><li>研究了构建基于GNN的语句级SVD模型的每个阶段的性能影响，包括节点嵌入方法和GNN模型选择。根据研究结果，开发LineVD是为了通过同时学习功能和语句级别的信息，在很大程度上提高性能。</li><li>LineVD是第一种通过图神经网络联合学习函数级和语句级信息以提高SVD性能的方法，在经验评估中，它显著优于仅使用一种类型信息的传统模型。</li><li>发布了数据集、源代码和带有支持脚本的模型，这为未来的基准测试和比较工作提供了一个现成的实现解决方案。<a href="https://github.com/davidhin/linevd">https://github.com/davidhin/linevd</a></li></ul><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312182110490.png" alt="image-20231218211008424" /></p><p>首先将问题定义为，节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">V\rightarrow Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>的映射，也就是语句是否易受攻击。</p><p>通过学习最小化损失loss:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>L</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>G</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>Y</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">min\sum_{i=1}^nL(f(G_i, Y_i|V_i))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p><strong>Feature Extraction</strong></p><p>LineVD将源代码的单个函数作为原始输入。通过处理函数并将其拆分为单独的语句Vi，首先通过CodeBERT的预训练BPE标记器对每个样本进行标记。在V＝{V1，V2，…，Vn}的集合之后，整个函数和包括该函数的各个语句被传递到CodeBERT中。因此，可以获得函数级和语句级的代码表示。</p><p>具体而言，LineVD分别嵌入了函数级和语句级代码，而不是为函数级嵌入聚合语句级嵌入。CodeBERT是一个双峰模型，这意味着除了函数代码本身之外，它还基于函数的自然语言描述进行了训练。作为输入，它使用一个特殊的分隔符标记来区分自然语言描述和函数代码。虽然函数的自然语言描述是不可访问的，但在这项工作中应用了文献中规定的一般操作，在每个输入前添加一个额外的分隔符标记，使描述为空白。对于CodeBERT的输出，我们使用了分类标记的嵌入，这适用于代码摘要任务。这使我们能够更好地利用CodeBERT模型强大的预训练源代码摘要功能。</p><p>总体而言，使用CodeBERT的LineVD的特征提取组件产生n+1个特征嵌入：一个嵌入用于整个函数，n个嵌入用于每个语句，我们分别表示为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mi>v</mi><mo>=</mo><mrow><msubsup><mi>x</mi><mn>1</mn><mi>v</mi></msubsup><mo separator="true">,</mo><msubsup><mi>x</mi><mn>2</mn><mi>v</mi></msubsup><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msubsup><mi>x</mi><mi>n</mi><mi>v</mi></msubsup></mrow></mrow><annotation encoding="application/x-tex">Xv={x^v_1,x^v_2,…,x^v_n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9125em;vertical-align:-0.24810799999999997em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span>。</p><p><strong>Graph Construction</strong></p><p>在LineVD中，我们专注于数据和控制相关性信息，为此我们引入了图注意力网络（GAT）模型。如第2.2节所述，图神经网络（GNN）基于信息扩散机制学习图结构数据，而不是将信息压缩成平面向量，平面向量根据图的连通性更新节点状态，以保留重要信息，即拓扑依赖信息。</p><p><strong>Classifier Learning</strong></p><p>目标是训练一个可以同时从函数级和语句级代码中联合学习的模型。为了实现这一点，我们认为函数级和语句级代码片段对预测结果的贡献相等。因此，我们利用函数级CodeBERT嵌入的输入和从GAT层获得的语句嵌入，构建了一组共享的线性层和dropout层。</p><p>虽然易受攻击的语句可能足以指示函数易受攻击，但我们使用元素乘法构建LineVD，以进一步利用函数级别的信息进行训练。此外，这种操作和谐地平衡了函数级和语句级嵌入之间的冲突输出，并将证明某些场景的决策是合理的，即，如果函数级嵌入的输出类为零，那么所有语句级输出也为零。对此的直觉是，非易受攻击的函数不可能具有易受攻击的代码行。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><p>最近的研究表明，SVD模型应该根据能够代表真实世界漏洞不同特征的数据进行评估[10]。这意味着评估从真实世界项目中提取的源代码（即非合成的），同时保持不平衡的比率，这是软件项目中漏洞固有的。在现实世界场景中应用时，使用不满足这些条件的数据集会导致模型性能的不一致。另一个数据集要求是足够多的样本，理想情况下跨越多个项目，以便获得一个可以很好地推广到看不见的代码的模型。最后一个要求是在语句级别访问基本事实标签，或可追溯到修复前代码，即原始gitcommit。</p><p><strong>Ground-Truth labels</strong></p><p>为了获得易受攻击和非易受攻击线路的基本事实标签，我们遵循文献[19，32]中的断言，而不是提出我们自己的启发式方法：（1）漏洞修复提交中删除的线路用作易受攻击的线路的指标，以及（2）所有依赖于添加线路的控制或数据的线路也被视为易受攻击。第二点的理由是，在漏洞修复提交中添加的任何行都是为了帮助修补漏洞。因此，在漏洞修复提交中未修改但与这些添加的行相关的行可以被视为与漏洞相关。为了获得与依赖于添加行的行相对应的标签，我们首先获得样本前后版本的代码变化，其中Big Vul中的样本指的是函数级代码片段。对于之前的版本，我们删除所有添加的行，对于之后的版本，删除所有删除的行。在这两种情况下，我们都保留空白占位符行，以确保行号的一致性。从后版本中提取的代码图可用于查找所有依赖于添加行的控制或数据行，这些行的行号对应于前版本。这组线可以与删除的线组合，以获得单个样本的最终脆弱线集。注释行被排除在代码图中，因此不用于训练或预测。这可以从图1和图2中看出；在这种情况下，只有一个修改的行，它被视为删除的行（22）和添加的行（23）。在这种情况下，前后版本的控制和数据依赖边恰好相同，因此我们可以使用图2来识别依赖于第23行的控制/数据的行，即第3、19和21行。</p><p><strong>Cleaning</strong></p><p>原始数据集中的一些样本被错误地截断，导致代码样本无法解析且无效。例如，一个原本是50行的函数可能会因为没有明显原因而被错误地截断为40行。原因可能是数据集最初是如何构建的错误；然而，在整个数据集中只有30个这样的样本。我们使用80:10:10的随机训练/验证/测试分割比。对于训练集，我们对不可破坏样本的数量进行了不足采样，以在函数级别生成近似平衡的数据集，而测试和验证集保持原始的不平衡比例。我们选择在函数级别上平衡样本，因为在语句级别上进行平衡，同时保持函数中语句之间的上下文依赖关系是非常重要的。</p><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><ul><li><p>RQ1：与最先进的基于解释的SVD模型相比，LineVD可以实现多大的性能提升？</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190937348.png" alt="image-20231219093737314" /></p></li><li><p>RQ2：不同的代码嵌入方法如何影响语句级漏洞检测？与其他粒度级别的SVD相比，语句级SVD的代码嵌入方法尚未得到探索。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190940483.png" alt="" /></p></li><li><p>RQ3：图神经网络和函数级信息如何对LineVD性能做出贡献？使用图神经网络的信息传播对语句级SVD的影响还有待探索。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190942923.png" alt="" /></p></li><li><p>RQ4：LineVD在跨项目分类场景中的表现如何？虽然在包含多个项目的数据集上进行训练已经减少了对模型通用性的歪曲，但来自同一项目的样本仍然有可能出现在训练集和测试集中。使用跨项目场景可以更好地表示模型在完全看不见的项目上的表现，而不仅仅是看不到的样本。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190943968.png" alt="image-20231219094311928" /></p></li><li><p>RQ5：对于真实世界的数据，LineVD最能区分哪些语句类型？从语句类型的角度研究模型预测结果，特别是对于真实世界的数据，可以帮助了解模型在哪里表现最好，在哪里失败，这可以指导未来的工作和语句级SVD的改进。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190943357.png" alt="image-20231219094343320" /></p></li></ul><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><p>LineVD，一种用于语句级漏洞检测的新型深度学习方法，它可以让开发人员更有效地评估潜在的漏洞功能。LineVD通过在训练过程中利用图神经网络和语句级信息，在真实世界的开源项目中实现了最先进的语句级漏洞检测。与最新的基于细粒度机器学习的模型相比，这一显著改进表明了直接利用语句级信息进行语句级SVD的有效性。最后，LineVD实现了合理的跨项目性能，表明即使对于完全看不见的软件项目，它也具有有效性和泛化能力。未来的方向将包括探索替代的预训练特征嵌入方法和新的GNN架构，这些架构可以更好地适应软件源代码的底层性质和漏洞。</p><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
            <tag> 代码行级检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Detecting Vulnerabilities using Patch-Enhanced Vulnerability Signatures</title>
      <link href="/2023/12/18/Papers/Vul/MVP/"/>
      <url>/2023/12/18/Papers/Vul/MVP/</url>
      
        <content type="html"><![CDATA[<h3 id="paper"><a class="markdownIt-Anchor" href="#paper"></a> Paper</h3><p>MVP: Detecting Vulnerabilities using Patch-Enhanced Vulnerability Signatures：USENIX 2020，Yang Xiao et al.</p><h3 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h3><p>重复漏洞（Recurring Vulnerability）广泛存在于真实的系统中，这些漏洞通常由可重用的代码库或共享的代码逻辑导致，因此同样的漏洞很可能在其他地方也存在而未被发现。本文提出了一种新的方法<strong>MVP</strong>来检测具有低假阳性和低假阴性的重复漏洞，首先利用新的程序切片技术从漏洞函数及其补丁函数中提取漏洞和补丁的语法和语义特征。如果目标函数匹配漏洞特征，但不匹配补丁特征，则该目标函数会被识别为存在漏洞。</p><p>本文在10个开源系统上对MVP方法进行实验，结果表明，MVP显著优于目前的基于克隆和基于功能匹配的重复漏洞检测的SOTA方法；MVP检测到了通用的漏洞检测方法无法检测到的重复漏洞；MVP检测到97个新的漏洞，并获得了23个CVE认证。</p><h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3><p>由于软件系统中代码库的重用或代码逻辑的共享(对不同用途的相似对象使用相似的处理逻辑)，使得具有相似特征的重复漏洞广泛存在，但在现实程序中却无法检测到，因此，重复漏洞检测得到了广泛的普及。本文的目的就是检测重复出现的漏洞，也即给定一个在程序中以一种特定的方式运行的漏洞，检测其他程序是否可能存在这种同样形式的漏洞。</p><p>现有的检测重复漏洞的方法可以分为两种：</p><ul><li>一种是基于代码克隆的方法，该方法将重复漏洞的检测问题视为代码克隆的检测问题，从已知的漏洞中提取token或语法级的signature，并将该signature的克隆代码视作漏洞。</li><li>另一种是基于函数匹配的方法，该方法不考虑任何漏洞特征，直接将已知的漏洞函数作为signature，检测是否存在这些signature的克隆函数。</li></ul><p>该领域目前存在的两个主要挑战是如何区分已经修补完成的漏洞，减少假阳性率；以及如何精确的生成一个已知漏洞的signature，来减少假阳性和假阴性。</p><p>本文提出了一个针对重复漏洞的漏洞检测方法MVP，<strong>为了解决第一个挑战，MVP不仅生成漏洞的signature，还同时生成补丁的signature</strong>。利用漏洞特征来检测可能存在的漏洞，并利用补丁特征来区分这些漏洞是否已经打过补丁。<strong>为了解决第二个挑战，我们提出了一种新的切片方法，只提取与漏洞和补丁相关的语句，在语法和语义级别生成更加精确的漏洞和补丁的signature</strong>。此外，我们采用语句抽象和基于熵的语句选择来进一步提高MVP的准确性。</p><p>本文在10个C/C++开源项目上对MVP方法进行了实验，发现了97个尚未被发现的安全漏洞，并获得了23个CVE认证。同时，将MVP与四种现有的SOTA方法进行比较，发现MVP在准确率上明显更胜一筹。</p><h3 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h3><p>本文在10个项目的34019对漏洞和补丁函数上进行了实验，使用SourcerCC同一对漏洞函数和补丁函数的相似度，发现有91.3%的样本对二者相似度均超过了70%，而实验证明有35.1%的真实漏洞目标函数与原漏洞函数的相似度小于70%，所以很难通过仅仅计算目标函数与漏洞函数的相似度来判断是否有漏洞，还要计算目标函数与补丁函数的相似度来综合判断。</p><h3 id="method"><a class="markdownIt-Anchor" href="#method"></a> Method</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958816.jpeg" alt="img" /></p><p>上图是本文MVP模型的Framework架构图，一个以函数为检测粒度的重复漏洞检测框架，主要包含以下3个步骤：(以下用“sig”代指“signature”)</p><ul><li>生成目标函数的sig：输入待检测的目标系统，为系统中的每个目标函数生成sig。</li><li>生成漏洞代码和补丁代码的sig：输入安全补丁程序，生成漏洞和补丁的sig，从漏洞产生和漏洞修复的角度反映漏洞，得到一个具有众多漏洞和补丁sig的待匹配集合。</li><li>将目标系统中的每个函数的sig与漏洞和补丁sig进行匹配：如果在待匹配集合中发现了与目标函数sig相匹配的漏洞sig，但不存在相匹配的补丁sig，则认为目标函数存在重复漏洞。</li></ul><p>接下来进行详细解读。</p><p>首先，定义函数签名，给定一个C/C++函数f，将f的签名定义为一个元组(fsyn，fsem)，其中fsyn是函数中所有语句的哈希值的集合；fsem是由一系列3元组(h1，h2，type)构成的集合，h1和h2表示任意两个语句的哈希值，type ∈\in\in {data，control}表示哈希值为h1的语句和哈希值为h2的语句具有数据依赖或控制依赖关系。<strong>fsyn捕获目标函数的语句作为语法签名；fsem捕获目标函数语句之间的数据依赖和控制依赖关系，作为语义签名</strong>。二者提供了一个函数的补充信息，以帮助提高匹配精度。</p><p>其次，使用(fv,pv)来代表一对漏洞函数和对应的补丁函数。给定一对(fv,pv)，函数Patch Pv由一个或多个hunk（块）组成。hunk是Patch中的一个基本单元，它由上下文行、已删除的代码行和已添加的代码行组成。删除的行在fv中，但不再pv中；添加的行不在fv中，但在pv中。</p><ul><li><strong>生成目标函数的signature</strong></li></ul><p>该过程有3个步骤，首先是parsing过程，使用Joern来parse代码生成代码属性图（一个AST、PDG、CFG联合的数据结构），以获取目标系统的所有函数，对每个目标函数生成AST和PDG。然后对函数做规范化处理，对形参、局部变量和字符串常量替换为同一形式，删除所有注释、大括号、tab、空白。</p><p>最后，进行函数签名的生成，首先对规范化后的函数中的每个语句计算hash值，得到fsyn。接着从函数的PDG中提取两个语句之间的数据和控制依赖关系，每一组关系表示成一个三元组的形式(h1，h2，type)，下图展示了一个从原始目标函数到生成sig的完整过程。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958827.jpeg" alt="img" /></p><ul><li><strong>生成漏洞代码和补丁代码的signature</strong></li></ul><p>给定一对(fv,pv)和Patch Pv，下面阐述如何生成sig来捕获与漏洞相关的关键语句，而不是将fv和pv中的所有语句都包含在内，以此获得小而准确的sig来进行有效匹配。</p><p>首先识别代码变化，通过解析安全补丁的头文件（diff文件）来识别更改的文件，通过解析diff文件来查找已删除和添加的语句及其行号。同时找到所有函数的起始和结束地址，如果一个语句包括一个或多个已删除（已添加）的代码行，则认为该语句已删除(已添加)，通过比较语句行号和函数行号的关系来确定哪些函数被更改。以此可以获得已添加的语句集合 SaddS_{add}S_{add} ，已删除的语句集合 SdelS_{del}S_{del} ，漏洞函数语句 SvulS_{vul}S_{vul} ，补丁函数语句SpatS_{pat}S_{pat} 。</p><p>利用切片技术可以提取相关的语句并排除无关的语句，本文在PDG上执行前向和后向切片，使用SaddS_{add}S_{add}和 SdelS_{del}S_{del} 作为切片的标准。传统的程序切片方法存在一定的问题，比如下图的例子，如果将第18行的条件语句作为切片标准，那么前向切片包含了太多的语句(19-40)，其中会包含很多与该漏洞无关的噪声语句，而如果将标准严格到与18行直接相关的前向切片，则只有23和24行，真正的漏洞行28行又没有包含在内。也就是说<strong>如果要求直接相关，则切片可能不包含漏洞语句，而如果允许间接相关，切片又存在太多的噪声</strong>。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958834.jpeg" alt="img" /></p><p>再比如说下图的例子，如果以第3行的函数调用作为切片标准，由于其没有返回值，因此只能得到后向切片而无法得到前向切片。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958824.jpeg" alt="img" /></p><p>基于以上的问题，本文提出了一种新的切片方法，将SaddS_{add}S_{add}和 SdelS_{del}S_{del} 中的每个语句作为切片的标准。对于后向切片，正常的基于PDG进行后向切片，获取与标准句相数据依赖和控制依赖的所有语句。对于前向切片，根据不同的语句类型执行不同的切片准则：</p><ul><li>赋值语句：正常按照数据流进行前向切片即可</li><li>条件语句：前向切片过程中只针对条件语句中使用的变量或参数切片（只考虑数据依赖），只有当这样产生的切片为空时，才考虑控制依赖</li><li>返回语句：不需要进行前向切片，因为返回值和返回语句与后面的语句无依赖关系</li><li>其他：包括未使用返回值的函数调用语句，对变量和参数的数据依赖语句切片</li></ul><p>（注：上面条件语句和其他语句指的数据依赖并不是严格意义上的数据依赖，而是先回溯到变量和参数的定义语句再求数据依赖，比如上图正常来说第4行和第3行不存在数据依赖，但在上面的语境下是存在的，第4行在第3行的前向切片中）</p><p>将SdelS_{del}S_{del}以及其对应的前向后向切片放在一起，构成了 SdelsemS_{del}<sup>{sem}S_{del}</sup>{sem} 蕴含着该函数已删除的语句的语义信息， SaddsemS_{add}<sup>{sem}S_{add}</sup>{sem} 同理。</p><p>接下来分别从语法和语义级别上计算漏洞sig和补丁sig，即(Vsyn,Vsem)和(Psyn,Psem)，漏洞sig与漏洞的产生相关，补丁sig与漏洞的修补相关。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958801.jpeg" alt="img" /></p><p>首先是计算Vsyn，SdelsemS_{del}<sup>{sem}S_{del}</sup>{sem}包含了漏洞产生的语义信息，但有漏洞的修改过程不涉及删除语句，只有增加语句，因此还要补上与增加的语句数据或控制依赖的原漏洞函数语句，也就是(1)式，然后根据PDG图由Vsyn得到Vsem，由SdelsemS_{del}<sup>{sem}S_{del}</sup>{sem}得到Tsem。接着将 SaddsemS_{add}<sup>{sem}S_{add}</sup>{sem} 和 SvulS_{vul}S_{vul} 做差集找到只存在于补丁函数中的语句即为Psyn，然后先根据PDG图计算漏洞函数的三元组集F，用T和F做差集就可以得到只存在于补丁函数中的语句（新加的语句）的三元组集Psem。</p><p>然而按照上述方式生成Vsyn还是会发现存在噪声，而且发现Vsyn这与删除(添加)语句远的语句更有可能是噪声。因此本文提出了一种基于信息熵的漏洞语句选择方法。</p><p>设目标系统中语句的总个数为N，Vsyn中某个语句s在目标系统中出现的次数为n，则信息熵为</p><p>Is=−log§=−log(nN)∝1nI_s=-log§=-log(\frac{n}{N}) \propto \frac{1}{n}I_s=-log§=-log(\frac{n}{N}) \propto \frac{1}{n}</p><p>对Vsyn中的所有语句的信息熵求和，得到总信息熵 III ，如果 III 高于某一阈值就不断的删除离删除(添加)语句最远的语句，直到低于该阈值，或者直到剩余的语句均为与改动代码直接数据或控制依赖的语句。</p><p>接着对Sdel，(Vsyn,Vsem)和 (Psyn,Psem)进行如上文所述的规范化处理和计算hash值，得到漏洞sig和补丁sig，对所有的漏洞补丁代码对处理后得到待检测集合。</p><ul><li><strong>将目标系统中的每个函数的signature与漏洞和补丁signature进行匹配</strong></li></ul><p>那么有了目标系统中每个目标函数的sig(fsyn,fsem)，以及删除的语句Sdel，漏洞的sig(Vsyn, Vsem)，补丁的sig(Psyn,Psem)，根据以下原则判断目标函数是否具有漏洞（与漏洞sig匹配但与补丁sig不匹配），规则有以下5条：</p><ul><li>目标函数必须包含所有已删除的语句</li><li>目标函数的签名与漏洞签名在语法层次上匹配（Vsyn和fsyn的交集大于某一阈值）</li><li>目标函数的签名与补丁签名在语法层次上不匹配（Psyn和fsyn的交集小于某一阈值）</li><li>目标函数的签名与漏洞签名在语义层次上匹配（Vsem和fsem的交集大于某一阈值）</li><li>目标函数的签名与补丁签名在语义层次上不匹配（Psem和fsem的交集小于某一阈值）</li></ul><h3 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h3><p>实验回答以下五个问题：</p><ul><li>Q1：与最先进的方法相比，MVP在检测重复漏洞方面的准确性如何？</li><li>Q2：与最先进的方法相比，MVP在检测重复漏洞方面的开销程度如何？</li><li>Q3：在MVP的匹配过程中，如何配置阈值？</li><li>Q4：语句抽象和语句信息的采样对结果的影响有多大？</li><li>Q5：其他漏洞检测方法检测重复漏洞的性能如何？</li></ul><p>本文作者对10个开源的C/C++项目代码进行测试，包含了25377个patch和34,378个有变动的函数，具体数据集如下表所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958794.jpeg" alt="img" /></p><p>本文将MVP模型与两类SOTA方法进行对比，一类是基于代码克隆的重复漏洞检测方法，比如Redebug和VUDDY。另一类是基于函数匹配的方法，比如SourcererCC和CCAligner。最后还对比了VulDeepecker和Devign这两种方法，都是目前漏洞检测领域非常优秀的方法。</p><ul><li>Q1：与最先进的方法相比，MVP在检测重复漏洞方面的准确性如何？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958242.jpeg" alt="img" /></p><p>由上图可见，在10个开源系统上MVP模型的准确率和召回率都大幅领先。</p><ul><li>Q2：与最先进的方法相比，MVP在检测重复漏洞方面的开销程度如何？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958250.jpeg" alt="img" /></p><p>由上图可见，该类方法都可以分为系统分析、补丁分析、匹配三部分，简单来说，时间花销与方法的规模是成比例的，ReDeBug是基于token的，VUDDY是基于语法的，MVP是基于语义的，因此所花费的时间也是以此递增。</p><ul><li>Q3：在MVP的匹配过程中，如何配置阈值？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958358.jpeg" alt="img" /></p><p>由上图可见，当匹配的漏洞sig大于0.8且补丁sig小于0.2时，MVP可以达到较高的准确率。当匹配的漏洞sig大于0.8时，召回率会大幅下降，而匹配的补丁sig比例不影响召回率（因为其实相当于不考虑补丁sig的话，主要问题是假阳性率，对召回率影响不大）。</p><ul><li>Q4：语句抽象和语句信息的采样对结果的影响有多大？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958341.jpeg" alt="img" /></p><p>如上图所示，其含义是Vsyn采样时信息熵阈值的大小对结果的影响。有图可见，该采样的效果还是非常明显的，阈值在5时，准确率和召回率最高。</p><ul><li>Q5：其他漏洞检测方法检测重复漏洞的性能如何？</li></ul><p>本文还对比了VulDeepecker和Devign这两种方法，发现MVP的结果远远好于这两种方法，VulDeePecker召回率仅为7.2%，Devign召回率为36.0%。</p><h3 id="limitation"><a class="markdownIt-Anchor" href="#limitation"></a> Limitation</h3><ul><li>MVP只专注于重复漏洞</li><li>使用joern生成代码属性图，只适用于C/C++</li><li>通过宏来修复的漏洞代码无法进行检测</li><li>对形式参数、局部变量和字符串进行抽象，无法发现有相似函数调用或相似数据类型的漏洞</li></ul><h3 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h3><p>本文提出了一个重复漏洞检测模型MVP，该模型通过同时生成漏洞signature和补丁signature的方式来区分漏洞函数是否打过补丁；同时提出了一种新的函数切片方法，只提取与漏洞和补丁相关的语句，在语法和语义级别生成更加精确的漏洞和补丁的signature。方法过程如下：首先对于待检测的目标系统，为系统中的每个目标函数生成signature；接着生成安全补丁数据集中每一个（漏洞，补丁）对对应的漏洞signature和补丁signature；最后将目标系统中的每个目标函数的signature与漏洞和补丁signature进行匹配，如果在待匹配集合中发现了与目标函数signature相匹配的漏洞signature，但不存在相匹配的补丁signature，则认为目标函数存在重复漏洞。该方法以函数为检测粒度，针对C/C++代码。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Modeling and Discovering Vulnerabilities with Code Property Graphs</title>
      <link href="/2023/12/18/Papers/Vul/Modeling%20and%20Discovering%20Vulnerabilities%20with%20Code%20Property%20Graphs/"/>
      <url>/2023/12/18/Papers/Vul/Modeling%20and%20Discovering%20Vulnerabilities%20with%20Code%20Property%20Graphs/</url>
      
        <content type="html"><![CDATA[<h2 id="modeling-and-discovering-vulnerabilities-with-code-property-graphsspa-2014-fabian-yamaguchi-et-al"><a class="markdownIt-Anchor" href="#modeling-and-discovering-vulnerabilities-with-code-property-graphsspa-2014-fabian-yamaguchi-et-al"></a> Modeling and Discovering Vulnerabilities with Code Property Graphs：S&amp;P(A) 2014, Fabian Yamaguchi et al.</h2><h3 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h3><p>本文提出了一种基于代码属性图CPG的源代码漏洞检测方法。代码属性图是包括抽象语法树AST、控制流图CFG和程序依赖图PDG的一个联合数据结构。本文通过图的遍历（graph traversals）来进行漏洞检测，检测的漏洞类别包括缓冲区溢出（buffer overflows），整数溢出（integer overflows），内存泄漏（memory disclosures），格式化字符串漏洞（format string vulnerabilities）。本文使用一个图数据库来实现该方案，并在Linux内核源代码中识别了18个以前未知的漏洞，证明了该方案的有效性。</p><h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148238.jpeg" alt="img" /></p><p>以上图为示例代码，介绍一下AST、CFG、PDG的含义。</p><ul><li>AST</li></ul><p>AST的全名为抽象语法树，是代码解析器或者编译器产生的一种代码的中间表示形式，是很多其它代码表示基础。AST非叶子节点表示运算或赋值操作，叶子节点表示常量或标识符，表达了代码的表达式和语句嵌套生成程序的方式。AST蕴含着丰富的代码语法信息，但缺乏控制流和数据依赖等信息，示例代码的AST如下图(a)所示。</p><ul><li>CFG</li></ul><p>CFG的全名为控制流图，表示了每条代码语句的执行顺序以及需要满足的条件分支，CFG的每个结点表示1条代码语句，结点之间通过有向边连接表示执行的顺序和分支。AST可以经过2个步骤变成CFG：首先用if, while, for等控制语句建立初步的CFG，然后用goto，break等语句来对CFG图进行修正。CFG可以用在许多安全应用上，比如检测已知恶意代码的变种以及指导模糊测试的工具，示例代码的CFG如下图(b)所示。</p><ul><li>PDG</li></ul><p>PDG的全名为程序依赖图，最初用于程序切片任务中，PDG同时包含数据依赖和控制依赖，数据依赖指的是变量的使用语句与变量的定义或赋值语句存在数据依赖；控制依赖指的是一条语句的执行与否依赖于另一条语句执行的结果，则称这两条语句控制依赖。示例代码的PDG如下图©所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148300.jpeg" alt="img" /></p><p>上文所述每种程序表示（AST，CFG，PDG）都是从不同的角度表示程序，而CPG就是要结合这几种表示，属性图在许多图数据库（ArangoDB，Neo4J，OrientDB）中是结构化数据的基础表示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148279.jpeg" alt="img" /></p><p>一个简单的属性图如上图所示，每个节点的属性key均为k，而属性value有x和w两个值，获取属性图的特征信息的主要方式是graph traversals（图的遍历）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148241.jpeg" alt="img" /></p><p>图的遍历有以上3种方式，分别是获取邻接节点，获取类别为l的边的可达节点，以及获取类别为l的边且属性为k和s的可达节点。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148245.jpeg" alt="img" /></p><p>上图就是一个CFG的完整实例，其中包括AST,CFG,PDG的边，包含语法和语义信息，控制依赖和数据依赖</p><ul><li>与AST对比，整个函数的AST被切分成4个语句的AST，并用CFG和PDG的边串起</li><li>与CFG对比，每个语句用它的AST来表示而不仅仅是token序列，并且多了PDG的边</li><li>与PDG对比,  每个语句用它的AST来表示而不仅仅是token序列，并且多了CFG的边</li></ul><p>本文的贡献点：</p><ul><li>CPG：一种结合了AST,CFG,PDG三种程序表示的综合图表示</li><li>CPG遍历检测漏洞：常见类型的漏洞可以被建模为代码属性图的遍历，并生成有效的漏洞检测模板</li><li>高效执行：将CPG导入到图数据库中后，可以高效的处理大型代码库</li></ul><h3 id="method"><a class="markdownIt-Anchor" href="#method"></a> Method</h3><p>下面，使用下图的C代码举例，展示本文是如何通过CPG图的遍历来检测4种代码漏洞的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148251.jpeg" alt="img" /></p><p>channelp-&gt;exit_signal =LIBSSH2_ALLOC(session, namelen +1);这行代码种namelen是用户输入的变量，所以可能会导致漏洞，本文从以下几个方面分析漏洞：</p><ul><li>Sensitive operations：敏感操作包括调用受保护的函数，缓冲区复制数据，比如示例中的算数表达式就需要特别关注，需要检查AST</li><li>Type usage：同时变量类型也需要进行关注，如果namelen是16位而不是32位变量就不会出现漏洞，该类型也需要检查AST</li><li>Attacker control：检测哪些data source处于用户控制之下很重要，这个示例中，_libssh2_ntohu32的返回值就是用户可控的，可以借助PDG中的数据依赖来建模</li><li>Sanitization：许多程序由于缺乏数据校验而导致漏洞，在示例中，如果对namelen进行校验，确保它的值在合适范围内，那么漏洞不会发生，此时需要检查CFG</li></ul><p>下面以3种漏洞为例，介绍分析代码属性图提供的不同视图如何有助于构建成功的图遍历以发现漏洞。</p><ol><li>Syntax-Only Vulnerability：在CPG中，语句内部的问题可以通过AST解决，而语句之间的依赖关系则需要CFG和PDG来处理。AST层面主要有如下问题：</li></ol><ul><li><p>Insecure arguments：不安全的参数，主要出自函数调用参数，比如格式化字符串漏洞(printf)，其中格式化字符串的一个必须满足的条件就是传递的第一个参数不是常量（比如%s）。</p></li><li><p>Integer overflows：整数溢出常常发生在内存分配（malloc）的算术运算中（+，*），比如LIBSSH2_ALLOC (session, namelen + 1);的第二个参数。所以在遍历AST时需重点访问malloc类函数调用中的算术运算结点。</p></li><li><p>Integer type issues：问题主要出现在赋值操作中，左边的数据类型宽度要小于右边的宽度（比如左边short，右边int），这在遍历AST的时候可能分别需要遍历赋值运算符的左右子树。</p></li><li><p>Control-Flow Vulnerability：引入CFG可以对更多的漏洞类型建模，通过使用代码属性图的控制流边，可以建模语句的执行顺序，从而可以访问更大范围的漏洞，比如：</p></li><li><p>Resource leaks：当资源被分配（allocate）但并没有被释放的时候，会导致系统爆内存，进而使得无法被外部访问。在CFG中，从分配内存空间的函数调用（malloc）开始，到释放这个指针的函数（free）构成一个路径，如果只有malloc没有free，则说明出现了内存泄露。</p></li><li><p>Failure to release locks：虽然在一般情况下并发问题很难检测到，但可以使用简单的控制流分析来检测在错误路径上没有释放锁的情况。</p></li><li><p>Use-after-free vulnerabilities：内存被释放后没有置为NULL，导致可能被再次利用，简单的控制流分析就足以在一个函数中识别这类漏洞。</p></li><li><p>Taint-Style Vulnerability：结合语法、控制和数据流信息对漏洞进行建模，与只使用语法和控制流的漏洞分析相比，加上PDG可以使用数据流边建模额外的代码漏洞，比如：</p></li><li><p>Buffer overflow vulnerabilities：缓冲区溢出漏洞大多由没有对输入数据进行校验导致，在许多linux内核代码中，当系统从get_user读取外部输入数据作为第3个参数传递给copy_from_user或者memcpy函数时会触发该漏洞。所以遍历的时候需要检查get_user的第一个参数和copy_from_user(memcpy)的第3个参数。</p></li><li><p>Code injection vulnerabilities：在C语言中，注入类漏洞通常在CPG中存在从recv第2个参数到system第1个参数的路径，并且中间没有对字符串进行校验和检查。</p></li><li><p>Missing permission checks：web应用程序和内核代码通常都需要在执行操作之前检查用户权限，这类漏洞没有对用户可控数据进行检查，确保他们有足够的权限。</p></li></ul><h3 id="experiment"><a class="markdownIt-Anchor" href="#experiment"></a> Experiment</h3><p>为了进行评估，我们基于代码属性图的遍历过程实现了一个静态代码漏洞检测系统。针对不同的漏洞类型使用不同的代码表示来处理，如下图所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148630.jpeg" alt="img" /></p><p>本文使用对CPG图遍历的方式在Linux内核源代码中识别了18个以前未知的漏洞，证明了该方案的有效性。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148698.jpeg" alt="img" /></p><h3 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h3><p>本文提出了一种基于代码属性图CPG的源代码漏洞检测方法，基于一种新颖的源代码表示形式，即代码属性图CPG，通过对图的遍历来对常见漏洞进行建模于检测。使用CPG图遍历的方式，本文对缓冲区溢出、格式字符串漏洞和内存地址泄漏等漏洞进行了建模与分析检测。此外，本文还审计了一个Linux内核代码库，并在源代码中确定了18个以前未知的漏洞，这些漏洞由供应商确认并修复。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Path-Sensitive Code Embedding via Contrastive Learning for Software Vulnerability Detection</title>
      <link href="/2023/12/18/Papers/Vul/Path-Sensitive%20Code%20Embedding%20via%20Contrastive%20Learning%20for%20Software%20Vulnerability%20Detection/"/>
      <url>/2023/12/18/Papers/Vul/Path-Sensitive%20Code%20Embedding%20via%20Contrastive%20Learning%20for%20Software%20Vulnerability%20Detection/</url>
      
        <content type="html"><![CDATA[<h1 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h1><p>为了获得代码的结构信息，当前的学习方法通常将程序抽象成图的形式（例如，数据流图，抽象语法树），然后基于安全和易受攻击的代码片段的（子）图来训练底层分类模型以进行漏洞预测。然而，这些模型仍然不足以精确检测缺陷，因为这些模型的目标是产生分类结果，而不是理解漏洞的语义，例如，关键的漏洞触发路径，这对于静态漏洞检测至关重要。本文提出了ContraFlow，这是一种选择性但精确的对比值流嵌入方法，用于静态检测软件漏洞。**ContraFlow的新颖之处在于使用自监督对比学习从预训练的路径嵌入模型中选择和保留可行的值流（也称为程序依赖）路径，从而显著减少了训练昂贵的下游模型进行基于路径的漏洞检测所需的标记数据量。**我们使用288个真实项目评估了ContraFlow，比较了八种最近的基于学习的方法。ContraFlow在信息度、标记度和F1得分方面的表现优于这八个基线方法，最高分别提高了334.1％、317.9％和58.3％，而在定位有缺陷的语句方面，ContraFlow的平均语句召回率、平均语句精度和平均IoU方面的改进分别最高提高了450.0％、192.3％和450.0％。</p><h1 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h1><h2 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h2><p>Existing Efforts and Limitations. 最近提出了代码嵌入，旨在通过分布式向量表示来表示代码语义，用于源代码分析和错误检测。</p><ul><li>最初，嵌入方法将程序视为文本标记[49-51]，通过应用自然语言处理技术来学习代码语义，而不需要代码结构信息。后来，几种方法[7, 10, 48, 81]通过保留结构信息（例如，通过程序依赖图）改进了嵌入结果，然后使用图神经网络（GNNs）[41, 47]来分类代码片段的（子）图是否易受攻击。</li><li>尽管学习代码的图表示可以用于代码分类或摘要任务，但对于基于路径的漏洞检测仍然不足。 这是因为输入图表示不区分程序路径，而后端GNNs无法识别程序路径。 图特征是从GNNs中所有连接节点对之间的消息传递中学习的，但不幸的是，缺乏任何可行/不可行的值流（程序依赖）路径的知识。but unfortunately, without the knowledge of any feasible/infeasible value-flow (program dependence) paths.</li><li>因此，这些预测模型并不知道潜在的错误路径，这些路径显示了错误的产生和触发方式。这是静态错误检测的主要目标之一：帮助从业者快速定位并修复报告的漏洞。</li></ul><p>Insights and Challenges. 为了解决上述限制，检测方法需要基于精确的学习模型，该模型能够保留价值流路径，而不是整个图，该图无法区分可行/不可行的程序依赖路径。受到词嵌入中令牌袋的概念的启发，一些最近的代码嵌入方法对抽象语法树（ASTs）或值流图（VFGs）上的路径进行了嵌入以进行代码分类和摘要 [62]。这些方法随机抽样一小部分路径以产生它们的嵌入向量，然后聚合它们形成代码片段的最终表示。然而，这些方法不能直接用于诸如基于路径的错误检测等复杂任务，因为可能存在需要嵌入的无界程序路径的数量。</p><p>基于路径的模型的有效性在于路径选择策略。**识别和保留个别可行路径而不是通过随机抽样聚合不可行或与错误无关的路径是具有挑战性但重要的，**以避免在嵌入过程中出现不精确。这需要在模型训练过程中选择性地学习具有判别特征的路径，这些特征在 bug 语义中起作用，以产生用于基于路径的漏洞检测的精确嵌入。</p><h2 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h2><p>图2通过使用从真实项目POCO（一个用于网络应用程序的库）[31]提取的业务逻辑错误（CWE840）[55]，沿着图1中的三个阶段，阐明了ContraFlow的关键思想。漏洞是由于在rebuild_list(&amp;hd)之后调用set_status(&amp;hd)时API误用引起的，其中hd首先在第2行定义，然后在第6行修改，并在第13行使用。hd的这种错误的值流路径可能导致意外行为并导致服务拒绝。</p><p>注意，从原始代码片段中提取的不同变量的值流路径很大，并且包含许多路径，包括用于可行性检查和嵌入的不可行或与错误无关的路径。我们在阶段（a）中的对比值流嵌入首先对VPE进行预训练，以在潜在空间中保留路径（例如，π1 − π4）的语义，然后使用主动学习在阶段（b）中选择最具代表性的路径，然后进行可行性检查，通过稀疏和受控的值流分析移除不可行的路径π2和π3。阶段（c）进一步微调并解释π1作为训练模型的排名注意分数（π1的90%）中可能存在错误的路径。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221117563.png" alt="image-20240422104749835" /></p><h4 id="a-contrastive-value-flow-embedding"><a class="markdownIt-Anchor" href="#a-contrastive-value-flow-embedding"></a> (a) Contrastive Value-Flow Embedding.</h4><p>如图2（a）所示，该阶段的输入是从代码片段中提取的一组值流路径袋，例如，π1（○2 → ○6 → 1○3），π2（○3 → ○9 → 1○3），π3（2○ → ○6 → 1○5）和π4（○3 → ○9 → 1○5）。我们将它们两次馈送到值流路径编码器（VPE）中，使用VPE中的不同dropout掩码[61]，以获得它们的向量表示，例如，vπ1，vπ2，vπ3和vπ4，以及它们的对应对比表示[26]，例如，v+π1，v+π2，v+π3和v+π4。VPE是使用对比学习进行预训练的，以捕获价值流路径的语义，使得预训练的相似嵌入向量（例如，vπ1和v+π1）彼此保持接近，而不相似的对（例如，vπ1和v+π3）则相距较远，如图2(a)所示的二维特征空间。</p><p>VPE的参数在反向传播过程中通过最小化NCE损失[9]来自动更新[33]，该损失编码了价值流嵌入向量之间的相似性。</p><h4 id="b-value-flow-path-selection"><a class="markdownIt-Anchor" href="#b-value-flow-path-selection"></a> (b) Value-Flow Path Selection.</h4><p>对value-flow path抽样，路径可行检查</p><p>该阶段使用从阶段（a）预训练的 VPE 将价值流路径转换为嵌入向量。之后，我们根据从自监督主动学习中学到的排名，对代表性的价值流路径进行抽样，例如，π1 − π4。这些路径进一步被输入到路径可行性检查中，以删除不可行的价值流路径。例如，路径 3○→○9 → 1○3 是不可行的，因为在 3○→ 9○ 和 ○9 → 1○3 处的控制流保护符 !FLG 和 FLG 相互矛盾。同样，○2 →○6 → 1○5 也是不可行的。最后，只有可行的价值流路径 π1 和 π4 被保留用于训练阶段（c）的检测模型。</p><h4 id="detection-model-training"><a class="markdownIt-Anchor" href="#detection-model-training"></a> © Detection Model Training.</h4><p>该阶段的输入是由阶段（b）产生的选择的可行且具有代表性的值流路径，这些路径首先使用从阶段（a）转移的VPE模型转换为向量。然后，这些嵌入向量通过一个transformer架构[69]生成每个值流路径的上下文向量。例如，通过与其他向量（例如，π4）进行关注来计算π1的上下文向量，以增加它们对π1的影响。之后，应用软注意力层[1]将这些上下文向量合并为一个向量，用于训练检测模型。</p><p>排名注意力权重指示了不同值流路径对模型输出的贡献。例如，值流路径π1（○2→6○→1○3）的注意力权重最高（90％），而其他路径可以忽略不计，表明该值流路径可能是一个有错误的路径。</p><h2 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h2><h1 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h1><h2 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h2><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221053254.png" alt="image-20240422105310211" style="zoom:50%;" /><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221047923.png" alt="image-20240422104749835" /></p><h3 id="a-contrastive-value-flow-embedding-2"><a class="markdownIt-Anchor" href="#a-contrastive-value-flow-embedding-2"></a> (a) Contrastive Value-Flow Embedding.</h3><p>该阶段旨在使用对比学习训练价值流嵌入模型，值流路径编码器（VPE）。</p><ul><li>给定一组从未标记的源代码中使用现有静态分析器SVF提取的值流路径。</li><li>首先执行数据增强以生成对比值流表示[26]，</li><li>然后利用标准的噪声对比估计（NCE）损失函数[9]来最大化语义上相似的值流路径向量之间的一致性。</li></ul><p>这更新了我们的VPE参数，以促使其保留价值流路径的深层语义。<strong>预训练的VPE在接下来的两个阶段中使用。</strong></p><h3 id="b-value-flow-path-selection-2"><a class="markdownIt-Anchor" href="#b-value-flow-path-selection-2"></a> (b) Value-Flow Path Selection.</h3><p>该阶段旨在精确选择可行且代表性的值流路径，以代表代码片段以支持基于路径的检测模型的快速训练。</p><ul><li>首先使用来自阶段（a）的预训练VPE生成输入路径的特征向量，并使用自监督主动学习[45]对路径进行采样，以捕获最具代表性的路径并使嵌入多样化且信息丰富。</li><li>然后，我们通过对带有注释的值流图（VFG）[12, 64]上的可达性问题进行路径敏感的代码嵌入来执行路径敏感的代码嵌入。</li><li>VFG以稀疏的方式捕获def-use关系，并使用描述控制流传输条件的注释保护边缘。然后，可行性检查被简化为在受保护的VFG上的可达性问题，以仅在低维嵌入空间中嵌入可行路径。</li></ul><h3 id="detection-model-training-2"><a class="markdownIt-Anchor" href="#detection-model-training-2"></a> © Detection Model Training.</h3><p>给定由阶段（b）产生的选定路径和从阶段（a）转移的VPE模型，本阶段将通过仅使用程序的选定路径及其标签（即易受攻击或安全）来训练精确的检测模型。我们首先为每个选定的值流路径获取来自VPE的嵌入向量，然后利用transformer架构[69]为每个路径生成上下文向量以捕获路径之间的交互。然后，这些向量被馈送到软注意力层[1]以对它们进行评分和聚合，形成最终的检测模型训练的一个向量。该模型还可以根据它们对模型输出的贡献来解释重要的值流路径和语句，这些贡献是由学习到的注意力分数排名的。</p><h4 id="contrastive-value-flow-embedding"><a class="markdownIt-Anchor" href="#contrastive-value-flow-embedding"></a> Contrastive Value-Flow Embedding.</h4><p>对比性值流嵌入旨在通过预训练 VPE 从未标记的代码片段中学习相似/不相似的受保护值流路径 π 的区分性向量表示 vπ。受保护值流路径 π 包括一系列程序语句，表示变量之间的 def-use 链，每个语句之间的边上的guard用于指示控制流转移条件 [12, 64]。这些guard将在阶段 (b) 中的路径可行性求解过程中使用。算法 1 总结了学习算法。对于每个学习时期，我们生成对比向量表示（第 2 行），并计算对比值流路径之间的对比损失（第 3 行）。VPE 的参数将在训练过程中自动更新（第 4 行）。以下段落描述了对比性值流表示和对比损失函数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221149879.png" alt="image-20240422114932815" /></p><h1 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h1><h2 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h2><h2 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h2><h1 id="4-discusion"><a class="markdownIt-Anchor" href="#4-discusion"></a> 4 Discusion</h1><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SySeVR</title>
      <link href="/2023/12/18/Papers/Vul/SySeVR/"/>
      <url>/2023/12/18/Papers/Vul/SySeVR/</url>
      
        <content type="html"><![CDATA[<h3 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h3><p>软件漏洞检测目前为止还是一个待被解决的重要问题，因为每天都有很多新的漏洞被发现。使用深度学习方法进行代码漏洞检测是非常有效的，这种方式减轻了对于人为定义特征的要求。尽管深度学习在各个领域取得了巨大的成功，但在漏洞检测领域并没有被研究透彻。为了填补这一空白，本文提出了第一个使用深度学习在C/C++源代码上进行漏洞检测的系统性框架，框架名称叫做SySeVR，全称是“基于语法语义的向量表征”，该框架聚焦于如何获取包含语法和语义信息的代码表征以应用于漏洞检测。该方法检测出了15个没有在NVD中报告过的漏洞，验证了模型的有效性。</p><h3 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h3><p>假设软件漏洞是不可避免的，那关键的问题是如何更早的发现这些漏洞。基于源代码的静态检测方法包含有基于代码相似性的方法和基于模式的方法，基于代码相似性的方法只能检测与代码克隆相关的漏洞，而基于模式的方法则需要耗费大量的人力去定义模式。因此，最有效的方法是使用深度学习。</p><p>之前的<a href="https://zhuanlan.zhihu.com/p/265616085">VulDeepecker</a>方法是在代码切片层级上进行漏洞检测的，这个方法有4个缺点：1）只能检测与API调用相关的漏洞；2）只包含了语义信息中的数据依赖；3）特征提取模块只用了BLSTM来实现；4）没有解释假阳性和假阴性的原因。本文的SySeVR框架则克服了以上4个缺点。</p><p>本文提出SySeVR框架核心是为了解答这个问题——“如何提取代码的向量化表征，该表征包含着适用于漏洞检测的语法和语义信息？”为了回答该问题，本文引入SyVCs(语法漏洞候选)和SeVCs(语义漏洞候选)两个概念，分别表示漏洞的语法特征和语义特征(数据依赖和控制依赖)。同时，本文设计了自动化提取SyVCs和SeVCs的算法。</p><p>为了评估SySeVR有效性，本文给出了一个从NVD和SARD中提取出来的包含126种漏洞的数据集，数据集的地址为<a href="https://link.zhihu.com/?target=https%3A//github.com/SySeVR/SySeVR">SySeVR</a>。有了新数据集，SySeVR可以实现以下功能：</p><ul><li>SySeVR验证了多种神经网络模型来进行漏洞检测。BRNN，BGRU比RNN，CNN模型更有效，也比DBN和浅层学习模型更有效。</li><li>BGRU的有效性依赖于训练数据，如果某些语法元素经常出现在代码的漏洞(非漏洞)片段中，那这些语法元素就会导致高的假阳(阴)性率，解释了假阳性率和假阴性率的原因。</li><li>考虑更多的语义信息(比如控制依赖和数据依赖)可以减少30.4％的假阴性率。</li><li>在4个软件产品上应用 SySeVR-enabled BGRU模型，检测出了15个没有在NVD中报告过的漏洞。</li></ul><h3 id="模型结构"><a class="markdownIt-Anchor" href="#模型结构"></a> 模型结构</h3><p>在图像处理领域有一个非常经典的概念叫做region proposal（候选区域），研究者可以从图像中提取出很多的proposal然后向量化，使用深度学习训练检测。对于程序代码而言，我们也可以模仿图像中的操作，利用proposal的思想来完成漏洞检测。</p><p>如果使用函数作为proposal，则粒度太高，无法定位具体漏洞位置；如果使用语句作为proposal则会导致正负样本不均衡，且分割了代码语句之间的语义信息。因此，本文采用语句的集合作为proposal，以其为单位进行代码漏洞检测。</p><p>首先，我们定义表示漏洞语法特征的SyVCs。下图展示了由region proposal的灵感产生的SySeVR的框架。简而言之，本文依次生成了SyVCs，SeVCs，对SeVCs向量化后使用深度学习进行训练和检测。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945931.jpeg" alt="img" /></p><p>总体而言，SyVCs包含了符合某种漏洞语法特征的代码元素（比如函数调用、指针使用）。SeVCs是由SyVCs生成的，在SyVCs的基础上增加了代码的语义信息，它是一部分相互数据依赖和控制依赖的代码语句的集合。下图是一个直观的示例，SyVCs中的每一个红框代表一个SyVC，不同的SyVC可以相互包含，因为其代表不同的漏洞，比如第18行。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945958.jpeg" alt="img" /></p><p>首先说说生成SyVCs。SyVCs包含了符合漏洞语法特征的代码元素，比如上图中18行的data就是一次指针使用，因为第9行出现了’*'号说明了data是指针类型。本文借助抽象语法树来实现SyVCs的生成。对于每一个函数，首先生成函数的抽象语法树，抽象语法树的根节点表示函数，叶子节点表示token，中间节点表示语句或者说连续的token。</p><p>可用于漏洞检测的代码元素可能是AST的叶子节点或中间节点，因此遍历抽象语法树的节点，如果该节点满足某一条漏洞规则，则该节点对应的一个或多个token将作为code element加入到SyVCs中，具体的伪代码如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945978.jpeg" alt="img" /></p><p>接下来是将SyVCs转化为SeVCs。本文借助代码切片技术去定义与SyVCs语义相关的语句，在介绍该过程前首先要了解几个概念。</p><ul><li>CFG：表示控制流图，它的点是函数语句，边为有向边，表示相邻语句间的运行先后关系。</li><li>数据依赖：如果控制流图中有一条A-&gt;B的路径，且在A语句中计算得到的值会在B语句中使用，则称B数据依赖A。</li><li>控制依赖：如果控制流图中有一条A-&gt;B的路径，且B是否执行需要看A执行的结果(即B不是post-dominate A), 则称B控制依赖A。</li><li>PDG：表示程序依赖图，它的点是函数语句，边为有向边，表示相邻语句间的数据依赖或控制依赖。</li><li>前向切片：一个(SyVC)代码元素的前向切片是由一些语句组成的，这些语句包含了在PDG上从该代码元素出发所有可达的点。</li><li>过程间前向切片：过程间前向切片比前向切片多了一些语句，多的语句是在PDG中代码元素可以通过函数调用到达的点。</li><li>后向切片：一个(SyVC)代码元素的后向切片是由一些语句组成的，这些语句包含了在PDG上所有与该代码元素可达的、且以该代码元素为终点的点。</li><li>过程间后向切片：过程间后向切片比后向切片多了一些语句，多的语句是在PDG中可以通过函数调用到达代码元素的点。</li><li>程序切片：由过程间前向切片和过程间后向切片的语句融合构成，删掉了其中重复的部分。</li></ul><p>有了这些概念后，就可以开始生成SeVCs了，SeVCs其实就是与SyVCs中的代码元素相控制依赖和数据依赖的语句的集合，其具体生成的伪代码如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945940.jpeg" alt="img" /></p><p>首先生成源代码的PDG图，对于PDG中一个的代码元素，生成前向切片和后向切片。然后，融合前向切片和被该函数调用的函数的前向切片，得到过程间前向切片。融合后向切片、被该函数调用的函数的后向切片、以及调用该函数的函数的后向切片，得到过程间后向切片。融合过程间前向切片和过程间后向切片得到程序切片，至此，对于PDG中的该代码元素，生成了其对应的程序切片。</p><p>程序切片中的所有函数语句构成一个集合。对于不同的函数的语句而言，调用者的语句在被调用者的语句之前。调整好顺序后，该集合就是该代码元素(SyVC)对应的SeVC了，对SyVCs中的每一个SyVC这样处理，就可以生成SeVCs。下图是一个以25行的data为SyVC的一个转换示例，体现了从PDG到切片到SeVC的完整过程。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945964.jpeg" alt="img" /></p><p>有了SeVCs，之后就是对SeVCs的向量化编码操作了。下图为该过程的详细伪代码，在此不一一赘述。简单来说，对于每个SeVC，首先删除不合法字符，对函数和变量名进行映射标准化(V1,V2,F1,F2之类的)。之后，将每个SeVC的每个单词embedding成固定长度的向量，将单词concate到一起。</p><p>此时要求concate后的SeVC的向量长度为固定值theta，如果不够就补全；如果超过theta就看SeVC向量两端到SyVC元素有没有小于 1/21/21/2 theta的，有则删去另一端至总长度为theta。如果都没有小于 1/21/21/2 theta的，则两端一起删到两端到SyVC元素都为1/21/21/2 theta。这样就将SeVCs编码为了长度为theta的向量的集合，此时给该集合加上标记，有漏洞的SeVC标签为1，没有漏洞则为0，之后使用双向GRU网络训练检测即可。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945970.jpeg" alt="img" /></p><h3 id="实验部分"><a class="markdownIt-Anchor" href="#实验部分"></a> 实验部分</h3><p>本文在NVD和SARD两个数据集上进行实验。对于NVD，本文收集了1591个开源C/C<ins>程序，其中874个是有漏洞的。对于SARD，本文收集了14000个C/C</ins>程序，其中13906个是有漏洞的，这里的有漏洞包含bad和mix，bad指的是有漏洞，mix指的是漏洞版本和修复好的版本都有。合计，本文收集了15591个程序，其中14780个是有漏洞的，对应126种CWE漏洞类型。</p><p>实验过程大体上和前文模型结构讲的类似，其中值得注意的是提取SyVCs的时候如何获取漏洞的语法特征并进行匹配。本文通过checkmarx工具提取出了4中类型的漏洞语法规则。</p><ul><li>API/库函数调用(FC)：包含了811个函数调用，对应于106种CWE漏洞。</li><li>数组使用(AU)：包含87种CWE漏洞，比如数组元素访问，地址计算等等。</li><li>指针使用(PU)：包含103种CWE漏洞，比如不合法的指针计算、引用、传参。</li><li>算术表达式(AE)：包含45种CWE漏洞，不合法的算术表达式，比如整数溢出等。</li></ul><p>下图为这4类漏洞覆盖的CWE漏洞类型。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945424.jpeg" alt="img" /></p><p>有了漏洞特征后重点是如何讲代码元素与漏洞特征进行匹配，下图是一个匹配SyVC的示例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945457.jpeg" alt="img" /></p><ul><li>FC判定需要满足该代码元素是一个函数调用，且属于811种函数调用之中。</li><li>AU判定需要满足这是一个标识符声明语句且包含’[‘和’]’。</li><li>PU判定需要满足这是一个标识符声明语句且包含’*’。</li><li>AE判定需要满足这是一个表达式语句且包含’=’，并且等号右端有两个以上的元素。</li></ul><p>从SyVCs转化为SeVCs按算法做就好，本文最终生成SeVCs的结果如下表所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945468.jpeg" alt="img" /></p><p>在编码阶段使用word2vec进行编码(gensim)，每个单词向量长度为30，一个SeVC最多500个单词，theta为15000。</p><p>最后说说生成标签，该过程分为两步。第一步是生成初始的标签，针对NVD数据集，如果一个SeVC包含的删除或修改的语句前面有’-’，则被标记为1(有漏洞)；而如果一个SeVC包含的移动的语句前面有’-’，且这个文件包含一个已知的漏洞，则被标记为1；其他情况都标记为0。针对SARD数据集，如果一个SeVC提取自一个good程序，则被标记为0；如果提取自bad或mix程序，则分情况，若该SeVC包含至少一个漏洞语句则标记为1，否则标记为0。</p><p>接下来第二步，使用交叉验证的方式来修正标签。比如将数据集分为5份，4份训练，1份测试。在测试过程中发现的假阴性样本（有漏洞的样本检测为无漏洞）将会被考虑是否标错了，对于这类样本手动检查修正标签。</p><p>接下来就是最后的模型结果。本文的实验结果旨在说明四个问题：</p><ul><li>1：SySeVR搭配BLSTM可以检测多种类型的漏洞吗？</li><li>2：SySeVR可以搭配各种各样的神经网络来进行漏洞检测吗，检测效果如何？</li><li>3：考虑控制依赖是否使得SySeVR更加有效，结果好了多少？</li><li>4：SySeVR相比现有的SOTA方法如何？</li></ul><p>对于第一个问题，作者将SySeVR-BLSTM模型分别检测4种类型的漏洞，于VulDeepecker模型的结果进行比较，结果如下图所示，可见SySeVR-BLSTM模型的结果明显优于VulDeepecker模型，证明了该模型可以有效的检测多种不同类型的漏洞。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945484.jpeg" alt="img" /></p><p>对于第二个问题，本文比较了使用LR,MLP,DBN,CNN,LSTM,GRU,BLSTM,BGRU等神经网络进行训练和检测的效果，发现使用BGRU对SeVCs进行训练检测的效果最好。RNNs比CNN更好，CNN比浅层网络更好，假阴性率高于假阳性率(没检测出来的偏多)。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945496.jpeg" alt="img" /></p><p>对于第三个问题，本文分别列举了在各个模型上只使用数据依赖(DD)和同时使用数据依赖控制依赖(DDCD)的模型结果，结果如下所示，可见控制依赖可以很大程度上提升模型的效果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945558.jpeg" alt="img" /></p><p>对于第四个问题，将本文的SySeVR-BGRU模型与Flawfinder,RATS,checkmarx,VUDDY，VulDeepecker进行比较，可见SySeVR-BGRU模型显著强于之前的所有模型。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945707.jpeg" alt="img" /></p><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>本文提出了一个叫做SySeVR的基于深度学习的代码漏洞检测框架，该模型提取待检测代码的语法和语义特征并应用于漏洞检测。大量的实验证明了SySeVR模型的有效性，本文使用SySeVR模型检测出NVD中15个未被报道过的漏洞。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Reveal</title>
      <link href="/2023/12/18/Papers/Vul/Reveal/"/>
      <url>/2023/12/18/Papers/Vul/Reveal/</url>
      
        <content type="html"><![CDATA[<h2 id="一背景"><a class="markdownIt-Anchor" href="#一背景"></a> 一.背景</h2><p>漏洞检测具有重大的意义，针对DLVP（Deep Learning Vulnerability detection）任务，作者在对现有的漏洞检测方法（VulDeepecker, SyScVR）等测试时发现了一些问题。</p><ul><li>在sard等合成数据集训练的模型用在真实场景下（FFMPeg, Qemu, Linux等）效果很差</li><li>在用解释方法（LEMNA等）来解释漏洞检测方法时经常发现模型学习到了无关的特征</li><li>训练/测试数据包含了许多重复</li><li>现有的方法没有解决样本类别不平衡问题</li></ul><p>论文贡献</p><ul><li>提出了新的漏洞检测方法Reveal</li><li>利用Chromium和Debian的修复commit构造数据集</li></ul><h2 id="二数据集"><a class="markdownIt-Anchor" href="#二数据集"></a> 二.数据集</h2><h3 id="21-现有数据集"><a class="markdownIt-Anchor" href="#21-现有数据集"></a> 2.1 现有数据集</h3><p>针对数据集，作者统计的一些结果<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657318.png" alt="在这里插入图片描述" /><br />有合成，半合成，真实 &amp; 类别平衡， 真实 &amp; 类别不平衡</p><ul><li>合成类：包括<a href="https://www.nist.gov/publications/report-static-analysis-tool-exposition-sate-iv">Juliet</a>。使用已知漏洞pattern构造。</li><li>半合成：包括<a href="https://samate.nist.gov/SRD/index.php">SARD</a>和<a href="https://www.nist.gov/publications/national-vulnerability-database-nvd-overview">NVD</a>。它们是从软件产品中提取，并做了一定修改。</li><li>真实：从代码仓库（github）的commit中提取，来自一些bug fix版本。</li></ul><h3 id="22-reveal数据集"><a class="markdownIt-Anchor" href="#22-reveal数据集"></a> 2.2 Reveal数据集</h3><p>从<a href="https://so.csdn.net/so/search?q=Linux&amp;spm=1001.2101.3001.7020">Linux</a> Debian Kernel 和Chromium的vulnerabilitiy fixed patches中构造。</p><ul><li>对于Chromium，从<a href="https://bugs.chromium.org/p/chromium/issues/list">Bugzilla</a>中提取。</li><li>对于Linux Debian Kernel， 从<a href="https://security-tracker.debian.org/tracker/">Debian security tracker</a>中提取。</li></ul><p>该数据集是针对function（单个函数）进行分类的，构造过程如下：</p><ul><li>对于每个patch，从选取其vulnerable版本到fixed版本中被修改过源文件（.c, .cpp）和头文件（.h）。</li><li>对于被修改过的function，将该function修改前的标注为<code>vulnerable</code>。fix之后的标注为clean，其余未在patch中出现的function均标注为<code>clean</code>。</li></ul><p>示例如图<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657344.png" alt="在这里插入图片描述" /><br />v e r s i o n k − 1 version_{k-1}versionk−1​ 表示有漏洞的源文件，v e r s i o n k version_kversionk​ 表示fix版本。<code>ham_0</code>会被标注为vulnerable，<code>ham_1</code>，<code>egg</code>，<code>spam</code>会被标注为<code>clean</code>。</p><p>数据集统计信息如下：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657348.png" alt="在这里插入图片描述" /></p><h2 id="三现有方法"><a class="markdownIt-Anchor" href="#三现有方法"></a> 三.现有方法</h2><p>现有的方法大致可分为token-based和graph-based</p><h3 id="31-token-based"><a class="markdownIt-Anchor" href="#31-token-based"></a> 3.1 token-based</h3><p>token-based模型将源代码当成一个简单的token序列。而序列长度则会很大程度上影响模型发挥，因为源代码token序列可能相当长。所以就有了code slicing（VulDeepecker, SySeVR）。slicing的初衷是不考虑每个代码行，预处理的时候忽略掉许多无关行。slicing技术上从一些interesting points（API调用，数组索引，指针使用）出发。尽管如此，token-based方法将源代码视为序列，容易丢失语义信息。做过slice也会丢失一些依赖。</p><h3 id="32-graph-based"><a class="markdownIt-Anchor" href="#32-graph-based"></a> 3.2 graph-based</h3><p>graph-based模型将代码视为一个基于句法和语义依赖的图。句法依赖包括AST（抽象语法树），语义依赖包括CFG（控制流图），DFG（数据流图），PDG（程序依赖图），Def-Use chain graph。比如<a href="https://blog.csdn.net/qq_44370676/article/details/115326040">Devign</a>使用了CPG（代码依赖图）。一般来说，使用的依赖信息越多，检出率越高，但是本身消耗的资源也会更多。</p><h3 id="33-存在的问题"><a class="markdownIt-Anchor" href="#33-存在的问题"></a> 3.3 存在的问题</h3><p>都存在vocabulary explosion（词表爆炸）问题。词表主要包括一些identifier（变量名，函数名，常量值等）。比如<code>int count = 0;</code>中包括了变量名<code>count</code>。而实际应用中变量名有无限种可能，如果简单粗暴的添加进词表那么100%要爆炸，有一种解决方案（VulDeepecker, SySeVR中采用的）是<strong>符号化</strong>。比如对于变量名<code>count</code>，将其用<code>VAR1</code>替代，对于自定义函数名<code>function</code>，将其用<code>FUNC1</code>替代，以此类推。</p><p>将代码转化为token序列后就是要向量化了，向量化主流的方案就是用embedding layer。这个embedding layer可以采用直接用下游任务（预测代码是否有漏洞）来训练，也可以用Word2Vec甚至Bert来先预训练。VulDeePecker和SySeVR用Word2Vec来将每个token向量化。Devign直接用Word2Vec来向量化一个statement的所有token（有点没搞懂Word2Vec是怎么对序列向量化的）。</p><p>向量化之后就是训练了，训练就需要损失函数，现有的方案采用交叉熵（cross entropy）或者带正则化的交叉熵损失函数。但仅仅靠交叉熵损失函数只能区分是否包含漏洞，并不能让模型学习到有漏洞和没有漏洞的代码的区别。</p><p>此外还有一个问题就是数据不平衡，因为数据集中包含漏洞和不包含漏洞的代码比例非常不协调。</p><h2 id="四reveal"><a class="markdownIt-Anchor" href="#四reveal"></a> 四.ReVeal</h2><p>总体过程如下图所示<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657355.png" alt="在这里插入图片描述" /><br />需要注意的是作者这里进行了2个阶段的训练</p><ul><li>第一个阶段是pre-train（Phase-I）。主要是训练GGNN，目标是能获得良好的graph embedding。</li><li>第二个阶段是train（Phase-II）。主要是训练MLP，目标是获得良好分类结果，SMOTE过采样也主要是应用在Phase-II。</li></ul><h3 id="41-feature-extraction-phase-i"><a class="markdownIt-Anchor" href="#41-feature-extraction-phase-i"></a> 4.1 Feature Extraction (Phase-I)</h3><p>这个阶段的目标是将源代码转化成一个向量，这个向量保存了代码的语义（semantic）和句法（syntactic）信息。因此作者用到了CPG（代码属性图）。</p><p>通常，CPG表示为 G = ( V , E ) G = (V,E)G=(V,E)。V是结点（英文vertices或者nodes）和边集合（edges）。与Devign不同的是，这里每个结点不仅包含原始的一行代码（statement或者code fragment）。还包括statement类型（即这一行代码大概是什么语句，ArithmeticExpression或者CallStatement等等）。</p><p>所以对于一个node v vv的向量化包括2部分</p><ul><li>用one-hot将其类型向量化，得到向量 T v T_vTv</li><li>用word2vec向量化code fragment内容，得到向量 C v C_vCv</li><li>拼接（concat）C v C_vCv 和 T v T_vTv 得到结点向量 x v x_vxv</li></ul><p>对于用Word2Vec向量化，代码里如下：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">node_split = nltk.word_tokenize(node_content)</span><br><span class="line">nrp = np.zeros(<span class="number">100</span>)</span><br><span class="line"><span class="keyword">for</span> token in node_split:</span><br><span class="line">try:</span><br><span class="line">   embedding = wv.wv[token]</span><br><span class="line">except:</span><br><span class="line">   embedding = np.zeros(<span class="number">100</span>)</span><br><span class="line">nrp = np.add(nrp, embedding)</span><br><span class="line"><span class="keyword">if</span> len(node_split) &gt; <span class="number">0</span>:</span><br><span class="line">   fNrp = np.divide(nrp, len(node_split))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   fNrp = nrp</span><br></pre></td></tr></table></figure><p>从<code>node_split = nltk.word_tokenize(node_content)</code>和<code>fNrp = np.divide(nrp, len(node_split))</code>可知对于一行代码（以<code>int a = 10</code>）为例。会将statement先解析成一个token序列，之后用Word2Vec对每个token向量化，然后取所有token向量的<strong>均值</strong>。</p><p>之后便用GGNN来进行结点向量的聚合，GGNN的计算过程前面总结过：<a href="https://blog.csdn.net/qq_44370676/article/details/115701325">图神经网络的计算过程</a></p><p>简单来说，经过GGNN的处理，每个结点的向量由 x v x_vxv 变成 x v ′ x_v^{’}xv′<br />x v ′ = G R U ( x v , ∑ ( u , v ) ∈ E g ( x u ) ) x_v^{’} = GRU(x_v, \sum\limits_{(u,v) \in E} g(x_u) )xv′​=GRU(xv​,(u,v)∈E∑​g(xu​))</p><p>GRU内部公式就不展开了，在RNN序列任务种 h t = G R U ( i n p u t i , h t − 1 ) h_t = GRU(input_i, h_{t-1})ht=GRU(inputi,ht−1) 。u uu 是 v vv 邻居结点，g ( ⋅ ) g(·)g(⋅) 是一个 transformation function。</p><p>最后一步就是用聚合函数（aggregate function）将每个结点的向量聚合成一个向量 x g x_gxg，作为整个CPG，也就是源代码的向量表示。</p><p>x g = ∑ v ∈ V x v ′ x_g = \sum\limits_{v \in V} x_v^{’}xg=v∈V∑xv′</p><p>这里在论文中，作者用向量总和（element-wise summation）作为聚合函数，而实际上在代码里，聚合函数是一个可配置参数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061709378.png" alt="image-20240406170926341" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657330.png" alt="在这里插入图片描述" /></p><h3 id="42-training-phase-ii"><a class="markdownIt-Anchor" href="#42-training-phase-ii"></a> 4.2 Training (Phase-II)</h3><p>现实数据集中的样本不平衡问题非常严重，不包含漏洞的代码数量远超过包括漏洞的。</p><p>因此作者将训练阶段分为2部分</p><ul><li>Reducing Class Imbalance：采用re-sampling（不知道该如何翻译）平衡训练集vulnerable和non-vulnerable的样本。</li><li>Representation Learning Model：基于平衡后的数据集训练一个可以很好的区分vulnerable和non-vulnerable样本的representation learning model。</li></ul><h4 id="421-reducing-class-imbalance"><a class="markdownIt-Anchor" href="#421-reducing-class-imbalance"></a> 4.2.1 Reducing Class Imbalance</h4><p>在处理样本不平衡问题上用到了SMOTE算法。对于样本中的多数类（non-vulnerable），SMOTE会进行sub-sampling（随机删除一些样本），对于少数类（vulnerable），SMOTE会进行super-sampling（新合成一些样本）。直到每个类别的出现频率相等。算法如下图表示</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657366.png" alt="在这里插入图片描述" /></p><h4 id="422-representation-learning-model"><a class="markdownIt-Anchor" href="#422-representation-learning-model"></a> 4.2.2 Representation Learning Model</h4><p>一个code fragment（一个method）的CPG（用 G GG 表示）经过graph embedding（phase-I）后得到向量 x g x_gxg， 作为 G GG 的最终向量表示。但是vulnerable codes 和 non-vulnerable codes的向量在特征空间上有很大重合。</p><p>codes的特征向量经过TSNE降维后如下表示，一个点代表一个code fragment，红色部分为vulnerable codes，绿色为non-vulnerable codes。可以看到一个好的embedding是需要能够在特征空间区分开它们的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657895.png" alt="在这里插入图片描述" /><br />分类函数如下所示<br />y = σ ( W . h ( x g ) + b ) y = \sigma(W .h(x_g) +b)y=σ(W.h(xg​)+b)</p><ul><li>σ \sigmaσ 为softmax</li><li>W WW 和 b bb 为最后一层全连接层的参数</li></ul><p>其中 h ( x g ) h(x_g)h(xg) 为一个全连接层，将 x g x_gxg 投影到新的向量平面 h g h_ghg。</p><p>为了将non-vulnerable和vulnerable特征向量区别最大化。作者在训练模型时用到了triplet loss而不是softmax，记为 L t r p L_{trp}Ltrp。每次训练需要用到的一个数据为一个3元组，记为 ( g , s a m e , d i f f ) (g, same, diff)(g,same,diff) 对应 ( a , p , n ) (a, p, n)(a,p,n)。s a m e samesame 和 g gg 为同属一个类的样本， d i f f diffdiff 则相反。</p><p>L t r p = L C E + α . L p + β ∗ L r e g L_{trp} = L_{CE} + \alpha .L_{p} + \beta * L_{reg}Ltrp=LCE+α.Lp+β∗Lreg</p><ul><li><p>α \alphaα 和 β \betaβ 为超参数</p></li><li><p>L C E L_{CE}LCE 为交叉熵损失<br />L C E = − ∑ y ^ ⋅ l o g ( y ) + ( 1 − y ^ ) ⋅ l o g ( 1 − y ) L_{CE} = - \sum \hat y·log(y) + (1−\hat y)·log(1−y)LCE​=−∑y<sup>​⋅log(y)+(1−y</sup>​)⋅log(1−y) ，y yy 和 y ^ \hat yy^​ 分别表示 g gg 的标签和预测结果</p></li><li><p>L r e g L_{reg}Lreg 为正则化损失<br />L r e g = ∣ ∣ h ( x g ) ∣ ∣ + ∣ ∣ h ( x s a m e ) ∣ ∣ + ∣ ∣ h ( x d i f f ) ∣ ∣ L_{reg} = ||h(x_g)||+||h(x_{same})|| + ||h(x_{diff})||Lreg​=∣∣h(xg​)∣∣+∣∣h(xsame​)∣∣+∣∣h(xdiff​)∣∣ 。这里正则化损失主要用来限制 h hh 即投影空间向量大小。</p></li><li><p>L p = ∣ D ( h ( x g ) , h ( x s a m e ) ) − D ( h ( x g ) , h ( x d i f f ) ) + γ ∣ L_{p} = | D(h(x_g), h(x_{same}))−D(h(x_g),h(x_{diff})) + \gamma|Lp=∣D(h(xg),h(xsame))−D(h(xg),h(xdiff))+γ∣<br />L p L_{p}Lp​ 为投影损失，是为了最大区分正类和负类样本在投影空间的差异。<br />D ( v 1 , v 2 ) = 1 − ∣ v 1 . v 2 ∣ ∣ v 1 ∣ ∣ ∗ ∣ ∣ v 2 ∣ ∣ ∣ D(v_1,v_2) = 1−|\frac{v_1.v_2}{||v1||∗||v2||}|D(v1​,v2​)=1−∣∣∣v1∣∣∗∣∣v2∣∣v1​.v2​​∣</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061710663.png" alt="image-20240406171004625" /></p></li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657836.png" alt="在这里插入图片描述" /></p><h2 id="五-实验设置"><a class="markdownIt-Anchor" href="#五-实验设置"></a> 五. 实验设置</h2><p>模型超参数大小<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657849.png" alt="在这里插入图片描述" /><br />评估指标:</p><ul><li>跟Devign一样，这是个针对function的二分类问题。</li><li>Accuracy, Precision, Recall, F1-score这4个指标用来评估模型。</li></ul><h2 id="六实验结果"><a class="markdownIt-Anchor" href="#六实验结果"></a> 六.实验结果</h2><h3 id="61-现有方法的有效性"><a class="markdownIt-Anchor" href="#61-现有方法的有效性"></a> 6.1 现有方法的有效性</h3><p>作者在评估其它模型（vuldeepecker等）的性能时统一使用真实数据集，针对现有的模型训练数据的问题，作者给出了2个场景</p><ul><li>Scenario-A (pre-trained models)<br />该模型在它本身的数据集上训练（比如VulDeepecker在sard数据集上训练），然后在真实数据集上测试</li><li>Scenario-B (re-trained models)<br />真实数据集上训练 + 真实数据集测试</li></ul><p>Scenario-A的测试结果如下：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657888.png" alt="在这里插入图片描述" /><br />Scenario-B的测试结果如下：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657917.png" alt="在这里插入图片描述" />同时，作者自己实现了一个Devign，并开源到<a href="https://github.com/saikat107/Devign">github</a>了。</p><p>可以看到，现有的方法泛化能力不强，在应用到真实数据集时效果有一定程度下降。</p><h3 id="62-现有方法的局限性"><a class="markdownIt-Anchor" href="#62-现有方法的局限性"></a> 6.2 现有方法的局限性</h3><h4 id="621-数据重复"><a class="markdownIt-Anchor" href="#621-数据重复"></a> 6.2.1 数据重复</h4><p>用slice和token-based方法都可能造成在训练集和测试集造成数据重复。作者做了一个统计，结果如下<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657046.png" alt="在这里插入图片描述" />可以看到合成数据集比真实数据集多了很多重复。虽然重复会有利于漏洞分类任务，但不利于模型提取漏洞特征。</p><h4 id="622-数据不平衡"><a class="markdownIt-Anchor" href="#622-数据不平衡"></a> 6.2.2 数据不平衡</h4><p>数据集的情况再粘贴以下，看看Vul这一列，可以看到很多数据集中，正负样本比例不均。所以会造成模型分类时倾向于多数类。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657244.png" alt="在这里插入图片描述" /></p><h4 id="623-学到不相关特征"><a class="markdownIt-Anchor" href="#623-学到不相关特征"></a> 6.2.3 学到不相关特征</h4><p>为了选择好的DL模型来做漏洞分类，非常有必要理解模型是基于什么特征来做的分类。好的模型应该分配更多的权重给漏洞相关的特征。</p><p>作者通过LEMNA（一种解释方法）来解释token-based模型的分类结果。结果如下<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657302.png" alt="在这里插入图片描述" /><br />对于graph-based模型，作者则用每个结点的激活值来表示，激活值越大，结点越关键。对一个被token-based方法错误分类而被graph-based方法正确方法分类的样本解释， 结果如下</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657290.png" alt="在这里插入图片描述" /></p><h4 id="624-模型选择缺乏区分度"><a class="markdownIt-Anchor" href="#624-模型选择缺乏区分度"></a> 6.2.4 模型选择：缺乏区分度</h4><p>这里主要展示不同的方法提取到的代码的特征向量对正类负类样本的区分度，即特征向量空间中两类代码是否很容易被区分开。作者用TSNE对不同方法提取的特征向量进行研究，并用centroid distance来衡量它们的效果， 结果如下（再粘贴一次）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657356.png" alt="在这里插入图片描述" /><br />绿色为负类（无漏洞）的样本，红色为正类（有漏洞）。</p><h3 id="63-解决上述问题"><a class="markdownIt-Anchor" href="#63-解决上述问题"></a> 6.3 解决上述问题</h3><p>作者分别用SMOTE解决样本不均衡问题，而REVEAL本身就能解决其它的问题。</p><p>为了分别研究re-sampling和GGNN的效果，作者做了几组实验。不过实验结果里作者并未提到用什么模型替代了GGNN。</p><p>Re-balance的效果</p><p>实验结果如下（主要看F1-score），W/O表示without<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657298.png" alt="在这里插入图片描述" /><br />跟其它模型（token-based + MLP,RF,SVM）的对比<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657371.png" alt="在这里插入图片描述" /></p><h2 id="七预训练word2vec"><a class="markdownIt-Anchor" href="#七预训练word2vec"></a> 七.预训练Word2Vec</h2><p>代码如下：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">def <span class="title function_">train</span><span class="params">(args)</span>:</span><br><span class="line">    files = args.data_paths</span><br><span class="line">    sentences = []</span><br><span class="line">    <span class="keyword">for</span> f in files:</span><br><span class="line">        data = json.load(open(f))</span><br><span class="line">        <span class="keyword">for</span> e in data:</span><br><span class="line">            code = e[<span class="string">&#x27;code&#x27;</span>]</span><br><span class="line">            sentences.append([token.strip() <span class="keyword">for</span> token in code.split()])</span><br><span class="line">    wvmodel = Word2Vec(sentences, min_count=args.min_occ, workers=<span class="number">8</span>, size=args.embedding_size)</span><br><span class="line">    print(<span class="string">&#x27;Embedding Size : &#x27;</span>, wvmodel.vector_size)</span><br><span class="line">    <span class="keyword">for</span> i in range(args.epochs):</span><br><span class="line">        wvmodel.train(sentences, total_examples=len(sentences), epochs=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> not os.path.exists(args.save_model_dir):</span><br><span class="line">        os.mkdir(args.save_model_dir)</span><br><span class="line">    save_file_path = os.path.join(args.save_model_dir, args.model_name)</span><br><span class="line">    wvmodel.save(save_file_path)</span><br><span class="line"><span class="number">12345678910111213141516</span></span><br></pre></td></tr></table></figure><p>这里大概就是将一个function的所有代码<code>split</code>成一个token序列当作一个sentence训练Word2Vec模型。</p><h2 id="八参考文献"><a class="markdownIt-Anchor" href="#八参考文献"></a> 八.参考文献</h2><blockquote><p><a href="https://arxiv.org/abs/2009.07235">Chakraborty, S. , Krishna, R. , Ding, Y. , &amp; Ray, B. . (2020). Deep<br />Learning based Vulnerability Detection: Are We There Yet?.</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VDSimilar</title>
      <link href="/2023/12/18/Papers/Vul/VDSimilar/"/>
      <url>/2023/12/18/Papers/Vul/VDSimilar/</url>
      
        <content type="html"><![CDATA[<h3 id="paper"><a class="markdownIt-Anchor" href="#paper"></a> Paper</h3><p>VDSimilar: Vulnerability detection based on code similarity of vulnerabilities and patches，Hao Sun, Lei Cui，C&amp;S(B)。</p><h3 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h3><p>现有的研究将漏洞检测视为一个分类问题，在捕获语义和语法相似性的同时需要大量的标记数据。本研究认为漏洞的相似性是漏洞检测的关键，本文准备了一个由漏洞和相关补丁组成的相对较小的数据集，并尝试比较漏洞之间的相似性、漏洞补丁之间的差异性来实现漏洞检测。为此，使用Siamese网络+BiLSTM+Attention作为检测模型。在OpenSSL和Linux的876个漏洞和补丁的数据集上，提出了模型VDSimilar，在OpenSSL的AUC值上达到了约97.17%，优于目前基于深度学习的漏洞检测SOTA方法。</p><h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3><p>现有的基于代码相似性的漏洞检测方法普遍是基于代码段语法和语义的相似性来进行的，但是两份语法语义相似的代码很可能因为一丁点差别而一个有漏洞一个没有漏洞，因此，本文希望找到一个能从漏洞角度捕获相似性的方法。另外，基于深度学习的方法总是需要大量的数据，比如VulDeepecker需要61638个code gadget，准备这样的数据集需要花费巨大的人力资源，本文希望找到一个可以在小数据集上使用的深度学习检测方法。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000651.jpeg" alt="img" /></p><p>本文提出了一个基于度量学习的代码漏洞检测方法，学习了一个应用于漏洞和补丁数据集上的代码相似性检测器。首先，准备一个CVE brunch的数据集，每个CVE brunch包含与一个CVE相关的多个漏洞函数和补丁函数，如上图所示，这些CVE函数可以从不同版本的软件中获得，它们遵循两个规则：</p><ul><li>对于同一个CVE中两个版本的漏洞函数，漏洞片段保持不变</li><li>对于一个漏洞函数和一个补丁函数，漏洞片段一定消失</li></ul><p>因此，每个CVE brunch都可能提供一个CVE漏洞特征。其次，从漏洞的角度来看，不同版本的两个漏洞函数应该被视为相似的，即使版本迭代过程中存在代码更改；另一方面，由于补丁代码中漏洞片段已经消除，因此即使漏洞函数与补丁函数语法和语义相似，也应视为不同。本研究在本文提出的数据集上与之前的方法比较，证明了VDSimilar的有效性。</p><p>本文认为，相比整个漏洞函数，漏洞代码片段是漏洞检测的关键，如下图所示，显示了t1_lib.c 的 tls_decrypt_ticket函数的代码片段，该函数在OpenSSL的三个版本中演进。该功能被报告为一个漏洞(CVE-2014-3567)，影响0.9.8zb和1.0.1i，然后在更高版本的1.0.1l中修复，下图中第二个函数应该是1.0.1i。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000691.jpeg" alt="img" /></p><p>可见，相比第一版，第二版增加了4行，改变了一行，都是漏洞函数。第三版相比第二版只增加了一行，和第一版相比更接近于第二版，但第三版确是补丁函数。OpenSSL程序不断发展，其中一个函数可能会由于诸多原因修改，如修复bug、优化性能或重构代码。两个版本的相同函数在语法和语义上可能会有很大的差异，而对于需要修复的漏洞，补丁可能只涉及几行甚至一行代码，因此跨连续版本的漏洞函数和补丁函数在语法上是高度相似的。</p><p>因此，一种好的基于代码相似度的漏洞检测方法应该更多地关注漏洞片段的相似度，而不是整个函数的代码语法和语义的相似度。</p><h3 id="method"><a class="markdownIt-Anchor" href="#method"></a> Method</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000615.jpeg" alt="img" /></p><p>上图是VDSimilar的整体framework，数据集包含了很多的CVE漏洞，每个CVE漏洞由几个版本的漏洞函数和补丁函数组成。由于训练样本过少，本文采用度量学习的方式训练计算相似性的分类器，对于漏洞-漏洞函数对，标记为相似label为1，对于漏洞-补丁函数对，标记为不相似label为0，训练Siamese网络，训练过程中引入Attention，最终计算测试函数和漏洞库函数的相似性，相似性高于一定阈值被认为存在漏洞。</p><ul><li><strong>数据准备</strong></li></ul><p>为了准备数据集，本文从CVE Details数据库中收集了一组CVE，如下图所示，漏洞一般可以通过两种途径得到。一种是直接下载product，然后根据漏洞详细信息中描述的文件名和函数名提取漏洞函数；另一种是直接从外部链接中引用的补丁中提取漏洞；由于有些外部链接并不可用，因此本文采用第一种方式。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000621.jpeg" alt="img" /></p><p>为了获得补丁，假设最新的有漏洞版本之后的Linux和OpenSSL版本漏洞已经修复，通过从多个版本的程序中提取漏洞和补丁函数，生成一组相似对({V, V, 1})和差异对({V, P, 0})。使用网络爬虫Scrapy框架爬取CVE Details中的程序版本、漏洞函数名、文件名和补丁等等信息，可以为每个CVE获取一个元组，即(CVE、软件、漏洞版本、补丁版本、文件名、函数名)。</p><p>对于每一个CVE，根据上文提取的详细信息，使用LLVM解析源代码，提取出一组漏洞函数和补丁函数。使用hash的方式去除重复函数、修正可能出现的漏洞标签错误信息。然后生成相似对和差异对，在该过程中扩大数据集，方便训练。</p><ul><li><strong>检测模型</strong></li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000648.jpeg" alt="img" /></p><p>本文的检测模型Siamese架构如上图所示，首先进行embedding，然后输入BiLSTM中得到输出，经过一层Attention后计算相似度即可。值得一提的是该Attention是self-attention，类似transformer一样，由H成参数矩阵生成Q,K,V，然后进行Attention计算，该Attention过程的作用是将注意力聚集在漏洞代码片段而不是整个函数上。</p><p>Siamese网络是一个共享权重的孪生网络，模型训练过程中最大化漏洞函数之间的相似度，最小化漏洞函数和补丁函数的相似度。在测试过程中计算每个目标函数与已有漏洞函数的相似度，如果接近1则有漏洞，如果接近0则没有漏洞，算法伪代码如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000618.jpeg" alt="img" /></p><h3 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h3><p>与Simian，Nicad，ReDeBug，PMD-CPD，SyseVR，VulDeePecker这几个方法做比较，本文的Siamese模型在Linux和OpenSSL数据集上取得了更高的检测准确率和F1值。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000002.jpeg" alt="img" /></p><p>本文将VDSimilar和几个之前的深度学习模型做比较，发现Siamese+BiLSTM+Attention的VDSimilar模型具有最好的泛化性能。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000010.jpeg" alt="img" /></p><h3 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h3><p>本文提出了一个基于代码相似性的源代码漏洞检测方法，准备了一个由漏洞和相关补丁组成的相对较小的数据集，并尝试比较漏洞之间的相似性、漏洞补丁之间的差异性来实现漏洞检测。为此，使用Siamese网络+BiLSTM+Attention作为检测模型。在OpenSSL和Linux的876个漏洞和补丁的数据集上取得了良好的实验效果，证明了模型的有效性。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VulDeePecke</title>
      <link href="/2023/12/18/Papers/Vul/VulDeepecker/"/>
      <url>/2023/12/18/Papers/Vul/VulDeepecker/</url>
      
        <content type="html"><![CDATA[<h2 id="vuldeepecker基于深度学习的漏洞检测系统"><a class="markdownIt-Anchor" href="#vuldeepecker基于深度学习的漏洞检测系统"></a> <a href="https://zhuanlan.zhihu.com/p/265616085">VulDeePecker：基于深度学习的漏洞检测系统</a></h2>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The Vulnerability Is in the Details Locating Fine-grained Information of Vulnerable Code Identified by Graph-based Detectors</title>
      <link href="/2023/12/18/Papers/Vul/VULEXPLAINER/"/>
      <url>/2023/12/18/Papers/Vul/VULEXPLAINER/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>漏洞检测是软件开发生命周期中的关键组成部分。现有的漏洞检测器，尤其是基于深度学习（DL）模型的检测器，已经取得了很高的效果。尽管它们能够从给定的代码片段中检测到易受攻击的代码片段，但通常无法进一步定位与漏洞相关的精细信息，比如精确的漏洞触发位置。在本文中，我们提出了VULEXPLAINER，这是一个用于自动定位由DL-based检测器报告的粗略级易受攻击代码片段中的漏洞关键代码行的工具。我们的方法利用了代码结构和漏洞的语义。具体来说，我们利用程序切片来获得一组包含漏洞触发和漏洞依赖语句的关键程序路径，并对它们进行排名，以确定最重要的一个（即子图），作为与漏洞相关联的数据流。我们证明了VULEXPLAINER在四个最先进的基于图表示（GP）的漏洞检测器上表现一致良好，即它可以针对八种常见的C/C++漏洞以约90％的准确率标记漏洞触发代码语句，优于五种广泛使用的基于GNN的解释方法。实验结果证明了VULEXPLAINER的有效性，它提供了一个有前景的研究线索：整合程序切片和深度学习来解释易受攻击的代码片段。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h3 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h3><p>To counteract the potential exploitation, both academia and industrial communities have proposed numerous techniques for identifying and locating those vulnerabilities.</p><ul><li><p>传统方法，例如基于规则的分析技术利用预定义的签名或规则来识别漏洞。问题是，通常报告高误报和漏报率。</p></li><li><p>基于 DL 的检测技术通常在提取的代码特征表示上运行，已经显示出在标记包含漏洞的代码片段（即函数或片段）方面的巨大效果。然而，分析的粗粒度和黑盒性质使得检测结果的可解释性较差。<strong>例如，一个函数或代码片段可能包含十几行代码，这对开发人员来说仍然是一个具有挑战性的任务，以理解漏洞的根本原因并进一步采取行动来修复它们</strong>。解决这个问题的一种有希望的方法是利用解释方法来选择 DL-based 检测器的重要特征，然后将它们映射到相应的代码行。</p></li><li><p>最近图形解释技术的快速发展显示出了解决这个问题的巨大潜力。现有的图解释方法通常从三个角度促进模型的可解释性：为图边分配数值 [10]，[11]，计算节点的重要性分数 [12]，以及在通过 GNN 时计算图遍历的分数 [13]。</p></li></ul><p>尽管它们在诸如子图分类之类的任务中取得了成功，但现有的基于 GNN 的解释技术仍然存在固有的不足，这些不足阻碍了直接应用以获得有关漏洞的细粒度信息，例如触发代码行。</p><p>**第一个不足之处在于捕捉潜藏在良性和脆弱代码库中的微妙但丰富的语义能力有限。**程序的功能由提取的代码图中的语句（即节点）及其信息流（即边）定义。因此，针对程序的特定语义对于解释方法至关重要。然而，现有的解释方法无法定位到这种细粒度的信息，因为它们通常忽视了程序图中丰富的语义信息。</p><p>这可能归因于程序漏洞检测的复杂性相对于现有任务（即，较简单的拓扑结构）而言。<mark>例如，由边表示的两个语句之间的控制流或程序依赖关系几乎没有反映出来。此外，节点中包含的语义信息难以编码到潜在空间中。</mark></p><p>**第二个不足之处源于对关键漏洞检测语句的不足考虑。**大多数易受攻击的程序及其修补版本通常具有类似的拓扑结构，因为它们都包含触发漏洞的语句，如图1所示。唯一的区别可能在于一些修复漏洞的语句，涉及与漏洞触发相关的控制流和程序相关信息。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404190957908.png" alt="image-20240419095734769" style="zoom:50%;" /><h3 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h3><p>提出了VULEXPLAINER，这是一种新颖的方法，用于从GNN-based漏洞检测器报告的脆弱代码中识别细粒度信息。给定一个检测到的脆弱代码片段，VULEXPLAINER首先从中提取程序切片，然后构造控制和数据依赖信息。与先前的工作（例如，DEEPWUKONG[6]）相比，VULEXPLAINER仅保留脆弱性触发和脆弱性依赖的程序路径级信息，而不是完整程序的信息。这显着提高了分析效率，因为程序路径包含较少的代码行。利用程序切片方法，VULEXPLAINER捕获了更多包含在代码行中的语义信息。因此，它可以提供比仅关注拓扑特征的方法更准确的解释结果。</p><p><strong>VULEXPLAINER的目标是识别漏洞的根本原因。 最近的工作[14]表明，错误触发路径是定位和修复漏洞的关键。</strong> 因此，为了评估我们方法的有效性，我们提出了一个新的评估指标，漏洞触发代码行覆盖率（以下简称LC，在第V-B节中详细说明）。 我们对VULEXPLAINER的有效性进行多维评估。 在第一个比较维度中，我们将VULEXPLAINER应用于解释四种基于图代码表示的最新漏洞检测器的输出，包括DEEPWUKONG [6]，REVEAL [7]，IVDETECT [8]和DEVIGN [9]。 这四个检测器都使用程序依赖图（PDGs，DEVIGN仅使用数据依赖图，不使用控制依赖图）作为代码图表示。</p><h3 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h3><p>总之，我们做出以下主要贡献：</p><p>• 一种新颖的基于 GNN 的漏洞检测器的漏洞细粒度信息定位技术。鉴于现有的基于 GNN 的漏洞检测器的解释能力不足，我们提出了 VULEXPLAINER 框架作为解决方案。它可以识别程序中包含漏洞触发语句的重要流路径，为识别出的漏洞提供更细粒度的语义上下文。我们在匿名仓库 [16] 上发布了本文中使用的源代码和数据集。</p><p>• 方法效果。通过对全面基准数据集的多维评估，我们展示了 VULEXPLAINER 在 LC 方面优于现有的解释方法，LC 是影响漏洞定位和修复的关键因素。平均而言，VULEXPLAINER 对本研究中使用的所有漏洞检测器的 LC 均高于 85%，显示出对不同基于 GNN 的漏洞检测器的良好泛化能力。</p><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h3 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h3><h4 id="an-example-of-locating-vulnerability"><a class="markdownIt-Anchor" href="#an-example-of-locating-vulnerability"></a> AN EXAMPLE OF LOCATING VULNERABILITY</h4><p>如图 3 所示。它包含一个缓冲区溢出漏洞，该漏洞通过复制更多数据（即代码片段第 11 行定义的 100 字节）来触发，而数组的最大容量为（即代码片段第 2 行定义的 50 字节）。基于 GNN 的漏洞检测器只输出检测结果为 1，表明代码片段是易受攻击的（或反之为 0）。漏洞定位任务的目标是构建一个包含漏洞触发代码行和漏洞相关变量的关键赋值的控制和数据依赖路径，或者此后称为流路径。为此，我们首先通过将语句映射到节点并根据节点之间的依赖信息构造流路径将源代码转换为图形表示。从路径中，我们选择满足我们漏洞定位目标的路径。具体来说，在图 3 中我们的示例中，从原始代码片段中提取了多条流路径，<strong>例如“8-11”、“2-6-7-13”等。其中，“2-6-7-11”被认为是最关键的路径，因为既包括第 2 行（关键变量赋值）又包括第 11 行（漏洞触发）。</strong><br />技术挑战。根据这个漏洞定位示例，对于一般和自动定位检测到的漏洞代码，技术挑战至少有两个方面：<br />• 挑战#1 <strong>通过基于 GNN 的检测器正确检测到易受攻击的代码后，缺乏一种有效的漏洞定位方法，该方法生成覆盖漏洞触发和相关关键变量赋值的流路径。</strong><br />• 挑战#2 <strong>给定生成的流路径，缺乏一种有效的路径选择机制，该机制识别最合适的路径作为检测到的漏洞的最合理最终数据流</strong>。为了解决这两个挑战，我们提出了 VULEXPLAINER，它可以从代码片段中导出的 PDG 中自动生成可行的流路径，并对它们进行排名以选择最合理的路径。该框架的技术细节将在第四节中介绍。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191945690.png" alt="image-20240419194551637" style="zoom:67%;" /><h4 id="locating-vulnerability-statements-using-gnn-based-detectors"><a class="markdownIt-Anchor" href="#locating-vulnerability-statements-using-gnn-based-detectors"></a> LOCATING VULNERABILITY STATEMENTS USING GNN-BASED DETECTORS</h4><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191959536.png" alt="image-20240419195905435" style="zoom:67%;" /><ul><li>流路径生成。</li></ul><p>给定一个以图形表示的脆弱代码片段，其控制和数据依赖已计算（见图4(a)），VULEXPLAINER 首先识别程序中可能触发漏洞的语句（即节点），表示为潜在汇点（potential sink points，PSPs）。接下来，VULEXPLAINER 在程序图中沿着从 PSP 开始的流路径迭代遍历，直到到达 PSP 的源（例如，表示关键变量赋值的节点）。类似地，VULEXPLAINER 生成图中所有符合条件的流路径，每个流路径以一个 PSP 结束。</p><ul><li>流程路径选择。</li></ul><p>VULEXPLAINER首先对每个流程路径进行向量化，并计算与漏洞概率相关的重要性分数（见图4(b)）。接下来，VULEXPLAINER选择具有最高重要性分数的流程路径作为漏洞数据流。请注意，我们不会直接针对路径选择训练分类器，因为每个路径被视为数据流而不是代码片段。</p><h4 id="流路径生成"><a class="markdownIt-Anchor" href="#流路径生成"></a> 流路径生成</h4><p>从原始代码图（即PDG）生成流路径，我们利用基于DLVD方法的程序切片，这种方法已被之前的作品广泛采用，例如DEEPWUKONG，REVEAL，IVDETECT，DEVIGN。切片原理基于PDG的控制依赖和数据依赖。更具体地，详细的流路径生成方法由算法1中的“GENERATESLICE”函数描述。它以代码图G和路径长度限制k（即，为了有效地移除后续搜索中的冗长路径）作为输入。我们将算法详细描述如下。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192022921.png" alt="image-20240419202206854" style="zoom:67%;" /><h4 id="流路径选择"><a class="markdownIt-Anchor" href="#流路径选择"></a> 流路径选择</h4><p><strong>在流程路径中，我们的目标是根据预测结果选择一个可以最好地定位触发漏洞的语句的路径。</strong></p><p>关键直觉是，如果一条路径包含了PSP及其源节点，则应选择该路径。例如，第III节中的示例中的路径“2 - 6 - 7 - 11”。如果有多条符合条件的路径，我们进一步根据路径重要性对它们进行排名，并选择具有最高重要性得分的路径。更正式地说，给定一个代码图G，我们从中提取流程路径并对每个流程路径进行向量化。</p><p>向量化一个流程路径的过程与检测器向量化相应代码图的过程相同。然后，我们通过将每个向量化的流程路径视为原始代码图的子图并将其输入经过良好训练的基于GNN的漏洞检测器来计算每个流程路径的重要性得分。这个过程可以正式描述为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192040306.png" alt="image-20240419204002233" /></p><p>在这里，g 是从 G 中提取的流路径，Φ 是基于 GNN 的漏洞检测器之一。最后，我们计算每条路径的重要性分数 ISg，衡量它们对于检测器预测相应代码片段的贡献。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192040633.png" alt="image-20240419204044559" /></p><p>假设在对G进行切片后有n个流路径，表示为{g1, …, gi, …gn}。漏洞数据流g∗表示为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192041488.png" alt="image-20240419204114457" /></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192030658.png" alt="image-20240419203043537" style="zoom:67%;" /><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><p>评估了VULEXPLAINER在DEEPWUKONG、REVEAL、IVDETECT和DEVIGN的预测结果中定位漏洞语句的有效性。评估是为了检测CWE中排名前30位的8个漏洞，与GNN的五种最先进的解释器进行比较。为此，我们概述了本研究中使用的数据集以及涉及其标记过程（第V-A节）。接下来，我们详细阐述了实验设置。</p><h3 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h3><p>目标漏洞：此处使用的数据集必须支持细粒度检测，这需要明确的有关易受攻击代码行的信息。许多实际数据集中的缺陷行，如DEVIGN [9]，REVEAL，Fan [26]，都标有从提交的版本修补程序中提取的代码更改信息。如图7所示，包含CVE-2015-2029漏洞ID的示例代码包括标记为绿色的漏洞修复代码行。<strong>然而，这种标记方法只能检测到漏洞修复行，而未检测到漏洞触发行。</strong></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192212129.png" alt="image-20240419221207069" style="zoom:67%;" /><p>在图7中的同一示例中，受污染流程中的语句被标记为粉红色，这并未涵盖触发漏洞的代码行。此外，fA函数处修复的漏洞可能会在fB函数处触发。在这种情况下，fA将被标记为易受攻击，而fB则为非易受攻击。更糟糕的是，Roland Croft等人[27]报告了真实数据集中约20-71%的假阳性漏洞样本的存在。由上可见，在实际数据集中准确标记易受攻击的代码行可能具有挑战性。由于噪声数据集可能会影响深度学习模型的性能[28]，我们从SARD [24]，一个合成漏洞数据库中组装我们的数据集。在SARD数据集中，每个程序（即测试用例）可能与一个或多个CWE ID相关联，因为一个程序可能包含不同类型的漏洞。更重要的是，每个易受攻击程序的触发漏洞语句已经被正确标记。我们的目标是检查2021年C/C++中30种最危险的软件缺陷中的八种，具体关注CWE20，CWE22，CWE78，CWE119，CWE125，CWE190，CWE400和CWE787。我们使用与DEEPWUKONG [6]相同的网络爬虫来收集所有可用程序。</p><p><strong>基准数据集处理：从 SARD 收集的数据按以下步骤进行处理。首先，我们将 SARD 程序的功能解析为供 REVEAL 和 IVDETECT 使用的 CPGs。我们直接利用由 DEEPWUKONG 生成的切片级别 XFGs（PDG 的子图），因为它们在其存储库中可用。然后，我们按照先前的工作对这些 CPGs 和 XFGs 进行标记和去重。任何包含一个或多个易受攻击语句的 CPG 或 XFG 将被标记为易受攻击，反之亦然。除此之外，我们将易受攻击样本中的关键语句标记为节点索引。</strong></p><p>基准数据集分布：经过处理阶段，我们从 SARD 数据集中收集了 82,243 个易受攻击的 CPGs 和 164,736 个非易受攻击的 CPGs，如表 I 所示。我们从 DEEPWUKONG 下载了 XFGs 数据集。重新标记后，我们总共组装了 151,774 个易受攻击的 XFGs 和 384,062 个非易受攻击的 XFGs。</p><h3 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h3><p>评估指标：我们首先使用六个常用的指标评估四种漏洞检测工具的有效性，包括准确率（ACC）、误报率（FPR）、漏报率（FNR）、召回率（R）、精确率（P）、F1分数（F1）。简化结果总结在表II中，详细结果可在我们的存储库[16]中找到。</p><p>评估解释方法以及VULEXPLAINER的有效性，我们提出度量<strong>行覆盖率</strong>，即LC。请注意，评估指标仅适用于真正阳性样本，即标记并检测为易受攻击的样本。**LC的定义如下：给定包含n个易受攻击代码行的代码片段C的流路径g，则LC = n/m，其中m（m ≥ n）表示数据集中标记为易受攻击的代码行的总数。**如果g包含数据集中标记的所有易受攻击语句，则LC为1；如果g不包含标记的易受攻击语句，则LC为0。</p><p>请注意，我们考虑使用忠实度[36]来衡量解释器和VULEXPLAINER的性能。然而，目前缺乏一种通用且标准的计算忠实度的方法，导致不同方法得出的结果差异巨大。这使得将忠实度作为评估指标之一变得不可靠。此外，我们的目标是定位和解释检测到的漏洞的原因，并不一定需要构建一个最大程度保留原始图属性的子图。</p><h4 id="rq1-vulexplainer能否准确定位触发漏洞的代码行"><a class="markdownIt-Anchor" href="#rq1-vulexplainer能否准确定位触发漏洞的代码行"></a> RQ1 VULEXPLAINER能否准确定位触发漏洞的代码行？</h4><p>设置两个参数，sparsity和k，用来控制flow path的节点数量，参数稀疏度由 1 − n/m 计算，其中 m 和 n 分别是图中和路径中的节点总数。直观地说，稀疏度控制着图中节点的分布均匀程度。更多节点集中在较少的路径中（即相对较长的路径）会导致较低的稀疏度。参数 k 指定了路径中的节点最大数量，如算法 1 所述。考虑这两个参数，流路径中的最大节点数 MaxN 由 min(k, (1 − 稀疏度) ∗ m) 给出。</p><p><strong>RQ1.1：VULEXPLAINER在各种类型的漏洞中能否表现一致？</strong></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201003834.png" alt="image-20240420100351781" /></p><p>如表III所示，VULEXPLAINER在定位不同类型的漏洞时表现出不同的性能。对于CWE-78漏洞，它取得了最高的LC分数（98％），对于CWE-20（84％）和CWE-119（87％）则相对较低。为了更好地理解这种差异背后的原因，我们对几个特殊案例进行了手动审查，并确认了以下三个可能的原因。</p><p>首先，所选的PSPs可能是不完整的。各种类型的语句可能会触发漏洞。某些漏洞，比如CWE-78，只能通过与系统命令相关的API触发，使得漏洞模式相对比较简单。然而，其他类型的漏洞（例如缓冲区溢出）可能会被各种语句触发，包括与内存相关的API、数组操作和指针操作。这导致代码图中出现更多的PSPs，随后在路径生成和选择过程中产生更多的干扰，这对我们的方法构成挑战。此外，我们目标的PSP模式可能不完整，可能会在解释过程中排除某些漏洞类型。</p><p>我们利用程序切片生成流程路径，以保留漏洞语义。在这个过程中，我们会筛选掉一些与漏洞有关的控制和数据依赖关系，而不包含变量。然而，使用我们的方法分析大量路径可能会变得困难，考虑到要探索和解析的指数级扩展可能性。</p><p>基于深度学习的检测器并不像我们期望的那样可靠。在某些情况下，检测器的输出分数显著低于预期，即使路径与漏洞强相关。这种不可靠性可能会影响到VULEXPLAINER的测量有效性。这也表明传统评估指标可能无法完全捕捉这些检测器的有效性。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201011857.png" alt="image-20240420101118758" style="zoom:50%;" /><p><strong>RQ1.2：VULEXPLAINER在不同基于图的漏洞检测器上能否表现一致？换句话说，VULEXPLAINER的性能是否受到检测器选择的影响？</strong></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201011256.png" alt="image-20240420101152223" style="zoom:50%;" /><h4 id="rq2-vulexplainer能否超越现有的gnn漏洞检测解释方法"><a class="markdownIt-Anchor" href="#rq2-vulexplainer能否超越现有的gnn漏洞检测解释方法"></a> RQ2 VULEXPLAINER能否超越现有的GNN漏洞检测解释方法？</h4><p>结果：在使用评估指标LC对八种漏洞进行评估时，VE在比较中超越了所有五种解释方法。由于当k的值变化时可以观察到解释器表现的相同趋势，我们基于页面约束使用k = 7呈现和分析最终结果。以CWE-20为例，基于DEEPWUKONG的预测定位易受攻击行时，VE在LC方面比GL大约30%。至于CWE-125，用于REVEAL的定位易受攻击行时，GR仅获得51%的LC，而我们的方法达到96%。对于IVDETECT，DL仅获得4%的LC，而VE达到97%。与GE相比，在CWE-787上为DEVIGN定位易受攻击行时，VE达到91%的LC，几乎比GE高出33%。对于PE也观察到类似的模式，仅实现33%的LC。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201020607.png" alt="image-20240420102009538" /></p><p>分析：实验结果表明，仅依赖节点嵌入和代码图的拓扑结构来定位易受攻击代码片段的根本原因是不足够的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201018628.png" alt="image-20240420101815581" /></p><h2 id="4-discussion"><a class="markdownIt-Anchor" href="#4-discussion"></a> 4 Discussion</h2><p>首先，我们只在SARD数据集上进行实验，该数据集包含合成和学术程序，但可能不代表真实世界的软件产品。我们在第V-A节中讨论了现有真实世界数据集中的问题。生成可靠的细粒度数据集仍然是一个悬而未决的问题。其次，我们的框架使用关键库API调用、数组或指针操作和操作符语句来执行程序切片作为PSPs。如第VI-A1节所述，这意味着某些边缘情况可能被忽视。此外，它还可能引入无关的语句作为汇点。增强我们的方法的一种方式是检测附加的补充类型的PSP模式，随后筛选出多余的汇点以减少潜在的不准确性。这需要对触发真实世界漏洞以及如何修复这些漏洞有额外的见解。我们只考虑分析PSPs，虽然进一步分析与漏洞相关数据输入到程序的潜在源点是一个有希望的对角线研究方向。第三，我们的实验仅限于C/C++程序中的八种漏洞类型。尽管如此，我们的方法可以轻松扩展到包括其他源-汇漏洞和其他编程语言。第四，我们的方法仅考虑基于四种基于图的漏洞检测器定位脆弱语句。然而，我们的方法很容易适用于其他检测器，并有可能用于其他程序分析任务。</p><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><aside> 💡 Others<hr /><h4 id="基于gnn的漏洞检测器"><a class="markdownIt-Anchor" href="#基于gnn的漏洞检测器"></a> 基于GNN的漏洞检测器</h4><p>最近，安全分析师和研究人员在漏洞检测任务中已经开始利用GNNs [9]，[7]，[8]，[6]，[17]，[18]。他们假设代码的图表示相对于传统的基于序列的表示方式，可以更好地保留与漏洞相关的程序的关键语义信息。通常，最常用的图表示是代码属性图（CPG），它与抽象语法树（AST）、控制流图（CFG）、控制依赖图（CDG）和数据依赖图（DDG）相结合。此外，另一种图表示程序依赖图（PDG）由CDG和DDG组成，可以被视为CPG的子结构，在程序切片中被广泛使用。在本研究中，我们主要利用PDG进行切片。通常，基于GNN的检测器的检测阶段通常包括三个步骤，如图2所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191939483.png" alt="image-20240419193946385" /></p><ul><li>将源代码解析为图形表示。</li></ul><p>目标源代码片段通常是函数或片段。在这里，我们利用Joern [20]来转储代码片段的图形表示，以支持那些基于GNN的检测器（DEEPWUKONG [6]，REVEAL [7]，IVDETECT）。</p><ul><li>将代码图嵌入到向量化表示中。</li></ul><p>在代码图中，一个节点通常代表一个程序语句，而一条边表示两个语句之间的关系（执行顺序或 def-use）。在这里，每个节点可以通过 DOC2VEC [21] 或 WORD2VEC [22] 进行向量化。然后，通过顺序向量化所有包含的节点生成向量化图数据。</p><ul><li>使用训练良好的 GNN 模型对向量化代码图进行分类。</li></ul><p>通过代码片段的向量化图和它们的标签，可以训练 GNN 模型，如图卷积网络（GCN）和门控图神经网络（GGNN），来检测目标程序的向量化图数据。</p><h4 id="控制和数据依赖关系"><a class="markdownIt-Anchor" href="#控制和数据依赖关系"></a> 控制和数据依赖关系</h4><p>在一个PDG中，控制依赖边Si → Sj表示Sj语句是否会根据Si中的约束条件执行。数据依赖边S′ i → S′ j意味着在S′ j中使用了在S′ i中定义的值。并且在从S′ i到S′ j的路径上没有其他语句重新定义相应的值。程序的控制依赖图可以通过Cytron R等人提出的算法确定。而数据依赖关系可以通过到达定义分析计算。</p><h4 id="potential-sink-pointspsps"><a class="markdownIt-Anchor" href="#potential-sink-pointspsps"></a> Potential Sink Points（PSPs）</h4><p>PSPs是与漏洞关系密切的语句。在算法1中，它们由函数“ExtractSinkNode”（第3行）提取，该函数考虑了我们程序切片中以下四种类型的PSPs。我们采用了李等人提出的相同定义[25]。</p><p>函数库/API函数调用（FC）</p><p>这种类型的PSP几乎涵盖了除整数溢出之外的所有漏洞类型。不同类型的漏洞由各种类型的API调用触发。例如，操作系统命令注入通常由诸如system和execl之类的API触发，而缓冲区溢出通常由类似memcpy的数据复制函数触发。</p><p>数组使用（AU）。</p><p>这种类型的PSP通常出现在内存错误中。在本研究中，AU仅涵盖缓冲区溢出漏洞。例如，“data[i] = 1;”可能导致缓冲区溢出。请注意，我们在这项工作中不考虑诸如带有常量索引的数组访问等微不足道的情况。</p><p>指针使用（PU）。</p><p>与AU类似，PU通常出现在内存错误中。本研究仅涵盖缓冲区溢出漏洞。</p><p>算术表达式（AE）。</p><p>这种类型的PSP通常是像“a + 1”或“a++”这样的算术表达式。AE通常与整数溢出和除零漏洞有关。在这里，我们主要关注前者。请注意，在这项工作中我们不考虑诸如带有条件检查的自增和自减操作等微不足道的情况。</p><h4 id="dependent-statement"><a class="markdownIt-Anchor" href="#dependent-statement"></a> Dependent Statement</h4><p>算法1中的函数“ExtractPrecNodes”（第19行）建立了节点“n”的依赖关系（即识别节点“n”依赖的节点）。我们发现，并非每个节点“n”的依赖关系都与漏洞有关，因为源代码语句可能包含多个表达式，其中仅有一个可能触发漏洞。因此，在提取依赖节点时，我们只关注涉及每个PSP相关关键变量的控制和数据依赖。在图5中进行说明，我们的工具识别了可能触发语句S3中整数下溢的算术操作“CHAR ARRAY SIZE - 1”。虽然S3通过变量“connectSocket”与S1存在数据依赖，但它们不出现在算术操作中。因此，在进行切片时，我们不考虑数据依赖边“S1 - S3”。对于其他节点，我们考虑当前节点的所有依赖语句。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vulnerability Detection by Learning From Syntax-Based Execution Paths of Code</title>
      <link href="/2023/12/18/Papers/Vul/Vulnerability%20Detection%20by%20Learning%20From%20Syntax-Based%20Execution%20Paths%20of%20Code/"/>
      <url>/2023/12/18/Papers/Vul/Vulnerability%20Detection%20by%20Learning%20From%20Syntax-Based%20Execution%20Paths%20of%20Code/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>在这项工作中，我们提出将代码片段的基于语法的控制流图（CFG）分解为多个执行路径来检测漏洞。具体来说，给定一个代码片段，我们首先基于它的抽象语法树（AST）构建它的CFG，将这种CFG称为基于语法的CFG，并将CFG分解为从入口节点到出口节点的多个路径。接下来，我们采用预先训练的代码模型和卷积神经网络来学习具有路径内和路径间注意力的路径表示。路径的特征向量被组合为代码片段的表示，并被输入分类器以检测漏洞。将代码片段分解为多个路径可以过滤掉一些与漏洞无关的冗余信息，并帮助模型关注漏洞特征。此外，由于分解的路径通常比代码片段短，位于长代码尾部的信息更有可能被处理和学习。为了评估我们模型的有效性，我们构建了一个包含超过231k个代码片段的数据集，其中有24k个漏洞。实验结果表明，所提出的方法在精度、召回率和F1分数方面分别优于最先进的基线至少22.30%、42.92%和32.58%。我们的进一步分析调查了所提出的方法优越性的原因。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><p>漏洞检测对于保护软件系统至关重要。已经提出了基于深度学习的各种方法来学习漏洞模式并识别它们。尽管这些方法在这项任务中显示出了巨大的潜力，但它们仍然存在以下问题：<mark>（1）它们很难将与漏洞相关的信息与大量无关的信息区分开来，这阻碍了它们捕捉漏洞特征的有效性。</mark>（2） <mark>它们在处理长代码方面效果较差，因为许多神经模型会限制输入长度，这阻碍了它们表示长时间易受攻击的代码片段的能力。</mark></p><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><p>Observation 1: A vulnerable function may contain a vast of statements unrelated to vulnerabilities.</p><p>Observation 2: Truncating the statements in the tail of a long code snippet may negatively affect the effectiveness of vulnerability detection.</p><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403151148919.png" alt="image-20240315114845862" /></p><p>形式上，我们采用Gi=（Vi，Ei）来表示代码片段ci的基于语法的CFG，其中Vi=（v1 i，v2 i，…v|Vi|i）是包含|Vi|语句的节点集。Ei是表示语句之间的控制流的边集。每条边都是ci中两个语句之间的关系，因此一个语句可以在另一个语句之后执行。Gi中的路径是节点序列p=（n1，n2，…，nk），其中节点nk是ci的陈述k。对于任何一对相邻节点np和nq，存在从np到nq的边。如果起始节点等于结束节点，则路径将是一个循环。</p><p>首先将每个代码片段解析为AST，并根据AST构建基于语法的CFG。接下来，我们提出了一种基于贪婪的路径选择算法，从基于语法的CFG中选择多个执行路径，即将代码片段分解为几个执行路径。然后，通过CodeBERT[24]将所选路径编码为具有路径内注意力的向量，然后将其馈送到CNN中以捕获路径间注意力。最后，我们利用MLP分类器来执行检测。</p><h4 id="22-method"><a class="markdownIt-Anchor" href="#22-method"></a> 2.2 Method</h4><p>Construction of Control Flow Graph From AST</p><p>该阶段以代码片段为输入，使用tree-sitter[50]将其解析为AST，并从AST构建基于语法的CFG。在本节中，我们使用图3中的示例来说明我们如何从代码片段的AST构建基于语法的CFG。在构造CFG之前，我们使用正则表达式删除代码段中的空行和注释。我们还在代码中标记每条语句的行号。由于基于语法的CFG中的每个节点代表一个单独的语句，因此在构造CFG时，我们只考虑AST中的语句节点。为了简化演示，我们做出以下定义：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403151615419.png" alt="image-20240315114834197" /></p><p>简单语句：在AST中不包含其他语句的语句。</p><p>Next语句：节点的Next语句是指在执行节点后可能执行的语句。一个节点可能有多个Next语句。</p><p>非子Next语句：节点的非子Next声明是指该节点的Next语句，不包含在以该节点为根的子树中。</p><p>Normal语句：不是break_语句、continue_Statement、return_Statement和throw_Statement的语句。</p><p>为了构造代码段的基于语法的CFG，我们首先将代码段的所有语句添加到CFG中作为其节点，并将第一个语句视为入口节点，将所有return_statement、assert_statement和throw_statement视为出口节点。如果代码片段的最后一条语句不是出口节点，我们将在代码末尾添加一个伪出口节点。然后，我们以广度优先的方式遍历AST，并为每个语句类型设计规则，以在CFG中构建边。</p><p>1） 对于每个既是简单语句又是普通语句的语句，如果AST中存在其下一个同级语句，我们将其连接到此同级语句。例如，在图3中，我们将节点2连接到节点3，将节点3连接到节点4。</p><p>2） 对于每个循环语句，即For_statement和while_statement，如果存在这样的语句，我们将其与第一个子语句和下一个同级语句连接起来。如果它的最后一个子语句是Normal语句，我们将此语句连接到循环语句。例如，在图3中，我们将节点4连接到节点5，将节点4与节点10连接，将节点5与节点4连接。</p><p>3） 对于每个break_statement，我们首先找到它的第一个祖先，它是沿着AST的循环语句或switch_statement。然后，我们将其连接到祖先的非子下一个语句。</p><p>4） 对于每个continue_statement，我们首先找到它的第一个祖先，即沿着AST的循环语句。然后，我们把它和这个祖先联系起来。</p><p>5） 对于每个if_statement，如果存在这样的语句，我们首先将其连接到其下一个同级语句，如果最后一个子语句是Normal语句，则将其then_block的最后一个子声明连接到其当前next语句。例如，在图3中，我们将节点6连接到节点4，将节点7连接到节点4.将节点10连接到节点12，将节点11连接到节点12。然后，如果它的子级包含else_statement，我们将else_Statements连接到它的每个Next Statements，将if_statement中的边移除到它的Next Statements中，并将if_sttatement中的边缘添加到else_statement。对于图3，我们将节点8连接到节点4，移除从节点6到节点4的边，并将节点6连接到节点8。接下来，我们遍历else_语句。我们将其最后一个子语句连接到当前的Next语句。如果它的最后一个子语句是Normal语句，我们会将其边缘移除到Next语句，并将其连接到第一个子语句。对于图3，我们将节点9连接到节点4，将节点8移除到节点4并将节点8连接到节点9。最后，我们将if_statement连接到它的then_block的第一个子语句。对于图3，我们将节点5连接到节点6，将节点6连接到节点7，将节点10连接到节点11。</p><p>6） 对于每个switch_statement，我们将其连接到其第一个case_statement。对于每个case_statement，我们首先将其连接到下一个case_statementor default_statement。然后，如果这个case_statement的最后一个子语句是Normal语句，我们将其连接到这个case_statement的当前Next语句。最后，我们将case_statement连接到它的第一个子语句。对于每个default_statement，如果其最后一个子语句不是Normal语句，我们将其连接到其第一个子语句，并将其最后一个子语句连接到switch_statement的Non-child-Next语句。</p><p>7） 对于每个try_statement，我们将其catch_clauses视为语句。我们不能为try_statement构造一个“声音”CFG，因为我们不能知道每个函数调用只能从调用方的AST抛出哪些异常。此外，构建一个“完整”的CFG需要将try_block中的每个语句连接到每个catch_clause，这可能会引入太多的死路径，并对以下阶段产生负面影响。因此，我们选择只将try_block中的最后一个Normal语句连接到catch_clauses。具体来说，我们将try_statement连接到其try_block中的第一个语句，将其try_bock中的最后一个Normal语句连接到其第一个catch_clause。对于每个catch_clause，我们将其连接到它的第一个语句和下一个catch_clause。此外，对于try_block和每个catch_clause中的最后一个语句，即Normal语句，我们将其连接到try_statement的Non-Child Next语句。</p><p><strong>Path Selection</strong><br />一个代码片段可以被视为其所有执行路径的组合。但是，如果代码段包含循环，则它可能具有无限的执行路径。它可能需要许多计算资源来编码代码片段的所有执行路径。**因此，我们认为，在CFG中对所有执行路径进行编码以学习相应代码片段的表示是不切实际的。我们将基于语法的CFG中的执行路径定义为从CFG的入口节点到出口节点的路径，并从此将其称为执行路径。此外，在看不见的代码片段中准确定位易受攻击的语句是非常重要的。**如果我们只提取一个执行路径来表示代码片段，那么很可能会错过易受攻击的语句，并对漏洞检测的性能产生负面影响。幸运的是，根据我们对现实世界漏洞的观察和第三节中给出的激励性示例，我们发现一些执行路径通常可以涵盖漏洞的根本原因。因此，我们选择并编码几个具有代表性的执行路径来表示相应的代码片段，而不是对CFG中的所有或仅一个执行路径进行编码。Alon等人也使用了类似的策略。[51]在将代码片段表示为AST路径时。该阶段负责从先前阶段构建的CFG中选择几个具有代表性的执行路径。</p><p>选择执行路径有两个要求：首先，为了避免丢失代码片段中的重要信息，所选路径应覆盖尽可能多的代码行。其次，为了减轻模型训练的负担，我们希望选择的路径尽可能短。不幸的是，这两个要求在某种程度上是冲突的。为了在它们之间进行权衡，我们提出了一种基于贪婪的路径选择算法。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BinaryAI - Binary Software Composition Analysis via Intelligent Binary Source Code Matching</title>
      <link href="/2023/12/18/Papers/binary/Binary%20Software%20Composition%20Analysis%20via%20Intelligent%20Binary%20Source%20Code%20Matching/"/>
      <url>/2023/12/18/Papers/binary/Binary%20Software%20Composition%20Analysis%20via%20Intelligent%20Binary%20Source%20Code%20Matching/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241531902.png" alt="image-20240424153138830" /></p><p>BinaryAI相关的学术论文《BinaryAI: Binary Software Composition Analysis via Intelligent Binary Source Code Matching》已被软件工程领域顶级学术会议 ICSE 2024录用，该项研究由腾讯安全科恩实验室和南方科技大学计算机科学与工程系张煜群教授团队联合完成。</p><p>随着开源软件在商业及个人项目中变得日益普及，开发团队越来越多地依赖外部组件库以加速开发进程，软件供应链的复杂性不断增加，同时也带来了潜在的安全风险。例如，XZ后门漏洞（CVE-2024-3094）导致了潜在的供应链攻击，它影响了Linux/Unix系统中用于处理.xz和.lzma文件的命令行压缩工具XZ Utils。这个漏洞允许攻击者在编译过程中植入恶意代码，进而可能破坏sshd认证并远程获取对整个系统的未授权访问。<strong>二进制软件成分分析（SCA）作为一项重要的软件工程实践，通过对软件构件进行审查，识别二进制中所包含的第三方代码库（Third-party Library, TPL）及其版本号，帮助确定许可证合规性问题和潜在的1-day安全漏洞。</strong></p><p>在此背景下，腾讯安全科恩实验室基于在静态分析和AI安全领域的经验研发出二进制安全智能分析平台—BinaryAI（<a href="https://www.binaryai.cn/%EF%BC%89%EF%BC%8C%E5%85%B6%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E%E5%8F%AF%E6%94%AF%E6%8C%81%E8%BD%AF%E4%BB%B6%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%E5%92%8C%E6%81%B6%E6%84%8F%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%EF%BC%8C%E5%AF%B9%E7%94%A8%E6%88%B7%E4%B8%8A%E4%BC%A0%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6%EF%BC%8CBinaryAI%E5%8F%AF%E4%BB%A5%E5%9C%A8GitHub%E5%85%A8%E9%87%8FC/C++%E5%BA%93%E8%8C%83%E5%9B%B4%E4%B8%AD%E5%81%9A%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%A3%80%E7%B4%A2%EF%BC%8C%E4%BB%A5%E4%B8%9A%E7%95%8C%E9%A2%86%E5%85%88%E7%9A%84%E8%AF%86%E5%88%AB%E5%87%86%E7%A1%AE%E7%8E%87%E5%8C%B9%E9%85%8D%E5%88%B0%E6%96%87%E4%BB%B6%E6%89%80%E4%BD%BF%E7%94%A8%E7%9A%84%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6%E3%80%82">https://www.binaryai.cn/），其智能分析引擎可支持软件成分分析和恶意软件分析，对用户上传的二进制文件，BinaryAI可以在GitHub全量C/C++库范围中做相似性检索，以业界领先的识别准确率匹配到文件所使用的开源组件。</a></p><h1 id="1-背景与现状"><a class="markdownIt-Anchor" href="#1-背景与现状"></a> 1 背景与现状</h1><p>二进制SCA可识别的第三方库（TPL）数据集由大规模开源C/C++项目组成，其中大部分是来自GitHub代码库以及GNU/Linux社区的源代码包，通常现有的二进制SCA技术从大规模的TPL数据集中提取源代码特征以构建特征到对应第三方库的倒排索引并存储在SCA数据库中。随后，二进制SCA工具利用代码克隆检测等技术来识别TPL与二进制文件之间的相似代码特征，如果相似特征的比例超过预定义的阈值则将其识别为二进制所包含的开源组件。</p><p>**二进制SCA中的关键步骤是二进制-源代码匹配，这一步骤将二进制代码映射到相应的源代码，进而实现二进制到源代码仓库的相似特征检测。**B2SFinder，作为最先进的二进制SCA工具之一，选择了在编译前后仍保持一致的基本语法特征（例如，字符串常量）来匹配源代码和对应的开源第三方组件。除了二进制SCA之外，二进制-源代码匹配在软件安全的其他场景中也至关重要，例如逆向工程和恶意软件分析等。</p><p>现有二进制SCA利用基本语法特征进行二进制-源代码匹配，建立了二进制代码与TPL源代码之间的对应关系，但是由于C/C++语法特性（例如，函数内联）、编译器优化等因素，二进制代码和源代码之间通常存在巨大差异，因而二进制SCA工具的有效性通常受到影响。首先，这些基本特征在大规模TPL数据集中往往表现出显著的冗余性，降低了各自在数据集中的独特性和有效性，进而影响了SCA的识别精确度。此外，在部分情况下，目标二进制文件与第三方库之间几乎或完全没有共同的基本语法特征，特别是剥离了符号表信息的二进制文件（stripped binary），导致二进制SCA的召回率受到影响。</p><p>因此，**在二进制SCA中采用细粒度的代码特征（例如，函数级特征）是至关重要的，这样可以通过处理高层次的语义信息以减轻基本特征带来的问题。**考虑到编译过程中引入的二进制和源代码函数之间的显著差异，我们在BinaryAI中首次尝试利用海量有监督数据训练自回归大语言模型，<strong>将二进制和源代码特征映射到同一高维向量空间得到其函数向量（function embeddings），并相应地进行二进制到源代码函数的相似度计算和检索匹配，以增强二进制SCA第三方库的识别准确度。</strong></p><h1 id="2-binaryai技术解析"><a class="markdownIt-Anchor" href="#2-binaryai技术解析"></a> 2 BinaryAI技术解析</h1><p>二进制安全智能分析平台BinaryAI基于大模型的二进制-源代码匹配进行二进制软件成分分析。图中展示的BinaryAI基本工作流程由四个阶段组成：</p><p><strong>特征提取、基于大模型的函数向量检索、链接时局部相关性驱动的函数匹配和第三方组件库检测。</strong></p><p>首先，BinaryAI分别从大规模TPL数据集中的代码库提取C/C++源代码函数，以及通过反编译从目标二进制文件中提取类C的伪代码函数（即，二进制函数）。相应地，BinaryAI采用<a href="http://mp.weixin.qq.com/s?__biz=MzU1MjgwNzc4Ng==&amp;mid=2247504387&amp;idx=1&amp;sn=895fb77806e09a74edfb08fd9b9f0ea2&amp;chksm=fbfeee06cc896710da3a9c589eba67c252f9ff6b9dd7644f729f252a9203656d051b0cbe2fa2&amp;scene=21#wechat_redirect">自研的代码匹配模型BAI</a>为源代码和二进制函数生成函数向量用于相似度计算。在BinaryAI中，二进制-源代码匹配过程被划分为两个单独的阶段进行。首先，代码匹配模型BAI架构基于自回归大语言模型，通过学习基于Token的函数语法特征，为每个二进制函数从数据库中检索到top-k相似的源代码函数。接下来，BinaryAI利用额外的结构化信息来捕获函数间的语义特征，进而从top-k个相似函数中准确匹配到对应的源代码函数。最终，BinaryAI通过计算目标二进制与第三方库之间匹配的源代码函数比例识别出二进制包含的第三方库。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241541048.png" alt="image-20240424154141981" /></p><h2 id="21-特征提取"><a class="markdownIt-Anchor" href="#21-特征提取"></a> <strong>2.1 特征提取</strong></h2><p>**源代码侧：**对于TPL数据集中的每个开源项目，我们收集所有版本中的C/C<ins>源文件，通过tree-sitter内置的解析器构建文件的AST并提取所有的C/C</ins>源代码函数并去重。**与此同时，我们在SCA数据库中维护了两个倒排索引来存储提取的源函数到对应源文件和第三方库的映射关系。**最终，我们从12K个开源项目中提取到了亿数量级独一无二的C/C++源代码函数。</p><p>**二进制侧：**我们利用Ghidra来实时反编译上传后的二进制文件，以生成二进制代码的类C伪代码表示作为二进制函数，用于后续BinaryAI的分析。此外，我们还利用Ghidra提取每个二进制函数的相对虚拟地址作为表示二进制文件中函数链接时局部相关性（link-time locality）的位置序号，以及二进制函数的调用图（function call graph）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241542833.png" alt="image-20240424154219725" /></p><h2 id="22-基于大模型的函数向量检索"><a class="markdownIt-Anchor" href="#22-基于大模型的函数向量检索"></a> 2.2 基于大模型的函数向量检索</h2><p>BinaryAI的核心是基于函数向量执行函数级别的二进制-源代码匹配，即我们的首要目标是训练一个Embedding模型，该模型能够在单一向量空间中为二进制和源代码函数学习到有意义的向量表示，其中相似的二进制到源函数对在向量空间中保持接近，而不相似的函数向量则相距较远。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241542558.webp" alt="图片" /></p><p>对于二进制-源代码匹配，二进制代码和源代码之间可能存在显著差异，然而典型的代码表示学习只匹配单一代码格式，即仅源代码到源代码或者二进制到二进制的代码匹配。现有的大语言模型在自然语言的语法学习方面极为有效，并且这种能力也扩展到了代码语言。尤其是一个在多种编程语言上训练的大模型能够跨不同代码格式识别相似的基于Token的语法特征，这有助于代码克隆检测，即使代码已经被翻译成不同的语言。为此，我们使用现有的大语言模型作为基础模型，并进一步使用标注好的二进制-源代码函数对作为语料库，采用有监督的对比学习方法进行预训练以构建BAI模型。</p><p>在BinaryAI中，我们采用Pythia套件中的模型作为基础模型来初始化BAI模型，然后进一步使用对比学习进行预训练。为了获得大量匹配的二进制源代码函数对作为训练模型的正样本，我们基于官方ArchLinux软件包和Arch用户仓库（AUR）构建了自动化的编译流水线。具体来说，我们使用makepkg命令自动编译所有的ArchLinux软件包。同时，我们通过编译器生成DWARF格式的调试信息。一方面，我们使用Ghidra反编译二进制文件以获得从虚拟地址到二进制函数的映射。另一方面，我们解析DWARF调试信息，并提取从虚拟地址到源文件及行号的映射关系。我们进一步利用tree-sitter来切分文件中相应的源函数。通过合并双方的映射，我们构建了包含10M二进制到源代码函数正样本对的训练语料，平均每个函数具有500个token。</p><p>作为对比学习中的关键要素之一，增加批内负样本（in-batch negatives）可以有效地帮助Embedding模型学习更具区分性的向量表示并提高下游SCA任务的性能。为此，我们使用Info NCELoss损失函数作为我们的对比训练目标，该函数最初设计用于对齐图像和文本标题的向量表示。图中展示了基于CLIP对比学习方法的训练过程，一个批次包含N个二进制到源代码的函数对，CLIP计算所有可能对之间的余弦相似度矩阵。训练目标是通过对称交叉熵损失对矩阵最大化N个正样本之间的相似度，同时最小化其余N*(N-1)个负样本之间的相似度。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241542554.webp" alt="图片" /></p><p>我们在BinaryAI中部署了训练好的模型，首先离线地为SCA数据库中的所有源代码函数生成对应的函数向量，并存储到向量数据库。对于在线的二进制SCA，BinaryAI从目标二进制中提取二进制函数，并实时生成二进制函数向量作为查询，从向量数据库中检索给定二进制函数的top-k相似的源代码函数。</p><h2 id="23-链接时局部相关性驱动的二次精排"><a class="markdownIt-Anchor" href="#23-链接时局部相关性驱动的二次精排"></a> <strong>2.3 链接时局部相关性驱动的二次精排</strong></h2><p>理想情况下，我们可以直接选择相似度最高的源函数作为匹配结果。然而，由于不同版本间源函数的细微修改，大规模TPL数据集内存在大量相似函数。仅依靠语言模型生成的函数向量来捕捉基于Token的语法特征对于准确匹配源代码函数是不够的，因为检索到的top-k可能非常接近。为此，我们尝试利用链接时局部相关性和函数调用图作为表示结构化的语义特征，这可以帮助在二进制源代码匹配的第二阶段从top-k相似函数中进一步识别出正样本。</p><p>对于用于构建二进制文件的传统C/C++工具链，源代码文件最初由编译器编译成目标文件。随后，链接器解析目标文件之间的符号引用，并将它们组合成二进制文件。通过分析编译过程，我们可以得出几个基本发现。</p><p>1.同一源文件中的所有源函数被编译进单个目标文件，尽管它们相对于源文件的局部位置可能会发生改变。</p><p>2.目标文件被连续地链接进二进制文件，目标文件代码段内的所有函数（即，机器代码格式的二进制函数）保持它们的相对位置不变。</p><p>因此，我们可以进一步推导出，从同一源文件编译的二进制函数在二进制文件中是连续的。我们称之为链接时局部相关性。相应地，给定二进制文件的地址空间，我们可以通过切割包含连续二进制函数的区间来进行逆向，以恢复目标文件的边界（CodeCut问题），并进一步识别出编译进二进制文件的相对应源文件，从而准确匹配出这些文件中包含的源函数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241543014.webp" alt="图片" /></p><p>BinaryAI中链接时局部相关性驱动的函数匹配的具体算法流程如下，首先我们将检索到的top-k相似函数构建为索引文件到二进制源代码函数对的映射。对于每个源文件，我们根据链接时局部相关性驱动对函数对进行排序，并使用两个独立指针的滑动窗口来切片文件，以提取包含连续函数对的区间并映射回二进制文件的地址空间。与其他文件相比，我们发现编译进二进制文件的文件有着更长的函数连续区间。因此，我们将文件选择视为二进制文件地址空间内的区间覆盖问题并且采用贪心算法进行求解，这使我们能够优先选择能够覆盖更多函数对并且较长的函数区间。与此同时，我们进一步利用函数调用图来限定在所选文件内的二进制源函数匹配。最终，我们 将所选文件中所有剩余的函数对更新为二进制到源函数的匹配结果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241543062.webp" alt="图片" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241543020.webp" alt="图片" /></p><h2 id="24-第三方组件库识别"><a class="markdownIt-Anchor" href="#24-第三方组件库识别"></a> <strong>2.4 第三方组件库识别</strong></h2><p>BinaryAI 获取匹配的源函数后进一步对目标二进制文件运行第三方库检测，（即软件成分分析任务）。通过查询SCA数据库中包含的从源函数到第三方库的倒排索引，我们保留了每个匹配源函数的所有包含的TPL。一般情况下，由于源函数在不同TPL之间中被广泛复用，如果我们保留所有包含的TPL，这种内部的代码克隆可能导致不可避免的误报。为了缓解这个问题，我们基于TPL依赖关系过滤无效的第三方库，该依赖关系显示了TPL之间的复用关系，并且我们只保留被复用方的第三方库。具体来说，我们提前生成TPL依赖关系，作为软件成分分析的额外输入。对于SCA任务，BinaryAI首先从 SCA 数据库中提取每个匹配的源函数的所有包含的 TPL，然后根据 TPL 依赖关系做进一步过滤，同时计算所有保留的函数个数。最后，我们计算每个选定TPL的匹配函数与源函数总数的比率，表示为二进制文件和第三方库的相似性。如果比率超过预定义的阈值，BinaryAI会将其标识为二进制文件中包含的组件。同时，BinaryAI检测这些组件是否会引入安全威胁。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241543041.webp" alt="图片" /></p><p>我们从以下三个方面对BinaryAI的性能进行了全面评估：<strong>函数向量的有效性，二进制-源代码函数匹配准确度，二进制-源代码函数匹配准确度</strong>。</p><h1 id="3-评估"><a class="markdownIt-Anchor" href="#3-评估"></a> 3 评估</h1><h2 id="31-函数向量的有效性"><a class="markdownIt-Anchor" href="#31-函数向量的有效性"></a> <strong>3.1 函数向量的有效性</strong></h2><p>我们首先在基于向量的函数检索方面比较BinaryAI和CodeCMR。CodeCMR作为目前最先进的二进制源代码匹配模型，采用单独的函数编码器（源函数的 DPCNN 和二进制函数的 GNN）和Triplet Loss作为对比学习目标。在两个查询集中BinaryAI在MRR（平均倒数排名）方面都优于CodeCMR。通过结合两个查询集，BinaryAI的MRR达到了0.3407，与CodeCMR的0.1769，这表明BinaryAI检索到的正样本平均排名更高。此外，与CodeCMR相比，BinaryAI有效地将recall@1从10.75%提高到22.54%，recall@100从33.87%提高到56.60%。</p><p>我们进一步研究了基于模型的技术（BinaryAI，CodeCMR）与传统依赖基本特征的技术（BinPro，B2SFinder）之间的差异。我们发现传统技术在检索源代码函数方面的性能相当有限。具体来说，BinPro和B2SFinderMRR都小于0.005，top-100内召回的正样本少于10%，在top-1的召回率不到5%。接下来，我们调查原因后发现几个导致性能下降的因素。首先，数据集中许多源代码函数共享类似的基本特征，这使得有效区分它们变得具有挑战性。其次，作为查询的一些二进制函数缺乏有意义的基本特征，进一步影响了检索结果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241544318.webp" alt="图片" /></p><h2 id="32-二进制-源代码函数匹配准确度"><a class="markdownIt-Anchor" href="#32-二进制-源代码函数匹配准确度"></a> <strong>3.2 二进制-源代码函数匹配准确度</strong></h2><p>尽管BinaryAI 在从大规模数据中检索源代码函数方面相较于现有最先进技术展现出了显著的性能提升。然而，BinaryAI 在二进制-源代码匹配方面仍然存在局限性，尤其是在直接应用recall@1指标时（如表所示，在SCA测试集中的23,529次查询中达到了22.73%的召回率），这对于后续的二进制SCA任务而言是不够的。所以我们进而探究了链接时局部相关性驱动的函数匹配的准确性及其对二进制-源代码匹配的贡献。</p><p>表中展示了以top-10相似函数为输入的匹配结果。除了精确匹配的结果之外，我们还评估了模糊匹配的结果，因为这些结果适用于其他不依赖极高精确度的下游任务，例如逆向工程。总体来看，我们发现精确匹配的平均精确度达到了81.63%，所有二进制文件的精确度均超过了75%。此外，模糊匹配的平均精确度为95.86%，在所有二进制文件中均超过了90%。这些结果表明，基于链接时局部相关性和函数调用图的函数匹配具有高准确性，并且能够适用于SCA测试集中的所有二进制文件。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241544332.webp" alt="图片" /></p><p>我们进一步评估了对二进制-源代码匹配的贡献。图中展示了基于向量检索的原始recall@1，不同top-k检索结果作为链接时局部相关性驱动匹配的输入并得到更新后的recall@1，以及相应的recall@k，recall@k表示了模型能力限制下的召回上限。总体而言，链接时局部相关性驱动的函数匹配显著提高了原始的recall@1，几乎达到了BinaryAI和CodeCMR的各自的性能上限。对于BinaryAI，链接时局部相关性驱动的匹配将recall@1从22.73%提高到54.70%，对应top-10的上限为57.35%，并进一步将recall@1提高到66.90%，对应top-100的上限为70.45%。</p><p>实验结果表明了链接时局部相关性驱动的函数匹配的贡献，以及BinaryAI中二进制-源代码匹配分两个阶段来识别语法和语义代码特征的有效性。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241544311.webp" alt="图片" /></p><h2 id="33-二进制sca性能"><a class="markdownIt-Anchor" href="#33-二进制sca性能"></a> 3.3 二进制SCA性能</h2><p>最后，我们比较了BinaryAI与现有二进制SCA工具的性能。表中展示了150个二进制文件中人工标记的1,045个TPL组件检测的总体结果。BinaryAI第三方库检测的准确率85.84%以及召回率64.98%，显著优于其他SCA工具。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241544320.webp" alt="图片" /></p><h1 id="4-总结"><a class="markdownIt-Anchor" href="#4-总结"></a> 4 总结</h1><p>二进制软件成分分析是降低第三方库（TPL）引入风险的重要手段，保障了软件供应链安全。传统依赖基本语法特征的SCA 技术在大规模TPL数据集表现出较高的误报率。腾讯安全科恩实验室自研二进制分析工具BinaryAI基于底座的二进制-源代码匹配模型BAI以及链接时局部相关性驱动的函数匹配实现相似源代码函数的高召回率，使得二进制SCA效果达行业高阶水准。</p><h2 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> <strong>参考文献</strong></h2><p><strong>1.</strong> Synopsys. 2023. Black Duck Binary Analysis (BDBA). <a href="https://www">https://www</a>. <a href="http://synopsys.com/software-integrity/security-testing/software-compositionanalysis/binary-analysis.html">synopsys.com/software-integrity/security-testing/software-compositionanalysis/binary-analysis.html</a>.</p><p><strong>2.</strong> Zimu Yuan, Muyue Feng, Feng Li, Gu Ban, Yang Xiao, Shiyang Wang, Qian Tang, He Su, Chendong Yu, Jiahuan Xu, et al. 2019. B2sfinder: detecting open-source software reuse in cots software. In 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 1038–1049.</p><p><strong>3.</strong> Scantist. 2023. Scantist Binary Analysis. <a href="https://scantist.io">https://scantist.io</a></p><p><strong>4.</strong> Ruian Duan, Ashish Bijlani, Meng Xu, Taesoo Kim, and Wenke Lee. 2017. Identifying open-source license violation and 1-day security risk at large scale. In Proceedings of the 2017 ACM SIGSAC Conference on computer and communications security. 2169–2185.</p><p><strong>5.</strong> Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, et al. 2023. Pythia: A suite for analyzing large language models across training and scaling. In International Conference on Machine Learning. PMLR, 2397–2430.</p><p>**6.**Wei Tang, Yanlin Wang, Hongyu Zhang, Shi Han, Ping Luo, and Dongmei Zhang. 2022. LibDB: An Effective and Efficient Framework for Detecting Third-Party Libraries in Binaries. In 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR). 423–434.</p><p><strong>7.</strong> Zeping Yu, Wenxin Zheng, Jiaqi Wang, Qiyi Tang, Sen Nie, and Shi Wu. 2020. Codecmr: Cross-modal retrieval for function-level binary source code matching. Advances in Neural Information Processing Systems 33 (2020), 3872–3883.</p><p><strong>8.</strong> Ling Jiang, Hengchen Yuan, Qiyi Tang, Sen Nie, Shi Wu, and Yuqun Zhang. 2023. Third-Party Library Dependency for Large-Scale SCA in the C/C++ Ecosystem: How Far Are We?. In Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis.</p><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Binary </tag>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tree-sitter安装与基本使用</title>
      <link href="/2023/12/18/Security/CA%20Tool/%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
      <url>/2023/12/18/Security/CA%20Tool/%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="初始化tree-sitter"><a class="markdownIt-Anchor" href="#初始化tree-sitter"></a> 初始化tree-sitter</h1><h2 id="安装tree-sitter"><a class="markdownIt-Anchor" href="#安装tree-sitter"></a> 安装tree-sitter</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install tree-sitter</span><br></pre></td></tr></table></figure><h2 id="语言支持"><a class="markdownIt-Anchor" href="#语言支持"></a> 语言支持</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">针对要解析的语言，创建文件夹，并从github的tree-sitter仓库下载语言支持</span></span><br><span class="line">mkdir vendor</span><br><span class="line">cd vendor</span><br><span class="line">git clone https://github.com/tree-sitter/tree-sitter-cpp</span><br><span class="line">git clone https://github.com/tree-sitter/tree-sitter-c</span><br></pre></td></tr></table></figure><h2 id="创建build文件夹"><a class="markdownIt-Anchor" href="#创建build文件夹"></a> 创建build文件夹</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">build于vendor是同级文件夹</span></span><br><span class="line">mkdir build</span><br></pre></td></tr></table></figure><p>创建language_build.py，生成.so文件，该文件相当于自定义的编译器，用于解析代码生成语法树</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tree_sitter <span class="keyword">import</span> Language, Parser</span><br><span class="line">Language.build_library(</span><br><span class="line">  <span class="comment"># Store the library in the `build` directory</span></span><br><span class="line">  <span class="string">&#x27;my-languages.so&#x27;</span>,</span><br><span class="line">  <span class="comment"># Include one or more languages</span></span><br><span class="line">  [</span><br><span class="line">    <span class="string">&#x27;../vendor/tree-sitter-c&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;../vendor/tree-sitter-cpp&#x27;</span></span><br><span class="line">  ]</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>运行该文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python language_build.py</span><br></pre></td></tr></table></figure><h1 id="使用初探"><a class="markdownIt-Anchor" href="#使用初探"></a> 使用初探</h1><h2 id="基本过程"><a class="markdownIt-Anchor" href="#基本过程"></a> 基本过程</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入依赖</span></span><br><span class="line"><span class="keyword">from</span> tree_sitter <span class="keyword">import</span> Language, Parser</span><br><span class="line"><span class="comment"># so文件路径和语言配置</span></span><br><span class="line">CPP_LANGUAGE = Language(<span class="string">&#x27;../build/my-languages.so&#x27;</span>, <span class="string">&#x27;cpp&#x27;</span>)</span><br><span class="line">C_LANGUAGE = Language(<span class="string">&#x27;../build/my-languages.so&#x27;</span>, <span class="string">&#x27;c&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 举一个CPP例子</span></span><br><span class="line">cpp_parser = Parser()</span><br><span class="line">cpp_parser.set_language(CPP_LANGUAGE)</span><br><span class="line"></span><br><span class="line">file_path = <span class="string">&quot;dot/177755_CVE-2015-7540_CWE-399_vul.c&quot;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    code = file.read()</span><br><span class="line">tree = cpp_parser.parse(<span class="built_in">bytes</span>(code, <span class="string">&quot;utf8&quot;</span>))</span><br><span class="line"><span class="comment"># tree = parser.parse(source.encode(&#x27;utf-8&#x27;).decode(&#x27;unicode_escape&#x27;).encode())</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(tree))</span><br></pre></td></tr></table></figure><h2 id="遍历tree"><a class="markdownIt-Anchor" href="#遍历tree"></a> 遍历tree</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_tree</span>(<span class="params">node, indent=<span class="number">0</span></span>):</span><br><span class="line">    code = node.text.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span> * indent, node.<span class="built_in">type</span>, code)</span><br><span class="line">    <span class="keyword">for</span> child <span class="keyword">in</span> node.children:</span><br><span class="line">        print_tree(child, indent + <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print_tree(tree.root_node)</span><br></pre></td></tr></table></figure><h2 id="tree节点属性"><a class="markdownIt-Anchor" href="#tree节点属性"></a> tree节点属性</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 孩子节点【节点数、节点列表】</span></span><br><span class="line">root_node.child_count: <span class="built_in">int</span></span><br><span class="line">root_node.children: <span class="built_in">list</span>[Node]| <span class="literal">None</span></span><br><span class="line"><span class="comment"># 该语法树节点对应代码字符串位置【左闭右开】</span></span><br><span class="line">root_node.start_byte: <span class="built_in">int</span></span><br><span class="line">root_node.end_byte: <span class="built_in">int</span></span><br><span class="line"><span class="comment"># 语法树节点对应代码 (行, 列) 位置元组</span></span><br><span class="line">root_node.start_point: <span class="built_in">tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line">root_node.end_point: <span class="built_in">tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">以上的行、列以及字符串位置都是以0开始</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 语法树命名节点、命名类型 以及 语法树对应的文本</span></span><br><span class="line"><span class="comment"># 因为具体语法树有代码所有的标记，所以一些符号可能没有类型</span></span><br><span class="line"><span class="comment"># 我猜测该属性可以用于区别具体语法树符号节点，构建抽象语法树</span></span><br><span class="line">root_node.is_named: <span class="built_in">bool</span></span><br><span class="line">root_node.<span class="built_in">type</span>: <span class="built_in">str</span> <span class="comment"># 没有类型时，这里显示代码原始标记</span></span><br><span class="line">root_node.text: <span class="built_in">bytes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 语法树父节点</span></span><br><span class="line">root_node.parent: Node| <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 语法树左兄弟、左命名兄弟</span></span><br><span class="line">root_node.prev_sibling: Node| <span class="literal">None</span></span><br><span class="line">root_node.prev_named_sibling: Node| <span class="literal">None</span></span><br><span class="line"><span class="comment"># 语法树右兄弟、右命名兄弟</span></span><br><span class="line">root_node.next_sibling: Node| <span class="literal">None</span></span><br><span class="line">root_node.next_named_sibling: Node| <span class="literal">None</span></span><br></pre></td></tr></table></figure><h3 id="附属性和方法"><a class="markdownIt-Anchor" href="#附属性和方法"></a> 附：属性和方法</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;tree_sitter.Tree&#x27;</span>&gt;</span><br><span class="line"><span class="comment"># print(dir(tree))</span></span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>, <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__init_subclass__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__module__&#x27;</span>, <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>, <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;changed_ranges&#x27;</span>, <span class="string">&#x27;edit&#x27;</span>, <span class="string">&#x27;included_ranges&#x27;</span>, <span class="string">&#x27;root_node&#x27;</span>, <span class="string">&#x27;root_node_with_offset&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;walk&#x27;</span>]</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;tree_sitter.Node&#x27;</span>&gt;</span><br><span class="line"><span class="comment"># print(dir(tree.root_node))</span></span><br><span class="line">[<span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>, <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__init_subclass__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__module__&#x27;</span>, <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>, <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;byte_range&#x27;</span>, <span class="string">&#x27;child&#x27;</span>, <span class="string">&#x27;child_by_field_id&#x27;</span>, <span class="string">&#x27;child_by_field_name&#x27;</span>, <span class="string">&#x27;child_count&#x27;</span>, <span class="string">&#x27;children&#x27;</span>, <span class="string">&#x27;children_by_field_id&#x27;</span>, <span class="string">&#x27;children_by_field_name&#x27;</span>, <span class="string">&#x27;descendant_count&#x27;</span>, <span class="string">&#x27;descendant_for_byte_range&#x27;</span>, <span class="string">&#x27;descendant_for_point_range&#x27;</span>, <span class="string">&#x27;edit&#x27;</span>, <span class="string">&#x27;end_byte&#x27;</span>, <span class="string">&#x27;end_point&#x27;</span>, <span class="string">&#x27;field_name_for_child&#x27;</span>, <span class="string">&#x27;grammar_id&#x27;</span>, <span class="string">&#x27;grammar_name&#x27;</span>, <span class="string">&#x27;has_changes&#x27;</span>, <span class="string">&#x27;has_error&#x27;</span>, <span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;is_error&#x27;</span>, <span class="string">&#x27;is_extra&#x27;</span>, <span class="string">&#x27;is_missing&#x27;</span>, <span class="string">&#x27;is_named&#x27;</span>, <span class="string">&#x27;kind_id&#x27;</span>, <span class="string">&#x27;named_child&#x27;</span>, <span class="string">&#x27;named_child_count&#x27;</span>, <span class="string">&#x27;named_children&#x27;</span>, <span class="string">&#x27;named_descendant_for_byte_range&#x27;</span>, <span class="string">&#x27;named_descendant_for_point_range&#x27;</span>, <span class="string">&#x27;next_named_sibling&#x27;</span>, <span class="string">&#x27;next_parse_state&#x27;</span>, <span class="string">&#x27;next_sibling&#x27;</span>, <span class="string">&#x27;parent&#x27;</span>, <span class="string">&#x27;parse_state&#x27;</span>, <span class="string">&#x27;prev_named_sibling&#x27;</span>, <span class="string">&#x27;prev_sibling&#x27;</span>, <span class="string">&#x27;range&#x27;</span>, <span class="string">&#x27;sexp&#x27;</span>, <span class="string">&#x27;start_byte&#x27;</span>, <span class="string">&#x27;start_point&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;type&#x27;</span>, <span class="string">&#x27;walk&#x27;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">byte_range (<span class="number">0</span>, <span class="number">283</span>)</span><br><span class="line">child &lt;built-<span class="keyword">in</span> method child of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">child_by_field_id &lt;built-<span class="keyword">in</span> method child_by_field_id of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">child_by_field_name &lt;built-<span class="keyword">in</span> method child_by_field_name of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">child_count <span class="number">1</span></span><br><span class="line">children [&lt;Node <span class="built_in">type</span>=function_definition, start_point=(<span class="number">0</span>, <span class="number">0</span>), end_point=(<span class="number">12</span>, <span class="number">2</span>)&gt;]</span><br><span class="line">children_by_field_id &lt;built-<span class="keyword">in</span> method children_by_field_id of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">children_by_field_name &lt;built-<span class="keyword">in</span> method children_by_field_name of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">descendant_count <span class="number">103</span></span><br><span class="line">descendant_for_byte_range &lt;built-<span class="keyword">in</span> method descendant_for_byte_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">descendant_for_point_range &lt;built-<span class="keyword">in</span> method descendant_for_point_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">edit &lt;built-<span class="keyword">in</span> method edit of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">end_byte <span class="number">283</span></span><br><span class="line">end_point (<span class="number">12</span>, <span class="number">2</span>)</span><br><span class="line">field_name_for_child &lt;built-<span class="keyword">in</span> method field_name_for_child of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">grammar_id <span class="number">214</span></span><br><span class="line">grammar_name translation_unit</span><br><span class="line">has_changes <span class="literal">False</span></span><br><span class="line">has_error <span class="literal">False</span></span><br><span class="line"><span class="built_in">id</span> <span class="number">24860624</span></span><br><span class="line">is_error <span class="literal">False</span></span><br><span class="line">is_extra <span class="literal">False</span></span><br><span class="line">is_missing <span class="literal">False</span></span><br><span class="line">is_named <span class="literal">True</span></span><br><span class="line">kind_id <span class="number">214</span></span><br><span class="line">named_child &lt;built-<span class="keyword">in</span> method named_child of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">named_child_count <span class="number">1</span></span><br><span class="line">named_children [&lt;Node <span class="built_in">type</span>=function_definition, start_point=(<span class="number">0</span>, <span class="number">0</span>), end_point=(<span class="number">12</span>, <span class="number">2</span>)&gt;]</span><br><span class="line">named_descendant_for_byte_range &lt;built-<span class="keyword">in</span> method named_descendant_for_byte_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">named_descendant_for_point_range &lt;built-<span class="keyword">in</span> method named_descendant_for_point_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">next_named_sibling <span class="literal">None</span></span><br><span class="line">next_parse_state <span class="number">0</span></span><br><span class="line">next_sibling <span class="literal">None</span></span><br><span class="line">parent <span class="literal">None</span></span><br><span class="line">parse_state <span class="number">0</span></span><br><span class="line">prev_named_sibling <span class="literal">None</span></span><br><span class="line">prev_sibling <span class="literal">None</span></span><br><span class="line"><span class="built_in">range</span> &lt;Range start_point=(<span class="number">0</span>, <span class="number">0</span>), start_byte=<span class="number">0</span>, end_point=(<span class="number">12</span>, <span class="number">2</span>), end_byte=<span class="number">283</span>&gt;</span><br><span class="line">sexp &lt;built-<span class="keyword">in</span> method sexp of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">start_byte <span class="number">0</span></span><br><span class="line">start_point (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">text <span class="string">b&#x27;bool fun1(struct var1 *var2, bool *var3)\n &#123;\n        uint8_t var4 = 0;\n       fun2(var2, var5);\n       fun3(var2, &amp;var4);\n        if (var4 == 0xFF) &#123;\n                *var3 = true;\n       &#125; else &#123;\n               *var3 = false;\n        &#125;\n       fun4(var2);\n       return !var2-&gt;var6;\n &#125;&#x27;</span></span><br><span class="line"><span class="built_in">type</span> translation_unit</span><br><span class="line">walk &lt;built-<span class="keyword">in</span> method walk of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Code Analysis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tree-sitter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flawfinder开源C/C++静态扫描分析工具安装与使用</title>
      <link href="/2023/12/18/Security/software%20security/FlawFinder_/"/>
      <url>/2023/12/18/Security/software%20security/FlawFinder_/</url>
      
        <content type="html"><![CDATA[<h2 id="flawfinder开源cc静态扫描分析工具安装与使用"><a class="markdownIt-Anchor" href="#flawfinder开源cc静态扫描分析工具安装与使用"></a> Flawfinder开源C/C++静态扫描分析工具安装与使用</h2><h2 id="flawfinder的介绍"><a class="markdownIt-Anchor" href="#flawfinder的介绍"></a> flawfinder的介绍</h2><p>Flawfinder是一款开源的关于C/C<ins>静态扫描分析工具，其根据内部字典数据库进行静态搜索，匹配简单的缺陷与漏洞，flawfinder工具不需要编译C/C</ins>代码，可以直接进行扫描分析。简单快速，最大的有点就是免费，不需要编译。flawfinder工具可以在官网进行下载。<br /><a href="https://dwheeler.com/flawfinder/#downloading">https://dwheeler.com/flawfinder/#downloading</a></p><h2 id="flawfinder的安装"><a class="markdownIt-Anchor" href="#flawfinder的安装"></a> flawfinder的安装</h2><h3 id="在线安装"><a class="markdownIt-Anchor" href="#在线安装"></a> 在线安装</h3><p>flawfinder安装比较简单，由于其是基于Python实现的一款工具，所以需要首先安装Python环境，并配置环境变量。flawfinder下载之后解压既可使用。flawfinder目前支持python2和python3，简单的方法是使用pip工具，执行以下指令进行安装。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install flawfinder</span><br></pre></td></tr></table></figure><h3 id="离线安装"><a class="markdownIt-Anchor" href="#离线安装"></a> 离线安装</h3><p>直接从flawfinder下载程序压缩包，解压完成以后，使用python直接加载flawfiner程序即可，或者直接下载flawfinder-*.whl，使用pip工具离线安装，这种通常是在一些甲方审计项目中出现，甲方客户无法协调审计设备上的管理员权限，又无法连接外网，只能使用一些免安装的工具。对于这种情况，python直接使用免安装版本，使用离线的方式使用pip安装或者使用python直接运行flawfinder,给各位审计人员一个建议，原理这些不靠谱的甲方企业。</p><h2 id="flawfinder的使用"><a class="markdownIt-Anchor" href="#flawfinder的使用"></a> flawfinder的使用</h2><p>方式一：<code>flawfinder --csv &gt; test-result.csv test.c</code><br />这种方式根据缺陷库生成一个 .csv文件  ，你只需要根据这个.csv文件就可以转换为正常Excel文件使用，转换方法自行百度。<br />方式二：<code>flawfinder --html &gt; test-result.html test.c</code></p><h2 id="案例讲解"><a class="markdownIt-Anchor" href="#案例讲解"></a> 案例讲解</h2><p>由于在日常审计过程中，项目中有其他格式的文件，通常使用linux<code>find</code>工具批量筛选.c或者.cpp文件，然后使用flawfinder进行扫描</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp --parents `find 程序目录/-name *.c`  指定扫描目录</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><ul><li>增加–parents目录主要作用是在拷贝的时候，会在目标路径中创建源文件参数中的所有父目录层级(不止是一层父目录)，然后将源文件拷贝进去。这样做的目的主要是清晰展示目录结构，方便写报告。</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flawfinder --csv &gt; result.csv 指定扫描目录</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>导出csv文件内容展示如下<br /><a href="https://hksanduo.github.io/img/flawfinder-csv.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047482.png" alt="flawfinder-csv.png" /></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-csv.png">flawfinder-csv.png</a></p><h2 id="flawfinder分析"><a class="markdownIt-Anchor" href="#flawfinder分析"></a> flawfinder分析</h2><p>Flawfinder 不是类似于fortify那样复杂的工具,它是一个简单并有意义工具。Flawfinder通过使用内置的C/C++函数数据库来工作，该数据库具有众所周知的安全风险，例如缓冲区溢出风险（例如strcpy()，strcat()，gets()，sprintf()和scanf()），格式字符串问题（printf()，snprintf()和syslog()），竞争条件（例如access()，chown()，chgrp()，chmod()，tmpfile()，tmpnam()，tempnam()和mktemp()），潜在的远程命令执行风险（大多数exec()系列，system()，popen()）和较差的随机数获取方法（例如random()）。<br />Flawfinder的好处是不必创建相关数据库，自身就拥有相关数据库。Flawfinder获取源代码，并将源代码文本与这些名称匹配，同时忽略注释和字符串中的文本。Flawfinder还支持gettext（国际化程序的公共库），并且会将通过gettext传递的常量字符串当作常量字符串对待。这减少了国际化程序中的错误命中次数。<br />Flawfinder生成按风险分类的（潜在安全漏洞）列表；默认情况下，最危险的匹配项将首先显示。风险级别不仅取决于功能，还取决于功能的参数值。例如：在许多情况下，常量字符串通常比完全可变字符串的风险要小。在某些情况下，代码审计人员可能能够确定该结构体完全没有风险，从而减少了误报。与仅在源代码上运行“ grep”相比，Flawfinder提供了更好的信息和更好的优先级。flawfinder可以忽略注释和字符串内部，并且还将检查参数以估计风险水平。但是，从根本上来说，flawfinder仅仅是一个简单的python程序。它甚至不知道函数参数的数据类型，并且当然也不进行控制流或数据流分析。由于Flawfinder很简单，因此不会被宏定义和更复杂的工具遇到的其他奇怪问题所混淆。Flawfinder可以分析无法构建的软件；在某些情况下，它可以分析甚至无法在本地编译的文件。但是需要主要一点儿，并非发现的每个问题都是一个安全漏洞，也不一定能找到所有安全漏洞。如上所述，flawfinder不能真正理解代码的语义，它主要完成简单的文本模式匹配（忽略注释和字符串），不执行数据流或控制流分析，尽管如此，flawfinder在实际代码审计项目中也可以协助安全人员发现和消除安全漏洞。</p><h2 id="错误修复"><a class="markdownIt-Anchor" href="#错误修复"></a> 错误修复</h2><h3 id="unicodedecodeerror-utf-8-codec-cant-decode-byte-0xff-in-position-0-invalid-start-byte"><a class="markdownIt-Anchor" href="#unicodedecodeerror-utf-8-codec-cant-decode-byte-0xff-in-position-0-invalid-start-byte"></a> UnicodeDecodeError: ‘utf-8’ codec can’t decode byte 0xff in position 0: invalid start byte</h3><p>在运行过程中，会出现解码出错，官方给出的建议是通过强制转换扫描文档的格式为utf-8，我们可以直接忽略<br /><code>UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte</code><br /><a href="https://hksanduo.github.io/img/flawfinder-error.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047480.png" alt="flawfinder-error.png" /></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-error.png">flawfinder-error.png</a></p><h4 id="官方修复建议"><a class="markdownIt-Anchor" href="#官方修复建议"></a> 官方修复建议</h4><p><a href="https://hksanduo.github.io/img/flawfinder-office-advice.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047486.png" alt="flawfinder-office-advice.png" /></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-office-advice.png">flawfinder-office-advice.png</a></p><p>将操作系统的编码格式设置成<code>utf-8</code>，将程序编码格式强制转换为utf-8，官方推荐的工具为<code>cvt2utf</code>，可以根据实际情况自行修改。</p><h4 id="个人修复建议"><a class="markdownIt-Anchor" href="#个人修复建议"></a> 个人修复建议</h4><p><a href="https://hksanduo.github.io/img/flawfinder-persional-advice1.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047489.png" alt="flawfinder-persional-advice1.png" /></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-persional-advice1.png">flawfinder-persional-advice1.png</a></p><p>个人这个就有点儿暴力，直接在打开文件的那一步设定，如果出现错误直接忽略。flawfinder如果使用pip安装，安装的位置位于<code>/usr/local/bin/flawfinder</code>，其他安装方式，请根据实际情况进行查找。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047492.png" alt="flawfinder-persional-advice2.png" /></p><p>flawfinder-persional-advice2.png</p><h3 id="unicodedecodeerror-ascii-codec-cant-decode-byte-0xe6-in-position-29-ordinal-not-in-range128"><a class="markdownIt-Anchor" href="#unicodedecodeerror-ascii-codec-cant-decode-byte-0xe6-in-position-29-ordinal-not-in-range128"></a> UnicodeDecodeError: ‘ascii’ codec can’t decode byte 0xe6 in position 29: ordinal not in range(128)</h3><h4 id="错误原因"><a class="markdownIt-Anchor" href="#错误原因"></a> 错误原因</h4><p>提示中的“ordinal not in range(128)”，意思是，字符不在128范围内，即说明不是普通的ASCII字符，超出处理能力了。</p><h4 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h4><p>找到flawfinder程序文件，用文本编辑器打开，在文件抬头加入以下代码。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&quot;utf-8&quot;)</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2><ul><li><a href="https://dwheeler.com/flawfinder/%E3%80%90flawfinder%E5%AE%98%E7%BD%91%E3%80%91">https://dwheeler.com/flawfinder/【flawfinder官网】</a></li><li><a href="https://github.com/david-a-wheeler/flawfinder%E3%80%90github%E3%80%91">https://github.com/david-a-wheeler/flawfinder【github】</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 静态分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>符号执行</title>
      <link href="/2023/12/18/Security/software%20security/Symbolic%20Execution/"/>
      <url>/2023/12/18/Security/software%20security/Symbolic%20Execution/</url>
      
        <content type="html"><![CDATA[<h1 id="符号执行"><a class="markdownIt-Anchor" href="#符号执行"></a> <strong>符号执行</strong></h1><h3 id="符号执行是什么"><a class="markdownIt-Anchor" href="#符号执行是什么"></a> 符号执行是什么</h3><p>符号执行 （Symbolic Execution）是一种程序分析技术，它可以通过分析程序来得到让特定代码区域执行的输入。顾名思义，使用符号执行分析一个程序时，该程序会使用符号值作为输入，而非一般执行程序时使用的具体值。在达到目标代码时，分析器可以得到相应的路径约束，然后通过约束求解器来得到可以触发目标代码的具体值。</p><h3 id="符号执行它的优势"><a class="markdownIt-Anchor" href="#符号执行它的优势"></a> 符号执行它的优势</h3><p>生成具体测试输入的能力是符号执行的主要优势之一：</p><p>从测试生成的角度来看，它允许创建高覆盖率的测试套件，而从bug查找的角度来看，它为开发人员提供了触发bug的具体输入，该输入可用于确认和调试打开的错误。</p><h3 id="符号执行过程"><a class="markdownIt-Anchor" href="#符号执行过程"></a> 符号执行过程</h3><p>在任何时候，符号执行引擎都维持一个状态（stmt，σ，π）。</p><ul><li><p>stmt是下一个要评估的语句。目前，我们假设stmt可以是赋值，条件分支或跳转。</p></li><li><p>σ是一个符号存储，它将程序变量与具体值或符号值αi上的表达式相关联。</p></li><li><p>π表示路径约束，即，是表示由于在执行中为了达到stmt而采取的分支而对符号αi的一组假设的公式。在分析开始时，π=真。</p></li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035360.png" alt="image-20210416135536910" /></p><p>下面是一个简单的符号执行的样例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035357.png" alt="图片" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035364.png" alt="image-20210416135605643" /></p><p>在沿着程序的执行路径的符号执行结束时，使用约束求解器来求解π以生成具体的输入值。</p><h3 id="符号执行实现的两种方案"><a class="markdownIt-Anchor" href="#符号执行实现的两种方案"></a> 符号执行实现的两种方案</h3><ul><li><p>1）基于IR的符号执行:IRs实现解释器比直接为机器代码实现符号解释器<strong>容易得多</strong>，因此这是许多系统所采用的方法,但是IR生成可能需要大量的工作, 而且<mark>解释IR要比相应二进制文件的本机执行慢得多</mark>。</p></li><li><p>2）无IR的符号执行:不是将被测程序翻译成IR然后解释，而是执行未修改的机器代码，并在运行时对其进行检测, 但是一般机器指令较多, 实现起来没有<mark>基于IR的符号执行简单</mark>。</p></li></ul><h3 id="concolic执行"><a class="markdownIt-Anchor" href="#concolic执行"></a> Concolic执行</h3><p>Concolic执行维护一个实际状态和一个符号化状态：实际状态将所有变量映射到实际值，<mark>符号状态只映射那些有非实际值的变量</mark>。Concolic执行首先用一些给定的或者随机的输入来执行程序，收集执行过程中条件语句对输入的符号化约束，然后使用约束求解器去推理输入的变化，从而将下一次程序的执行导向另一条执行路径。</p><p>简单地说来，就是在已有实际输入得到的路径上，对分支路径条件进行取反，就可以让执行走向另外一条路径。这个过程会不断地重复，加上系统化或启发式的路径选择算法，直到所有的路径都被探索，或者用户定义的覆盖目标达到，或者时间开销超过预计。</p><p>我们依旧以上面那个程序的例子来说明。我们从一个实际输入{a=0, b=7}出发，符号化执行得到第一个约束条件a0 == 0，第一次取反得到a0 != 0 ，从而得到测试输入{x=2, y=1}和新约束(a0 != 0) &amp; (b0 !=0)；第二次取反得到(a0 != 0) &amp; (b0 ==0)，从而求解出测试输入{x=1, y=0}。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035369.png" alt="image-20210416135618076" /></p><h1 id="混合模糊"><a class="markdownIt-Anchor" href="#混合模糊"></a> 混合模糊</h1><p>模糊技术可以以近乎自然的速度快速探索输入空间，但它只擅长于发现<mark>导致执行路径具有松散分支条件</mark>（如x&gt;0）的输入。相反，concolic执行擅长于找到将程序驱动到紧凑而复杂的分支条件的输入，例如x==0xdeadbeef，但是计算和解决这些约束非常昂贵且缓慢。</p><p>将模糊化和concolic执行结合起来，希望模糊程序能快速地探索琐碎的输入空间（即松散条件），concolic执行能解决复杂的分支。</p><h3 id="driller"><a class="markdownIt-Anchor" href="#driller"></a> Driller</h3><p>比较早(2016年)将符号执行和模糊测试结合的工具是Driller.Driller是基于fuzz工具AFL和符号执行工具angr来实现的，<strong>当模糊程序卡住时调用符号执行来求解能够到达新路径的输入</strong>，使得fuzz能够快速突破条件判断语句。</p><p>具体实现是，通过监测AFL的执行，可以决定什么时候开始符号执行以探索新路径。如果AFL执行了x轮后，<mark>bitmap上显示没有发现新的状态转换（也即新的代码块转移）</mark>，说明AFL卡住了，这时候调用<mark>angr</mark>进行符号执行。</p><p>每个具体输入对应于PathGroup中的单个路径， 在PathGroup的每一步中，检查每个分支以确保最新的跳转指令引入先前AFL未知的路径。当发现这样的跳转时，SMT求解器被查询以创建一个输入来驱动执行到新的跳转。这个输入反馈给AFL，AFL在未来的模糊步骤中进行变异。这个反馈循环使我们能够<mark>将昂贵的符号执行时间与廉价的模糊时间进行平衡</mark>，并且减轻了模糊对程序操作的低语义洞察力。</p><h3 id="qsym"><a class="markdownIt-Anchor" href="#qsym"></a> QSYM</h3><p>2018年一款新的混合模糊引擎QSYM被提出，它的作者观察到，他们的 concolic executors的性能瓶颈是阻止他们被复杂的实际应用所采用的主要限制因素。</p><p>下面讲述了QSYM的作者任务影响符号执行性能的因素。</p><ul><li>1)慢符号执行</li></ul><p>现有的协同执行器选择IR来大大降低它们的实现复杂度；然而，这牺牲了性能。此外，加速IR使用的优化禁止了进一步的优化机会，特别是通过以基本块粒度将程序转换为IRs。此设计不允许跳过不涉及符号执行指令的仿真指令。</p><p>首先，IR翻译本身增加了开销。在大多数情况下，机器指令的翻译会导致多条IR指令。从而产生了大量的符号模拟处理.</p><p>如果基本块不处理任何符号变量，它们就不会在模拟器中执行。虽然这有效地减少了开销，但仍有优化的空间。根据我们对libjpeg、libpng、libtiff和file等真实软件的测量，<em>符号基本块中只有30%的指令需要符号执行</em>。这个这意味着一个指令级的方法有机会减少不必要的符号执行的数量。然而，由于IR缓存的原因，当前的concolic执行器不容易采用这种方法。</p><ul><li>2)无效的快照</li></ul><p>常规concolic执行引擎使用<strong>快照技术</strong>来减少在探索目标程序的多条路径时重新执行目标程序的开销。</p><p>引擎在一个分支中备份程序的符号状态，然后探索其中一条路径。</p><p>当路径耗尽或卡住时，发动机将符号状态恢复到分支上的先前状态，并移动到另一条路径。</p><p>引擎可以探索路径，而无需支付重新执行分支程序的费用。</p><p>为什么说快照是无效的?</p><p>第一，混合模糊中的concolic执行引擎从fuzzer中获取多个测试用例，<strong>这些测试用例与程序的不同路径相关联</strong>（即，不共享公共分支）.</p><p>第二，快照机制由于打破了进程边界,快照机制成为支持外部环境的问题.</p><p>当一个程序通过fork（）发散-就像系统调用一样，内核不再维护与外部环境相关的内部状态。因此，协同执行引擎应该自己维护状态.</p><p>通过全系统的concolic执行或外部环境建模来解决这个问题，但是它们分别导致了显著的性能降低和不准确的测试，而且快照无法反映外部状态。</p><ul><li>3)缓慢而不灵活的可靠分析</li></ul><p>concolic执行试图==通过收集完整的约束来保证可靠性。==这种完整性确保满足约束的输入将导致执行到预期的路径。但是，计算完全约束在各种情况下都是昂贵的,并且有可能陷入对复杂事物的永无止境的分析逻辑.例如。下的上半部分显示了文件程序的代码片段。它卡在计算zlib解压的复杂约束，无法搜索其他有趣的代码。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035366.png" alt="image-20210416135633846" /></p><p>其次,concolic完全约束也会过度约束路径，从而限制concolic执行以找到未来路径。特别是，在默认执行之后插入的约束可能会导致过度约束问题.如图三下半部分,</p><p>首先执行到第三行生成约束{ch&gt;=0x20∧ch&lt;0x7f}</p><p>然后到第6行{ch&gt;=0x20∧ch&lt;0x7f&lt;∧ch==0x7f}</p><p>这一不可满足约束,求解这个不可满足约束是无意义的.但是第六行的逻辑不依赖于第三行的相关逻辑,因为在不考虑路径约束的情况下，由concolic执行生成的输入ch==0x7f将探索满足第六行条件的路径。</p><p>为了解决上面的一些瓶颈，QSYM被设计出来，下面讲述QSYM的设计细节。</p><p>1)概述</p><p>QSYM首先使用<mark>动态二进制翻译（DBT）和覆盖引导模糊器</mark>提供的输入运行目标程序。</p><p>DBT为本机执行生成基本块，并为符号执行修剪它们，允许我们在两个执行模型之间快速切换。</p><p>QSYM只选择性地模拟生成符号约束所需的指令，这与现有方法在受污染的基本块中模拟所有的构造不同。</p><p>通过这样做，QSYM大大减少了符号模拟的数量。</p><p>由于QSYM的高效执行，它可以重复执行符号执行，而不是使用需要外部环境建模的快照。</p><p>QSYM可以以具体的方式与外部环境进行交互，而不依赖于人为的环境模型。</p><p>为了提高约束求解的性能，QSYM应用了各种启发式算法，在严格的稳健性之间进行折中以获得更好的性能。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035374.png" alt="image-20210416135641815" /></p><p>2)指令级符号执行</p><p>原来的执行器是块级污染分析,要把整块进行模拟进行符号执行,而指令级只需要将被污染的指令进行模拟来符号执行.</p><p>对于QSYM，高效的DBT使得实现细粒度的、指令级的污点跟踪和符号执行成为可能，帮助我们避免不必要的仿真开销。</p><p>下面这个例子,如果size是一个符号,就只需要符号执行虚线框的指令,而不需要符号执行punpXXX这种复杂而没被污染的指令.</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035604.png" alt="image-20210416135651308" /></p><p>3)仅解决相关约束</p><p>QSYM通过更新一小部分初始输入来生成新的测试用例。然而，Driller生成了新的测试用例，这些用例看起来与原始输入完全不同。这表明Driller在解决模糊程序反复测试的不相关约束.</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035619.png" alt="image-20210416135658693" /></p><p>4)不使用快照</p><p>QSYM的快速concolic执行使得重新执行比为重复的concolic测试拍摄快照更容易。</p><p>由于QSYM的conclic执行器变得更快，快照的开销不再小于重新执行的开销。</p><p>5)具体的外部环境</p><p>qsym通过与外部环境的具体互动避免了由不完整或错误的环境建模.</p><p>由于建模的<mark>不完整性和正确性偏离了符号执行和本机执行</mark>，误导了进一步的探索，我们应该避免它们的进一步分析。</p><ol start="6"><li>乐观的求解<br />QSYM努力从生成的约束中生成有趣的新测试用例，通过乐观地选择和解决约束的某些部分，如果不能作为一个整体解决的话.特别是，<mark>QSYM选择路径的最后一个约束进行乐观求解</mark>，原因如下。</li></ol><p>第一，它通常有一个非常简单的形式，使得它能够有效地解决约束。</p><p>第二，从解决最后一个约束生成的测试用例可能会探索目标路径，因为它们在到达目标分支时至少满足局部约束。</p><p>由于QSYM首先消除了与最后一个约束无关的约束，因此所有不相关的约束都不会影响乐观求解的结果。</p><p>7)基本块的修剪</p><p>首先,相同代码重复生成的约束对于在真实软件中发现新的代码覆盖是没有用的。</p><p>特别是，程序中计算密集型操作生成的约束在最后不太可能是可解的（即非线性的），即使它们的约束已经形成。</p><p>更糟糕的是，这些约束倾向于阻塞探索其他不相关但足够有趣的部分的可能。</p><p>为了缓解这个问题，QSYM尝试检测具有竞争性的基本块，然后修剪它们以符号执行，并且只生成约束的子集.更具体地说，QSYM在运行时测量每个执行执行的频率，并选择重复的块来修剪.如果一个基本块执行得太频繁，QSYM将停止从它生成更多的约束.</p><p>QSYM决定使用指数回退来修剪基本块，因为它可以快速地截断过于频繁的块。</p><p>l评价</p><p>这个表展示的是在对这些程序进行测试,QSYM能找到漏洞,而只用fuzz不能找到的漏洞,其中有些空白行则是都能找到的漏洞。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035631.png" alt="image-20210416135707898" /></p><p>Driller系统调用存在的问题清单</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035643.png" alt="image-20210416135715923" /></p><p>这是测试libpng的代码覆盖率随着种子输入数量的增加而增加的条形图来对比AFL和QSYM.</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035655.png" alt="image-20210416135722567" /></p><p>这张彩色地图描绘了qsym与Driller的五分钟相对代码覆盖率：蓝色表示qsym发现的代码比Driller多，红色表示相反。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035663.png" alt="image-20210416135730633" /></p><p>下图是以初始POV作为初始种子文件的126CGC二进制文件的QSYM和Driller的平均执行时间和指令数,其中Norm是QSYM指令数乘以4.69。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035805.png" alt="image-20210416135744137" /></p><p>下图是,由于QSYM的限制，CGC挑战中没有被模拟的指令数：不支持浮点操作。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035859.png" alt="image-20210416135756070" /></p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux 内核安全增强(一)— stack canary</title>
      <link href="/2023/12/18/Security/software%20security/stack%20canary/"/>
      <url>/2023/12/18/Security/software%20security/stack%20canary/</url>
      
        <content type="html"><![CDATA[<h1 id="linux-内核安全增强一-stack-canary"><a class="markdownIt-Anchor" href="#linux-内核安全增强一-stack-canary"></a> linux 内核安全增强(一)— stack canary</h1><h3 id="一-背景知识-aarch64的函数栈"><a class="markdownIt-Anchor" href="#一-背景知识-aarch64的函数栈"></a> 一、背景知识 —— aarch64的函数栈</h3><h4 id="1栈生长方向与pushpop操作"><a class="markdownIt-Anchor" href="#1栈生长方向与pushpop操作"></a> 1.栈生长方向与push/pop操作</h4><blockquote><p>栈是一种运算受限的线性表, 入栈的一端为栈顶，另一端则为栈底, 其生长方向和操作顺序理论上没有限定.</p></blockquote><p>在aarch64平台上，栈是向低地址方向增长的(STACK_GROWS_DOWNWARD)<br />栈的PUSH/POP通常要先移动SP:</p><ul><li>PUSH操作为PRE_DEC,即 PUSH操作为 sp = sp -4; store;</li><li>POP操作为 POST_INC,即POP操作为 read; sp=sp+4;</li></ul><h4 id="2返回地址的存储"><a class="markdownIt-Anchor" href="#2返回地址的存储"></a> 2.返回地址的存储</h4><ul><li><p>x86平台是call指令时自动push函数返回地址到栈;</p></li><li><p>ret指令自动pop函数返回地址出栈;</p></li></ul><p>这两步操作都是在callee执行前硬件自动完成的.</p><p>而在arm/aarch64平台发生函数调用时(blx),硬件负责将函数的返回地址设置到通用寄存器LR(/X30)中, callee中的代码负责将LR保存到栈中(需保存的寄存器参考AAPCS标准)</p><h4 id="3函数栈分配"><a class="markdownIt-Anchor" href="#3函数栈分配"></a> 3.函数栈分配</h4><p>在不考虑动态分配的情况下, 函数中使用的栈大小在编译阶段就已经确定了(见备注1), 一个aarch64中的典型的程序栈如下所示:</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241042333.png" alt="img" /></p><p>x86/arm平台的不同在于:<mark>x86和arm平台的函数返回地址通常都存于callee栈的栈底:</mark></p><ul><li>x86平台是硬件完成的push/pop操作,故返回地址先入栈</li><li><strong>arm平台callee函数的首指令通常是先push通用寄存器, 函数返回前最后语句pop通用寄存器</strong>如:</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">000005fc &lt;test&gt;:                                                                                                                                                                       </span><br><span class="line">5fc:   b590            push    &#123;r4, r7, lr&#125;                /* 先push通用寄存器和函数返回地址 */</span><br><span class="line">5fe:   b089            sub     sp, #36 ; 0x24              /* 再为局部变量预留存储空间 */</span><br><span class="line">600:   af00            add     r7, sp, #0</span><br><span class="line">602:   6078            str     r0, [r7, #4]</span><br><span class="line">    ......</span><br><span class="line">634:   3724            adds    r7, #36 ; 0x24</span><br><span class="line">636:   46bd            mov     sp, r7</span><br><span class="line">638:   bd90            pop     &#123;r4, r7, pc&#125;</span><br></pre></td></tr></table></figure><p>​    在此两个平台中若发生了<strong>栈溢出则直接可以覆盖到当前函数的返回地址</strong>.</p><ul><li>而aarch64通常是先预留栈再保存函数返回地址,如:</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0000000000400654 &lt;test&gt;:</span><br><span class="line">                                                                             /* 预留栈         ||  在栈顶保存函数返回地址       */            </span><br><span class="line">  400654:       a9bc7bfd        stp     x29, x30, [sp, #-64]!                /* sp = sp - 64;      sp[0] = x29; sp[1] = x30; */</span><br><span class="line">  400658:       910003fd        mov     x29, sp</span><br><span class="line">  40065c:       b9001fe0        str     w0, [sp, #28]</span><br><span class="line">  400660:       b9801fe1        ldrsw   x1, [sp, #28]</span><br><span class="line">  ......</span><br><span class="line">  400680:       a8c47bfd        ldp     x29, x30, [sp], #64                  /* x29 = sp[0]; x30 = sp[1]; sp = sp +64;  */</span><br><span class="line">  400684:       d65f03c0        ret</span><br></pre></td></tr></table></figure><p>最终的函数栈如上图所示, 由于变量是向高地址方向生长的，故:</p><ul><li>在x86/arm平台的栈上溢(向高地址溢出)通常可直接修改当前函数(这里的callee)的返回地址</li><li>在aarch64平台的栈上溢(向高地址溢出)则通常只能修改到父函数(caller)的返回地址</li></ul><h3 id="二-stack-canary简介"><a class="markdownIt-Anchor" href="#二-stack-canary简介"></a> 二、stack canary简介</h3><blockquote><p>stack canary是一个比较久远的安全特性，linux内核在2.6版本便已经引入, 在5.0又引入了增强的per-task stack canary</p></blockquote><p>其原理比较简单,即:</p><ul><li>每个函数执行前先向栈底插入一个canary值(如下图)以确保顺序的栈上溢在破坏到父函数栈帧前必须要先破坏canary</li><li>每个函数返回时检测当前栈帧中的canary是否被修改,若被修改则代表发生了溢出(报错)</li></ul><p><mark>stack canary并不能检测到所有的栈溢出问题</mark>, 只有在满足:</p><ul><li><p><strong>攻击者不知当前插入当函数栈中canary的值(无infoleak)</strong></p></li><li><p><strong>攻击者只能顺序的覆盖栈中数据，无法跳过canary覆盖数据</strong></p></li></ul><p>两个前提条件时才能检测到栈溢出,故其并非一种理论上安全的防御方式,也只能针对顺序覆盖的栈溢出提供一定的缓解。</p><h3 id="三-stack-canary基本思路与业界实现"><a class="markdownIt-Anchor" href="#三-stack-canary基本思路与业界实现"></a> 三、stack canary基本思路与业界实现</h3><p>虽然原理简单，但实现上还是要解决两个主要问题:</p><h4 id="1作为对比基准的canary来自哪里"><a class="markdownIt-Anchor" href="#1作为对比基准的canary来自哪里"></a> 1.作为对比基准的canary来自哪里?</h4><p>函数入口需要向函数栈push一个原始的canary，函数出口需要将函数栈中的canary(后续称为stack_canary)和原始值做对比，在此过程中原始值需要保持不变并且可以被代码获取到:</p><h5 id="11-原始值来自全局变量"><a class="markdownIt-Anchor" href="#11-原始值来自全局变量"></a> 1.1 原始值来自全局变量</h5><p>默认stack canary使用全局符号(变量) __stack_chk_guard 作为原始的canary(后续称为全局canary), 在gcc/clang中均使用相同的名字.</p><ul><li>全局canary的优点在于:实现简单,开启stack_canary保护的代码中只需要定义一个全局变量__stack_chk_guard 并在初始化时为其赋值一个随机数即可__</li><li>全局canary的缺点在于:<ul><li>所有进程间共享同一个全局canary,只要某进程/线程中发生了infoleak，那么整个canary机制就可以被绕过了.</li><li>全局canary(__stack_chk_guard)的值在运行期间难以改变，否则会导致已有的函数返回时直接crash</li></ul></li></ul><h5 id="12-原始值来自per-cpu变量"><a class="markdownIt-Anchor" href="#12-原始值来自per-cpu变量"></a> 1.2 原始值来自per-cpu变量</h5><p>per-cpu变量的引入是为了实现per-task的stack canary，每个cpu上同时只能运行一个进程/线程, per-cpu变量可以随进程的切换而切换，故通过一个per-cpu变量完全可以为每个进程/线程解引用到不同的canary地址(后续称为per-cpu canary)，以实现per-task的canary。</p><h5 id="per-cpu-canary的优点在于"><a class="markdownIt-Anchor" href="#per-cpu-canary的优点在于"></a> per-cpu canary的优点在于:</h5><p>每个进程/线程拥有自己的canary, 可减少infoleak的影响</p><h5 id="per-cpu-canary的缺点在于"><a class="markdownIt-Anchor" href="#per-cpu-canary的缺点在于"></a> per-cpu canary的缺点在于:</h5><p>需要依赖于硬件平台的一个per-cpu变量(如aarch64 用户态tpidr_el0,内核态sp_el0)</p><p>需要编译器增加对应支持</p><h4 id="2每个函数中pushpopcheck-canary的代码谁来写"><a class="markdownIt-Anchor" href="#2每个函数中pushpopcheck-canary的代码谁来写"></a> 2.每个函数中push/pop/check canary的代码谁来写？</h4><p>通常stack canary的桩代码都是由编译器来插入的,但对具体硬件平台, 不同编译器的支持也有所不同</p><h5 id="21-gccllvm-均支持全局canary"><a class="markdownIt-Anchor" href="#21-gccllvm-均支持全局canary"></a> 2.1 gcc/llvm 均支持全局canary:</h5><p>gcc/llvm中编译选项-fstack-protector/-fstack-protector-strong均已支持, 开启后函数出入口会从全局变量__stack_chk_guard中获取全局canary</p><h5 id="22-gccllvm-均支持aarch64的per-cpu-canary"><a class="markdownIt-Anchor" href="#22-gccllvm-均支持aarch64的per-cpu-canary"></a> 2.2 gcc/llvm 均支持aarch64的per-cpu canary:</h5><ul><li>gcc通过-mstack-protector-guard<em>系列选项可以指定某系统寄存器作为stack canary per cpu的资源(后面称为sysreg)</em></li><li><em>clang 主线目前也已支持-mstack-protector-guard</em> 系列选项,但目前尚无可用发行版[1]</li><li>clang --target=–target=aarch64-linux-android 中支持per cpu的stack canary，但其只能使用默认的 tpidr_el0系统寄存器作为索引, 偏移值也是默认的0x40</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-mstack-protector-guard*系列包含三个选项:</span><br><span class="line">  * -mstack-protector-guard=sysreg:      使用系统寄存器作为per cpu canary的索引</span><br><span class="line">  * -mstack-protector-guard-reg=sp_el0:  作为索引的系统寄存器名(必须是系统寄存器,代码中最终会生成msr/mrs作为访问指令)</span><br><span class="line">  * -mstack-protector-guard-offset=16:   偏移地址,最终canary来自 *(sp_el0 + offset)</span><br></pre></td></tr></table></figure><h5 id="23-arm-linux内核可通过gcc-plugin支持-per-cpu-canary"><a class="markdownIt-Anchor" href="#23-arm-linux内核可通过gcc-plugin支持-per-cpu-canary"></a> 2.3 arm linux内核可通过gcc plugin支持 per-cpu canary:</h5><p>​      arm linux kernel 通过一个gcc plugin(arm_ssp_per_task_plugin)基于per-cpu 寄存器sp实现了 per-task canary功能</p><h3 id="四-编译器中全局canary的实现"><a class="markdownIt-Anchor" href="#四-编译器中全局canary的实现"></a> 四、编译器中全局canary的实现</h3><p>这里以aarch64平台，gcc + -fstack-protector-strong为例,其实现逻辑如下(源码分析见备注2):</p><ul><li>函数入口将全局canary =&gt; stack_canary(stack_canary地址为编译期间预留在当前函数栈底的)</li><li>函数出口对比全局canary和stack_canary是否还一致,一致则跳转到4)</li><li>检测到栈溢出, 调用__stack_chk_fail函数</li><li>函数返回</li></ul><p>在aarch64的汇编代码如下:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//aarch64-linux-gnu-gcc -g -fstack-protector-strong test.c -S -o ./gcc/test.s</span><br><span class="line">1 test:</span><br><span class="line">2         stp     x29, x30, [sp, -64]!                    /* 分配函数栈帧 */</span><br><span class="line">3         mov     x29, sp</span><br><span class="line">4         str     w0, [sp, 28]    </span><br><span class="line">5         adrp    x0, __stack_chk_guard                   /* 获取全局canary *__stack_chk_guard */</span><br><span class="line">6         add     x0, x0, :lo12:__stack_chk_guard</span><br><span class="line">7         ldr     x1, [x0]</span><br><span class="line">8         str     x1, [sp, 56]                            /* 全局canary =&gt; stack_canary(位于栈底) */</span><br><span class="line"> </span><br><span class="line">9         .......                                         /* 函数体 */</span><br><span class="line"> </span><br><span class="line">10        adrp    x0, __stack_chk_guard                   /* 函数返回前再次获取全局canary */</span><br><span class="line">11        add     x0, x0, :lo12:__stack_chk_guard</span><br><span class="line">12        ldr     x0, [x0]</span><br><span class="line">13        ldr     x2, [sp, 56]                            /* 读取stack_canary */</span><br><span class="line">14        eor     x0, x2, x0                              /* 对比stack_canary是否被破坏 */</span><br><span class="line">15        cmp     x0, 0</span><br><span class="line">16        beq     .L3                                     /* 未破坏跳转到函数返回 */</span><br><span class="line">17        bl      __stack_chk_fail                        /* 被破坏则跳转到 __stack_chk_fail */        </span><br><span class="line">18</span><br><span class="line">19 .L3:</span><br><span class="line">20        ldp     x29, x30, [sp], 64</span><br><span class="line">21        ret</span><br></pre></td></tr></table></figure><h3 id="五-编译器中per-cpu-canary的实现"><a class="markdownIt-Anchor" href="#五-编译器中per-cpu-canary的实现"></a> 五、编译器中per-cpu canary的实现</h3><p>​    per-cpu canary时编译器会通过  *(reg + offset)的方式获取当前cpu上的canary(如下面例子中的 * (sp_el0  + 16), 而程序自身需要确保线程切换时per-cpu的canary也要随之切换, 在aarch64下的汇编代码如下(源码分析见备注2):</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/*</span><br><span class="line">    -mstack-protector-guard=sysreg:      使用系统寄存器作为per cpu canary的索引</span><br><span class="line">    -mstack-protector-guard-reg=sp_el0:  作为索引的系统寄存器名(必须是系统寄存器,代码中最终会生成msr/mrs作为访问指令)</span><br><span class="line">    -mstack-protector-guard-offset=16:   偏移地址,最终canary来自 *(sp_el0 + offset)</span><br><span class="line">*/</span><br><span class="line">//aarch64-linux-gnu-gcc -g -fstack-protector-strong -mstack-protector-guard=sysreg -mstack-protector-guard-reg=sp_el0 -mstack-protector-guard-offset=16 test.c -S -o ./gcc/test.s</span><br><span class="line">  1 test:</span><br><span class="line">  2         stp     x29, x30, [sp, -64]!    /* 分配函数栈帧 */</span><br><span class="line">  3         mov     x29, sp</span><br><span class="line">  4         str     w0, [sp, 28]</span><br><span class="line">  5         mrs     x0, sp_el0              /* x1 = *(sp_el0 + 16); 为per cpu canary值 */</span><br><span class="line">  6         add     x0, x0, 16</span><br><span class="line">  7         ldr     x1, [x0]</span><br><span class="line">  8         str     x1, [sp, 56]            /* per cpu canary =&gt; stack_canary */</span><br><span class="line">  9         ......</span><br><span class="line">10         mrs     x0, sp_el0               /* 再次获取per cpu的canary */</span><br><span class="line">11         add     x0, x0, 16</span><br><span class="line">12         ldr     x0, [x0]</span><br><span class="line">13         ldr     x1, [sp, 56]             /* 再次获取stack_canary */</span><br><span class="line">14         eor     x0, x1, x0               /* 对比匹配则正常结束,不匹配跳转到__stack_chk_fail */</span><br><span class="line">15         cmp     x0, 0</span><br><span class="line">16         beq     .L2</span><br><span class="line">17         bl      __stack_chk_fail</span><br><span class="line">18 .L2:</span><br><span class="line">19         ldp     x29, x30, [sp], 64</span><br><span class="line">20         ret</span><br></pre></td></tr></table></figure><h3 id="六-linux内核对stack-canary的支持"><a class="markdownIt-Anchor" href="#六-linux内核对stack-canary的支持"></a> 六、linux内核对stack canary的支持</h3><p>linux内核中与stack canary相关的配置项主要有三个,分别是:</p><ol><li><p>CONFIG_STACKPROTECTOR:</p><p>平台无关的编译选项,其决定是否开启 stack canary保护, 开启则默认指定编译选项 -fstack-protector，使用__stack_chk_guard 作为全局canary对比</p></li><li><p>CONFIG_STACKPROTECTOR_STRONG</p><p>平台无关的编译选项,其决定是否开启strong保护,开启则额外指定编译选项 -fstack-protector-strong.</p></li><li><p>CONFIG_STACKPROTECTOR_PER_TASK</p><p>平台相关的编译选项, 其决定是否开启内核per-task的stack canary保护(此时需编译器的per-cpu canary和对应硬件平台支持)</p></li></ol><h3 id="七-aarch64平台内核stack-canary的实现"><a class="markdownIt-Anchor" href="#七-aarch64平台内核stack-canary的实现"></a> 七、aarch64平台内核stack canary的实现</h3><h4 id="1全局canary的实现"><a class="markdownIt-Anchor" href="#1全局canary的实现"></a> 1.全局canary的实现</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">CONFIG_STACKPROTECTOR =y</span><br><span class="line">CONFIG_STACKPROTECTOR_STRONG =y</span><br><span class="line">CONFIG_STACKPROTECTOR_PER_TASK=n</span><br></pre></td></tr></table></figure><p>全局canary对于内核来说并没有太多的工作，只需要在系统启动时设置好__stack_chk_guard并定义检测失败的回调__stack_chk_fail 即可，插桩代码均由编译器实现(见四), 代码如下:</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">./arch/arm64/kernel/process.c</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(CONFIG_STACKPROTECTOR) &amp;&amp; !defined(CONFIG_STACKPROTECTOR_PER_TASK)</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/stackprotector.h&gt;</span></span></span><br><span class="line"><span class="comment">/* 这里__stack_chk_guard被定义为一个变量, 实际上定义为__ro_after_init可能更好, 此变量可写通常也不会有太大问题，因为对此变量的修改通常会直接导致内核检测到栈溢出而crash */</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> __stack_chk_guard __read_mostly;        </span><br><span class="line">EXPORT_SYMBOL(__stack_chk_guard);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">./arch/arm64/include/<span class="keyword">asm</span>/stackprotector.h</span><br><span class="line"><span class="type">static</span> __always_inline <span class="type">void</span> <span class="title function_">boot_init_stack_canary</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(CONFIG_STACKPROTECTOR)</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> canary;</span><br><span class="line"></span><br><span class="line">    get_random_bytes(&amp;canary, <span class="keyword">sizeof</span>(canary));        <span class="comment">/* 获取一个半随机数 */</span></span><br><span class="line">    canary ^= LINUX_VERSION_CODE;</span><br><span class="line">    canary &amp;= CANARY_MASK;</span><br><span class="line">    current-&gt;stack_canary = canary;</span><br><span class="line">     </span><br><span class="line">    <span class="keyword">if</span> (!IS_ENABLED(CONFIG_STACKPROTECTOR_PER_TASK))        </span><br><span class="line">        __stack_chk_guard = current-&gt;stack_canary;    <span class="comment">/* 如果没指定 per thread,则初始化全局canary */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        .......</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">./kernel/panic.c</span><br><span class="line">__visible noinstr <span class="type">void</span> __stack_chk_fail(<span class="type">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    instrumentation_begin();</span><br><span class="line">    panic(<span class="string">&quot;stack-protector: Kernel stack is corrupted in: %pB&quot;</span>,</span><br><span class="line">        __builtin_return_address(<span class="number">0</span>));</span><br><span class="line">    instrumentation_end();</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(__stack_chk_fail);</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="2per-task-canary的实现"><a class="markdownIt-Anchor" href="#2per-task-canary的实现"></a> 2.per-task canary的实现</h4><p>CONFIG_STACKPROTECTOR =y<br />CONFIG_STACKPROTECTOR_STRONG =y<br />CONFIG_STACKPROTECTOR_PER_TASK=y<br />per-task canary时内核除了初始化外还需要负责为每个进程生成随机的canary，并负责在进程切换时同步per-cpu的寄存器与进程的关系，此时内核新增的配置项和数据结构如下:</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">./arch/arm64/kernel/<span class="keyword">asm</span>-offsets.c</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_STACKPROTECTOR</span></span><br><span class="line">  <span class="built_in">DEFINE</span>(TSK_STACK_CANARY,    <span class="built_in">offsetof</span>(<span class="keyword">struct</span> task_struct, stack_canary));        <span class="comment">/* task_struct中增加per thread的canary */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">./arch/arm64/Kconfig</span><br><span class="line">config STACKPROTECTOR_PER_TASK</span><br><span class="line">    def_bool y</span><br><span class="line">    depends on STACKPROTECTOR &amp;&amp; CC_HAVE_STACKPROTECTOR_SYSREG</span><br><span class="line"></span><br><span class="line">./arch/arm64/<span class="function">Makefile</span></span><br><span class="line"><span class="function"><span class="title">ifeq</span> <span class="params">($(CONFIG_STACKPROTECTOR_PER_TASK),y)</span></span></span><br><span class="line"><span class="function">prepare: stack_protector_prepare</span></span><br><span class="line"><span class="function">/* 增加编译选项 -mstack-protector-guard=</span>sysreg -mstack-protector-guard-reg=sp_el0 -mstack-protector-guard-offset=TSK_STACK_CANARY*/</span><br><span class="line">stack_protector_prepare: prepare0                                             </span><br><span class="line">    $(eval KBUILD_CFLAGS += -mstack-protector-guard=sysreg          \        #<span class="meta"># per-task编译选项支持</span></span><br><span class="line">                -mstack-protector-guard-reg=sp_el0      \</span><br><span class="line">                -mstack-protector-guard-offset=$(shell      \</span><br><span class="line">            awk <span class="string">&#x27;&#123;if ($$2 == &quot;TSK_STACK_CANARY&quot;) print $$3;&#125;&#x27;</span> \</span><br><span class="line">                    include/generated/<span class="keyword">asm</span>-offsets.h))</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>根据编译选项可知，per-task模式下内核指定编译器通过 *(sp_el0 + TSK_STACK_CANARY) 来解引用per-cpu canary, sp_el0在内核中用来存储当前进程task_struct的指针，即对于内核来说对 *(sp_el0 + TSK_STACK_CANARY) 的解引用即相当于访问 current-&gt;stack_canary.</p><p>由于sp_el0在内核中是随着进程切换而切换的(见__switch_to)，故stack canary特性并不需要做额外的操作，其只需要在每个线程创建时为其生成新的canary即可:</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">struct</span> <span class="title class_">task_struct</span> *<span class="built_in">dup_task_struct</span>(<span class="keyword">struct</span> task_struct *orig, <span class="type">int</span> node)</span><br><span class="line">&#123;</span><br><span class="line">  ......</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_STACKPROTECTOR                        <span class="comment">/* 这里不是CONFIG_STACKPROTECTOR_PER_TASK是因为x86平台此特性兼容的历史原因，这里欠缺一点优雅 */</span></span></span><br><span class="line">    tsk-&gt;stack_canary = <span class="built_in">get_random_canary</span>();        <span class="comment">/* fork线程时总是新生成一个随机数作为新线程的canary */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>故在aarch64内核中 per-task canary的思路可整理如下:</p><ul><li>内核自身sp_el0记录task_struct(即current)地址，并随进程切换而切换</li><li>在task_struct中增加一个成员stack_canary, 则此成员总是可以通过 (sp_el0 + TSK_STACK_CANARY)找到<br />进程创建时总是为其生成一个新的canary记录到 current-&gt;stack_canary</li><li>编译器开启per-cpu canary支持，基准的canary值总是来自sp_el0 + TSK_STACK_CANARY，也就是 current-&gt;stack_canary</li></ul><p><a href="https://blog.csdn.net/lidan113lidan/article/details/120318707">(69条消息) linux 内核安全增强(一)— stack canary_ashimida@的博客-CSDN博客___stack_chk_guard</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> 漏洞分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码静态分析工具调研</title>
      <link href="/2023/12/18/Security/software%20security/%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"/>
      <url>/2023/12/18/Security/software%20security/%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/92886d979401">C/C++代码静态分析工具调研 - 简书 (jianshu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/367641334">干货|代码安全审计权威指南（附下载地址） - 知乎 (zhihu.com)</a></p><p><a href="https://zhengtianzuo.blog.csdn.net/article/details/122679768">C++代码静态分析与优化_专栏总目录_devskim-CSDN博客</a></p><h1 id="简述"><a class="markdownIt-Anchor" href="#简述"></a> 简述</h1><p>静态分析（static analysis）是指在不执行代码的情况下对其进行分析评估的过程，是软件质量和软件安全保障的重要一环。它通过词法分析、语义分析、控制流分析、数据流分析等技术对代码逐行解析暴露问题，从而协助我们将许多在运行时才会暴露的棘手麻烦扼杀于摇篮之中。</p><h1 id="典型问题示例"><a class="markdownIt-Anchor" href="#典型问题示例"></a> 典型问题示例</h1><p>代码静态分析能够识别诸多类型的漏洞或缺陷，轻至警告级的「变量未使用」，重至错误级的各类bug，这里列举几种常见的、较严重的、可静态检测的问题。</p><h4 id="缓冲区溢出"><a class="markdownIt-Anchor" href="#缓冲区溢出"></a> ■ 缓冲区溢出</h4><p>缓冲区溢出是指向缓冲区中存入超出其空间大小的数据量，导致多余的数据覆盖其他区域的合法数据，类似倒入容器中的水过多而导致溢出，流到它不该去的地方，造成不可预期的后果。从实践统计看，缓冲区溢出问题是软件中最普遍存在的漏洞问题，在C/C++这类不提供内存越界检测的语言中尤甚。通常，发生缓冲区溢出的情况有：</p><ul><li>字符串拷贝，当目标缓冲区长度小于源字串的长度时（此类的函数包括<code>strcpy</code>、<code>_mbscpy</code>、<code>strcat</code>、<code>wcscat</code>、<code>memcpy</code>、<code>strncpy</code>、<code>_mbsncpy</code>、<code>strncat</code>、<code>wcsncat</code>等）。</li></ul><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 字符串拷贝之前没有对s做长度判断，如果超过10，就会造成缓冲区溢出。</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">char</span>* s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">char</span> buf[<span class="number">10</span>];</span><br><span class="line">    <span class="built_in">strcpy</span>(buf, s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>格式化字符串处理，当参数与格式化字符串不匹配时（此类的函数包括<code>printf</code>、<code>fprintf</code>、<code>sprintf</code>、<code>swprintf</code>等）。</li></ul><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// %n将前面打印的字串长度信息写到相应地址</span></span><br><span class="line"><span class="type">int</span> <span class="built_in">len</span> = <span class="number">0</span>;</span><br><span class="line">printf(<span class="string">&quot;This is a test string.%n&quot;</span>, &amp;<span class="built_in">len</span>);</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 错误的写法，此时长度信息会写到地址为0的内存空间中</span></span><br><span class="line"><span class="type">int</span> <span class="built_in">len</span> = <span class="number">0</span>;</span><br><span class="line">printf(<span class="string">&quot;This is a test string.%n&quot;</span>, <span class="built_in">len</span>);</span><br></pre></td></tr></table></figure><ul><li>字符串读取，当缓冲区小于所要读入的字符串长度时（此类的函数包括<code>scanf</code>、<code>fscanf</code>、<code>sscanf</code>、<code>gets</code>、<code>getc</code>、<code>fgets</code>、<code>fgetc</code>等）。</li></ul><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 用户输入的字串长度不受控制，如果超过10，就会造成缓冲区溢出。</span></span><br><span class="line"><span class="type">char</span> buf[<span class="number">10</span>];</span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>, &amp;buf);</span><br></pre></td></tr></table></figure><h4 id="内存泄漏"><a class="markdownIt-Anchor" href="#内存泄漏"></a> ■ 内存泄漏</h4><p>内存泄漏一般指堆内存的泄漏（也有系统资源的泄漏），程序申请的内存资源没有被合理地释放，导致这部分内存不能被回收利用而造成资源的浪费。严重时，过多的内存泄漏会造成系统崩溃。C/C++语言没有自动回收机制，需要程序员自行确保内存使用的闭环（<code>new/delete</code>、<code>alloc/free</code>、<code>malloc/free</code>、<code>GlobalAlloc/GlobalFree</code>成对使用）。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-311849d814d36878.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/318/format/webp" alt="img" /></p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-afcd25b4580f01aa.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/318/format/webp" alt="img" /></p><p>通常，发生内存泄漏的情况有：</p><ul><li>分配内存后忘了调用相应的释放函数。</li><li>过程因达到某种条件提前结束，未能执行后面的内存释放函数。</li><li>程序设计不合理，不断分配内存，到最后才一起释放，虽然整体上不算内存泄漏，但在过程中已经酝酿了资源耗尽的可能性，无异于内存泄漏。</li></ul><h4 id="野指针"><a class="markdownIt-Anchor" href="#野指针"></a> ■ 野指针</h4><p>当指针变量未被初始化，或指向的内存已被回收时，该指针便成了野指针。其指向的内存地址是非法的，对这块非法区域进行操作将导致不可预料的后果。</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 对指针是否为空的判断看是严谨，其实是无效的。</span></span><br><span class="line"><span class="type">char</span> *p = (<span class="type">char</span>*)<span class="built_in">malloc</span>(<span class="number">10</span>);</span><br><span class="line"><span class="built_in">free</span>(p);</span><br><span class="line"><span class="keyword">if</span> (p != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">strcpy</span>(p, <span class="string">&quot;danger&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="工具调研"><a class="markdownIt-Anchor" href="#工具调研"></a> 工具调研</h1><p>根据工作需要，从可检测的语言、使用平台和授权三方面考量，调研了20余种主流的C/C++代码静态分析工具。</p><table><thead><tr><th>工具</th><th>语言</th><th>平台</th><th>授权</th></tr></thead><tbody><tr><td><a href="http://adlint.sourceforge.net/">AdLint</a></td><td>C</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>开源</td></tr><tr><td><a href="https://www.absint.com/astree/index.htm">Astrée</a></td><td>C</td><td>Windows, Linux</td><td>付费</td></tr><tr><td><a href="http://www.iste.uni-stuttgart.de/en/ps/project-bauhaus.html">Bauhaus Toolkit</a></td><td>C, C++, Java, C#, Ada</td><td>Windows, Linux, Solaris</td><td>付费</td></tr><tr><td><a href="https://forge.ispras.ru/projects/blast">BLAST</a></td><td>C</td><td>Linux</td><td>开源</td></tr><tr><td><a href="http://cppcheck.sourceforge.net/">Cppcheck</a></td><td>C, C++</td><td>Windows, Linux</td><td>开源</td></tr><tr><td><a href="http://coccinelle.lip6.fr/">Coccinelle</a></td><td>C</td><td>Linux</td><td>开源</td></tr><tr><td><a href="https://www.synopsys.com/software-integrity/resources/datasheets/coverity.html">Coverity</a></td><td>C, C++, C#, Java, JS, PHP, Python, Objective-C, Ruby, Swift, Fortran, VB</td><td>Windows, Linux, Mac OS, FreeBSD, Solaris</td><td>付费</td></tr><tr><td><a href="https://www.cppdepend.com/">CppDepend</a></td><td>C, C++</td><td>Windows, Linux</td><td>付费</td></tr><tr><td><a href="http://www.bugseng.com/eclair">ECLAIR</a></td><td>C, C++</td><td>Windows, Linux, Mac OS</td><td>付费</td></tr><tr><td><a href="https://www.dwheeler.com/flawfinder/">Flawfinder</a></td><td>C, C++</td><td>Python</td><td>开源</td></tr><tr><td><a href="http://www.lix.polytechnique.fr/Labo/Sylvie.Putot/fluctuat.html">Fluctuat</a></td><td>C, Ada</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>付费</td></tr><tr><td><a href="http://frama-c.com/">Frama-C</a></td><td>C</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>开源/付费</td></tr><tr><td><a href="https://www.grammatech.com/products/codesonar">CodeSonar</a></td><td>C, C++, Java, 二进制码</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>付费</td></tr><tr><td><a href="https://www.klocwork.com/">Klocwork</a></td><td>C, C++, Java, C#</td><td>Windows, Linux, Solaris</td><td>付费</td></tr><tr><td><a href="https://ldra.com/industrial-energy/products/ldra-testbed-tbvision/">LDRA Testbed</a></td><td>C, C++, Java, Ada</td><td>Windows, Linux, Mac OS</td><td>付费</td></tr><tr><td><a href="https://www.parasoft.com/products/ctest">Parasoft C/C++test</a></td><td>C, C++</td><td>Windows, Linux, Solaris</td><td>付费</td></tr><tr><td><a href="http://www.gimpel.com/html/pcl.htm">PC-Lint</a></td><td>C, C++</td><td>Windows</td><td>付费</td></tr><tr><td><a href="https://cn.mathworks.com/products/polyspace.html">Polyspace</a></td><td>C, C++, Ada</td><td>Windows, Linux, Mac OS</td><td>付费</td></tr><tr><td><a href="http://www.prqa.com/static-analysis-software/qac-qacpp-static-analyzers/">PRQA QA·Static Analyzers</a></td><td>C, C++, Java</td><td>Windows, Linux</td><td>付费</td></tr><tr><td><a href="https://www.microsoft.com/en-us/research/project/slam/?from=http%3A%2F%2Fresearch.microsoft.com%2Fslam">SLAM</a></td><td>C</td><td>Windows</td><td>免费</td></tr><tr><td><a href="https://sparse.wiki.kernel.org/index.php/Main_Page">Sparse</a></td><td>C</td><td>Linux, Mac OS, BSD</td><td>开源</td></tr><tr><td><a href="http://lclint.cs.virginia.edu/">Splint</a></td><td>C</td><td>Linux, FreeBSD, Solaris</td><td>开源</td></tr><tr><td><a href="http://code.tencent.com/tscancode.html">TscanCode</a></td><td>C, C++, C#, Lua</td><td>Windows, Linux, Mac OS</td><td>开源</td></tr></tbody></table><p>根据以下标准，筛选出3款适用性较高的工具——Cppcheck、Flawfinder、TscanCode——进行详细调研：</p><ul><li>语言：支持C/C++代码分析</li><li>平台：支持在Windows和/或Linux平台运行</li><li>授权：免费</li></ul><p>为进行一次实践对比，从TscanCode的GitHub上抓到一组现成的C/C++编码问题示例，共94个CPP文件，考察三者的检测效果。</p><blockquote><p>运行平台：Windows<br />被测语言：C/C++<br />测试集：<a href="https://github.com/Tencent/TscanCode/tree/master/samples/cpp">TscanCode/samples/cpp</a></p></blockquote><h4 id="cppcheck"><a class="markdownIt-Anchor" href="#cppcheck"></a> ■ <a href="http://cppcheck.sourceforge.net/">Cppcheck</a></h4><blockquote><p>Cppcheck可检测的问题包括：</p><ul><li>Dead pointers</li><li>Division by zero</li><li>Integer overflows</li><li>Invalid bit shift operands</li><li>Invalid conversions</li><li>Invalid usage of STL</li><li>Memory management</li><li>Null pointer dereferences</li><li>Out of bounds checking</li><li>Uninitialized variables</li><li>Writing const data</li></ul><p>并将问题分为以下6类：</p><ul><li><strong>错误（error）</strong>：bug。</li><li><strong>警告（warning）</strong>：预防性编程方面的建议。</li><li><strong>风格警告（style）</strong>：出于对代码简洁性的考虑（函数未使用、冗余代码等）。</li><li><strong>可移植性警告（portability）</strong>：64/32位可移植性、编译器通用性等。</li><li><strong>性能警告（performance）</strong>：使代码更高效的建议，但不保证一定有明显效果。</li><li><strong>信息消息（information）</strong>：条件编译方面的警告。</li></ul></blockquote><p>安装十分简便，只需在官网下载最新的可执行安装包（本文目前为<code>cppcheck-1.83-x86-Setup.msi</code>）跟着向导「下一步」即可。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-7e2c0428206a5133.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/816/format/webp" alt="img" /></p><p>Cppcheck有GUI，选择菜单栏「Analyze」下的「文件」或「目录」即可对源代码进行静态分析。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-69215d004372d570.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp" alt="img" /></p><p>运行结果对94个例子的分析十分到位，只不过底侧的代码预览对中文注释似乎不太友好。</p><p>除了GUI，Cppcheck还支持与多种IDE（如VS、Eclipse、QtCreator等）、版本管理系统（如Tortoise SVN、Git）集成使用。</p><p>可对每次分析进行配置甚至自定义规则，并作为项目文件进行保存或重载。</p><p>分析的结果报告可保存为格式化纯文本或XML，并可借助Python pygments将XML生成为HTML。</p><h4 id="tscancode"><a class="markdownIt-Anchor" href="#tscancode"></a> ■ <a href="http://code.tencent.com/tscancode.html">TscanCode</a></h4><p>TscanCode是腾讯的开源项目，为此次调研的唯一一款本土工具，起初构建于Cppcheck的基础之上，后来进行了重新实现，并加入了对C#和Lua的支持。</p><blockquote><p>TscanCode可检测的问题包括：</p><ul><li>空指针检查，包含可疑的空指针，判空后解引用比如Crash等共3类subid检查</li><li>数据越界，Sprintf_S越界共1类subid检查</li><li>内存泄漏，分配和释放不匹配同1类subid检查</li><li>逻辑错误，重复的代码分支，bool类型和INT进行比较，表达式永远True或者false等共18类检查</li><li>可疑代码检查，if判断中含有可疑的=号，自由变量返回局部变量等共计15类检查</li><li>运算错误，判断无符号数小于0,对bool类型进行++自增等，共计11类检查</li></ul><p>并将问题分为<strong>致命</strong>、<strong>严重</strong>、<strong>警告</strong>、<strong>提示</strong>、<strong>风格</strong>5类。</p></blockquote><p>安装同样便捷，下载安装包（本文目前为<code>TscanCodeV2.14.24.windows.exe</code>）跟着向导「下一步」即可。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-7833720f633ac65b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800/format/webp" alt="img" /></p><p>同样具有用户友好的GUI，且UI设计更时尚些。点击「扫描文件夹」或「扫描文件」选定路径后点击「开始扫描」即可使用。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-bf4a49679a1f362a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp" alt="img" /></p><p>扫描结果，对中文注释必然友好。</p><p>TscanCode的提示信息可以说直接照搬了Cppcheck，但给出的提示数量明显少于Cppcheck，以<code>mismatchsize.cpp</code>为例：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Demo</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//分配的内存空间不匹配</span></span><br><span class="line">    <span class="type">int</span> i = <span class="built_in">malloc</span>(<span class="number">3</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https:////upload-images.jianshu.io/upload_images/30022-387ab0daf9e25b64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/658/format/webp" alt="img" /></p><p>Cppcheck对mismatchsize.cpp的检测结果有4条提示，TscanCode相应地只给出了后两条。</p><h4 id="flawfinder"><a class="markdownIt-Anchor" href="#flawfinder"></a> ■ <a href="https://www.dwheeler.com/flawfinder/">Flawfinder</a></h4><p>Flawfinder由计算机安全专家<a href="https://www.dwheeler.com/">David A. Wheeler</a>个人开发，依托于Python，自然而然拥有了跨平台性。</p><p>安装：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install flawfinder</span><br></pre></td></tr></table></figure><p>运行：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> *python_path*/Scripts</span><br><span class="line">python flawfinder *directory_with_source_code*</span><br></pre></td></tr></table></figure><p>实践表明，Flawfinder对中文注释更不友好，直接拿TscanCode的测试集跑会报编码错误，尽管这些CPP文件本来就是Flawfinder文档所建议的UTF-8格式：</p><blockquote><p>UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xaf in position 92: illegal multibyte sequence</p></blockquote><p>将测试集批量转换为ANSI格式后方可正常运行：</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-314cdadac2240642.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/677/format/webp" alt="img" /></p><p>94个示例，仅检测出11个问题。</p><p>David A. Wheeler本人也在官网特别声明Flawfinder是款相对简单的静态分析工具，不进行数据流和控制流分析，甚至不识别函数的参数类型。</p><p>Flawfinder可将结果保存为<a href="https://www.dwheeler.com/flawfinder/correct-results.txt">格式化纯文本</a>、<a href="https://www.dwheeler.com/flawfinder/correct-results.html">HTML</a>和<a href="https://www.dwheeler.com/flawfinder/correct-results.csv">CSV</a>三种格式。</p><h4 id="3款工具对比"><a class="markdownIt-Anchor" href="#3款工具对比"></a> 3款工具对比</h4><ul><li>检测能力：Cppcheck &gt; TscanCode &gt; Flawfinder</li><li>友好度：TscanCode &gt; Cppcheck &gt; Flawfinder</li><li>易用性：TscanCode &gt; Cppcheck &gt; Flawfinder</li></ul><h1 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h1><ul><li>向东, 刘海燕. C/C++静态代码安全检查工具研究[J]. 计算机工程与设计, 2005, 26(8):2110-2112.</li><li>罗琴灵. 基于静态检测的代码审计技术研究[J]. 2016.</li><li><a href="https://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis#C,_C++">List of tools for static code analysis - Wikipedia</a></li><li><a href="https://blog.csdn.net/wetest_tencent/article/details/51516347">C++代码质量扫描主流工具深度比较 - CSDN博客</a></li><li><a href="http://qa.blog.163.com/blog/static/190147002201611147530522/">C/C++静态代码检查工具对比分析 - 网易博客</a></li><li><a href="https://blog.csdn.net/liang19890820/article/details/52778149">Cppcheck 用法（上篇） - CSDN博客</a></li><li><a href="http://cppcheck.sourceforge.net/manual.pdf">Cppcheck手册</a></li><li><a href="https://www.dwheeler.com/flawfinder/flawfinder.pdf">Flawfinder文档</a></li></ul><p>作者：逸之<br />链接：<a href="https://www.jianshu.com/p/92886d979401">https://www.jianshu.com/p/92886d979401</a><br />来源：简书<br />著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 静态分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo bug</title>
      <link href="/2023/12/16/hello-bug/"/>
      <url>/2023/12/16/hello-bug/</url>
      
        <content type="html"><![CDATA[<p>这是一个bug指南，在使用Hexo的时候遇到了一些bug，自己在这里对解决过的bug做以记录。</p><h4 id="nunjucks-error-line-26-column-109-parseaggregate-expected-comma-after-expression"><a class="markdownIt-Anchor" href="#nunjucks-error-line-26-column-109-parseaggregate-expected-comma-after-expression"></a> Nunjucks Error: [Line 26, Column 109] parseAggregate: expected comma after expression</h4><p>这个自己是hexo在render公式的时候产生的问题，不能两个”{“紧接着放在一起，应该{ {…} }在<strong>之间加空格</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 指南 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/12/16/hello-world/"/>
      <url>/2023/12/16/hello-world/</url>
      
        <content type="html"><![CDATA[<p>这是一个指南</p><p><a href="https://gavinblog.github.io/anzhiyu-docs/">安知鱼主题指南 (gavinblog.github.io)</a></p><h3 id="布局layout"><a class="markdownIt-Anchor" href="#布局layout"></a> 布局（Layout）</h3><p>Hexo 有三种默认布局：<code>post</code>、<code>page</code> 和 <code>draft</code>。在创建这三种不同类型的文件时，它们将会被保存到不同的路径；而您自定义的其他布局和 <code>post</code> 相同，都将储存到 <code>source/_posts</code> 文件夹。</p><table><thead><tr><th style="text-align:left">布局</th><th style="text-align:left">路径</th></tr></thead><tbody><tr><td style="text-align:left"><code>post</code></td><td style="text-align:left"><code>source/_posts</code></td></tr><tr><td style="text-align:left"><code>page</code></td><td style="text-align:left"><code>source</code></td></tr><tr><td style="text-align:left"><code>draft</code></td><td style="text-align:left"><code>source/_drafts</code></td></tr></tbody></table><h1 id="1-常用命令"><a class="markdownIt-Anchor" href="#1-常用命令"></a> 1 常用命令</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># draft</span><br><span class="line">hexo new draft &quot;test&quot;</span><br><span class="line"></span><br><span class="line">hexo publish draft &quot;test&quot;</span><br></pre></td></tr></table></figure><h1 id="2-公式"><a class="markdownIt-Anchor" href="#2-公式"></a> 2 公式</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm un hexo-renderer-marked --save</span><br><span class="line"># or</span><br><span class="line">npm un hexo-renderer-kramed --save</span><br><span class="line"># 安装 `hexo-renderer-markdown-it-plus`</span><br><span class="line">npm i @upupming/hexo-renderer-markdown-it-plus --save</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在根目录的 _config.yml 中使用下面的配置将 strict 设置为 false</span></span><br><span class="line"><span class="attr">markdown_it_plus:</span></span><br><span class="line">  <span class="attr">plugins:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">plugin:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">&#x27;@neilsustc/markdown-it-katex&#x27;</span></span><br><span class="line">      <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">options:</span></span><br><span class="line">        <span class="attr">strict:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 指南 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>c语言混淆技术</title>
      <link href="/2023/12/16/Security/c%E8%AF%AD%E8%A8%80%E6%B7%B7%E6%B7%86%E6%8A%80%E6%9C%AF/"/>
      <url>/2023/12/16/Security/c%E8%AF%AD%E8%A8%80%E6%B7%B7%E6%B7%86%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<h4 id="代码混淆定义"><a class="markdownIt-Anchor" href="#代码混淆定义"></a> 代码混淆定义：</h4><p>原代码 P 通过某种变换变成代码 P’，若 P 和 P’运行结果与过程行为保持一致，该种变换就称之为混淆变换。</p><p>具体来说，当混淆转换满足以下两种情况时，这种混淆变化称之为合法的转换：</p><ul><li>（1）如果源程序 P 无法停止运行或报错结束运行，则变换后的程序 P’可以结束运行也可以继续运行。</li><li>（2）否则，目标程序 P’也结束运行并且输出与源程序相同的结果。</li><li><mark>两个程序之间操作并不一定完全相同，且不一定有相同的效率。</mark></li></ul><p>实际上，混淆工具预先设定若干混淆规则，并使用其它更为复杂的代码取代源代码中符合条件的代码语句，<strong>虽然源代码语义并未改变但混淆后的程序运行过程中空间复杂度往往更高，执行时间也更长，甚至有可能改变系统环境</strong>等。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/imgs202312171007669.png" alt="image-20231217100733637" /></p><p>图 2.1 展示了混淆编译的整体流程，</p><ul><li>首先混淆工具会对输入的源代码进行代码预处理得到<mark>程序控制流图 CFG、抽象语法树 AST</mark> 等信息，</li><li>然后对<mark>数据流、控制流</mark>等进行分析，并根据输入的混淆参数选择对应的混淆算法处理源代码，</li><li>最后输出混淆编译后的程序。</li></ul><p>尽管混淆策略多种多样，但通常按 Collberg 提出的方法将其大致分为四类[16]：</p><ul><li>布局混淆</li><li>数据流混淆</li><li>控制流混淆</li><li>预防混淆</li></ul><p>接下来将对这几类混淆策略进行详细分析。</p><h4 id="布局混淆"><a class="markdownIt-Anchor" href="#布局混淆"></a> 布局混淆</h4><p>布局混淆是一种在不影响源程序正常运行的情况下，即<strong>不修改程序核心控制流和数据流</strong>，对程序包含有用信息的非核心代码做出修改的一种混淆策略；此处的非核心代码一般包括注释语句、多余代码片段、用于调试的代码语句以及自定义的变量名。</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Basic terms and concepts</title>
      <link href="/2023/12/16/Security/%E5%9F%BA%E6%9C%AC%E6%9C%AF%E8%AF%AD/"/>
      <url>/2023/12/16/Security/%E5%9F%BA%E6%9C%AC%E6%9C%AF%E8%AF%AD/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Basic terms and concepts</p></blockquote><h2 id="vulnerability"><a class="markdownIt-Anchor" href="#vulnerability"></a> Vulnerability</h2><h4 id="vulnerability-2"><a class="markdownIt-Anchor" href="#vulnerability-2"></a> Vulnerability</h4><p><code>VUL</code>，Vulnerability的缩写，泛指<code>漏洞</code>。漏洞是指计算机系统中存在可能被攻击者利用的弱点、缺陷或安全漏洞。这些漏洞允许未经授权的访问，如窃取敏感数据，或允许攻击者在目标计算机系统上执行任意操作，如安装恶意软件。此类漏洞可能表现在不同方面，包括软件代码、硬件组件、配置或设计。</p><h4 id="cwe"><a class="markdownIt-Anchor" href="#cwe"></a> CWE</h4><p>CWE是社区开发的漏洞列表。它提供了一种标准化和结构化的方法来识别和分类这些漏洞，并为每个漏洞分配一个唯一的标识符。例如，CWE-119提到了臭名昭著的“缓冲区溢出”。遵循不同级别的概念抽象，CWE将漏洞组织在树状层次结构中，其中低级CWE ID与高级CWE ID相关联。例如，表示“越界写入”的CWE-787和表示“越界读取”的CWE-125都是属于CWE-119的较低级别类型。</p><h4 id="poc"><a class="markdownIt-Anchor" href="#poc"></a> <strong>POC</strong></h4><p><code>POC，Proof of Concept</code>，中文意思是“<code>概念证明</code>”。这个短语会在漏洞报告中使用，漏洞报告中的POC则是<code>一段说明或者一个攻击的样</code>例，使得读者能够确认这个漏洞是真实存在的。</p><h4 id="exp"><a class="markdownIt-Anchor" href="#exp"></a> <strong>EXP</strong></h4><p><code>EXP</code>，Exploit，中文意思是“<code>漏洞利用</code>”。意思是一段对漏洞<code>如何利用的详细说明或者一个演示的漏洞攻击代码</code>，可以使得读者完全了解漏洞的机理以及利用的方法。</p><h4 id="cve漏洞编号"><a class="markdownIt-Anchor" href="#cve漏洞编号"></a> <strong>CVE漏洞编号</strong></h4><p><code>CVE</code> 的英文全称是“Common Vulnerabilities &amp; Exposures”公共漏洞和暴露，例如CVE-2015-0057、CVE-1999-0001等等。CVE就好像是一个字典表，为广泛认同的<a href="https://so.csdn.net/so/search?q=%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8&amp;spm=1001.2101.3001.7020">信息安全</a>漏洞或者已经暴露出来的弱点给出一个公共的名称。如果在一个漏洞报告中指明的一个漏洞，如果有CVE名称，你就可以快速地在任何其它CVE兼容的数据库中找到相应修补的信息，解决安全问题。</p><p>可以在https://cve.mitre.org/网站根据漏洞的CVE编号搜索该漏洞的介绍。</p><p>也可以在中文社区http://www.scap.org.cn/上搜索关于漏洞的介绍</p><h4 id="0day漏洞和0day攻击"><a class="markdownIt-Anchor" href="#0day漏洞和0day攻击"></a> <strong>0DAY漏洞和0DAY攻击</strong></h4><p>在计算机领域中，零日漏洞或零时差漏洞（英语：Zero-dayexploit）通常是指还没有补丁的安全漏洞，而零日攻击或零时差攻击（英语：Zero-dayattack）则是指利用这种漏洞进行的攻击。提供该漏洞细节或者利用程序的人通常是该漏洞的发现者。零日漏洞的利用程序对网络安全具有巨大威胁，因此零日漏洞不但是黑客的最爱，掌握多少零日漏洞也成为评价黑客技术水平的一个重要参数。<br />零日漏洞及其利用代码不仅对犯罪黑客而言，具有极高的利用价值，一些国家间谍和网军部队，例如美国国家安全局和美国网战司令部也非常重视这些信息。据路透社报告称美国政府是零日漏洞黑市的最大买家。</p><h4 id="can"><a class="markdownIt-Anchor" href="#can"></a> CAN</h4><p>CAN和CVE的唯一区别是前者代表了候选条目，还未经CVE编辑委员会认可，而后者则是经过认可的条目。 然后，两种类型的条目都对公众可见，条目的编号不会随着认可而改变—仅仅是“CAN”前缀替换成了“CVE”。</p><h4 id="bugtraq"><a class="markdownIt-Anchor" href="#bugtraq"></a> BUGTRAQ</h4><p>一个完整的对计算机安全漏洞（它们是什么，如何利用它们，以及如何修补它们）的公告及详细论述进行适度披露的邮件列表</p><h4 id="cncve"><a class="markdownIt-Anchor" href="#cncve"></a> CNCVE</h4><p>中国（CN）的 CVE ，是CNCERT/CC（国家计算机网络应急处理协调中心）为漏洞进行编号的一个自己的标准。CNCVE不但包含漏洞的描述予以统一定义，还将包括漏洞的补丁、验证等措施，更方便、有用。</p><h4 id="cnvd"><a class="markdownIt-Anchor" href="#cnvd"></a> CNVD</h4><p>国家信息安全漏洞共享平台。是由国家计算机网络应急技术处理协调中心（简称CNCERT）联合国内重要信息系统单位、基础电信运营商、网络安全厂商、软件厂商和互联网企业建立的信息安全漏洞信息共享知识库。</p><h4 id="cnnvd"><a class="markdownIt-Anchor" href="#cnnvd"></a> CNNVD</h4><p>中国国家信息安全漏洞库。是中国信息安全测评中心为切实履行漏洞分析和风险评估的职能，负责建设运维的国家信息安全漏洞库，为我国信息安全保障提供基础服务</p><h4 id="cvsscommon-vulnerability-scoring-system"><a class="markdownIt-Anchor" href="#cvsscommon-vulnerability-scoring-system"></a> CVSS(Common Vulnerability Scoring System)</h4><p>通用漏洞评分系统，行业公开标准，用来评测漏洞的严重程度，0-10分值越高越严重,美国国家漏洞数据库官网：<a href="https://nvd.nist.gov/vuln/search%E5%8F%AF%E6%9F%A5%E8%AF%A2CVE%E5%AF%B9%E5%BA%94CVSS%E5%88%86%E5%80%BC">https://nvd.nist.gov/vuln/search可查询CVE对应CVSS分值</a></p><p>PS：评分会受时间和空间影响，如随着时间推移，漏洞相关补丁越多，可被利用性越低；漏洞存在不同的环境，也会影响漏洞的威胁程度</p><h4 id="cpecommon-platform-enumeration"><a class="markdownIt-Anchor" href="#cpecommon-platform-enumeration"></a> CPE（Common Platform Enumeration）</h4><p>以标准化方式为软件应用程序、操作系统及硬件命名的方法</p><h2 id="code-representation"><a class="markdownIt-Anchor" href="#code-representation"></a> Code Representation</h2><h4 id="code-tokens"><a class="markdownIt-Anchor" href="#code-tokens"></a> Code Tokens</h4><p>代码标记是指程序中带有特定语义的词法标记。它们包括标识符（例如变量和函数名）、关键字、分隔符（例如标点符号和分隔符）和运算符（例如算术运算符和逻辑运算符）。通过词法解析，代码片段可以直接表示为一个序列或一组标记。</p><h4 id="ast"><a class="markdownIt-Anchor" href="#ast"></a> AST</h4><p>抽象语法树，是将代码元素组织成树结构的基本代码表示。树叶对应于主代码元素，如变量类型、符号和运算符，而非叶节点表示一组受限的代码结构，如表达式和循环。与词汇解析的代码标记相比，AST除了词汇信息外，还自然地体现了源代码的句法结构。</p><p>AST 是源代码的有序树表示结构。 通常，它是代码解析器用来理解程序的基本结构并检查语法错误的第一步表示。 因此，它构成了生成许多其他代码表示的基础，并且 AST V ast 的节点集包括本文使用的其余三种代码表示的所有节点。 从根节点开始，代码被分解为代码块、语句、声明、表达式等，最后分解为形成叶节点的主标记。 主要的AST节点如图所示。所有方框都是AST节点，第一行有具体代码，并注释了节点类型。 蓝色框是 AST 的叶节点，紫色箭头表示子父 AST 关系。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062143171.png" alt="image-20240306214316124" /></p><h4 id="cfg"><a class="markdownIt-Anchor" href="#cfg"></a> CFG</h4><p>CFG或控制流图是一个有向图，其中每个节点表示语句的基本块，每条边表示函数内块之间的控制流。CFG是通过识别AST中的控制相关性来构建的。通常要求代码在功能上是完整的和可编译的，以精确地生成CFG。</p><p>CFG 描述了程序在执行期间可能遍历的所有路径。 路径选择由条件语句确定，例如 if、for 和 switch 语句。 在CFG中，节点表示语句和条件，它们通过有向边连接以指示控制的转移。  CFG 边缘在图 2 中用绿色虚线箭头突出显示。特别是，流程从入口开始并在出口结束，并且在 if 语句处派生出两条不同的路径。</p><h4 id="pdg"><a class="markdownIt-Anchor" href="#pdg"></a> PDG</h4><p>程序依赖图，是代码的另一种图形表示，强调代码元素之间的数据和控制依赖关系。与CFG类似，它可以在AST的基础上构建。在构建过程中，某些代码细节被抽象，以更明确地揭示控制和数据依赖关系。</p><h4 id="cpg"><a class="markdownIt-Anchor" href="#cpg"></a> CPG</h4><p>代码属性图，提出了一种更为综合的代码混合图表示，它集成了从AST、CFG和PDG导出的信息。</p><h4 id="数据流图-dfg"><a class="markdownIt-Anchor" href="#数据流图-dfg"></a> 数据流图 (DFG)</h4><p>DFG 跟踪整个 CFG 中变量的使用情况。 数据流是面向变量的，任何数据流都涉及某些变量的访问或修改。 DFG 边表示对相同变量的后续访问或修改。 它在图 2 中用橙色双箭头表示，并在边缘标注了所涉及的变量。 例如，参数b既用在if条件中，又用在赋值语句中。 自然代码序列（NCS） 为了对源代码的自然顺序进行编码，我们使用 NCS 边来连接 AST 中的相邻代码标记。 这种编码的主要好处是保留源代码序列反映的编程逻辑。 NCS 边在图 2 中用红色箭头表示，连接 AST 的所有叶节点。</p><h4 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h4><p>[1]Zhenzhou T ,Binhui T ,Jiajun L , et al.Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding[J].Expert Systems With Applications,2024,238(PB):</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> 基本术语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>挑战与问题</title>
      <link href="/2023/12/16/Security/%E6%8C%91%E6%88%98%E4%B8%8E%E9%97%AE%E9%A2%98/"/>
      <url>/2023/12/16/Security/%E6%8C%91%E6%88%98%E4%B8%8E%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>已经开发了各种方法来检测漏洞（Cui et al.，2022），包括静态、动态、一致性分析和模糊方法。正如我们将在相关工作部分进一步深入研究的那样，TrVD属于静态检测系列中基于学习的范式。在这种范式中，漏洞检测任务被公式化为一个分类问题。具体来说，在训练阶段，分类器 通过代码表示构建、特征提取和模型训练，从一组带有基本事实标签的训练样本中学习。在检测阶段，当出现一段可能看不见的源代码时, 执行代码表示构造和特征提取的相同过程。经过训练的分类器预测漏洞的存在，或者进一步精确定位特定的漏洞类型。</p><h2 id="可用性"><a class="markdownIt-Anchor" href="#可用性"></a> 可用性</h2><p>其他被广泛采用的代码表示包括CFG、PDG和各种基于图形的变体。这些表示更明确地描述了代码元素之间的控制或数据依赖关系，然而，当面对不可执行或不完整的代码片段时，很难精确推导出这些依赖关系。因此，它们可能并不总是适用于漏洞检测。按照约定，AST可以很容易地为任何代码片段构建，例如文件、函数或单个语句。</p><h2 id="效率"><a class="markdownIt-Anchor" href="#效率"></a> 效率</h2><p>与需要相对复杂和耗时的控制或依赖性分析的代码表示（例如CFG、PDG和代码小工具）相比，从代码构建AST要简单得多，重量轻，从而有助于提高整个检测方法的效率。</p><h2 id="语义综合性"><a class="markdownIt-Anchor" href="#语义综合性"></a> 语义综合性</h2><p>那些人工创建的代码表示（例如，PDG和XFG）倾向于强调代码的特定方面，例如控制流或数据依赖关系。然而，它们经常在转换过程中丢失一些重要信息，这会导致语义损失，尤其是在表示不完整的代码片段时。不同的是，AST使源代码具有高度结构化的性质，其中关于语句和表达式的底层语法是直接可用的；也就是说，AST提供了更全面、更丰富、更精确的代码语义，使TrVD不遗漏任何可疑的漏洞含义，提高了检测的准确性。</p><p>[1]Zhenzhou T ,Binhui T ,Jiajun L , et al.Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding[J].Expert Systems With Applications,2024,238(PB):</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的审稿意见</title>
      <link href="/2023/12/16/Manuscripts/review/"/>
      <url>/2023/12/16/Manuscripts/review/</url>
      
        <content type="html"><![CDATA[<h2 id="intelligent-vulnerability-detector-using-deep-sequence-and-graph-based-hybrid-feature-extraction"><a class="markdownIt-Anchor" href="#intelligent-vulnerability-detector-using-deep-sequence-and-graph-based-hybrid-feature-extraction"></a> Intelligent Vulnerability Detector using deep sequence and graph based Hybrid Feature Extraction</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191506692.png" alt="image-20231210113010116" /></p><p>This manuscript proposed a graph-based and sequence-based neural network model for detecting vulnerabilities in Java code, utilizing multiple program features，which addresses the detection problem of a range of vulnerabilities collected from the Common Weakness Enumeration (CWE) . It introduces GCN-RFEMLP for extracting graph-based features and employs CodeBERT for extracting sequence-based features. However, there are some critical issues outlined in the manuscript making the referee has to reject it.</p><p>Comments：</p><ol><li>The COVID-19 pandemic, which is unrelated to the research and should not have been mentioned.</li><li>The manuscript presents a list of seven contributions; however, they lack conciseness and do not effectively emphasize the primary contributions.</li><li>Certain figures in the manuscript are not appropriate. Figure 1 appears to be more focused on the classification of machine learning methods and lacks contextual relevance, considering that the manuscript is specifically about vulnerability detection. Other figures also suffer from similar issues, as they seem to be detached from vulnerability detection and lack any meaningful connection. Figures 3 and 4 depict the node2vec process and GCN, respectively. However, these figures are not relevant to the vulnerability detection discussed in the paper and do not contribute to the study. Instead, the figures should focus on illustrating the transformation process from source code to code property graph, highlighting the comprehensive model proposed in the manuscript.</li><li>In the experimental section, the formatting of the tables presenting the experimental results lacks consistency. And, it is customary to report experimental results with two decimal places, such as 98.90. It is important to ensure that other result comparison data follow the same formatting convention.</li><li>The dataset description in the manuscript lacks clarity, and there is no mention of the labeling process for the data. Additionally, the comparison with other benchmarks does not indicate the dataset that was utilized.</li><li>Moreover, the manuscript lacks relevant explanations and approaches for addressing data imbalance, which can pose a risk of overfitting.</li></ol><h2 id="vuldet-bc-binary-software-vulnerability-detection-based-on-bigru-and-cnn"><a class="markdownIt-Anchor" href="#vuldet-bc-binary-software-vulnerability-detection-based-on-bigru-and-cnn"></a> VulDet-BC: Binary Software Vulnerability Detection Based on BiGRU and CNN</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191506699.png" alt="image-20231210113205646" /></p><p>this manuscript 提出了一种二进制漏洞检测方法VulDet-BC，从二进制机器指令级别，结合BiGRU与CNN构建二进制漏洞检测模型，其中利用了注意力机制，并且通过与一些基线的对比在一些指标上优于基线，However, there are some critical issues outlined in the manuscript making the referee has to reject it.</p><p>Comments:</p><ol><li>文章在相关工作部分对漏洞检测这一研究领域的介绍不够充分，近期的许多新颖的工作并没有被提及。</li><li>深度学习方法常常基于一定的漏洞模式，来实现漏洞检测。文稿中的方法将二进制机器指令转换为数字形式，再转换过程中并没有提出任何与漏洞模式相关的概念，无论在语义或是语法上；</li><li>文中提到的BiGRU结合注意力模块并不新颖，且文中实验部分所提出的一系列RQ，缺乏对漏洞成因的思考，仅仅是从深度学习的角度在进行消融实验；</li><li>BinVulDet，在文稿中是第40个引用，是比较新的工作，在伪代码级别检测二进制软件的漏洞，文稿既没有对其工作进行介绍（related work)也没有与其进行对比研究。源代码漏洞检测方法VulDeePecker使用了code-gadget结合BiLSTM构建漏洞检测模型，但是文中似乎使用后半部分的BiLSTM进行对比，这样的对比实验设计已经不是同VulDeePecker工作进行对比了，这显然是错误的；</li><li>文稿中缺乏对漏洞检测任务的误报和漏报的分析，即FNR和FPR，这在漏洞检测的工作中非常重要，且缺乏对真实世界的软件漏洞进行检测的实验研究，使实验中提出的RQ变得更加单薄，对论文的研究缺乏支撑度；</li></ol><p>This manuscript proposed a binary software vulnerability detection method called VulDet-BC, which operates at the binary machine instruction level. It employs a combination of BiGRU and CNN along with attention mechanisms to build a vulnerability detection model. The manuscript claims superiority over baselines in certain metrics. However, the manuscript has several critical issues outlined below, which led the referee to reject it.</p><ol><li>The related work of the paper lacks a comprehensive review of the research field of vulnerability detection. Many recent and innovative works in the field have not been mentioned.</li></ol><p>2.Deep learning methods often rely on some vulnerability patterns to achieve effective vulnerability detection. The proposed method in the manuscript converts binary machine instructions into numeric representations without introducing any concepts related to vulnerability patterns, either semantically or syntactically.</p><p>3.The combination of BiGRU and attention mechanisms mentioned in the paper is not novel. Additionally, the series of research questions(RQ) proposed in the experimental section lacks contemplation on the causes of vulnerabilities. The experiments conducted only focus on the impact of deep learning techniques.</p><p>4.“BinVulDet” is referenced as the 40th citation in the manuscript and represents a relatively recent work that focuses on detecting vulnerabilities in binary software at the pseudo code level. However, the manuscript fails to provide an introduction to this work in the related work section and does not compare it with the proposed method. The source code vulnerability detection method “VulDeePecker” utilizes code-gadgets combined with BiLSTM to build a vulnerability detection model. However, it seems that the manuscript incorrectly compares its method with only the latter part, BiLSTM, which is not a valid comparison to the original VulDeePecker work. This discrepancy in the experimental design is evidently an error.</p><p>5.The manuscript lacks an analysis of false negatives (FNR) and false positives (FPR), which are crucial in vulnerability detection. Furthermore, there is a lack of experiments on detecting real-world software vulnerabilities, making the proposed research questions less substantiated.</p>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 审稿 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Siamese Network</title>
      <link href="/2023/12/16/AILearning/DL/siamese/"/>
      <url>/2023/12/16/AILearning/DL/siamese/</url>
      
        <content type="html"><![CDATA[<h2 id="siamese网络"><a class="markdownIt-Anchor" href="#siamese网络"></a> Siamese网络</h2><h4 id="问题背景"><a class="markdownIt-Anchor" href="#问题背景"></a> 问题背景</h4><p>分类问题：</p><ul><li><p>分类数量较少，每一类的数据量较多，比如ImageNet、VOC等。这种分类问题可以使用神经网络或者SVM解决，只要事先知道了所有的类。</p></li><li><p>分类数量较多（或者说无法确认具体数量），每一类的数据量较少，比如人脸识别、人脸验证任务。</p></li></ul><p>解决方法：</p><ul><li>提出一种思路：将输入映射为一个特征向量，使用两个向量之间的距离来表示输入之间的差异，如图像语义上的差异。</li><li>Siamese网络，每次需要输入两个样本作为一个sample对计算损失函数。</li><li>提出Contrastive Loss用于训练。</li></ul><h4 id="应用场景"><a class="markdownIt-Anchor" href="#应用场景"></a> 应用场景</h4><p>孪生神经网络用于处理两个输入&quot;比较类似&quot;的情况。伪孪生神经网络适用于处理两个输入&quot;有一定差别&quot;的情况。比如，我们要计算两个句子或者词汇的语义相似度，使用siamese network比较适合；如果验证标题与正文的描述是否一致（标题和正文长度差别很大），或者文字是否描述了一幅图片（一个是图片，一个是文字），就应该使用pseudo-siamese network。也就是说，要根据具体的应用，判断应该使用哪一种结构，哪一种Loss。</p><h4 id="siamese创新点"><a class="markdownIt-Anchor" href="#siamese创新点"></a> Siamese创新点</h4><p>网络的创新点是淡化了标签，是的网络具有很好的扩展性，可以对那些没有训练过的类别进行分类，这一点优于很多算法。</p><p>该算法对一些小数据量的数据集也适用，变相地增加了整个数据集的大小，使得数据量相对较小的数据集也能用深度神经网络训练出不错的效果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528397.png" alt="image-20220104195309340" /></p><p>不同输入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>通过统一<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">G_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>得到两个向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo stretchy="false">)</mo><msub><mi>G</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G_W(X_1)G_W(X_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，计算两个向量之间的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">L1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mord">1</span></span></span></span>距离获得<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">E_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<br />其中，两个network是两个共享权值的网络，实际上就是两个完全相同的网络。孪生神经网络有两个输入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">X1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord">1</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">X2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord">2</span></span></span></span>,将两个输入feed进入两个神经网络（Network1 and Network2），这两个神经网络分别将输入映射到新的空间，形成输入在新的空间中的表示。通过<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">Loss</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span>的计算，评价两个输入的相似度。</p><p>如果左右两边不共享权值，而是两个不同的神经网络，叫做<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mi>s</mi><mi>e</mi><mi>u</mi><mi>d</mi><mi>o</mi><mo>−</mo><mi>s</mi><mi>i</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>t</mi><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">pseudo-siamese network</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault">d</span><span class="mord mathdefault">o</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>，伪孪生神经网络。对于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mi>s</mi><mi>e</mi><mi>u</mi><mi>d</mi><mi>o</mi><mo>−</mo><mi>s</mi><mi>i</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>t</mi><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">pseudo-siamese network</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault">d</span><span class="mord mathdefault">o</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>，两边可以是不同的神经网络（如一个是lstm，一个是cnn），也可以是相同类型的神经网络。</p><h2 id="siamese的损失函数"><a class="markdownIt-Anchor" href="#siamese的损失函数"></a> Siamese的损失函数</h2><blockquote><p>Contrastive Loss</p></blockquote><h4 id="损失函数的选择"><a class="markdownIt-Anchor" href="#损失函数的选择"></a> 损失函数的选择</h4><p>Softmax当然是一种好的选择，但不一定是最优选择，即使是在分类问题中。传统的siamese network使用Contrastive Loss。损失函数还有更多的选择，siamese network的初衷是计算两个输入的相似度,。左右两个神经网络分别将输入转换成一个&quot;向量&quot;，在新的空间中，通过判断cosine距离就能得到相似度了。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Cosine</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span></span></span></span>是一个选择，<code>exp function</code>也是一种选择，欧式距离什么的都可以，<strong>训练的目标是让两个相似的输入距离尽可能的小，两个不同类别的输入距离尽可能的大。</strong></p><h4 id="论文中contrastive-loss"><a class="markdownIt-Anchor" href="#论文中contrastive-loss"></a> 论文中Contrastive Loss</h4><p>论文中的损失函数定义如下：<br />Y代表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是否属于同一类别。输入同一类别为0，不属于同一类别为1。<br />P代表输入数据数量。<br />i表示当前输入数据下标。<br /><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>G</mi></msub></mrow><annotation encoding="application/x-tex">L_G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表两个输入数据属于同一类别时的损失函数（G，genuine）。<br /><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>I</mi></msub></mrow><annotation encoding="application/x-tex">L_I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表两个输入数据不属于同一类别的损失函数（I，imposter）。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>P</mi></munderover><mi>L</mi><mo stretchy="false">(</mo><mi>W</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>Y</mi><mo separator="true">,</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}(W)=\sum_{i=1}^{P}L(W,(Y,X_{1},X_{2})^{i})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.15999999999999992em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>W</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>Y</mi><mo stretchy="false">)</mo><msub><mi>L</mi><mi>G</mi></msub><mrow><mo fence="true">(</mo><msub><mi>E</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mrow></mrow><mrow><mo>+</mo><mi>Y</mi><msub><mi>L</mi><mi>I</mi></msub><mrow><mo fence="true">(</mo><msub><mi>E</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo fence="true">)</mo></mrow></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array} {c}{ {L(W,(X_{1},X_{1},X_{2})^{i})=(1-Y)L_{G}\left(E_{W}(X_{1},X_{2})^{i}\right)} }\\ { { } } { {+ {Y}L_{I}\left(E_{W}(X_{1},{ { {X} } }_{2})^{i}\right)} }\end{array}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.42em;vertical-align:-0.96em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.46em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span><span style="top:-2.4em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"></span></span><span class="mord"><span class="mord"><span class="mord">+</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.96em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p><p>根据我们对两个向量间举例的定义，可以得到以下条件：<br />即不同类别向量间的距离比相同类别向量间距离大。<br />两个向量之间距离越小，属于同一类别的可能性就越大。</p><h4 id="目前的contrastive-loss"><a class="markdownIt-Anchor" href="#目前的contrastive-loss"></a> 目前的Contrastive Loss</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528403.png" alt="img" /></p><p>其中：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528406.png" alt="img" /></p><p>代表两个样本特征X1和X2 的欧氏距离（二范数）P 表示样本的特征维数，Y 为两个样本是否匹配的标签，Y=1 代表两个样本相似或者匹配，Y=0 则代表不匹配，m 为设定的阈值，N 为样本个数。</p><p>观察上述的contrastive loss的表达式可以发现，这种损失函数可以很好</p><p>的表达成对样本的匹配程度，也能够很好用于训练提取特征的模型。</p><p>当 Y=1（即样本相似时），损失函数只剩下</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528402.png" alt="在这里插入图片描述" /></p><p>当 Y=0 (即样本不相似时），损失函数为</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528405.png" alt="在这里插入图片描述" /></p><p>即当样本不相似时，其特征空间的欧式距离反而小的话，损失值会变大，这也正好符号我们的要求。<br /><strong>注意：</strong><br />这里设置了一个阈值<strong>ｍargin</strong>，表示我们只考虑不相似特征欧式距离在<strong>０～ｍargin</strong>之间的，当距离超过ｍargin的，则把其loss看做为０**(即不相似的特征离的很远，其loss应该是很低的；而对于相似的特征反而离的很远，我们就需要增加其loss，从而不断更新成对样本的匹配程度)**</p><h2 id="siamese的思想总结"><a class="markdownIt-Anchor" href="#siamese的思想总结"></a> Siamese的思想总结</h2><p>其实讲了这么多，主要思想就是三点：</p><ul><li>输入不再是单个样本，而是一对样本，不再给单个的样本确切的标签，而且给定一对样本是否来自同一个类的标签，是就是0，不是就是1</li><li>设计了两个一模一样的网络，网络共享权值W，对输出进行了距离度量，可以说l1、l2等。</li><li>针对输入的样本对是否来自同一个类别设计了损失函数，损失函数形式有点类似交叉熵损失：<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528415.png" alt="" /></li></ul><p>最后使用获得的损失函数，使用反向传播梯度下降去更新两个网络共享的权值W。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>低秩分解</title>
      <link href="/2023/12/16/AILearning/DL/%E4%BD%8E%E7%A7%A9%E5%88%86%E8%A7%A3/"/>
      <url>/2023/12/16/AILearning/DL/%E4%BD%8E%E7%A7%A9%E5%88%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="低秩分解的几何解释"><a class="markdownIt-Anchor" href="#低秩分解的几何解释"></a> 低秩分解的几何解释</h1><p>低秩分解（Low-rank factorization）也可以通过几何的方式来解释，帮助我们理解其含义和应用。</p><p>假设我们有一个m×n的矩阵A，我们希望对其进行低秩分解，即将其分解为两个低秩矩阵的乘积：A ≈ UV^T。其中，U是一个m×k的矩阵，V是一个n×k的矩阵，k远远小于m和n。</p><p>几何上，可以将矩阵A视为描述一个向量空间中的点集。每一列可以看作是一个向量，而这些向量组成了一个n维的向量空间。低秩分解可以理解为通过两个低维的向量空间的点集的线性组合来近似表示原始向量空间中的点集。</p><p>具体地说，U矩阵的列向量可以看作是原始向量空间的基向量，它们将原始向量空间中的点集映射到一个低维的子空间。V矩阵的列向量则表示这个低维子空间中的基向量。通过对这两个子空间的基向量的线性组合，我们可以近似表示原始向量空间中的点集。</p><p>这个分解可以理解为以下几个几何步骤：</p><ol><li>U矩阵的列向量将原始向量空间中的点集映射到一个低维的子空间。这个子空间具有较低的维度k。</li><li>V矩阵的列向量表示这个低维子空间中的基向量，用于描述子空间中的点集。</li><li>通过对U和V的线性组合，将低维子空间中的点集映射回原始向量空间，近似重构出原始的点集。</li></ol><p>通过低秩分解，我们可以利用较低维度的向量空间来近似表示原始向量空间中的点集。这种近似表示可以在降低存储和计算成本的同时，尽可能地保留原始数据的主要结构和特征。</p><p>综上所述，几何视角可以帮助我们将低秩分解理解为通过两个低维子空间的基向量的线性组合来近似表示原始向量空间中的点集，从而实现对原始数据的降维和近似表示。这种几何解释有助于我们理解低秩分解的概念和原理。</p><h1 id="奇异值分解的几何理解"><a class="markdownIt-Anchor" href="#奇异值分解的几何理解"></a> <a href="https://www.cnblogs.com/lukairui/p/17475145.html">奇异值分解的几何理解</a></h1><p>奇异值分解（SVD）可以通过几何的方式来解释，从而帮助我们理解其含义和应用。</p><p>首先，我们可以将一个矩阵视为对向量空间的一种变换。假设有一个m×n的矩阵A，其中每一列可以看作是一个向量，而这些向量组成了一个n维的向量空间。奇异值分解可以将这个向量空间的变换分解为三个基本的几何操作：旋转、缩放和再次旋转。</p><p>具体地说，奇异值分解将矩阵A分解为三个矩阵的乘积：A = UΣVT。其中，U是一个正交矩阵，表示一个旋转操作；Σ是一个对角矩阵，对角线上的元素是奇异值，表示一个缩放操作；VT是另一个正交矩阵，表示另一个旋转操作。</p><p>这个分解可以理解为以下几个几何步骤：</p><ol><li>U对应的旋转矩阵将原始向量空间进行旋转操作，使其与新的基向量相对应。</li><li>Σ对应的对角矩阵进行缩放操作，将每个基向量的长度进行缩放，即改变了向量空间的比例关系。</li><li>V^T对应的旋转矩阵将缩放后的向量空间进行进一步旋转操作，以使其与原始向量空间对齐。</li></ol><p>通过奇异值分解，我们可以将原始矩阵A分解为这三个操作的组合，从而更好地理解和描述原始矩阵A的结构和特征。</p><p>此外，奇异值分解还提供了一种基于奇异值的重要性排序。奇异值的大小表示了每个基向量在变换中的重要性。较大的奇异值对应的基向量在变换中具有更大的影响力，而较小的奇异值对应的基向量在变换中贡献较小。</p><p>综上所述，几何视角可以帮助我们将奇异值分解理解为对向量空间的旋转、缩放和再次旋转等几何操作的组合，从而更好地理解和应用奇异值分解的概念和原理。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>可解释机器学习</title>
      <link href="/2023/12/16/AILearning/DL/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2023/12/16/AILearning/DL/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="可解释机器学习"><a class="markdownIt-Anchor" href="#可解释机器学习"></a> 可解释机器学习</h1><p>作者：SkylaSun</p><p>链接：<a href="https://zhuanlan.zhihu.com/p/570926717">https://zhuanlan.zhihu.com/p/570926717</a></p><p>来源：知乎</p><p>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h2 id="可解释机器学习-2"><a class="markdownIt-Anchor" href="#可解释机器学习-2"></a> 可解释机器学习</h2><p>可解释性方法将机器学习模型的决策过程转变成人类更能理解的结果。通用可解释性方法一般仅基于特征进行解释，无法处理图结构信息，在处理漏洞发掘场景下的图数据时，作者将边的相关性分数传递到<a href="https://www.zhihu.com/search?q=%E9%82%BB%E6%8E%A5%E8%8A%82%E7%82%B9&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">邻接节点</a>中，从而产生一个节点级别的解释。</p><ul><li>CAM（<a href="https://www.zhihu.com/search?q=%E7%B1%BB%E5%88%AB%E6%BF%80%E6%B4%BB%E6%98%A0%E5%B0%84%E5%9B%BE&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">类别激活映射图</a>），一种特征<a href="https://www.zhihu.com/search?q=%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8A%80%E6%9C%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">可视化技术</a>，最初为解释CNN模型而设计，将深层网络中学习到的<a href="https://www.zhihu.com/search?q=%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">语义信息</a>，通过权重与输出节点联系起来。</li><li><a href="https://www.zhihu.com/search?q=%E7%BA%BF%E6%80%A7%E8%BF%91%E4%BC%BC&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">线性近似</a>，通过梯度与输入，计算每个特征对分类输出的线性化贡献。</li><li>GradCAM，将<a href="https://www.zhihu.com/search?q=%E7%BA%BF%E6%80%A7%E8%BF%91%E4%BC%BC%E6%96%B9%E6%B3%95&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">线性近似方法</a>应用于GNN层的中间<a href="https://www.zhihu.com/search?q=%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">激活函数</a>，而非输入激活，产生了类似CAM的优势。</li><li>SmoothGrad，对多个噪声输入进行节点特征梯度平均，并且产生了抗噪声的解释。</li><li>IG（<a href="https://www.zhihu.com/search?q=%E7%A7%AF%E5%88%86%E6%A2%AF%E5%BA%A6&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">积分梯度</a>），改进了线性近似，过程中参考了反事实基线输入G‘，并且使用延实际输入G的<a href="https://www.zhihu.com/search?q=%E7%9B%B4%E7%BA%BF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">直线</a>路径平均的梯度，以及G和G’之间的输入激活。</li><li>Gradient or Saliency Method，通过梯度衡量预测结果相对不同输入的变化情况。</li><li>GB（导向反向传播），对普通的<a href="https://www.zhihu.com/search?q=%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">反向传播</a>加了指导，限制了小于0的梯度的回传。</li><li>LRP（逐层相关性传播），将预测结果反向传递会输入，创建相关性映射。</li><li>EB（<a href="https://www.zhihu.com/search?q=%E6%BF%80%E5%8A%B1%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">激励反向传播</a>），使用反向传播计算l-1层到第1层中<a href="https://www.zhihu.com/search?q=%E7%A5%9E%E7%BB%8F%E5%85%83&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">神经元</a>激活的相对影响，而且仅考虑<a href="https://www.zhihu.com/search?q=%E6%AD%A3%E6%9D%83%E9%87%8D&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">正权重</a>。</li></ul><p>另外，本文关注的三种针对<a href="https://www.zhihu.com/search?q=GNN%E6%A8%A1%E5%9E%8B&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">GNN模型</a>的可解释性方法概述如下：</p><p><strong>GNNExplainer</strong>，<a href="https://www.zhihu.com/search?q=%E9%BB%91%E7%9B%92%E5%89%8D%E5%90%91%E8%A7%A3%E9%87%8A%E6%8A%80%E6%9C%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">黑盒前向解释技术</a>，最大化整体预测结果和可判别子图S以及节点特征子集的<a href="https://www.zhihu.com/search?q=%E4%BA%92%E4%BF%A1%E6%81%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">互信息</a>。</p><p><strong>PGExplainer</strong>，解决了GNNExplainer需要针对每个单独的图实例进行计算的问题，同样也是通过提取相关子图S进行全局解释，但支持归纳式学习方法。</p><p><strong>Graph-LRP</strong>使用<a href="https://www.zhihu.com/search?q=%E9%AB%98%E9%98%B6%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">高阶泰勒展开</a>处理多层GNN上节点之间的消息传递。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++ lamda表达式</title>
      <link href="/2023/12/16/Programmer/c-c++/lambda/"/>
      <url>/2023/12/16/Programmer/c-c++/lambda/</url>
      
        <content type="html"><![CDATA[<p>创建一个匿名函数并执行。Objective-C采用的是上尖号^，而C++ 11采用的是配对的方括号[]。实例如下：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    []&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;Hello,Worldn&quot;</span>; </span><br><span class="line">    &#125;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们也可以方便的将这个创建的匿名函数赋值出来调用：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> func = [](<span class="type">int</span> i) &#123; <span class="comment">// (int i) 是指传入改匿名函数的参数</span></span><br><span class="line">        cout &lt;&lt; i;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="捕获选项"><a class="markdownIt-Anchor" href="#捕获选项"></a> 捕获选项</h1><ul><li>[] Capture nothing (or, a scorched earth strategy?)</li><li>[&amp;] Capture any referenced variable by reference</li><li>[=] Capture any referenced variable by making a copy</li><li>[=, &amp;foo] Capture any referenced variable by making a copy, but capture variable foo by reference</li><li>[bar] Capture bar by making a copy; don’t copy anything else</li><li>[this] Capture the this pointer of the enclosing class</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-[]不捕获任何变量</span><br><span class="line"></span><br><span class="line">-[&amp;]通过引用捕获任何引用变量</span><br><span class="line"></span><br><span class="line">-[=]通过复制捕获任何引用变量</span><br><span class="line"></span><br><span class="line">-[=，&amp;foo]通过复制捕获任何引用的变量，但通过引用捕获变量foo</span><br><span class="line"></span><br><span class="line">-[bar]通过复制来捕获bar；不要复制其他任何东西</span><br><span class="line"></span><br><span class="line">-[this]捕获封闭类的this指针</span><br></pre></td></tr></table></figure><h1 id="不捕获任何变量"><a class="markdownIt-Anchor" href="#不捕获任何变量"></a> [] 不捕获任何变量</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> func = [] &#123; cout &lt;&lt; i; &#125;;</span><br><span class="line">    <span class="built_in">func</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>vs 报错<br />error C3493: 无法隐式捕获“i”，因为尚未指定默认捕获模式<br />error C2064: 项不会计算为接受 0 个参数的函数</p><p>g++ 报错：<br />error: ‘i’ is not captured</p><p>要直接沿用外部的变量需要在 [] 中指名捕获。</p><h1 id="拷贝捕获"><a class="markdownIt-Anchor" href="#拷贝捕获"></a> [=] 拷贝捕获</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> func = [=]&#123;  <span class="comment">// [=] 表明将外部的所有变量拷贝一份到该函数内部</span></span><br><span class="line">        cout &lt;&lt; i;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">func</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br />1024</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [=]&#123;</span><br><span class="line">        <span class="comment">// fun1 内存在 i</span></span><br><span class="line">        cout &lt;&lt; i; <span class="comment">// 1024</span></span><br><span class="line">        <span class="keyword">auto</span> fun2 = []&#123; <span class="comment">// 未指名捕获， i 不存在</span></span><br><span class="line">            cout &lt;&lt; i;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="built_in">fun2</span>();</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="引用捕获"><a class="markdownIt-Anchor" href="#引用捕获"></a> [&amp;] 引用捕获</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    cout &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [&amp;]&#123;</span><br><span class="line">        cout &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果:<br />0x28ff0c<br />0x28ff0c</p><h1 id="拷贝与引用混合"><a class="markdownIt-Anchor" href="#拷贝与引用混合"></a> [=, &amp;] 拷贝与引用混合</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [=, &amp;i]&#123; <span class="comment">// 默认拷贝外部所有变量，但引用变量 i</span></span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果<br />outside i:0x28ff0c<br />outside j:0x28ff08<br />inside i:0x28ff0c<br />inside j:0x28ff04</p><h1 id="bar-指定引用或拷贝"><a class="markdownIt-Anchor" href="#bar-指定引用或拷贝"></a> [bar] 指定引用或拷贝</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [i]&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        <span class="comment">// cout &lt;&lt; j &lt;&lt; endl; // j 未捕获</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br />outside i value:1024 addr:0x28ff08<br />inside i value:1024 addr:0x28ff04</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [&amp;i]&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        <span class="comment">// cout &lt;&lt; j &lt;&lt; endl; // j 未捕获</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br />outside i value:1024 addr:0x28ff08<br />inside i value:1024 addr:0x28ff08</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>, k;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [i, &amp;j]&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">        <span class="comment">// cout &lt;&lt; k; // k 未捕获</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br />outside i:0x28ff0c<br />outside j:0x28ff08<br />inside i:0x28ff00<br />inside j:0x28ff08</p><h1 id="this-捕获-this-指针"><a class="markdownIt-Anchor" href="#this-捕获-this-指针"></a> [this] 捕获 this 指针</h1><figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="title">std</span>;</span><br><span class="line"><span class="keyword">class</span> <span class="title">test</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">hello</span>()</span> &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;test hello!n&quot;</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lambda</span>()</span> &#123;</span><br><span class="line">        auto fun = [<span class="keyword">this</span>]&#123; <span class="comment">// 捕获了 this 指针</span></span><br><span class="line">            <span class="keyword">this</span>-&gt;hello(); <span class="comment">// 这里 this 调用的就是 class test 的对象了</span></span><br><span class="line">        &#125;;</span><br><span class="line">        fun();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">int</span> <span class="title">main</span>()</span></span><br><span class="line">&#123;</span><br><span class="line">    test t;</span><br><span class="line">    t.lambda();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> C/C++ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>overleaf 葵花宝典</title>
      <link href="/2023/12/16/Manuscripts/overleaf/overleaf%E7%BB%8F%E9%AA%8C/"/>
      <url>/2023/12/16/Manuscripts/overleaf/overleaf%E7%BB%8F%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="1列表"><a class="markdownIt-Anchor" href="#1列表"></a> 1.列表</h1><h2 id="itemize命令无序列表"><a class="markdownIt-Anchor" href="#itemize命令无序列表"></a> <strong>{itemize}命令【无序列表】</strong></h2><blockquote><p>{itemize}命令对文本进行简单的排列，不是采用序号，默认是用实心圆点符号进行排列。这个命令需要和\item配合使用。</p></blockquote><p>默认为实心圆点符号</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;itemize&#125;</span><br><span class="line">    <span class="keyword">\item</span> one</span><br><span class="line">    <span class="keyword">\item</span> two</span><br><span class="line">    <span class="keyword">\item</span> ...</span><br><span class="line"><span class="keyword">\end</span>&#123;itemize&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191508804.png" alt="image-20231210154216456" /></p><p>使用其他符号进行排列</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;itemize&#125;</span><br><span class="line">    <span class="keyword">\item</span>[*] one</span><br><span class="line">    <span class="keyword">\item</span>[*] two</span><br><span class="line">    <span class="keyword">\item</span>[*] ...</span><br><span class="line"><span class="keyword">\end</span>&#123;itemize&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191508806.png" alt="image-20231210155010036" /></p><h2 id="enumerate命令有序列表"><a class="markdownIt-Anchor" href="#enumerate命令有序列表"></a> <strong>{enumerate}命令【有序列表】</strong></h2><blockquote><p>{enumerate}命令采用序号对文本进行简单的排列，默认是用1，2，3进行排列。这个命令需要和\item配合使用。</p></blockquote><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;enumerate&#125;</span><br><span class="line">    <span class="keyword">\item</span> one</span><br><span class="line">    <span class="keyword">\item</span> two</span><br><span class="line">    <span class="keyword">\item</span> ...</span><br><span class="line"><span class="keyword">\end</span>&#123;enumerate&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191508812.png" alt="image-20231210155244000" /></p><p><strong>使用其他形式的编号</strong>：</p><blockquote><p>{enumerate}产生所需要的编号，默认是采用数字1,2,3……进行排列。</p><p><strong>使用命令\usepackage{enumerate}</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;enumerate&#125;[i)]</span><br><span class="line">    \item one</span><br><span class="line">    \item two</span><br><span class="line">    \item ...</span><br><span class="line">\end&#123;enumerate&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;enumerate&#125;[1)]</span><br><span class="line">    \item one</span><br><span class="line">    \item two</span><br><span class="line">    \item ...</span><br><span class="line">\end&#123;enumerate&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 自定义编号形式</span><br><span class="line"></span><br><span class="line">\begin&#123;description&#125;</span><br><span class="line">    \item[Step1] one</span><br><span class="line">    \item[Step2] two</span><br><span class="line">    \item[Step3] ...</span><br><span class="line">\end&#123;description&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191509540.png" alt="image-20231219150916511" /></p><h1 id="2三线表"><a class="markdownIt-Anchor" href="#2三线表"></a> 2.三线表</h1><p>使用方法1或者2都可以，两种latex编辑器WinEdt和TexStudio各有优点，看你选择，我用的是方法1，使用WinEdt。</p><p>直接显示latex 代码，然后你们根据自己的情况进行修改即可</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">\begin&#123;table&#125;[h] %h表示三线表在当前位置插入</span><br><span class="line">\setlength&#123;\abovecaptionskip&#125;&#123;<span class="number">0.</span>05cm&#125; %设置三线表标题与第一条线间距</span><br><span class="line">\centering</span><br><span class="line">\caption&#123;\textbf&#123;The characteristics of various methods&#125;&#125;</span><br><span class="line">%表头文本加黑，但不加黑Table <span class="number">1.</span>字样，引入包即可：\usepackage[labelfont=bf]&#123;caption&#125;</span><br><span class="line">\arrayrulecolor&#123;black&#125; %设置三线表线条颜色：黑色</span><br><span class="line">\begin&#123;tabular*&#125;&#123;\hsize&#125;&#123;@&#123;\extracolsep&#123;\fill&#125;&#125;c c c c&#125; %&#123;\hsize&#125;使三线表自适应宽度，c表示文本居中</span><br><span class="line">  \hline</span><br><span class="line">  <span class="number">1</span> &amp; <span class="number">2</span> &amp; <span class="number">3</span> &amp; <span class="number">4</span>\\</span><br><span class="line">  \hline</span><br><span class="line">  <span class="number">11</span> &amp; <span class="number">22</span> &amp; <span class="number">33</span> &amp; <span class="number">44</span> \\</span><br><span class="line">  <span class="number">111</span> &amp; <span class="number">222</span> &amp; <span class="number">333</span> &amp; <span class="number">444</span> \\</span><br><span class="line">  <span class="number">1111</span> &amp; <span class="number">2222</span> &amp; <span class="number">3333</span> &amp; <span class="number">4444</span> \\</span><br><span class="line">  <span class="number">11111</span> &amp; <span class="number">22222</span> &amp; <span class="number">33333</span> &amp; <span class="number">44444</span> \\</span><br><span class="line">  <span class="number">111111</span> &amp; <span class="number">222222</span> &amp; <span class="number">333333</span> &amp; <span class="number">444444</span> \\</span><br><span class="line">  \hline</span><br><span class="line">\end&#123;tabular*&#125;</span><br><span class="line">\end&#123;table&#125;</span><br></pre></td></tr></table></figure><p>添加包：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">\usepackage&#123;booktabs&#125;</span><br><span class="line">\usepackage&#123;amsmath&#125;</span><br><span class="line">\usepackage&#123;setspace&#125;</span><br><span class="line">\usepackage&#123;array,caption&#125;</span><br><span class="line">\usepackage[labelfont=bf]&#123;caption&#125;</span><br></pre></td></tr></table></figure><h1 id="3图片过大处理"><a class="markdownIt-Anchor" href="#3图片过大处理"></a> 3.图片过大处理</h1><p>在<a href="https://so.csdn.net/so/search?q=LaTeX%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87&amp;spm=1001.2101.3001.7020">LaTeX插入图片</a>的时候，经常需要调整图片的大小。我们可以通过如下代码来完成：</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[htb]</span><br><span class="line">  <span class="keyword">\centering</span></span><br><span class="line">  <span class="keyword">\includegraphics</span>[width=0.5<span class="keyword">\linewidth</span>]&#123;fig2.png&#125;</span><br><span class="line">  <span class="keyword">\caption</span>&#123;图片的解释&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure><p>其中，width=0.5[linewidth](<a href="https://so.csdn.net/so/search?q=linewidth&amp;spm=1001.2101.3001.7020">https://so.csdn.net/so/search?q=linewidth&amp;spm=1001.2101.3001.7020</a>) 表明将插入的图像等比例缩小至0.6倍。经验证，调整比例后图像成功地缩小了。</p><p>这样可以适应模板 自动地调整大小 不用手动去调整长宽 非常好用</p><h1 id="4空格"><a class="markdownIt-Anchor" href="#4空格"></a> 4.空格</h1><p>quad空格a \quad b一个m的宽度<br />大空格a\ b1/3m宽度<br />中等空格a;b2/7m宽度<br />小空格a,b1/6m宽度<br />没有空格ab<br />紧贴a!b缩进1/6m宽度</p><h1 id="5latex的粗体"><a class="markdownIt-Anchor" href="#5latex的粗体"></a> 5.latex的粗体</h1><p>latTx的粗体一般用以下命令：</p><p>\textbf{}：文本环境加粗。在数学环境使用的话，会使斜体效果消失。并且无法输出加粗的希腊字母。</p><p>\mathbf{}：会变为粗体，但同样会导致数学字母斜体形式的丢失。 \boldmath{}：数学环境里可以加粗且不会使斜体消失。需要添加amsmath宏包。 \boldsymbol{}：可以对希腊字母加粗。需要添加amsmath宏包。 在数学环境中，比较推荐的方式是添加宏包\usepackage{bm}, 使用\bm{}命令加粗。</p><p>但是在xelatex或Luatex引擎的unicode-math环境中中，\bm{}会报错。此时，可以使用以下命令：</p><p>\symbfit{}：加粗，且有斜体效果 \symbf{}：加粗，没有斜体效果 \mathbfcal{}：加粗的\mathcal字体</p><p>[<a href="https://blog.csdn.net/xovee/article/details/106325136">翻译] [Overleaf] LaTeX 中的粗体、斜体、下划线_latex 斜体-CSDN博客</a></p><h1 id="6图片与引用"><a class="markdownIt-Anchor" href="#6图片与引用"></a> 6.图片与引用</h1><p>示例：</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure*&#125;</span><br><span class="line"><span class="keyword">\centering</span></span><br><span class="line"><span class="keyword">\includegraphics</span>[scale=0.45]&#123;double<span class="built_in">_</span>single.eps&#125; <span class="comment">%scale=缩小比例，或者用width=2in</span></span><br><span class="line"><span class="keyword">\caption</span>&#123;Search&#125;     <span class="keyword">\label</span>&#123;fig:ss&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure*&#125;</span><br></pre></td></tr></table></figure><p>引用注意</p><p>\label{} 必须写在 \caption{} 的后面。</p><p>\ref{}:引用</p><p>\ref{fig:ss}, 即\ref{}, {}内为标签名称,我这里的标签名称是：fig:ss</p><h1 id="7宽度问题"><a class="markdownIt-Anchor" href="#7宽度问题"></a> 7.宽度问题</h1><p>\hsize: 是 Latex中定义的长度，是一种叫做水平盒子的长度，它的主要作用是告诉TeX系统什么时候换行。所以大部分时候和\textwidth是一致的，但是在分栏状况下，\hsize只是栏的宽度；</p><p>\textwidth: 是 Latex中定义的长度，等效于\hsize，并且是固定不变的，可以理解为一行文字的宽度。</p><p>\pagewidth: 包含了页边的宽度，比\textwidth要大</p><p>\linewidth: 这指得是目前环境的宽度，是依赖于上下文的一个宽度值，例如新建了一个box，在这个box中，</p><p>\linewidth是box中文字的宽度。再例如minipage环境中，\linewidth就和这个minipage的大小有关.</p><p>\columnwidth: 如果文章分栏的话，这个宽度就是每一栏的宽度。</p>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> overleaf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>overleaf 问题</title>
      <link href="/2023/12/16/Manuscripts/overleaf/overleaf%E9%97%AE%E9%A2%98%20/"/>
      <url>/2023/12/16/Manuscripts/overleaf/overleaf%E9%97%AE%E9%A2%98%20/</url>
      
        <content type="html"><![CDATA[<h1 id="algorithm最后出现0"><a class="markdownIt-Anchor" href="#algorithm最后出现0"></a> algorithm最后出现=0</h1><p><strong>解决方法：</strong></p><p>注释掉&quot;\usepackage{algpseudocode}&quot;</p><p>因为<code>\usepackage&#123;algpseudocode&#125; %This introduces extra zero at the end of algorithm</code></p><h1 id="table位置问题"><a class="markdownIt-Anchor" href="#table位置问题"></a> table位置问题</h1><p>如果table默认置顶，在.sty文件中定义了table环境，那么可尝试将</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;table&#125;[h] </span><br></pre></td></tr></table></figure><p>改为</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;table&#125;[pos=h] </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> overleaf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Computers&amp;Security</title>
      <link href="/2023/12/16/Manuscripts/sci/Computers&amp;Security/"/>
      <url>/2023/12/16/Manuscripts/sci/Computers&amp;Security/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www2.cloud.editorialmanager.com/cose/default2.aspx">Editorial Manager®</a></p>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sci投稿 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Triplet Loss</title>
      <link href="/2023/10/10/AILearning/DL/Triplet-Loss/"/>
      <url>/2023/10/10/AILearning/DL/Triplet-Loss/</url>
      
        <content type="html"><![CDATA[<h1 id="triplet-loss"><a class="markdownIt-Anchor" href="#triplet-loss"></a> Triplet Loss</h1><h2 id="aside-tripletloss案例"><a class="markdownIt-Anchor" href="#aside-tripletloss案例"></a> <aside><br />💡 TripletLoss案例</h2><p><a href="https://zhuanlan.zhihu.com/p/462539667">【对比学习】| Triplet loss</a></p><p><a href="https://www.jianshu.com/p/f97fab0d5989?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io">MXNet/Gluon 中 Triplet Loss 算法</a></p><p><strong>1.什么是triplet loss 损失函数？</strong></p><p>triplet loss 是深度学习的一种损失函数，主要是用于训练差异性小的样本，比如人脸，细粒度分类等；其次在训练目标是得到样本的embedding任务中，triplet loss 也经常使用，比如文本、图片的embedding。本文主要讨论，对于训练样本差异小的问题。</p><p><strong>2.tripletloss原理</strong></p><p>损失函数公式：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019722.webp" alt="https://pic1.zhimg.com/80/v2-90daccead9843f3bf5b1489e58dbd578_720w.webp" /></p><p>。输入是一个三元组，包括锚（Anchor）示例、正（Positive）示例、负（Negative）示例，通过优化锚示例与正示例的距离小于锚示例与负示例的距离，实现样本之间的相似性计算。a：anchor，锚示例；p：positive，与a是同一类别的样本；n：negative，与a是不同类别的样本；margin是一个大于0的常数。最终的优化目标是拉近a和p的距离，拉远a和n的距离。其中样本可以分为三类：</p><p>**easy triplets：**即</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019709.webp" alt="https://pic2.zhimg.com/80/v2-dd0386738a3604977a84ea8eb7487a21_720w.webp" /></p><p>，这种情况不需要优化，天然a和p的距离很近，a和n的距离很远，如下图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019727.webp" alt="https://pic1.zhimg.com/80/v2-ad02e580b107eae95d8feedcd1cfc50c_720w.webp" /></p><p>easy triplets示例</p><p>**hard triplets：**即d(a,n)&lt;d(a,p)</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019682.webp" alt="https://pic4.zhimg.com/80/v2-c0f8f2ddcb833953d4746f5cab18b3db_720w.webp" /></p><p>，a和n的距离近，a和p的距离远，这种情况损失最大，需要优化，如下图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019720.webp" alt="https://pic1.zhimg.com/80/v2-0e26c64925ef2bcb9806eaf18c2aad0c_720w.webp" /></p><p>hard triplets示例</p><p>**semi-hard triplets：**即</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019718.png" alt="https://pic3.zhimg.com/80/v2-e4dfc15a84b8f0c2edfcb0943bf3895e_720w.webp" /></p><p>，即a和p的距离比a和n的距离近，但是近的不够多，不满足margin，这种情况存在损失，但损失比hard triplets要小，也需要优化，如下图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019984.webp" alt="https://pic2.zhimg.com/80/v2-a84e1ad1b49496a5806c14613f662b31_720w.webp" /></p><p>semi-hard triplets示例</p><p><strong>3.Margin的作用</strong></p><ul><li><p>避免模型走捷径，将negative和positive的embedding训练成很相近，因为如果没margin，triplets loss公式就变成了，那么只要就可以满足上式，也就是锚点a和正例p与锚点a和负例n的距离一样即可，这样模型很难正确区分正例和负例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019027.webp" alt="https://pic4.zhimg.com/80/v2-94655266dc5db1158df340927e4e8f3f_720w.webp" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242019017.png" alt="https://pic2.zhimg.com/80/v2-656b1ac96526f9140a11ae0c021e36d1_720w.webp" /></p></li><li><p>设定一个margin常量，可以迫使模型努力学习，能让锚点a和负例n的distance值更大，同时让锚点a和正例p的distance值更小。</p></li><li><p>由于margin的存在，使得triplets loss多了一个参数，margin的大小需要调参。如果margin太大，则模型的损失会很大，而且学习到最后，loss也很难趋近于0，甚至导致网络不收敛，但是可以较有把握的区分较为相似的样本，即a和p更好区分；如果margin太小，loss很容易趋近于0，模型很好训练，但是较难区分a和p。</p></li></ul><p>在训练的时候，一个重要的选择就是对于负样本进行挑选。称之为，负样本选择或者三元组采集(triplet mining)。一个原则时，easy triplet应该尽量避免被采集到，因为loss为0，所以对训练并没有贡献。</p><h2 id="triplet-loss使用案例"><a class="markdownIt-Anchor" href="#triplet-loss使用案例"></a> Triplet Loss使用案例</h2><hr /><p>在此任务中使用Triplet Loss，可以通过以下方式实现模型：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, output_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.output_size = output_size</span><br><span class="line">        self.fc1 = nn.Linear(input_size, hidden_size)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_size, output_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = MyModel(input_size=<span class="number">10</span>, hidden_size=<span class="number">5</span>, output_size=<span class="number">2</span>)</span><br><span class="line">triplet_loss = nn.TripletMarginLoss(margin=<span class="number">1.0</span>, p=<span class="number">2</span>)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training loop</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (anchor, pos, neg) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        anchor_output = model(anchor)</span><br><span class="line">        pos_output = model(pos)</span><br><span class="line">        neg_output = model(neg)</span><br><span class="line">        loss = triplet_loss(anchor_output, pos_output, neg_output)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Validation loop</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> anchor, pos, neg <span class="keyword">in</span> val_loader:</span><br><span class="line">        anchor_output = model(anchor)</span><br><span class="line">        pos_output = model(pos)</span><br><span class="line">        neg_output = model(neg)</span><br><span class="line">        dist_pos = F.pairwise_distance(anchor_output, pos_output)</span><br><span class="line">        dist_neg = F.pairwise_distance(anchor_output, neg_output)</span><br><span class="line">        total += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> dist_pos &lt; dist_neg:</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">accuracy = <span class="number">100</span> * correct / total</span><br><span class="line"></span><br><span class="line"><span class="comment"># Testing loop</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> anchor, pos, neg <span class="keyword">in</span> test_loader:</span><br><span class="line">        anchor_output = model(anchor)</span><br><span class="line">        pos_output = model(pos)</span><br><span class="line">        neg_output = model(neg)</span><br><span class="line">        dist_pos = F.pairwise_distance(anchor_output, pos_output)</span><br><span class="line">        dist_neg = F.pairwise_distance(anchor_output, neg_output)</span><br><span class="line">        total += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> dist_pos &lt; dist_neg:</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">accuracy = <span class="number">100</span> * correct / total</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在这个示例代码中，我们定义了一个自定义模型，并使用<code>nn.TripletMarginLoss</code>作为损失函数来最小化锚点、正样本和负样本之间的距离。在训练循环中，我们首先通过模型获取锚点、正样本和负样本的输出，然后将它们传递给<code>nn.TripletMarginLoss</code>来计算损失并更新模型参数。</p><p>在验证循环和测试循环中，我们首先通过模型获取锚点、正样本和负样本的输出，然后使用PyTorch内置函数<code>F.pairwise_distance</code>来计算锚点和正样本之间的欧几里得距离（或其他距离度量），以及锚点和负样本之间的距离。如果锚点和正样本之间的距离小于锚点和负样本之间的距离，则认为预测正确。</p><p>请注意，在上面的示例代码中，模型的<code>forward</code>函数只接受一个输入，并且我们假设锚点、正样本和负样本都是从<code>train_loader</code>、<code>val_loader</code>和<code>test_loader</code>中获取的。如果你的输入数据包含两个样本，你可以修改<code>forward</code>函数来接受两个输入：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x1, x2</span>):</span><br><span class="line">    x = torch.cat((x1, x2), dim=<span class="number">1</span>)</span><br><span class="line">    x = F.relu(self.fc1(x))</span><br><span class="line">    x = self.fc2(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后在训练循环中，您需要分别传递两个输入分别计算输出。在验证和测试循环中，您需要在计算欧几里得距离之前将两个输入传递给模型以获得它们的特征向量。</p><p><code>with torch.no_grad()</code>是在PyTorch中的上下文管理器，用于在执行代码期间禁用梯度计算和自动求导。这在测试模型时非常有用，因为在测试时我们不需要计算梯度，而且如果开启自动求导，会增加计算时间和内存占用。在<code>with torch.no_grad()</code>中执行的所有操作都不会计算梯度，所以可以加速代码执行速度和节省内存消耗。</p><p>在PyTorch中，<code>model.train()</code>和<code>model.eval()</code>方法是用于控制模型训练和评估模式的。当调用<code>model.train()</code>时，模型将被设置为训练模式，这意味着它将启用dropout和batch normalization等训练特定的操作。当调用<code>model.eval()</code>时，模型将被设置为评估模式，这意味着它将禁用dropout和batch normalization等特定于训练的操作，并使用整个测试集对模型进行评估。在测试或验证期间，应该始终调用<code>model.eval()</code>，以确保模型不会受到dropout等操作的影响，从而获得准确的测试结果。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Loss </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-Head Attention</title>
      <link href="/2023/10/10/AILearning/DL/Multi-head%20Attention/"/>
      <url>/2023/10/10/AILearning/DL/Multi-head%20Attention/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242017228.png" alt="image-20240424201713198" /></p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>在此，笔者可以得到一些对Multi-Head-Attention的结论：</p><ul><li><p>通俗点理解<strong>Self-Attention就是用Q、K计算出每个token的权重进而对V向量进行提纯的方法</strong>，为什么叫Self-Attention呢，就是Q、K、V是来自于同一个输入经过三个不同的线性变换得到的。</p></li><li><p>对于大部分query，每个头都学习了某种固定的pattern模式，而且12个头中大部分pattern是差不多的，<strong>但是总有少数的pattern才能捕捉到语法/句法/词法信息。</strong></p></li><li><p>《Attention Is All You Need》这篇原论文原文中解释了多头的作用：<strong>将隐状态向量分成多个头，形成多个子语义空间，可以让模型去关注不同维度语义空间的信息（或者说让模型去关注不同方面的信息）。</strong></p></li><li><p>多头attention的有些头的功能是不一样的，有的头可能没啥信息（如第5head），有的头pattern由位置信息主导，有的头由语法信息主导，有的头由词法信息主导，<strong>而能够捕捉到语法/句法/词法信息的头其实是非常少的</strong>（这一点已被大量学术论文证明，笔者的句法破坏实验也验证了这一点）<strong>，那么multi-head的作用就是为了保证这些pattern能够被抽取出来，需要让其有一定的头的基数，因为单头很容易就变成自己注意力全在自己身上了</strong>，这一点也可以从‘以上pattern中大部分pattern都是自己关注自己’这个现象身上得到佐证。</p></li><li><p>越靠近底层的attention，其pattern种类越丰富，关注到的点越多，越到顶层的attention，各个head的pattern趋同。</p></li><li><p>head数越少，**pattern会更倾向于token关注自己本身(**或者其他的比较单一的模式，比如都关注CLS)。</p></li><li><p>多头的核心思想应该就是ensemble，如随机森林一样，将特征切分，每个head就像是一个弱分类器，让最后得到的embedding关注多方面信息，不要过拟合到某一种pattern上。</p></li><li><p>已有论文证明head数目不是越多越好，bert-base上实验的结果为8、16最好，太多太少都会变差。</p></li><li><p>multi-head-attention中大部分头没有捕捉到语法/句法信息，但是笔者这里没办法做出断言说它们是没有用的，具体还是要看下游任务对其的适配程度。个人倾向于大部分pattern只是不符合人类的语法，在不同的下游任务中应该还是有用武之地的。</p></li></ul><blockquote><p><strong>Transformer的角色定位是特征抽取器。所以多头对一个向量切分不同的维度来捕捉不同的pattern，这里就可以解释论文里原话中的不同维度的语义信息。</strong></p></blockquote><p><a href="https://zhuanlan.zhihu.com/p/626820422">Multi-Head-Self-Attention的作用到底是什么? - 知乎 (zhihu.com)</a></p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>注意力机制</title>
      <link href="/2023/10/10/AILearning/DL/%E5%87%A0%E7%A7%8D%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
      <url>/2023/10/10/AILearning/DL/%E5%87%A0%E7%A7%8D%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="注意力机制"><a class="markdownIt-Anchor" href="#注意力机制"></a> <strong>注意力机制</strong></h1><p>注意力机制是深度学习模型中的一种强大工具，可以选择性地关注输入数据的特定特征或部分。注意力机制的引入在各种自然语言处理（NLP）任务中，如机器翻译、文本摘要和语音识别等方面，都取得了显著的改进。</p><p>有几种类型的注意力机制。以下是其中一些最流行的类型：</p><h2 id="1-软注意力"><a class="markdownIt-Anchor" href="#1-软注意力"></a> <strong>1. 软注意力</strong></h2><p>软注意力是一种注意力机制，它计算输入特征的加权和，其中权重在训练过程中学习。软注意力通常用于序列到序列模型中，在这种模型中，输出取决于整个输入序列。软注意力已被证明可以显著提高机器翻译模型的性能。</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Soft Attention</mtext><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>x</mi></msub></msubsup><msub><mi>α</mi><mi>i</mi></msub><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{Soft Attention} = \sum_{i=1}^{T_x} \alpha_i h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">Soft Attention</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.13889em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">T_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是输入序列的长度，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个输入特征向量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个特征向量的权重，由以下公式计算：</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>x</mi></msub></msubsup><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha_i = \frac{\exp(e_i)}{\sum_{j=1}^{T_x} \exp(e_j)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.825845em;vertical-align:-0.8158449999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.506975em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.97575em;"><span style="top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-2.987657142857143em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23056em;"><span style="top:-2.3em;margin-left:-0.13889em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mathdefault mtight">x</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mop mtight">exp</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight">exp</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8158449999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个特征向量的能量，由以下公式计算：</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_i = a(s_{i-1}, h_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">a</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">s_{i-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>是解码器的上一个隐藏状态，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是编码器的第i个特征向量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span>是一个可学习的函数，用于计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">s_{i-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>之间的相似度。</p><h2 id="2-硬注意力"><a class="markdownIt-Anchor" href="#2-硬注意力"></a> <strong>2. 硬注意力</strong></h2><p>硬注意力是一种注意力机制，它在解码过程的每个步骤中从输入序列中选择一个特征。硬注意力通常用于图像字幕任务，其中输出取决于图像的特定区域。硬注意力在计算上比较昂贵，在某些情况下可能会导致性能不佳。</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Hard Attention</mtext><mo>=</mo><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{Hard Attention} = h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">Hard Attention</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>是解码器的当前步骤，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是编码器中与解码器状态最相关的特征向量。</p><h2 id="3-多头注意力"><a class="markdownIt-Anchor" href="#3-多头注意力"></a> <strong>3. 多头注意力</strong></h2><p>多头注意力是一种注意力机制，它允许模型同时关注输入序列的多个部分。多头注意力在基于Transformer的模型中特别有效，这些模型已成为各种NLP任务中的最先进方法。</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Multi-Head Attention</mtext><mo>=</mo><mtext>Concat</mtext><mo stretchy="false">(</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>h</mi></msub><mo stretchy="false">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">\text{Multi-Head Attention} = \text{Concat}(head_1, ..., head_h) W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">Multi-Head Attention</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Concat</span></span><span class="mopen">(</span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">h</span></span></span></span>是头数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">head_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个头的注意力向量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span>是一个可学习的权重矩阵，用于将所有头的注意力向量组合成最终的输出向量。</p><h2 id="4-自注意力"><a class="markdownIt-Anchor" href="#4-自注意力"></a> <strong>4. 自注意力</strong></h2><p>自注意力是一种注意力机制，它计算输入特征的加权和，其中权重基于输入本身进行学习。自注意力在语言建模任务中尤其有效，其中模型需要预测序列中的下一个单词。</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Self-Attention</mtext><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>x</mi></msub></msubsup><msub><mi>α</mi><mi>i</mi></msub><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{Self-Attention} = \sum_{i=1}^{T_x} \alpha_i h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">Self-Attention</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.13889em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">T_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是输入序列的长度，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个输入特征向量，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个特征向量的权重，由以下公式计算：</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>x</mi></msub></msubsup><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha_i = \frac{\exp(e_i)}{\sum_{j=1}^{T_x} \exp(e_j)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.825845em;vertical-align:-0.8158449999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.506975em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.97575em;"><span style="top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-2.987657142857143em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23056em;"><span style="top:-2.3em;margin-left:-0.13889em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mathdefault mtight">x</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mop mtight">exp</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight">exp</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8158449999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">e_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个特征向量的能量，由以下公式计算：</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="false">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_i = a(h_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">a</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span>是一个可学习的函数，用于计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>与所有输入特征向量之间的相似度。</p><p>综上所述，注意力机制已成为深度学习模型中的重要工具，特别是在NLP任务中。软注意力、硬注意力、多头注意力和自注意力是在不同应用中使用的最流行的注意力机制类型。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>正则化</title>
      <link href="/2023/10/10/AILearning/DL/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
      <url>/2023/10/10/AILearning/DL/%E6%AD%A3%E5%88%99%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h2 id="正则化"><a class="markdownIt-Anchor" href="#正则化"></a> 正则化</h2><ul><li>0 范数：向量中非零元素的个数</li><li>1 范数: 向量中各个元素绝对值之和。</li><li>2 范数: 向量中各个元素平方和的 1/2 次方，L2 范数又称 Euclidean 范数或者 Frobenius 范数</li><li>p 范数: 为 x 向量各个元素绝对值 p 次方和的 1/p 次方</li></ul><p>L1 和 L2 正则先验分别服从什么分布？L1 是拉普拉斯分布，L2 是高斯分布。</p><h3 id="为什么-l1-和-l2-正则化可以防止过拟合"><a class="markdownIt-Anchor" href="#为什么-l1-和-l2-正则化可以防止过拟合"></a> 为什么 L1 和 L2 正则化可以防止过拟合？</h3><ul><li>拟合过程中通常都<strong>倾向于让权值尽可能小</strong>，最后构造一个所有参数都比较小的模型。因为一般认为参数值小的模型比较简单，能适应不同的数据集，也在一定程度上避免了过拟合现象。可以设想一下对于一个线性回归方程，<strong>若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响</strong>；但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响，即抗扰动能力强。</li><li>L1 &amp; L2 正则化会使模型偏好于更小的权值。更小的权值意味着更低的模型复杂度；**添加 L1 &amp; L2 正则化相当于为模型添加了某种先验，**限制了参数的分布，从而降低了模型的复杂度。</li><li>模型的复杂度降低，意味着模型对于<strong>噪声与异常点的抗干扰性的能力增强</strong>，从而提高模型的<strong>泛化能力</strong>。直观来说，<mark>就是对训练数据的拟合刚刚好，不会过分拟合训练数据（比如异常点，噪声）</mark></li></ul><h3 id="l1-与-l2-的相同点"><a class="markdownIt-Anchor" href="#l1-与-l2-的相同点"></a> L1 与 L2 的相同点</h3><blockquote><p>都可以限制模型的学习能力，即通过限制参数的规模，使模型偏好于权值较小的目标函数，防止过拟合。</p></blockquote><h3 id="l1-与-l2-的不同点"><a class="markdownIt-Anchor" href="#l1-与-l2-的不同点"></a> L1 与 L2 的不同点</h3><ul><li>L1 正则化可以产生<strong>更稀疏的权值矩阵</strong>，可以用于<strong>特征选择</strong>，同时<strong>一定程度上防止过拟合</strong>；L2 正则化主要用于防止模型过拟合;</li><li><strong>L1 正则化适用于特征之间有关联的情况；L2 正则化适用于特征之间没有关联的情况;</strong></li></ul><h3 id="l1-能使得权值稀疏"><a class="markdownIt-Anchor" href="#l1-能使得权值稀疏"></a> L1 能使得权值稀疏</h3><p>使用 0范数来正则化参数，也可以使大部分参数为0，实现稀疏，但是 0范数的优化求解特性不如 1 范数好，所以通常用 1 范数来实现稀疏。</p><p>L1 相对于 L2 更能实现权值稀疏，是由他们本身的计算方式决定的，L1 是各元素绝对值之和，L2 是各元素平方和的根，在对不同参数进行惩罚时，L1 无论参数大小如何，对它们的惩罚值都相同，导致那些参数大小和惩罚值相等的参数，一减就变为0，而 L2 对参数的惩罚值是根据参数本身的大小来变化的，越小的参数惩罚值越小，越大的参数惩罚值越大，所以最终使得所有参数都接近 0，但不会等于 0。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习专业术语</title>
      <link href="/2023/10/10/AILearning/DL/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/"/>
      <url>/2023/10/10/AILearning/DL/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/</url>
      
        <content type="html"><![CDATA[<h4 id="激活函数activation-function"><a class="markdownIt-Anchor" href="#激活函数activation-function"></a> 激活函数（Activation Function）</h4><p>为了让神经网络能够学习复杂的决策边界（decision boundary），我们在其一些层应用一个非线性激活函数。最常用的函数包括 sigmoid、tanh、ReLU（Rectified Linear Unit 线性修正单元） 以及这些函数的变体。</p><h4 id="adadelta"><a class="markdownIt-Anchor" href="#adadelta"></a> Adadelta</h4><p>Adadelta 是一个基于梯度下降的学习算法，可以随时间调整适应每个参数的学习率。它是作为 Adagrad 的改进版提出的，它比超参数（hyperparameter）更敏感而且可能会太过严重地降低学习率。Adadelta 类似于 rmsprop，而且可被用来替代 vanilla SGD。</p><p>论文：Adadelta：一种自适应学习率方法（ADADELTA: An Adaptive Learning Rate Method）<br />技术博客：斯坦福 CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br />技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="adagrad"><a class="markdownIt-Anchor" href="#adagrad"></a> Adagrad</h4><p>Adagrad 是一种自适应学习率算法，能够随时间跟踪平方梯度并自动适应每个参数的学习率。它可被用来替代vanilla SGD (<a href="http://www.wildml.com/deep-learning-glossary/#sgd">http://www.wildml.com/deep-learning-glossary/#sgd</a>)；而且在稀疏数据上更是特别有用，在其中它可以将更高的学习率分配给更新不频繁的参数。</p><p>论文：用于在线学习和随机优化的自适应次梯度方法（Adaptive Subgradient Methods for Online Learning and Stochastic Optimization）<br />技术博客：斯坦福 CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br />技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="adam"><a class="markdownIt-Anchor" href="#adam"></a> Adam</h4><p>Adam 是一种类似于 rmsprop 的自适应学习率算法，但它的更新是通过使用梯度的第一和第二时刻的运行平均值（running average）直接估计的，而且还包括一个偏差校正项。</p><p>论文：Adam：一种随机优化方法（Adam: A Method for Stochastic Optimization）<br />技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="仿射层affine-layer"><a class="markdownIt-Anchor" href="#仿射层affine-layer"></a> 仿射层（Affine Layer）</h4><p>神经网络中的一个全连接层。仿射（Affine）的意思是前面一层中的每一个神经元都连接到当前层中的每一个神经元。在许多方面，这是神经网络的「标准」层。仿射层通常被加在卷积神经网络或循环神经网络做出最终预测前的输出的顶层。仿射层的一般形式为 y = f(Wx + b)，其中 x 是层输入，w 是参数，b 是一个偏差矢量，f 是一个非线性激活函数。</p><h4 id="注意机制attention-mechanism"><a class="markdownIt-Anchor" href="#注意机制attention-mechanism"></a> 注意机制（Attention Mechanism）</h4><p>注意机制是由人类视觉注意所启发的，是一种关注图像中特定部分的能力。注意机制可被整合到语言处理和图像识别的架构中以帮助网络学习在做出预测时应该「关注」什么。</p><p>技术博客：深度学习和自然语言处理中的注意和记忆（<a href="http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/%EF%BC%89">http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/）</a></p><h4 id="alexnet"><a class="markdownIt-Anchor" href="#alexnet"></a> Alexnet</h4><p>Alexnet 是一种卷积神经网络架构的名字，这种架构曾在 2012 年 ILSVRC 挑战赛中以巨大优势获胜，而且它还导致了人们对用于图像识别的卷积神经网络（CNN）的兴趣的复苏。它由 5 个卷积层组成。其中一些后面跟随着最大池化（max-pooling）层和带有最终 1000 条路径的 softmax (1000-way softmax)的 3个全连接层。Alexnet 被引入到了使用深度卷积神经网络的 ImageNet 分类中。</p><h4 id="自编码器autoencoder"><a class="markdownIt-Anchor" href="#自编码器autoencoder"></a> 自编码器（Autoencoder）</h4><p>自编码器是一种神经网络模型，它的目标是预测输入自身，这通常通过网络中某个地方的「瓶颈（bottleneck）」实现。通过引入瓶颈，我们迫使网络学习输入更低维度的表征，从而有效地将输入压缩成一个好的表征。自编码器和 PCA 等降维技术相关，但因为它们的非线性本质，它们可以学习更为复杂的映射。目前已有一些范围涵盖较广的自编码器存在，包括 降噪自编码器（Denoising Autoencoders）、变自编码器（Variational Autoencoders）和序列自编码器（Sequence Autoencoders）。</p><p>降噪自编码器论文：Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion<br />变自编码器论文：Auto-Encoding Variational Bayes<br />序列自编码器论文：Semi-supervised Sequence Learning</p><h4 id="平均池化average-pooling"><a class="markdownIt-Anchor" href="#平均池化average-pooling"></a> 平均池化（Average-Pooling）</h4><p>平均池化是一种在卷积神经网络中用于图像识别的池化（Pooling）技术。它的工作原理是在特征的局部区域上滑动窗口，比如像素，然后再取窗口中所有值的平均。它将输入表征压缩成一种更低维度的表征。</p><h4 id="反向传播backpropagation"><a class="markdownIt-Anchor" href="#反向传播backpropagation"></a> 反向传播（Backpropagation）</h4><p>反向传播是一种在神经网络中用来有效地计算梯度的算法，或更一般而言，是一种前馈计算图（feedforward computational graph）。其可以归结成从网络输出开始应用分化的链式法则，然后向后传播梯度。反向传播的第一个应用可以追溯到 1960 年代的 Vapnik 等人，但论文 Learning representations by back-propagating errors常常被作为引用源。</p><p>技术博客：计算图上的微积分学：反向传播（<a href="http://colah.github.io/posts/2015-08-Backprop/%EF%BC%89">http://colah.github.io/posts/2015-08-Backprop/）</a></p><h4 id="通过时间的反向传播bpttbackpropagation-through-time"><a class="markdownIt-Anchor" href="#通过时间的反向传播bpttbackpropagation-through-time"></a> 通过时间的反向传播（BPTT：Backpropagation Through Time）</h4><p>通过时间的反向传播是应用于循环神经网络（RNN）的反向传播算法。BPTT 可被看作是应用于 RNN 的标准反向传播算法，其中的每一个时间步骤（time step）都代表一个计算层，而且它的参数是跨计算层共享的。因为 RNN 在所有的时间步骤中都共享了同样的参数，一个时间步骤的错误必然能「通过时间」反向到之前所有的时间步骤，该算法也因而得名。当处理长序列（数百个输入）时，为降低计算成本常常使用一种删节版的 BPTT。删节的 BPTT 会在固定数量的步骤之后停止反向传播错误。</p><p>论文：Backpropagation Through Time: What It Does and How to Do It</p><h4 id="分批标准化bnbatch-normalization"><a class="markdownIt-Anchor" href="#分批标准化bnbatch-normalization"></a> 分批标准化（BN：Batch Normalization）</h4><p>分批标准化是一种按小批量的方式标准化层输入的技术。它能加速训练过程，允许使用更高的学习率，还可用作规范器（regularizer）。人们发现，分批标准化在卷积和前馈神经网络中应用时非常高效，但尚未被成功应用到循环神经网络上。</p><p>论文：分批标准化：通过减少内部协变量位移（Covariate Shift）加速深度网络训练（Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift）<br />论文：使用分批标准化的循环神经网络（Batch Normalized Recurrent Neural Networks）</p><h4 id="双向循环神经网络bidirectional-rnn"><a class="markdownIt-Anchor" href="#双向循环神经网络bidirectional-rnn"></a> 双向循环神经网络（Bidirectional RNN）</h4><p>双向循环神经网络是一类包含两个方向不同的 RNN 的神经网络。其中的前向 RNN 从起点向终点读取输入序列，而反向 RNN 则从终点向起点读取。这两个 RNN 互相彼此堆叠，它们的状态通常通过附加两个矢量的方式进行组合。双向 RNN 常被用在自然语言问题中，因为在自然语言中我们需要同时考虑话语的前后上下文以做出预测。</p><p>论文：双向循环神经网络（Bidirectional Recurrent Neural Networks）</p><h4 id="caffe"><a class="markdownIt-Anchor" href="#caffe"></a> Caffe</h4><p>Caffe 是由伯克利大学视觉和学习中心开发的一种深度学习框架。在视觉任务和卷积神经网络模型中，Caffe 格外受欢迎且性能优异。</p><h4 id="分类交叉熵损失categorical-cross-entropy-loss"><a class="markdownIt-Anchor" href="#分类交叉熵损失categorical-cross-entropy-loss"></a> 分类交叉熵损失（Categorical Cross-Entropy Loss）</h4><p>分类交叉熵损失也被称为负对数似然（negative log likelihood）。这是一种用于解决分类问题的流行的损失函数，可用于测量两种概率分布（通常是真实标签和预测标签）之间的相似性。它可用 L = -sum(y * log(y_prediction)) 表示，其中 y 是真实标签的概率分布（通常是一个one-hot vector），y_prediction 是预测标签的概率分布，通常来自于一个 softmax。</p><h4 id="信道channel"><a class="markdownIt-Anchor" href="#信道channel"></a> 信道（Channel）</h4><p>深度学习模型的输入数据可以有多个信道。图像就是个典型的例子，它有红、绿和蓝三个颜色信道。一个图像可以被表示成一个三维的张量（Tensor），其中的维度对应于信道、高度和宽度。自然语言数据也可以有多个信道，比如在不同类型的嵌入（embedding）形式中。</p><h4 id="卷积神经网络cnnconvnetconvolutional-neural-network"><a class="markdownIt-Anchor" href="#卷积神经网络cnnconvnetconvolutional-neural-network"></a> 卷积神经网络（CNN/ConvNet：Convolutional Neural Network）</h4><p>CNN 使用卷积连接从输入的局部区域中提取的特征。大部分 CNN 都包含了卷积层、池化层和仿射层的组合。CNN 尤其凭借其在视觉识别任务的卓越性能表现而获得了普及，它已经在该领域保持了好几年的领先。</p><p>技术博客：斯坦福CS231n类——用于视觉识别的卷积神经网络（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br />技术博客：理解用于自然语言处理的卷积神经网络（<a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/%EF%BC%89">http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/）</a></p><h4 id="深度信念网络dbndeep-belief-network"><a class="markdownIt-Anchor" href="#深度信念网络dbndeep-belief-network"></a> 深度信念网络（DBN：Deep Belief Network）</h4><p>DBN 是一类以无监督的方式学习数据的分层表征的概率图形模型。DBN 由多个隐藏层组成，这些隐藏层的每一对连续层之间的神经元是相互连接的。DBN 通过彼此堆叠多个 RBN（限制波尔兹曼机）并一个接一个地训练而创建。</p><p>论文：深度信念网络的一种快速学习算法（A fast learning algorithm for deep belief nets）</p><h4 id="deep-dream"><a class="markdownIt-Anchor" href="#deep-dream"></a> Deep Dream</h4><p>这是谷歌发明的一种试图用来提炼深度卷积神经网络获取的知识的技术。这种技术可以生成新的图像或转换已有的图片从而给它们一种幻梦般的感觉，尤其是递归地应用时。</p><p>代码：Github 上的 Deep Dream（<a href="https://github.com/google/deepdream%EF%BC%89">https://github.com/google/deepdream）</a><br />技术博客：Inceptionism：向神经网络掘进更深（<a href="https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html%EF%BC%89">https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html）</a></p><h4 id="dropout"><a class="markdownIt-Anchor" href="#dropout"></a> Dropout</h4><p>Dropout(随机失活) 是一种用于神经网络防止过拟合的正则化技术。它通过在每次训练迭代中随机地设置神经元中的一小部分为 0 来阻止神经元共适应（co-adapting），Dropout 可以通过多种方式进行解读，比如从不同网络的指数数字中随机取样。Dropout 层首先通过它们在卷积神经网络中的应用而得到普及，但自那以后也被应用到了其它层上，包括输入嵌入或循环网络。</p><p>通俗讲随机失活（Dropout）在训练的过程中以一定比例随机失活神经元来达到提高模型泛化能力的效果。</p><p>论文：Dropout: 一种防止神经网络过拟合的简单方法（Dropout: A Simple Way to Prevent Neural Networks from Overfitting）<br />论文：循环神经网络正则化（Recurrent Neural Network Regularization）</p><h4 id="嵌入embedding"><a class="markdownIt-Anchor" href="#嵌入embedding"></a> 嵌入（Embedding）</h4><p>一个嵌入映射到一个输入表征，比如一个词或一句话映射到一个矢量。一种流行的嵌入是词语嵌入（word embedding，国内常用的说法是：词向量），如 word2vec 或 GloVe。我们也可以嵌入句子、段落或图像。比如说，通过将图像和他们的文本描述映射到一个共同的嵌入空间中并最小化它们之间的距离，我们可以将标签和图像进行匹配。嵌入可以被明确地学习到，比如在 word2vec 中；嵌入也可作为监督任务的一部分例如情感分析（Sentiment Analysis）。通常一个网络的输入层是通过预先训练的嵌入进行初始化，然后再根据当前任务进行微调（fine-tuned）。</p><h4 id="梯度爆炸问题exploding-gradient-problem"><a class="markdownIt-Anchor" href="#梯度爆炸问题exploding-gradient-problem"></a> 梯度爆炸问题（Exploding Gradient Problem）</h4><p>梯度爆炸问题是梯度消失问题（Vanishing Gradient Problem）的对立面。在深度神经网络中，梯度可能会在反向传播过程中爆炸，导致数字溢出。解决梯度爆炸的一个常见技术是执行梯度裁剪（Gradient Clipping）。</p><p>论文：训练循环神经网络的困难之处（On the difficulty of training Recurrent Neural Networks）</p><h4 id="微调fine-tuning"><a class="markdownIt-Anchor" href="#微调fine-tuning"></a> 微调（Fine-Tuning）</h4><p>Fine-Tuning 这种技术是指使用来自另一个任务（例如一个无监督训练网络）的参数初始化网络，然后再基于当前任务更新这些参数。比如，自然语言处理架构通常使用 word2vec 这样的预训练的词向量（word embeddings），然后这些词向量会在训练过程中基于特定的任务（如情感分析）进行更新。</p><h4 id="梯度裁剪gradient-clipping"><a class="markdownIt-Anchor" href="#梯度裁剪gradient-clipping"></a> 梯度裁剪（Gradient Clipping）</h4><p>梯度裁剪是一种在非常深度的网络（通常是循环神经网络）中用于防止梯度爆炸（exploding gradient）的技术。执行梯度裁剪的方法有很多，但常见的一种是当参数矢量的 L2 范数（L2 norm）超过一个特定阈值时对参数矢量的梯度进行标准化，这个特定阈值根据函数：新梯度=梯度*阈值/L2范数（梯度）{new_gradients = gradients * threshold / l2_norm(gradients)}确定。</p><p>论文：训练循环神经网络的困难之处（On the difficulty of training Recurrent Neural Networks）</p><h4 id="glove"><a class="markdownIt-Anchor" href="#glove"></a> GloVe</h4><p>Glove 是一种为话语获取矢量表征（嵌入）的无监督学习算法。GloVe 的使用目的和 word2vec 一样，但 GloVe 具有不同的矢量表征，因为它是在共现（co-occurrence）统计数据上训练的。</p><p>论文：GloVe：用于词汇表征（Word Representation）的全局矢量（Global Vector）（GloVe: Global Vectors for Word Representation ）</p><h4 id="googlelenet"><a class="markdownIt-Anchor" href="#googlelenet"></a> GoogleLeNet</h4><p>GoogleLeNet 是曾赢得了 2014 年 ILSVRC 挑战赛的一种卷积神经网络架构。这种网络使用 Inception 模块（Inception Module）以减少参数和提高网络中计算资源的利用率。</p><p>论文：使用卷积获得更深（Going Deeper with Convolutions）</p><h4 id="gru"><a class="markdownIt-Anchor" href="#gru"></a> GRU</h4><p>GRU（Gated Recurrent Unit：门控循环单元）是一种 LSTM 单元的简化版本，拥有更少的参数。和 LSTM 细胞（LSTM cell）一样，它使用门控机制，通过防止梯度消失问题（vanishing gradient problem）让循环神经网络可以有效学习长程依赖（long-range dependency）。GRU 包含一个复位和更新门，它们可以根据当前时间步骤的新值决定旧记忆中哪些部分需要保留或更新。</p><p>论文：为统计机器翻译使用 RNN 编码器-解码器学习短语表征（Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation）<br />技术博客：循环神经网络教程，第 4 部分：用 Python 和 Theano 实现 GRU/LSTM RNN（<a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/%EF%BC%89">http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/）</a></p><h4 id="ground-truth"><a class="markdownIt-Anchor" href="#ground-truth"></a> ground truth</h4><p>在机器学习中， ground truth表示监督学习的训练集的分类准确性，用于证明或者推翻某个假设。有监督的机器学习会对训练数据打标记，试想一下如果训练标记错误，那么将会对测试数据的预测产生影响，因此这里将那些正确打标记的数据成为ground truth。</p><h4 id="highway-layer"><a class="markdownIt-Anchor" href="#highway-layer"></a> Highway Layer</h4><p>Highway Layer　是使用门控机制控制通过层的信息流的一种神经网络层。堆叠多个 Highway Layer 层可让训练非常深的网络成为可能。Highway Layer 的工作原理是通过学习一个选择输入的哪部分通过和哪部分通过一个变换函数（如标准的仿射层）的门控函数来进行学习。Highway Layer 的基本公式是 T * h(x) + (1 - T) * x；其中 T 是学习过的门控函数，取值在 0 到 1 之间；h(x) 是一个任意的输入变换，x 是输入。注意所有这些都必须具有相同的大小。</p><p>论文：Highway Networks</p><h4 id="icml"><a class="markdownIt-Anchor" href="#icml"></a> ICML</h4><p>即国际机器学习大会（International Conference for Machine Learning），一个顶级的机器学习会议。</p><h4 id="ilsvrc"><a class="markdownIt-Anchor" href="#ilsvrc"></a> ILSVRC</h4><p>即 ImageNet 大型视觉识别挑战赛（ImageNet Large Scale Visual Recognition Challenge），该比赛用于评估大规模对象检测和图像分类的算法。它是计算机视觉领域最受欢迎的学术挑战赛。过去几年中，深度学习让错误率出现了显著下降，从 30% 降到了不到 5%，在许多分类任务中击败了人类。</p><h4 id="inception模块inception-module"><a class="markdownIt-Anchor" href="#inception模块inception-module"></a> Inception模块（Inception Module）</h4><p>Inception模块被用在卷积神经网络中，通过堆叠 1×1 卷积的降维（dimensionality reduction）带来更高效的计算和更深度的网络。</p><p>论文：使用卷积获得更深（Going Deeper with Convolutions）</p><h4 id="keras"><a class="markdownIt-Anchor" href="#keras"></a> Keras</h4><p>Kears 是一个基于 Python 的深度学习库，其中包括许多用于深度神经网络的高层次构建模块。它可以运行在 TensorFlow 或 Theano 上。</p><h4 id="lstm"><a class="markdownIt-Anchor" href="#lstm"></a> LSTM</h4><p>长短期记忆（Long Short-Term Memory）网络通过使用内存门控机制防止循环神经网络（RNN）中的梯度消失问题（vanishing gradient problem）。使用 LSTM 单元计算 RNN 中的隐藏状态可以帮助该网络有效地传播梯度和学习长程依赖（long-range dependency）。</p><p>论文：长短期记忆（LONG SHORT-TERM MEMORY）<br />技术博客：理解 LSTM 网络（<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/%EF%BC%89">http://colah.github.io/posts/2015-08-Understanding-LSTMs/）</a><br />技术博客：循环神经网络教程，第 4 部分：用 Python 和 Theano 实现 GRU/LSTM RNN（<a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/%EF%BC%89">http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/）</a></p><h4 id="最大池化max-pooling"><a class="markdownIt-Anchor" href="#最大池化max-pooling"></a> 最大池化（Max-Pooling）</h4><p>池化（Pooling）操作通常被用在卷积神经网络中。一个最大池化层从一块特征中选取最大值。和卷积层一样，池化层也是通过窗口（块）大小和步幅尺寸进行参数化。比如，我们可能在一个 10×10 特征矩阵上以 2 的步幅滑动一个 2×2 的窗口，然后选取每个窗口的 4 个值中的最大值，得到一个 5×5 特征矩阵。池化层通过只保留最突出的信息来减少表征的维度；在这个图像输入的例子中，它们为转译提供了基本的不变性（即使图像偏移了几个像素，仍可选出同样的最大值）。池化层通常被安插在连续卷积层之间。</p><h4 id="mnist"><a class="markdownIt-Anchor" href="#mnist"></a> MNIST</h4><p>MNIST数据集可能是最常用的一个图像识别数据集。它包含 60,000 个手写数字的训练样本和 10,000 个测试样本。每一张图像的尺寸为 28×28像素。目前最先进的模型通常能在该测试集中达到 99.5% 或更高的准确度。</p><h4 id="动量momentum"><a class="markdownIt-Anchor" href="#动量momentum"></a> 动量（Momentum）</h4><p>动量是梯度下降算法（Gradient Descent Algorithm）的扩展，可以加速和阻抑参数更新。在实际应用中，在梯度下降更新中包含一个动量项可在深度网络中得到更好的收敛速度（convergence rate）。</p><p>论文：通过反向传播（back-propagating error）错误学习表征</p><h4 id="多层感知器mlpmultilayer-perceptron"><a class="markdownIt-Anchor" href="#多层感知器mlpmultilayer-perceptron"></a> 多层感知器（MLP：Multilayer Perceptron）</h4><p>多层感知器是一种带有多个全连接层的前馈神经网络，这些全连接层使用非线性激活函数（activation function）处理非线性可分的数据。MLP 是多层神经网络或有两层以上的深度神经网络的最基本形式。</p><p>负对数似然（NLL：Negative Log Likelihood）</p><p>参见分类交叉熵损失（Categorical Cross-Entropy Loss）。</p><h4 id="神经网络机器翻译nmtneural-machine-translation"><a class="markdownIt-Anchor" href="#神经网络机器翻译nmtneural-machine-translation"></a> 神经网络机器翻译（NMT：Neural Machine Translation）</h4><p>NMT 系统使用神经网络实现语言（如英语和法语）之间的翻译。NMT 系统可以使用双语语料库进行端到端的训练，这有别于需要手工打造特征和开发的传统机器翻译系统。NMT 系统通常使用编码器和解码器循环神经网络实现，它可以分别编码源句和生成目标句。</p><p>论文：使用神经网络的序列到序列学习（Sequence to Sequence Learning with Neural Networks）<br />论文：为统计机器翻译使用 RNN 编码器-解码器学习短语表征（Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation）</p><h4 id="神经图灵机ntmneural-turing-machine"><a class="markdownIt-Anchor" href="#神经图灵机ntmneural-turing-machine"></a> 神经图灵机（NTM：Neural Turing Machine）</h4><p>NTM 是可以从案例中推导简单算法的神经网络架构。比如，NTM 可以通过案例的输入和输出学习排序算法。NTM 通常学习记忆和注意机制的某些形式以处理程序执行过程中的状态。</p><p>论文：神经图灵机（Neural Turing Machines）</p><p>非线性（Nonlinearity）</p><p>参见激活函数（Activation Function）。</p><h4 id="噪音对比估计ncenoise-contrastive-estimation"><a class="markdownIt-Anchor" href="#噪音对比估计ncenoise-contrastive-estimation"></a> 噪音对比估计（NCE：noise-contrastive estimation）</h4><p>噪音对比估计是一种通常被用于训练带有大输出词汇的分类器的采样损失（sampling loss）。在大量的可能的类上计算 softmax 是异常昂贵的。使用 NCE，我们可以将问题降低成二元分类问题，这可以通过训练分类器区别对待取样和「真实」分布以及人工生成的噪声分布来实现。</p><p>论文：噪音对比估计：一种用于非标准化统计模型的新估计原理（Noise-contrastive estimation: A new estimation principle for unnormalized statistical models ）<br />论文：使用噪音对比估计有效地学习词向量（Learning word embeddings efficiently with noise-contrastive estimation）</p><h4 id="池化"><a class="markdownIt-Anchor" href="#池化"></a> 池化</h4><p>参见最大池化（Max-Pooling）或平均池化（Average-Pooling）。</p><h4 id="受限玻尔兹曼机rbnrestricted-boltzmann-machine"><a class="markdownIt-Anchor" href="#受限玻尔兹曼机rbnrestricted-boltzmann-machine"></a> 受限玻尔兹曼机（RBN：Restricted Boltzmann Machine）</h4><p>RBN 是一种可被解释为一个随机人工神经网络的概率图形模型。RBN 以无监督的形式学习数据的表征。RBN 由可见层和隐藏层以及每一个这些层中的二元神经元的连接所构成。RBN 可以使用对比散度（contrastive divergence）进行有效的训练，这是梯度下降的一种近似。</p><p>第六章：动态系统中的信息处理：和谐理论基础<br />论文：受限玻尔兹曼机简介（An Introduction to Restricted Boltzmann Machines）</p><h4 id="循环神经网络rnnrecurrent-neural-network"><a class="markdownIt-Anchor" href="#循环神经网络rnnrecurrent-neural-network"></a> 循环神经网络（RNN：Recurrent Neural Network）</h4><p>RNN 模型通过隐藏状态（或称记忆）连续进行相互作用。它可以使用最多 N 个输入，并产生最多 N 个输出。比如，一个输入序列可能是一个句子，其输出为每个单词的词性标注（part-of-speech tag）（N 到 N）；一个输入可能是一个句子，其输出为该句子的情感分类（N 到 1）；一个输入可能是单个图像，其输出为描述该图像所对应一系列词语（1 到 N）。在每一个时间步骤中，RNN 会基于当前输入和之前的隐藏状态计算新的隐藏状态「记忆」。其中「循环（recurrent）」这个术语来自这个事实：在每一步中都是用了同样的参数，该网络根据不同的输入执行同样的计算。</p><p>技术博客：了解 LSTM 网络（<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/%EF%BC%89">http://colah.github.io/posts/2015-08-Understanding-LSTMs/）</a><br />技术博客：循环神经网络教程第1部分——介绍 RNN （<a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/%EF%BC%89">http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/）</a></p><h4 id="递归神经网络recursive-neural-network"><a class="markdownIt-Anchor" href="#递归神经网络recursive-neural-network"></a> 递归神经网络（Recursive Neural Network）</h4><p>递归神经网络是循环神经网络的树状结构的一种泛化（generalization）。每一次递归都使用相同的权重。就像 RNN 一样，递归神经网络可以使用向后传播（backpropagation）进行端到端的训练。尽管可以学习树结构以将其用作优化问题的一部分，但递归神经网络通常被用在已有预定义结构的问题中，如自然语言处理的解析树中。</p><p>论文：使用递归神经网络解析自然场景和自然语言（Parsing Natural Scenes and Natural Language with Recursive Neural Networks ）</p><h4 id="relu"><a class="markdownIt-Anchor" href="#relu"></a> ReLU</h4><p>即线性修正单元（Rectified Linear Unit）。ReLU 常在深度神经网络中被用作激活函数。它们的定义是 f(x) = max(0, x) 。ReLU 相对于 tanh 等函数的优势包括它们往往很稀疏（它们的活化可以很容易设置为 0），而且它们受到梯度消失问题的影响也更小。ReLU 主要被用在卷积神经网络中用作激活函数。ReLU 存在几种变体，如Leaky ReLUs、Parametric ReLU (PReLU) 或更为流畅的 softplus近似。</p><p>论文：深入研究修正器（Rectifiers）：在 ImageNet 分类上超越人类水平的性能（Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification）<br />论文：修正非线性改进神经网络声学模型（Rectifier Nonlinearities Improve Neural Network Acoustic Models ）<br />论文：线性修正单元改进受限玻尔兹曼机（Rectified Linear Units Improve Restricted Boltzmann Machines ）</p><h4 id="残差网络resnet"><a class="markdownIt-Anchor" href="#残差网络resnet"></a> 残差网络（ResNet）</h4><p>深度残差网络（Deep Residual Network）赢得了 2015 年的 ILSVRC 挑战赛。这些网络的工作方式是引入跨层堆栈的快捷连接，让优化器可以学习更「容易」的残差映射（residual mapping）而非更为复杂的原映射（original mapping）。这些快捷连接和 Highway Layer 类似，但它们与数据无关且不会引入额外的参数或训练复杂度。ResNet 在 ImageNet 测试集中实现了 3.57% 的错误率。</p><p>论文：用于图像识别的深度残差网络（Deep Residual Learning for Image Recognition）</p><h4 id="rmsprop"><a class="markdownIt-Anchor" href="#rmsprop"></a> RMSProp</h4><p>RMSProp 是一种基于梯度的优化算法。它与 Adagrad 类似，但引入了一个额外的衰减项抵消 Adagrad 在学习率上的快速下降。</p><p>PPT：用于机器学习的神经网络 讲座6a<br />技术博客：斯坦福CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br />技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="序列到序列seq2seq"><a class="markdownIt-Anchor" href="#序列到序列seq2seq"></a> 序列到序列（Seq2Seq）</h4><p>序列到序列（Sequence-to-Sequence）模型读取一个序列（如一个句子）作为输入，然后产生另一个序列作为输出。它和标准的 RNN 不同；在标准的 RNN 中，输入序列会在网络开始产生任何输出之前被完整地读取。通常而言，Seq2Seq 通过两个分别作为编码器和解码器的 RNN 实现。神经网络机器翻译是一类典型的 Seq2Seq 模型。</p><p>论文：使用神经网络的序列到序列学习（Sequence to Sequence Learning with Neural Networks）</p><h4 id="随机梯度下降sgdstochastic-gradient-descent"><a class="markdownIt-Anchor" href="#随机梯度下降sgdstochastic-gradient-descent"></a> 随机梯度下降（SGD：Stochastic Gradient Descent）</h4><p>随机梯度下降是一种被用在训练阶段学习网络参数的基于梯度的优化算法。梯度通常使用反向传播算法计算。在实际应用中，人们使用微小批量版本的 SGD，其中的参数更新基于批案例而非单个案例进行执行，这能增加计算效率。vanilla SGD 存在许多扩展，包括动量（Momentum）、Adagrad、rmsprop、Adadelta 或 Adam。</p><p>论文：用于在线学习和随机优化的自适应次梯度方法（Adaptive Subgradient Methods for Online Learning and Stochastic Optimization）<br />技术博客：斯坦福CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br />技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="softmax"><a class="markdownIt-Anchor" href="#softmax"></a> Softmax</h4><p>Softmax 函数通常被用于将原始分数（raw score）的矢量转换成用于分类的神经网络的输出层上的类概率（class probability）。它通过对归一化常数（normalization constant）进行指数化和相除运算而对分数进行规范化。如果我们正在处理大量的类，例如机器翻译中的大量词汇，计算归一化常数是很昂贵的。有许多种可以让计算更高效的替代选择，包括分层 Softmax（Hierarchical Softmax）或使用基于取样的损失函数，如 NCE。</p><h4 id="tensorflow"><a class="markdownIt-Anchor" href="#tensorflow"></a> TensorFlow</h4><p>TensorFlow是一个开源 C ++ / Python 软件库，用于使用数据流图的数值计算，尤其是深度神经网络。它是由谷歌创建的。在设计方面，它最类似于 Theano，但比 Caffe 或 Keras 更低级。</p><h4 id="theano"><a class="markdownIt-Anchor" href="#theano"></a> Theano</h4><p>Theano 是一个让你可以定义、优化和评估数学表达式的 Python 库。它包含许多用于深度神经网络的构造模块。Theano 是类似于 TensorFlow 的低级别库。更高级别的库包括Keras 和 Caffe。</p><h4 id="梯度消失问题vanishing-gradient-problem"><a class="markdownIt-Anchor" href="#梯度消失问题vanishing-gradient-problem"></a> 梯度消失问题（Vanishing Gradient Problem）</h4><p>梯度消失问题出现在使用梯度很小（在 0 到 1 的范围内）的激活函数的非常深的神经网络中，通常是循环神经网络。因为这些小梯度会在反向传播中相乘，它们往往在这些层中传播时「消失」，从而让网络无法学习长程依赖。解决这一问题的常用方法是使用 ReLU 这样的不受小梯度影响的激活函数，或使用明确针对消失梯度问题的架构，如LSTM。这个问题的反面被称为梯度爆炸问题（exploding gradient problem）。</p><p>论文：训练循环神经网络的困难之处（On the difficulty of training Recurrent Neural Networks）</p><h4 id="vgg"><a class="markdownIt-Anchor" href="#vgg"></a> VGG</h4><p>VGG 是在 2014 年 ImageNet 定位和分类比赛中分别斩获第一和第二位置的卷积神经网络模型。这个 VGG 模型包含 16-19 个权重层，并使用了大小为 3×3 和 1×1 的小型卷积过滤器。</p><p>论文：用于大规模图像识别的非常深度的卷积网络（Very Deep Convolutional Networks for Large-Scale Image Recognition）</p><h4 id="word2vec"><a class="markdownIt-Anchor" href="#word2vec"></a> word2vec</h4><p>word2vec 是一种试图通过预测文档中话语的上下文来学习词向量（word embedding）的算法和工具 (<a href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a>)。最终得到的词矢量（word vector）有一些有趣的性质，例如vector(‘queen’) ~= vector(‘king’) - vector(‘man’) + vector(‘woman’) （女王~=国王-男人+女人）。两个不同的目标函数可以用来学习这些嵌入：Skip-Gram 目标函数尝试预测一个词的上下文，CBOW 目标函数则尝试从词上下文预测这个词。</p><p>论文：向量空间中词汇表征的有效评估（Efficient Estimation of Word Representations in Vector Space）<br />论文：分布式词汇和短语表征以及他们的组合性（Distributed Representations of Words and Phrases and their Compositionality）<br />论文：解释 word2vec 参数学习（word2vec Parameter Learning Explained）</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Terms </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>激活函数</title>
      <link href="/2023/10/10/AILearning/DL/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0_/"/>
      <url>/2023/10/10/AILearning/DL/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0_/</url>
      
        <content type="html"><![CDATA[<blockquote><p>激活函数对神经网络的重要性自不必多言，机器之心也曾发布过一些相关的介绍文章，比如《<a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650732724%26idx%3D4%26sn%3D5230b8bb1811cda38ab97afb417d1613%26chksm%3D871b3ccab06cb5dcdf0bdfadcc7ae85d8ae95588bed0b884a55ba50b76d541771104675fbb3e%26scene%3D21%23wechat_redirect">一文概览深度学习中的激活函数</a>》。本文同样关注的是激活函数。来自丹麦技术大学的 Casper Hansen 通过公式、图表和代码实验介绍了 sigmoid、ReLU、ELU 以及更新的 Leaky ReLU、SELU、GELU 这些激活函数，并比较了它们的优势和短板。</p></blockquote><p>选自mlfromscratch，作者：Casper Hansen，机器之心编译，参与：熊猫、杜伟。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036753.webp" alt="动图" /></p><p>在计算每一层的激活值时，我们要用到激活函数，之后才能确定这些激活值究竟是多少。根据每一层前面的激活、权重和偏置，我们要为下一层的每个激活计算一个值。但在将该值发送给下一层之前，我们要使用一个激活函数对这个输出进行缩放。本文将介绍不同的激活函数。</p><p><strong>目录</strong></p><p>1.概述</p><p>2.sigmoid 函数是什么？</p><p>3.梯度问题：反向传播</p><ul><li>梯度消失问题</li><li>梯度爆炸问题</li><li>梯度爆炸的极端案例</li><li>避免梯度爆炸：梯度裁剪/范数</li></ul><p>4.整流线性单元（ReLU）</p><ul><li>死亡 ReLU：优势和缺点</li></ul><p>5.指数线性单元（ELU）</p><p>6.渗漏型整流线性单元（Leaky ReLU）</p><p>7.扩展型指数线性单元（SELU）</p><ul><li>SELU：归一化的特例</li><li>权重初始化+dropout</li></ul><p>8.高斯误差线性单元（GELU）</p><p>9.代码：深度神经网络的超参数搜索</p><p>10.扩展阅读：书籍与论文</p><h2 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> <strong>概述</strong></h2><p>激活函数是神经网络中一个至关重要的部分。在这篇长文中，我将全面介绍六种不同的激活函数，并阐述它们各自的优缺点。我会给出激活函数的方程和微分方程，还会给出它们的图示。本文的目标是以简单的术语解释这些方程以及图。我会介绍梯度消失和爆炸问题；对于后者，我将按照 Nielsen 提出的那个很赞的示例来解释梯度爆炸的原因。最后，我还会提供一些代码让你可以自己在 Jupyter Notebook 中运行。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036751.jpg" alt="动图封面" /></p><p>我会在 MNIST 数据集上进行一些小型代码实验，为每个激活函数都获得一张损失和准确度图。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036756.jpg" alt="img" /></p><h2 id="sigmoid-函数是什么"><a class="markdownIt-Anchor" href="#sigmoid-函数是什么"></a> <strong>sigmoid 函数是什么？</strong></h2><p>sigmoid 函数是一个 logistic 函数，意思就是说：不管输入是什么，得到的输出都在 0 到 1 之间。也就是说，你输入的每个神经元、节点或激活都会被缩放为一个介于 0 到 1 之间的值。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036760.jpg" alt="img" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036761.jpg" alt="img" />sigmoid 函数图示。</p><p>sigmoid 这样的函数常被称为非线性函数，因为我们不能用线性的项来描述它。很多激活函数都是非线性或者线性和非线性的组合（有可能函数的一部分是线性的，但这种情况很少见）。这基本上没什么问题，但值恰好为 0 或 1 的时候除外（有时候确实会发生这种情况）。为什么这会有问题？这个问题与反向传播有关（有关反向传播的介绍请参阅我的前一篇文章）。在反向传播中，我们要计算每个权重的梯度，即针对每个权重的小更新。这样做的目的是优化整个网络中激活值的输出，使其能在输出层得到更好的结果，进而实现对成本函数的优化。在反向传播过程中，我们必须计算每个权重影响成本函数（cost function）的比例，具体做法是计算成本函数相对于每个权重的偏导数。假设我们不定义单个的权重，而是将最后一层 L 中的所有权重 w 定义为 w^L，则它们的导数为:</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036764.jpg" alt="img" /></p><p>注意，当求偏导数时，我们要找到 ∂a^L 的方程，然后仅微分 ∂z^L，其余部分保持不变。我们用撇号「’」来表示任意函数的导数。当计算中间项 ∂a<sup>L/∂z</sup>L 的偏导数时，我们有：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036048.jpg" alt="img" /></p><p>则 sigmoid 函数的导数就为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036059.jpg" alt="img" /></p><p>当我们向这个 sigmoid 函数输入一个很大的 x 值（正或负）时，我们得到几乎为 0 的 y 值——也就是说，当我们输入 w×a+b 时，我们可能得到一个接近于 0 的值。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036074.jpg" alt="img" />sigmoid 函数的导数图示。</p><p>当 x 是一个很大的值（正或负）时，我们本质上就是用一个几乎为 0 的值来乘这个偏导数的其余部分。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036086.jpg" alt="img" /></p><p>如果有太多的权重都有这样很大的值，那么我们根本就没法得到可以调整权重的网络，这可是个大问题。如果我们不调整这些权重，那么网络就只有细微的更新，这样算法就不能随时间给网络带来多少改善。对于针对一个权重的偏导数的每个计算，我们都将其放入一个梯度向量中，而且我们将使用这个梯度向量来更新神经网络。可以想象，如果该梯度向量的所有值都接近 0，那么我们根本就无法真正更新任何东西。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036436.png" alt="img" /></p><p>这里描述的就是梯度消失问题。这个问题使得 sigmoid 函数在神经网络中并不实用，我们应该使用后面介绍的其它激活函数。</p><h2 id="梯度问题"><a class="markdownIt-Anchor" href="#梯度问题"></a> <strong>梯度问题</strong></h2><p><strong>梯度消失问题</strong></p><p>我的前一篇文章说过，如果我们想更新特定的权重，则更新规则为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036602.png" alt="img" /></p><p>但如果偏导数 ∂C/∂w^(L) 很小，如同消失了一般，又该如何呢？这时我们就遇到了梯度消失问题，其中许多权重和偏置只能收到非常小的更新。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036999.jpg" alt="img" /></p><p>可以看到，如果权重的值为 0.2，则当出现梯度消失问题时，这个值基本不会变化。因为这个权重分别连接了第一层和第二层的首个神经元，所以我们可以用</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036024.png" alt="img" /></p><p>的表示方式将其记为</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036037.png" alt="img" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036050.png" alt="img" /></p><p>假设这个权重的值为 0.2，给定一个学习率（具体多少不重要，这里使用了 0.5），则新的权重为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036060.png" alt="img" /></p><p>这个权重原来的值为 0.2，现在更新为了 0.199999978。很明显，这是有问题的：梯度很小，如同消失了一样，使得神经网络中的权重几乎没有更新。这会导致网络中的节点离其最优值相去甚远。这个问题会严重妨碍神经网络的学习。人们已经观察到，如果不同层的学习速度不同，那么这个问题还会变得更加严重。层以不同的速度学习，前面几层总是会根据学习率而变得更差。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036072.jpg" alt="img" />出自 Nielsen 的书《Neural Networks and Deep Learning》。</p><p>在这个示例中，隐藏层 4 的学习速度最快，因为其成本函数仅取决于连接到隐藏层 4 的权重变化。我们看看隐藏层 1；这里的成本函数取决于连接隐藏层 1 与隐藏层 2、3、4 的权重变化。如果你看过了我前一篇文章中关于反向传播的内容，那么你可能知道网络中更前面的层会复用后面层的计算。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036517.jpg" alt="img" /></p><p>同时，如前面介绍的那样，最后一层仅取决于计算偏导时出现的一组变化：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036680.jpg" alt="img" /></p><p>最终，这就是个大问题了，因为现在权重层的学习速度不同。这意味着网络中更后面的层几乎肯定会被网络中更前面的层受到更多优化。而且问题还在于反向传播算法不知道应该向哪个方向传递权重来优化成本函数。</p><p><strong>梯度爆炸问题</strong></p><p>梯度爆炸问题本质上就是梯度消失问题的反面。研究表明，这样的问题是可能出现的，这时权重处于「爆炸」状态，即它们的值快速增长。</p><p>我们将遵照以下示例来进行说明：</p><ul><li><a href="https://link.zhihu.com/?target=http%3A//neuralnetworksanddeeplearning.com/chap5.html%23what">http://neuralnetworksanddeeplearning.com/chap5.html#what</a>’s_causing_the_vanishing_gradient_problem_unstable_gradients_in_deep_neural_nets</li></ul><p>注意，这个示例也可用于展示梯度消失问题，而我是从更概念的角度选择了它，以便更轻松地解释。本质上讲，当 0&lt;w&lt;1 时，我们可能遇到梯度消失问题；当 w&gt;1 时，我们可能遇到梯度爆炸问题。但是，当一个层遇到这个问题时，必然有更多权重满足梯度消失或爆炸的条件。我们从一个简单网络开始。这个网络有少量权重、偏置和激活，而且每一层也只有一个节点。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036692.jpg" alt="img" /></p><p>这个网络很简单。权重表示为 w_j，偏置为 b_j，成本函数为 C。节点、神经元或激活表示为圆圈。Nielsen 使用了物理学上的常用表示方式 Δ 来描述某个值中的变化（这不同于梯度符号 ∇）。举个例子，Δb_j 描述的是第 j 个偏置的值变化。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036704.jpg" alt="img" /></p><p>我前一篇文章的核心是我们要衡量与成本函数有关的权重和偏置的变化率。先不考虑层，我们看看一个特定的偏置，即第一个偏置 b_1。然后我们通过下式衡量变化率：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036713.jpg" alt="img" /></p><p>下面式子的论据和上面的偏导一样。即我们如何通过偏置的变化率来衡量成本函数的变化率？正如刚才介绍的那样，Nielsen 使用 Δ 来描述变化，因此我们可以说这个偏导能大致通过 Δ 来替代：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036041.jpg" alt="img" /></p><p>权重和偏置的变化可以进行如下可视化：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036315.jpg" alt="动图封面" /></p><p>动图出自 3blue1brown，视频地址：<a href="https://www.youtube.com/watch?v=tIeHLnjs5U8%E3%80%82">https://www.youtube.com/watch?v=tIeHLnjs5U8。</a></p><p>我们先从网络的起点开始，计算第一个偏置 b_1 中的变化将如何影响网络。因为我们知道，在上一篇文章中，第一个偏置 b_1 会馈入第一个激活 a_1，我们就从这里开始。我们先回顾一下这个等式：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036325.jpg" alt="img" /></p><p>如果 b_1 改变，我们将这个改变量表示为 Δb_1。因此，我们注意到当 b_1 改变时，激活 a_1 也会改变——我们通常将其表示为 ∂a_1/∂b_1。因此，我们左边有偏导的表达式，这是 b_1 中与 a_1 相关的变化。但我们开始替换左边的项，先用 z_1 的 sigmoid 替换 a_1：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036336.jpg" alt="img" /></p><p>上式表示当 b_1 变化时，激活值 a_1 中存在某个变化。我们将这个变化描述为 Δa_1。我们将变化 Δa_1 看作是与激活值 a_1 中的变化加上变化 Δb_1 近似一样。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036350.jpg" alt="img" /></p><p>这里我们跳过了一步，但本质上讲，我们只是计算了偏导数，并用偏导的结果替代了分数部分。</p><p><strong>a_1 的变化导致 z_2 的变化</strong></p><p>所描述的变化 Δa_1 现在会导致下一层的输入 z_2 出现变化。如果这看起来很奇怪或者你还不信服，我建议你阅读我的前一篇文章。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036361.jpg" alt="img" /></p><p>表示方式和前面一样，我们将下一个变化记为 Δz_2。我们又要再次经历前面的过程，只是这次要得到的是 z_2 中的变化：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036469.jpg" alt="img" /></p><p>我们可以使用下式替代 Δa_1：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036691.jpg" alt="img" /></p><p>我们只计算这个式子。希望你清楚地明白到这一步的过程——这与计算 Δa_1 的过程一样。这个过程会不断重复，直到我们计算完整个网络。通过替换 Δa_j 值，我们得到一个最终函数，其计算的是成本函数中与整个网络（即所有权重、偏置和激活）相关的变化。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036703.png" alt="img" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036719.jpg" alt="img" /></p><p>基于此，我们再计算 ∂C/∂b_1，得到我们需要的最终式：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036791.png" alt="img" /></p><p><strong>梯度爆炸的极端案例</strong></p><p>据此，如果所有权重 w_j 都很大，即如果很多权重的值大于 1，我们就会开始乘以较大的值。举个例子，所有权重都有一些非常高的值，比如 100，而我们得到一些在 0 到 0.25 之间、 sigmoid 函数导数的随机输出：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036802.png" alt="img" /></p><p>最后一个偏导为</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036042.png" alt="img" /></p><p>，可以合理地相信这会远大于 1，但为了方便示例展示，我们将其设为 1。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036123.jpg" alt="img" /></p><p>使用这个更新规则，如果我们假设 b_1 之前等于 1.56，而学习率等于 0.5。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036477.png" alt="img" /></p><p>尽管这是一个极端案例，但你懂我的意思。权重和偏置的值可能会爆发式地增大，进而导致整个网络爆炸。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036504.jpg" alt="img" /></p><p>现在花点时间想想网络的权重和偏置以及激活的其它部分，爆炸式地更新它们的值。这就是我们所说的梯度爆炸问题。很显然，这样的网络学不到什么东西，因此这会完全毁掉你想要解决的任务。</p><p><strong>避免梯度爆炸：梯度裁剪/规范</strong></p><p>解决梯度爆炸问题的基本思路就是为其设定一个规则。这部分我不会深入进行数学解释，但我会给出这个过程的步骤：</p><ul><li>选取一个阈值——如果梯度超过这个值，则使用梯度裁剪或梯度规范；</li><li>定义是否使用梯度裁剪或规范。如果使用梯度裁剪，你就指定一个阈值，比如 0.5。如果这个梯度值超过 0.5 或 -0.5，则要么通过梯度规范化将其缩放到阈值范围内，要么就将其裁剪到阈值范围内。</li></ul><p>但是要注意，这些梯度方法都不能避免梯度消失问题。所以我们还将进一步探索解决这个问题的更多方法。通常而言，如果你在使用循环神经网络架构（比如 LSTM 或 GRU），那么你就需要这些方法，因为这种架构常出现梯度爆炸的情况。</p><h2 id="整流线性单元relu"><a class="markdownIt-Anchor" href="#整流线性单元relu"></a> <strong>整流线性单元（ReLU）</strong></h2><p>整流线性单元是我们解决梯度消失问题的方法，但这是否会导致其它问题呢？请往下看。ReLU 的公式如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036514.jpg" alt="img" /></p><p>ReLU 公式表明：</p><ul><li>如果输入 x 小于 0，则令输出等于 0；</li><li>如果输入 x 大于 0，则令输出等于输入。</li></ul><p>尽管我们没法用大多数工具绘制其图形，但你可以这样用图解释 ReLU。x 值小于零的一切都映射为 0 的 y 值，但 x 值大于零的一切都映射为它本身。也就是说，如果我们输入 x=1，我们得到 y=1。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036525.jpg" alt="img" />ReLU 激活函数图示。</p><p>这很好，但这与梯度消失问题有什么关系？首先，我们必须得到其微分方程：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036682.jpg" alt="img" /></p><p>其意思是：</p><ul><li>如果输入 x 大于 0，则输出等于 1；</li><li>如果输入小于或等于 0，则输出变为 0。</li></ul><p>用下图表示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036752.jpg" alt="img" />已微分的 ReLU。</p><p>现在我们得到了答案：当使用 ReLU 激活函数时，我们不会得到非常小的值（比如前面 sigmoid 函数的 0.0000000438）。相反，它要么是 0（导致某些梯度不返回任何东西），要么是 1。但这又催生出另一个问题：死亡 ReLU 问题。如果在计算梯度时有太多值都低于 0 会怎样呢？我们会得到相当多不会更新的权重和偏置，因为其更新的量为 0。要了解这个过程的实际表现，我们反向地看看前面梯度爆炸的示例。我们在这个等式中将 ReLU 记为 R，我们只需要将每个 sigmoid σ 替换成 R：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036818.png" alt="img" /></p><p>现在，假如说这个微分后的 ReLU 的一个随机输入 z 小于 0——则这个函数会导致偏置「死亡」。假设是 R’(z_3)=0：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036837.png" alt="img" /></p><p>反过来，当我们得到 R’(z_3)=0 时，与其它值相乘自然也只能得到 0，这会导致这个偏置死亡。我们知道一个偏置的新值是该偏置减去学习率减去梯度，这意味着我们得到的更新为 0。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036851.jpg" alt="img" /></p><p><strong>死亡 ReLU：优势和缺点</strong></p><p>当我们将 ReLU 函数引入神经网络时，我们也引入了很大的稀疏性。那么稀疏性这个术语究竟是什么意思？稀疏：数量少，通常分散在很大的区域。在神经网络中，这意味着激活的矩阵含有许多 0。这种稀疏性能让我们得到什么？当某个比例（比如 50%）的激活饱和时，我们就称这个神经网络是稀疏的。这能提升时间和空间复杂度方面的效率——常数值（通常）所需空间更少，计算成本也更低。Yoshua Bengio 等人发现 ReLU 这种分量实际上能让神经网络表现更好，而且还有前面提到的时间和空间方面的效率。</p><p>论文地址：<a href="https://link.zhihu.com/?target=https%3A//www.utc.fr/~bordesan/dokuwiki/_media/en/glorot10nipsworkshop.pdf">https://www.utc.fr/~bordesan/dokuwiki/_media/en/glorot10nipsworkshop.pdf</a>优点：</p><ul><li>相比于 sigmoid，由于稀疏性，时间和空间复杂度更低；不涉及成本更高的指数运算；</li><li>能避免梯度消失问题。</li></ul><p>缺点：</p><ul><li>引入了死亡 ReLU 问题，即网络的大部分分量都永远不会更新。但这有时候也是一个优势；</li><li>ReLU 不能避免梯度爆炸问题。</li></ul><h2 id="指数线性单元elu"><a class="markdownIt-Anchor" href="#指数线性单元elu"></a> <strong>指数线性单元（ELU）</strong></h2><p>指数线性单元激活函数解决了 ReLU 的一些问题，同时也保留了一些好的方面。这种激活函数要选取一个 α 值；常见的取值是在 0.1 到 0.3 之间。如果你数学不好，ELU 的公式看起来会有些难以理解：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036859.jpg" alt="img" /></p><p>我解释一下。如果你输入的 x 值大于 0，则结果与 ReLU 一样——即 y 值等于 x 值；但如果输入的 x 值小于 0，则我们会得到一个稍微小于 0 的值。所得到的 y 值取决于输入的 x 值，但还要兼顾参数 α——你可以根据需要来调整这个参数。更进一步，我们引入了指数运算 e^x，因此 ELU 的计算成本比 ReLU 高。下面绘出了 α 值为 0.2 的 ELU 函数的图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036996.jpg" alt="img" />ELU 激活函数图示。</p><p>上图很直观，我们应该还能很好地应对梯度消失问题，因为输入值没有映射到非常小的输出值。但 ELU 的导数又如何呢？这同样也很重要。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036030.jpg" alt="img" /></p><p>看起来很简单。如果输入 x 大于 0，则 y 值输出为 1；如果输入 x 小于或等于 0，则输出是 ELU 函数（未微分）加上 α 值。可绘出图为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036128.jpg" alt="img" />微分的 ELU 激活函数。</p><p>你可能已经注意到，这里成功避开了死亡 ReLU 问题，同时仍保有 ReLU 激活函数的一些计算速度增益——也就是说，网络中仍还有一些死亡的分量。优点：</p><ul><li>能避免死亡 ReLU 问题；</li><li>能得到负值输出，这能帮助网络向正确的方向推动权重和偏置变化；</li><li>在计算梯度时能得到激活，而不是让它们等于 0。</li></ul><p>缺点：</p><ul><li>由于包含指数运算，所以计算时间更长；</li><li>无法避免梯度爆炸问题；</li><li>神经网络不学习 α 值。</li></ul><h2 id="渗漏型整流线性单元激活函数leaky-relu"><a class="markdownIt-Anchor" href="#渗漏型整流线性单元激活函数leaky-relu"></a> <strong>渗漏型整流线性单元激活函数（Leaky ReLU）</strong></h2><p>渗漏型整流线性单元激活函数也有一个 α 值，通常取值在 0.1 到 0.3 之间。Leaky ReLU 激活函数很常用，但相比于 ELU 它也有一些缺陷，但也比 ReLU 具有一些优势。Leaky ReLU 的数学形式如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036144.jpg" alt="img" /></p><p>因此，如果输入 x 大于 0，则输出为 x；如果输入 x 小于或等于 0，则输出为 α 乘以输入。这意味着能够解决死亡 ReLU 问题，因为梯度的值不再被限定为 0——另外，这个函数也能避免梯度消失问题。尽管梯度爆炸的问题依然存在，但后面的代码部分会介绍如何解决。下面给出了 Leaky ReLU 的图示，其中假设 α 值为 0.2：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036158.jpg" alt="img" />Leaky ReLU 图示。</p><p>和在公式中看到的一样，如果 x 值大于 0，则任意 x 值都映射为同样的 y 值；但如果 x 值小于 0，则会多一个系数 0.2。也就是说，如果输入值 x 为 -5，则映射的输出值为 -1。因为 Leaky ReLU 函数是两个线性部分组合起来的，所以它的导数很简单：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036169.jpg" alt="img" /></p><p>第一部分线性是当 x 大于 0 时，输出为 1；而当输入小于 0 时，输出就为 α 值，这里我们选择的是 0.2。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036438.jpg" alt="img" />微分的 Leaky ReLU 图示。</p><p>从上图中也能明显地看出来，输入 x 大于或小于 0，微分的 Leaky ReLU 各为一个常量。优点：</p><ul><li>类似 ELU，Leaky ReLU 也能避免死亡 ReLU 问题，因为其在计算导数时允许较小的梯度；</li><li>由于不包含指数运算，所以计算速度比 ELU 快。</li></ul><p>缺点：</p><ul><li>无法避免梯度爆炸问题；</li><li>神经网络不学习 α 值；</li><li>在微分时，两部分都是线性的；而 ELU 的一部分是线性的，一部分是非线性的。</li></ul><h2 id="扩展型指数线性单元激活函数selu"><a class="markdownIt-Anchor" href="#扩展型指数线性单元激活函数selu"></a> <strong>扩展型指数线性单元激活函数（SELU）</strong></h2><p>扩展型指数线性单元激活函数比较新，介绍它的论文包含长达 90 页的附录（包括定理和证明等）。当实际应用这个激活函数时，必须使用 lecun_normal 进行权重初始化。如果希望应用 dropout，则应当使用 AlphaDropout。后面的代码部分会更详细地介绍。论文作者已经计算出了公式的两个值：α 和 λ；如下所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036447.jpg" alt="img" /></p><p>可以看到，它们的小数点后还有很多位，这是为了绝对精度。而且它们是预先确定的，也就是说我们不必担心如何为这个激活函数选取合适的 α 值。说实话，这个公式看起来和其它公式或多或少有些类似。所有新的激活函数看起来就像是其它已有的激活函数的组合。SELU 的公式如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036590.jpg" alt="img" /></p><p>也就是说，如果输入值 x 大于 0，则输出值为 x 乘以 λ；如果输入值 x 小于 0，则会得到一个奇异函数——它随 x 增大而增大并趋近于 x 为 0 时的值 0.0848。本质上看，当 x 小于 0 时，先用 α 乘以 x 值的指数，再减去 α，然后乘以 λ 值。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036619.jpg" alt="img" />SELU 函数图示。</p><p><strong>SELU 的特例</strong></p><p>SELU 激活能够对神经网络进行自归一化（self-normalizing）。这是什么意思？首先，我们先看看什么是归一化（normalization）。简单来说，归一化首先是减去均值，然后除以标准差。因此，经过归一化之后，网络的组件（权重、偏置和激活）的均值为 0，标准差为 1。而这正是 SELU 激活函数的输出值。均值为 0 且标准差为 1 又如何呢？在初始化函数为 lecun_normal 的假设下，网络参数会被初始化一个正态分布（或高斯分布），然后在 SELU 的情况下，网络会在论文中描述的范围内完全地归一化。本质上看，当乘或加这样的网络分量时，网络仍被视为符合高斯分布。我们就称之为归一化。反过来，这又意味着整个网络及其最后一层的输出也是归一化的。均值 μ 为 0 且标准差 σ 为 1 的正态分布看起来是怎样的？</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036633.jpg" alt="img" /></p><p>SELU 的输出是归一化的，这可称为内部归一化（internal normalization），因此事实上其所有输出都是均值为 0 且标准差为 1。这不同于外部归一化（external normalization）——会用到批归一化或其它方法。很好，也就是说所有分量都会被归一化。但这是如何做到的？简单解释一下，当输入小于 0 时，方差减小；当输入大于 0 时，方差增大——而标准差是方差的平方根，这样我们就使得标准差为 1。我们通过梯度得到零均值。我们需要一些正值和负值才能让均值为 0。我的上一篇文章介绍过，梯度可以调整神经网络的权重和偏置，因此我们需要这些梯度输出一些负值和正值，这样才能控制住均值。均值 μ 和方差 ν 的主要作用是使我们有某个域 Ω，让我们总是能将均值和方差映射到预定义的区间内。这些区间定义如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036662.jpg" alt="img" /></p><p>∈ 符号表示均值和方差在这些预定义的区间之内。反过来，这又能避免网络出现梯度消失和爆炸问题。下面引述一段论文的解释，说明了他们得到这个激活函数的方式，我认为这很重要：</p><blockquote><p>SELU 允许构建一个映射 g，其性质能够实现 SNN（自归一化神经网络）。SNN 不能通过（扩展型）修正线性单元（ReLU）、sigmoid 单元、tanh 单元和 Leaky ReLU 实现。这个激活函数需要有：（1）负值和正值，以便控制均值；（2）饱和区域（导数趋近于零），以便抑制更低层中较大的方差；（3）大于 1 的斜率，以便在更低层中的方差过小时增大方差；（4）连续曲线。后者能确保一个固定点，其中方差抑制可通过方差增大来获得均衡。我们能通过乘上指数线性单元（ELU）来满足激活函数的这些性质，而且 λ&gt;1 能够确保正值净输入的斜率大于 1。</p></blockquote><p>我们再看看 SELU 的微分函数：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036739.jpg" alt="img" /></p><p>很好，不太复杂，我们可以简单地解释一下。如果 x 大于 0，则输出值为 λ；如果 x 小于 0，则输出为 α 乘以 x 的指数再乘 λ。其图形如下所示，看起来很特别：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036749.jpg" alt="img" />微分的 SELU 函数。</p><p>注意 SELU 函数也需要 lecun_normal 进行权重初始化；而且如果你想使用 dropout，你也必须使用名为 Alpha Dropout 的特殊版本。优点：</p><ul><li>内部归一化的速度比外部归一化快，这意味着网络能更快收敛；</li><li>不可能出现梯度消失或爆炸问题，见 SELU 论文附录的定理 2 和 3。</li></ul><p>缺点：</p><ul><li>这个激活函数相对较新——需要更多论文比较性地探索其在 CNN 和 RNN 等架构中应用。</li><li>这里有一篇使用 SELU 的 CNN 论文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1905.01338.pdf">https://arxiv.org/pdf/1905.01338.pdf</a></li></ul><h2 id="gelu"><a class="markdownIt-Anchor" href="#gelu"></a> <strong>GELU</strong></h2><p>高斯误差线性单元激活函数在最近的 Transformer 模型（谷歌的 BERT 和 OpenAI 的 GPT-2）中得到了应用。GELU 的论文来自 2016 年，但直到最近才引起关注。这种激活函数的形式为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036011.png" alt="img" /></p><p>看得出来，这就是某些函数（比如双曲正切函数 tanh）与近似数值的组合。没什么过多可说的。有意思的是这个函数的图形：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036037.jpg" alt="img" />GELU 激活函数。</p><p>可以看出，当 x 大于 0 时，输出为 x；但 x=0 到 x=1 的区间除外，这时曲线更偏向于 y 轴。我没能找到该函数的导数，所以我使用了 WolframAlpha 来微分这个函数。结果如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036066.png" alt="img" /></p><p>和前面一样，这也是双曲函数的另一种组合形式。但它的图形看起来很有意思：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036094.jpg" alt="img" />微分的 GELU 激活函数。</p><p>优点：</p><ul><li>似乎是 NLP 领域的当前最佳；尤其在 Transformer 模型中表现最好；</li><li>能避免梯度消失问题。</li></ul><p>缺点：</p><ul><li>尽管是 2016 年提出的，但在实际应用中还是一个相当新颖的激活函数。</li></ul><p><strong>用于深度神经网络的代码</strong></p><p>假如说你想要尝试所有这些激活函数，以便了解哪种最适合，你该怎么做？通常我们会执行超参数优化——这可以使用 scikit-learn 的 GridSearchCV 函数实现。但是我们想要进行比较，所以我们的想法是选取一些超参数并让它们保持恒定，同时修改激活函数。说明一下我这里要做的事情：</p><ul><li>使用本文提及的激活函数训练同样的神经网络模型；</li><li>使用每个激活函数的历史记录，绘制损失和准确度随 epoch 的变化图。</li></ul><p>本代码也发布在了 GitHub 上，并且支持 colab，以便你能够快速运行。地址：<a href="https://link.zhihu.com/?target=https%3A//github.com/casperbh96/Activation-Functions-Search">https://github.com/casperbh96/Activation-Functions-Search</a>我更偏好使用 Keras 的高级 API，所以这会用 Keras 来完成。首先导入我们所需的一切。注意这里使用了 4 个库：tensorflow、numpy、matplotlib、 keras。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from keras.datasets import mnist</span><br><span class="line">from keras.utils.np_utils import to_categorical</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU</span><br><span class="line">from keras.layers.noise import AlphaDropout</span><br><span class="line">from keras.utils.generic_utils import get_custom_objects</span><br><span class="line">from keras import backend as K</span><br><span class="line">from keras.optimizers import Adam</span><br></pre></td></tr></table></figure><p>现在加载我们运行实验所需的数据集；这里选择了 MNIST 数据集。我们可以直接从 Keras 导入它。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br></pre></td></tr></table></figure><p>很好，但我们想对数据进行一些预处理，比如归一化。我们需要通过很多函数来做这件事，主要是调整图像大小（.reshape）并除以最大的 RGB 值 255（/= 255）。最后，我们通过 to_categorical() 对数据进行 one-hot 编码。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">def preprocess_mnist(x_train, y_train, x_test, y_test):</span><br><span class="line">    # Normalizing all images of 28x28 pixels</span><br><span class="line">    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)</span><br><span class="line">    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)</span><br><span class="line">    input_shape = (28, 28, 1)</span><br><span class="line"></span><br><span class="line">    # Float values for division</span><br><span class="line">    x_train = x_train.astype(&#x27;float32&#x27;)</span><br><span class="line">    x_test = x_test.astype(&#x27;float32&#x27;)</span><br><span class="line"></span><br><span class="line">    # Normalizing the RGB codes by dividing it to the max RGB value</span><br><span class="line">    x_train /= 255</span><br><span class="line">    x_test /= 255</span><br><span class="line"></span><br><span class="line">    # Categorical y values</span><br><span class="line">    y_train = to_categorical(y_train)</span><br><span class="line">    y_test= to_categorical(y_test)</span><br><span class="line"></span><br><span class="line">    return x_train, y_train, x_test, y_test, input_shape</span><br><span class="line"></span><br><span class="line">x_train, y_train, x_test, y_test, input_shape = preprocess_mnist(x_train, y_train, x_test, y_test)</span><br></pre></td></tr></table></figure><p>现在我们已经完成了数据预处理，可以构建模型以及定义 Keras 运行所需的参数了。首先从卷积神经网络模型本身开始。SELU 激活函数是一个特殊情况，我们需要使用核初始化器 ‘lecun_normal’ 和特殊形式的 dropout AlphaDropout()，其它一切都保持常规设定。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">def build_cnn(activation,</span><br><span class="line">              dropout_rate,</span><br><span class="line">              optimizer):</span><br><span class="line">    model = Sequential()if(activation == &#x27;selu&#x27;):</span><br><span class="line">        model.add(Conv2D(32, kernel_size=(3, 3),</span><br><span class="line">                  activation=activation,</span><br><span class="line">                  input_shape=input_shape,</span><br><span class="line">                  kernel_initializer=&#x27;lecun_normal&#x27;))</span><br><span class="line">        model.add(Conv2D(64, (3, 3), activation=activation, </span><br><span class="line">                         kernel_initializer=&#x27;lecun_normal&#x27;))</span><br><span class="line">        model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">        model.add(AlphaDropout(0.25))</span><br><span class="line">        model.add(Flatten())</span><br><span class="line">        model.add(Dense(128, activation=activation, </span><br><span class="line">                        kernel_initializer=&#x27;lecun_normal&#x27;))</span><br><span class="line">        model.add(AlphaDropout(0.5))</span><br><span class="line">        model.add(Dense(10, activation=&#x27;softmax&#x27;))else:</span><br><span class="line">        model.add(Conv2D(32, kernel_size=(3, 3),</span><br><span class="line">                  activation=activation,</span><br><span class="line">                  input_shape=input_shape))</span><br><span class="line">        model.add(Conv2D(64, (3, 3), activation=activation))</span><br><span class="line">        model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">        model.add(Dropout(0.25))</span><br><span class="line">        model.add(Flatten())</span><br><span class="line">        model.add(Dense(128, activation=activation))</span><br><span class="line">        model.add(Dropout(0.5))</span><br><span class="line">        model.add(Dense(10, activation=&#x27;softmax&#x27;))</span><br><span class="line"></span><br><span class="line">    model.compile(</span><br><span class="line">        loss=&#x27;binary_crossentropy&#x27;, </span><br><span class="line">        optimizer=optimizer, </span><br><span class="line">        metrics=[&#x27;accuracy&#x27;])return model</span><br></pre></td></tr></table></figure><p>使用 GELU 函数有个小问题；Keras 中目前还没有这个函数。幸好我们能轻松地向 Keras 添加新的激活函数。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line"># Add the GELU function to Keras</span><br><span class="line">def gelu(x):</span><br><span class="line">    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))</span><br><span class="line">get_custom_objects().update(&#123;&#x27;gelu&#x27;: Activation(gelu)&#125;)</span><br><span class="line"></span><br><span class="line"># Add leaky-relu so we can use it as a string</span><br><span class="line">get_custom_objects().update(&#123;&#x27;leaky-relu&#x27;: Activation(LeakyReLU(alpha=0.2))&#125;)</span><br><span class="line"></span><br><span class="line">act_func = [&#x27;sigmoid&#x27;, &#x27;relu&#x27;, &#x27;elu&#x27;, &#x27;leaky-relu&#x27;, &#x27;selu&#x27;, &#x27;gelu&#x27;]</span><br></pre></td></tr></table></figure><p>现在我们可以使用 act_func 数组中定义的不同激活函数训练模型了。我们会在每个激活函数上运行一个简单的 for 循环，并将结果添加到一个数组：</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">result = []for activation in act_func:print(&#x27;\nTraining with --&gt;&#123;0&#125;&lt;-- activation function\n&#x27;.format(activation))</span><br><span class="line"></span><br><span class="line">    model = build_cnn(activation=activation,</span><br><span class="line">                      dropout_rate=0.2,</span><br><span class="line">                      optimizer=Adam(clipvalue=0.5))</span><br><span class="line"></span><br><span class="line">    history = model.fit(x_train, y_train,</span><br><span class="line">          validation_split=0.20,</span><br><span class="line">          batch_size=128, # 128 is faster, but less accurate. 16/32 recommended</span><br><span class="line">          epochs=100,</span><br><span class="line">          verbose=1,</span><br><span class="line">          validation_data=(x_test, y_test))</span><br><span class="line"></span><br><span class="line">    result.append(history)</span><br><span class="line"></span><br><span class="line">    K.clear_session()del model</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><p>基于此，我们可以为每个激活函数绘制从 model.fit() 得到的历史图，然后看看损失和准确度结果的变化情况。现在我们可以为数据绘图了，我用 matplotlib 写了一小段代码：</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">new_act_arr = act_func[1:]</span><br><span class="line">new_results = result[1:]def plot_act_func_results(results, activation_functions = []):</span><br><span class="line">    plt.figure(figsize=(10,10))</span><br><span class="line">    plt.style.use(&#x27;dark_background&#x27;)# Plot validation accuracy valuesfor act_func in results:</span><br><span class="line">        plt.plot(act_func.history[&#x27;val_acc&#x27;])</span><br><span class="line"></span><br><span class="line">    plt.title(&#x27;Model accuracy&#x27;)</span><br><span class="line">    plt.ylabel(&#x27;Test Accuracy&#x27;)</span><br><span class="line">    plt.xlabel(&#x27;Epoch&#x27;)</span><br><span class="line">    plt.legend(activation_functions)</span><br><span class="line">    plt.show()# Plot validation loss values</span><br><span class="line">    plt.figure(figsize=(10,10))for act_func in results:</span><br><span class="line">        plt.plot(act_func.history[&#x27;val_loss&#x27;])</span><br><span class="line"></span><br><span class="line">    plt.title(&#x27;Model loss&#x27;)</span><br><span class="line">    plt.ylabel(&#x27;Test Loss&#x27;)</span><br><span class="line">    plt.xlabel(&#x27;Epoch&#x27;)</span><br><span class="line">    plt.legend(activation_functions)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_act_func_results(new_results, new_act_arr)</span><br></pre></td></tr></table></figure><p>这会得到如下图表：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242036115.jpg" alt="img" /></p><p><strong>扩展阅读</strong></p><p>下面是四本写得很赞的书：</p><ul><li>Deep Learning，作者：Ian Goodfellow、Yoshua Bengio、Aaron Courville</li><li>The Hundred-Page Machine Learning Book，作者：Andriy Burkov</li><li>Hands-On Machine Learning with Scikit-Learn and TensorFlow，作者：Aurélien Géron</li><li>Machine Learning: A Probabilistic Perspective，作者：Kevin P. Murphy</li></ul><p>下面是本文讨论过的重要论文：</p><ul><li>Leaky ReLU 论文：<a href="https://link.zhihu.com/?target=https%3A//ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf">https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf</a></li><li>ELU 论文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1511.07289.pdf">https://arxiv.org/pdf/1511.07289.pdf</a></li><li>SELU 论文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1706.02515.pdf">https://arxiv.org/pdf/1706.02515.pdf</a></li><li>GELU 论文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1606.08415.pdf">https://arxiv.org/pdf/1606.0841</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Activation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Similarity</title>
      <link href="/2023/10/10/AILearning/DL/%E7%9B%B8%E4%BC%BC%E6%80%A7%E8%AE%A1%E7%AE%97/"/>
      <url>/2023/10/10/AILearning/DL/%E7%9B%B8%E4%BC%BC%E6%80%A7%E8%AE%A1%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<h4 id="cosinesimilarity"><a class="markdownIt-Anchor" href="#cosinesimilarity"></a> CosineSimilarity</h4><h4 id="dotproductsimilarity"><a class="markdownIt-Anchor" href="#dotproductsimilarity"></a> DotProductSimilarity</h4><h4 id="projecteddotproductsimilarity"><a class="markdownIt-Anchor" href="#projecteddotproductsimilarity"></a> ProjectedDotProductSimilarity</h4><h4 id="bilinearsimilarity"><a class="markdownIt-Anchor" href="#bilinearsimilarity"></a> BiLinearSimilarity</h4><h4 id="trilinearsimilarity"><a class="markdownIt-Anchor" href="#trilinearsimilarity"></a> TriLinearSimilarity</h4><h4 id="multiheadedsimilarity"><a class="markdownIt-Anchor" href="#multiheadedsimilarity"></a> MultiHeadedSimilarity</h4><h2 id="1-余弦相似度"><a class="markdownIt-Anchor" href="#1-余弦相似度"></a> <strong>1、余弦相似度</strong></h2><p>余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，称为&quot;余弦相似性&quot;</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">torch.cosine_similarity()</span><br></pre></td></tr></table></figure><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">class CosineSimilarity(nn.Module):</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        normalized_tensor_1 = tensor_1 / tensor_1.norm(dim=-1, keepdim=True)</span><br><span class="line">        normalized_tensor_2 = tensor_2 / tensor_2.norm(dim=-1, keepdim=True)</span><br><span class="line">        return (normalized_tensor_1 * normalized_tensor_2).sum(dim=-1)</span><br></pre></td></tr></table></figure><h2 id="2-dotproductsimilarity"><a class="markdownIt-Anchor" href="#2-dotproductsimilarity"></a> <strong>2、DotProductSimilarity</strong></h2><p>这个相似度函数简单地计算每对向量之间的点积，并使用可选的缩放来减少输出的方差。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">class DotProductSimilarity(nn.Module):</span><br><span class="line"> </span><br><span class="line">    def __init__(self, scale_output=False):</span><br><span class="line">        super(DotProductSimilarity, self).__init__()</span><br><span class="line">        self.scale_output = scale_output</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        result = (tensor_1 * tensor_2).sum(dim=-1)</span><br><span class="line">        if self.scale_output:</span><br><span class="line">            # TODO why allennlp do multiplication at here ?</span><br><span class="line">            result /= math.sqrt(tensor_1.size(-1))</span><br><span class="line">        return result</span><br></pre></td></tr></table></figure><h2 id="3-projecteddotproductsimilarity"><a class="markdownIt-Anchor" href="#3-projecteddotproductsimilarity"></a> <strong>3、ProjectedDotProductSimilarity</strong></h2><p>这个相似度函数做一个投影，然后计算点积，计算公式为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242052017.jpg" alt="img" /></p><p>计算后的激活函数。默认为不激活。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">class ProjectedDotProductSimilarity(nn.Module):</span><br><span class="line">   </span><br><span class="line">    def __init__(self, tensor_1_dim, tensor_2_dim, projected_dim,</span><br><span class="line">                 reuse_weight=False, bias=False, activation=None):</span><br><span class="line">        super(ProjectedDotProductSimilarity, self).__init__()</span><br><span class="line">        self.reuse_weight = reuse_weight</span><br><span class="line">        self.projecting_weight_1 = nn.Parameter(torch.Tensor(tensor_1_dim, projected_dim))</span><br><span class="line">        if self.reuse_weight:</span><br><span class="line">            if tensor_1_dim != tensor_2_dim:</span><br><span class="line">                raise ValueError(&#x27;if reuse_weight=True, tensor_1_dim must equal tensor_2_dim&#x27;)</span><br><span class="line">        else:</span><br><span class="line">            self.projecting_weight_2 = nn.Parameter(torch.Tensor(tensor_2_dim, projected_dim))</span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(1)) if bias else None</span><br><span class="line">        self.activation = activation</span><br><span class="line"> </span><br><span class="line">    def reset_parameters(self):</span><br><span class="line">        nn.init.xavier_uniform_(self.projecting_weight_1)</span><br><span class="line">        if not self.reuse_weight:</span><br><span class="line">            nn.init.xavier_uniform_(self.projecting_weight_2)</span><br><span class="line">        if self.bias is not None:</span><br><span class="line">            self.bias.data.fill_(0)</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        projected_tensor_1 = torch.matmul(tensor_1, self.projecting_weight_1)</span><br><span class="line">        if self.reuse_weight:</span><br><span class="line">            projected_tensor_2 = torch.matmul(tensor_2, self.projecting_weight_1)</span><br><span class="line">        else:</span><br><span class="line">            projected_tensor_2 = torch.matmul(tensor_2, self.projecting_weight_2)</span><br><span class="line">        result = (projected_tensor_1 * projected_tensor_2).sum(dim=-1)</span><br><span class="line">        if self.bias is not None:</span><br><span class="line">            result = result + self.bias</span><br><span class="line">        if self.activation is not None:</span><br><span class="line">            result = self.activation(result)</span><br><span class="line">        return result</span><br></pre></td></tr></table></figure><h2 id="4-bilinearsimilarity"><a class="markdownIt-Anchor" href="#4-bilinearsimilarity"></a> <strong>4、BiLinearSimilarity</strong></h2><p>此相似度函数执行两个输入向量的双线性变换。这个函数有一个权重矩阵“W”和一个偏差“b”，以及两个向量之间的相似度，计算公式为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242052018.jpg" alt="img" /></p><p>计算后的激活函数。 默认为不激活。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">class BiLinearSimilarity(nn.Module):</span><br><span class="line"> </span><br><span class="line">    def __init__(self, tensor_1_dim, tensor_2_dim, activation=None):</span><br><span class="line">        super(BiLinearSimilarity, self).__init__()</span><br><span class="line">        self.weight_matrix = nn.Parameter(torch.Tensor(tensor_1_dim, tensor_2_dim))</span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(1))</span><br><span class="line">        self.activation = activation</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"> </span><br><span class="line">    def reset_parameters(self):</span><br><span class="line">        nn.init.xavier_uniform_(self.weight_matrix)</span><br><span class="line">        self.bias.data.fill_(0)</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        intermediate = torch.matmul(tensor_1, self.weight_matrix)</span><br><span class="line">        result = (intermediate * tensor_2).sum(dim=-1) + self.bias</span><br><span class="line">        if self.activation is not None:</span><br><span class="line">            result = self.activation(result)</span><br><span class="line">        return result</span><br></pre></td></tr></table></figure><h2 id="5-trilinearsimilarity"><a class="markdownIt-Anchor" href="#5-trilinearsimilarity"></a> <strong>5、TriLinearSimilarity</strong></h2><p>此相似度函数执行两个输入向量的三线性变换，计算公式为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404242052183.jpg" alt="img" /></p><p>计算后的激活函数。 默认为不激活。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">class TriLinearSimilarity(nn.Module):</span><br><span class="line"> </span><br><span class="line">    def __init__(self, input_dim, activation=None):</span><br><span class="line">        super(TriLinearSimilarity, self).__init__()</span><br><span class="line">        self.weight_vector = nn.Parameter(torch.Tensor(3 * input_dim))</span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(1))</span><br><span class="line">        self.activation = activation</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"> </span><br><span class="line">    def reset_parameters(self):</span><br><span class="line">        std = math.sqrt(6 / (self.weight_vector.size(0) + 1))</span><br><span class="line">        self.weight_vector.data.uniform_(-std, std)</span><br><span class="line">        self.bias.data.fill_(0)</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        combined_tensors = torch.cat([tensor_1, tensor_2, tensor_1 * tensor_2], dim=-1)</span><br><span class="line">        result = torch.matmul(combined_tensors, self.weight_vector) + self.bias</span><br><span class="line">        if self.activation is not None:</span><br><span class="line">            result = self.activation(result)</span><br><span class="line">        return result</span><br></pre></td></tr></table></figure><h2 id="6-multiheadedsimilarity"><a class="markdownIt-Anchor" href="#6-multiheadedsimilarity"></a> <strong>6、MultiHeadedSimilarity</strong></h2><p>这个相似度函数使用多个“头”来计算相似度。也就是说，我们将输入张量投影到多个新张量中，并分别计算每个投影张量的相似度。这里的结果比典型的相似度函数多一个维度。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class MultiHeadedSimilarity(nn.Module):</span><br><span class="line"> </span><br><span class="line">    def __init__(self,</span><br><span class="line">                 num_heads,</span><br><span class="line">                 tensor_1_dim,</span><br><span class="line">                 tensor_1_projected_dim=None,</span><br><span class="line">                 tensor_2_dim=None,</span><br><span class="line">                 tensor_2_projected_dim=None,</span><br><span class="line">                 internal_similarity=DotProductSimilarity()):</span><br><span class="line">        super(MultiHeadedSimilarity, self).__init__()</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.internal_similarity = internal_similarity</span><br><span class="line">        tensor_1_projected_dim = tensor_1_projected_dim or tensor_1_dim</span><br><span class="line">        tensor_2_dim = tensor_2_dim or tensor_1_dim</span><br><span class="line">        tensor_2_projected_dim = tensor_2_projected_dim or tensor_2_dim</span><br><span class="line">        if tensor_1_projected_dim % num_heads != 0:</span><br><span class="line">            raise ValueError(&quot;Projected dimension not divisible by number of heads: %d, %d&quot;</span><br><span class="line">                             % (tensor_1_projected_dim, num_heads))</span><br><span class="line">        if tensor_2_projected_dim % num_heads != 0:</span><br><span class="line">            raise ValueError(&quot;Projected dimension not divisible by number of heads: %d, %d&quot;</span><br><span class="line">                             % (tensor_2_projected_dim, num_heads))</span><br><span class="line">        self.tensor_1_projection = nn.Parameter(torch.Tensor(tensor_1_dim, tensor_1_projected_dim))</span><br><span class="line">        self.tensor_2_projection = nn.Parameter(torch.Tensor(tensor_2_dim, tensor_2_projected_dim))</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"> </span><br><span class="line">    def reset_parameters(self):</span><br><span class="line">        torch.nn.init.xavier_uniform_(self.tensor_1_projection)</span><br><span class="line">        torch.nn.init.xavier_uniform_(self.tensor_2_projection)</span><br><span class="line"> </span><br><span class="line">    def forward(self, tensor_1, tensor_2):</span><br><span class="line">        projected_tensor_1 = torch.matmul(tensor_1, self.tensor_1_projection)</span><br><span class="line">        projected_tensor_2 = torch.matmul(tensor_2, self.tensor_2_projection)</span><br><span class="line"> </span><br><span class="line">        # Here we split the last dimension of the tensors from (..., projected_dim) to</span><br><span class="line">        # (..., num_heads, projected_dim / num_heads), using tensor.view().</span><br><span class="line">        last_dim_size = projected_tensor_1.size(-1) // self.num_heads</span><br><span class="line">        new_shape = list(projected_tensor_1.size())[:-1] + [self.num_heads, last_dim_size]</span><br><span class="line">        split_tensor_1 = projected_tensor_1.view(*new_shape)</span><br><span class="line">        last_dim_size = projected_tensor_2.size(-1) // self.num_heads</span><br><span class="line">        new_shape = list(projected_tensor_2.size())[:-1] + [self.num_heads, last_dim_size]</span><br><span class="line">        split_tensor_2 = projected_tensor_2.view(*new_shape)</span><br><span class="line"> </span><br><span class="line">        # And then we pass this off to our internal similarity function. Because the similarity</span><br><span class="line">        # functions don&#x27;t care what dimension their input has, and only look at the last dimension,</span><br><span class="line">        # we don&#x27;t need to do anything special here. It will just compute similarity on the</span><br><span class="line">        # projection dimension for each head, returning a tensor of shape (..., num_heads).</span><br><span class="line">        return self.internal_similarity(split_tensor_1, split_tensor_2)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>baseline、benchmark、groundtruth</title>
      <link href="/2023/10/10/AILearning/DL/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%9C%AF%E8%AF%ADbaseline%E3%80%81benchmark%E3%80%81groundtruth/"/>
      <url>/2023/10/10/AILearning/DL/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%9C%AF%E8%AF%ADbaseline%E3%80%81benchmark%E3%80%81groundtruth/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读术语"><a class="markdownIt-Anchor" href="#论文阅读术语"></a> 论文阅读术语</h1><blockquote><p>baseline、benchmark、groundtruth</p></blockquote><h4 id="1-benchmark"><a class="markdownIt-Anchor" href="#1-benchmark"></a> <em><strong>1. benchmark</strong></em></h4><p>benchmark是一种评价方式。在计算机领域应用最多的就是针对不同Model的性能测试。<br />对于benchmark过程，有三个步骤：<br /><strong>设置</strong>：这部分我们最常听到的就是数据集，说白了就是输入。<br />数据又分为结构化数据、半结构化数据和非结构化数据。其中非结构化数据包含各种文档、图片、视频和音频等。典型的应用有视频网站、图片相册、交通视频监控等等。<br /><strong>执行</strong>：对于自己提出的模型进行试验。<br /><strong>分析度量指标</strong>：<br />常用的指标：<br />（1）从架构角度度量：浮点型操作密度、整数型操作密度、指令中断、cache命中率、TLB命中；<br />（2）从Spark系统执行时间和吞吐的角度度量：Job作业执行时间、Job吞吐量、Stage执行时间、Stage吞吐量、Task执行时间、Task吞吐量；<br />（3）从Spark系统资源利用率的角度度量：CPU在指定时间段的利用率、内存在指定时间段的利用率、磁盘在指定时间段的利用率、网络带宽在指定时间段的利用率；<br />（4）从扩展性的角度度量：数据量扩展、集群节点数据扩展（scale out）、单机性能扩展（scale up）。</p><h4 id="2-baseline"><a class="markdownIt-Anchor" href="#2-baseline"></a> <em><strong>2. baseline</strong></em></h4><p>在benchmark的第二步中，我们自己所提出的模型/算法指的就是baseline，这是我们提出的模型的基准。之后所有的改进都需要跟这个基准来比较。</p><h4 id="3-groundtruth"><a class="markdownIt-Anchor" href="#3-groundtruth"></a> <em><strong>3. groundtruth</strong></em></h4><p>groundtruth:真值,针对不同的方向，真值所指代的具体内容是不同的，不过都可以理解为我们人工给定的标签。对于针对人的目标检测而言，真值代表的是数据集给定的人工标定框；而对于行为/视频分类而言，真值代表的是动作或视频的实际对应类别。总之就是实际给定的y值。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Term </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DGL整图分类</title>
      <link href="/2023/10/10/AILearning/GNN/DGL%E6%95%B4%E5%9B%BE%E5%88%86%E7%B1%BB/"/>
      <url>/2023/10/10/AILearning/GNN/DGL%E6%95%B4%E5%9B%BE%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<p>许多场景中的图数据是由多个图组成，而不是单个的大图数据。例如不同类型的人群社区。 通过用图刻画同一社区里人与人间的友谊，可以得到多张用于分类的图。 在这个场景里，整图分类模型可以识别社区的类型，即根据结构和整体信息对图进行分类。</p><h2 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id2">¶</a></h2><p>整图分类与节点分类或链接预测的主要区别是：预测结果刻画了整个输入图的属性。 与之前的任务类似，用户还是在节点或边上进行消息传递。但不同的是，整图分类任务还需要得到整个图的表示。</p><p>整图分类的处理流程如下图所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241756451.png" alt="Graph Classification Process" /></p><p><em>整图分类流程</em><a href="https://docs.dgl.ai/guide_cn/training-graph.html#id11">¶</a></p><p>从左至右，一般流程是：</p><ul><li>准备一个批次的图；</li><li>在这个批次的图上进行消息传递以更新节点或边的特征；</li><li>将一张图里的节点或边特征聚合成整张图的图表示；</li><li>根据任务设计分类层。</li></ul><h3 id="批次的图"><a class="markdownIt-Anchor" href="#批次的图"></a> 批次的图<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id3">¶</a></h3><p>整图分类任务通常需要在很多图上进行训练。如果用户在训练模型时一次仅使用一张图，训练效率会很低。 借用深度学习实践中常用的小批次训练方法，用户可将多张图组成一个批次，在整个图批次上进行一次训练迭代。</p><p>使用DGL，用户可将一系列的图建立成一个图批次。一个图批次可以被看作是一张大图，图中的每个连通子图对应一张原始小图。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241756455.png" alt="Batched Graph" /></p><p><em>批次化的图</em><a href="https://docs.dgl.ai/guide_cn/training-graph.html#id12">¶</a></p><p>需要注意，DGL里对图进行变换的函数会去掉图上的批次信息。用户可以通过 <a href="https://docs.dgl.ai/generated/dgl.DGLGraph.set_batch_num_nodes.html#dgl.DGLGraph.set_batch_num_nodes"><code>dgl.DGLGraph.set_batch_num_nodes()</code></a> 和 <a href="https://docs.dgl.ai/generated/dgl.DGLGraph.set_batch_num_edges.html#dgl.DGLGraph.set_batch_num_edges"><code>dgl.DGLGraph.set_batch_num_edges()</code></a> 两个函数在变换后的图上重新加入批次信息。</p><h3 id="图读出"><a class="markdownIt-Anchor" href="#图读出"></a> 图读出<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id4">¶</a></h3><p>数据集中的每一张图都有它独特的结构和节点与边的特征。为了完成单个图的预测，通常会聚合并汇总单个图尽可能多的信息。 这类操作叫做“读出”。<mark><strong>常见的聚合方法包括：对所有节点或边特征求和、取平均值、逐元素求最大值或最小值。</strong></mark></p><p>给定一张图 g，对它所有节点特征取平均值的聚合读出公式如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241756464.png" alt="image-20231211162452437" /></p><p>其中，hgℎ是图 g的表征， V 是图 g中节点的集合， hvℎ 是节点 v的特征。</p><p>DGL内置了常见的图读出函数，例如 <a href="https://docs.dgl.ai/generated/dgl.readout_nodes.html#dgl.readout_nodes"><code>dgl.readout_nodes()</code></a> 就实现了上述的平均值读出计算。</p><p>在得到 hgℎ 后，用户可将其传给一个多层感知机(MLP)来获得分类输出。</p><h2 id="编写神经网络模型"><a class="markdownIt-Anchor" href="#编写神经网络模型"></a> 编写神经网络模型<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id5">¶</a></h2><p>模型的输入是带节点和边特征的批次化图。需要注意的是批次化图中的节点和边属性没有批次大小对应的维度。 模型中应特别注意以下几点。</p><h3 id="批次化图上的计算"><a class="markdownIt-Anchor" href="#批次化图上的计算"></a> 批次化图上的计算<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id6">¶</a></h3><p>首先，一个批次中不同的图是完全分开的，即任意两个图之间没有边连接。 根据这个良好的性质，所有消息传递函数(的计算)仍然具有相同的结果。</p><p>其次，读出函数会分别作用在图批次中的每张图上。假设批次大小为 B，要聚合的特征大小为 D， 则图读出的张量形状为 (B,D)。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import dgl</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line">g1 = dgl.graph(([0, 1], [1, 0]))</span><br><span class="line">g1.ndata[&#x27;h&#x27;] = torch.tensor([1., 2.])</span><br><span class="line">g2 = dgl.graph(([0, 1], [1, 2]))</span><br><span class="line">g2.ndata[&#x27;h&#x27;] = torch.tensor([1., 2., 3.])</span><br><span class="line"></span><br><span class="line">dgl.readout_nodes(g1, &#x27;h&#x27;)</span><br><span class="line"># tensor([3.])  # 1 + 2</span><br><span class="line"></span><br><span class="line">bg = dgl.batch([g1, g2])</span><br><span class="line">dgl.readout_nodes(bg, &#x27;h&#x27;)</span><br><span class="line"># tensor([3., 6.])  # [1 + 2, 1 + 2 + 3]</span><br></pre></td></tr></table></figure><p>最后，批次化图中的每个节点或边特征张量均通过将所有图上的相应特征拼接得到。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bg.ndata[&#x27;h&#x27;]</span><br><span class="line"># tensor([1., 2., 1., 2., 3.])</span><br></pre></td></tr></table></figure><h3 id="模型定义"><a class="markdownIt-Anchor" href="#模型定义"></a> 模型定义<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id7">¶</a></h3><p>了解了上述计算规则后，用户可以定义一个非常简单的模型。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import dgl.nn.pytorch as dglnn</span><br><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line">class Classifier(nn.Module):</span><br><span class="line">    def __init__(self, in_dim, hidden_dim, n_classes):</span><br><span class="line">        super(Classifier, self).__init__()</span><br><span class="line">        self.conv1 = dglnn.GraphConv(in_dim, hidden_dim)</span><br><span class="line">        self.conv2 = dglnn.GraphConv(hidden_dim, hidden_dim)</span><br><span class="line">        self.classify = nn.Linear(hidden_dim, n_classes)</span><br><span class="line"></span><br><span class="line">    def forward(self, g, h):</span><br><span class="line">        # 应用图卷积和激活函数</span><br><span class="line">        h = F.relu(self.conv1(g, h))</span><br><span class="line">        h = F.relu(self.conv2(g, h))</span><br><span class="line">        with g.local_scope():</span><br><span class="line">            g.ndata[&#x27;h&#x27;] = h</span><br><span class="line">            # 使用平均读出计算图表示</span><br><span class="line">            hg = dgl.mean_nodes(g, &#x27;h&#x27;)</span><br><span class="line">            return self.classify(hg)</span><br></pre></td></tr></table></figure><h2 id="模型的训练"><a class="markdownIt-Anchor" href="#模型的训练"></a> 模型的训练<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id8">¶</a></h2><h3 id="数据加载"><a class="markdownIt-Anchor" href="#数据加载"></a> 数据加载<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id9">¶</a></h3><p>模型定义完成后，用户就可以开始训练模型。由于整图分类处理的是很多相对较小的图，而不是一个大图， 因此通常可以在随机抽取的小批次图上进行高效的训练，而无需设计复杂的图采样算法。</p><p>以下例子中使用了 <a href="https://docs.dgl.ai/guide_cn/data.html#guide-cn-data-pipeline">第4章：图数据处理管道</a> 中的整图分类数据集。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import dgl.data</span><br><span class="line">dataset = dgl.data.GINDataset(&#x27;MUTAG&#x27;, False)</span><br></pre></td></tr></table></figure><p>整图分类数据集里的每个数据点是一个图和它对应标签的元组。为提升数据加载速度， 用户可以调用GraphDataLoader，从而以小批次遍历整个图数据集。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from dgl.dataloading import GraphDataLoader</span><br><span class="line">dataloader = GraphDataLoader(</span><br><span class="line">    dataset,</span><br><span class="line">    batch_size=1024,</span><br><span class="line">    drop_last=False,</span><br><span class="line">    shuffle=True)</span><br></pre></td></tr></table></figure><p>训练过程包括遍历dataloader和更新模型参数的部分。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line"># 这仅是个例子，特征尺寸是7</span><br><span class="line">model = Classifier(7, 20, 5)</span><br><span class="line">opt = torch.optim.Adam(model.parameters())</span><br><span class="line">for epoch in range(20):</span><br><span class="line">    for batched_graph, labels in dataloader:</span><br><span class="line">        feats = batched_graph.ndata[&#x27;attr&#x27;]</span><br><span class="line">        logits = model(batched_graph, feats)</span><br><span class="line">        loss = F.cross_entropy(logits, labels)</span><br><span class="line">        opt.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br></pre></td></tr></table></figure><p>DGL实现了一个整图分类的样例： <a href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/gin">DGL的GIN样例</a>。 模型训练的代码请参考位于 <a href="https://github.com/dmlc/dgl/blob/master/examples/pytorch/gin/main.py">main.py</a> 源文件中的 <code>train</code> 函数。 模型实现位于 <a href="https://github.com/dmlc/dgl/blob/master/examples/pytorch/gin/gin.py">gin.py</a> ， 其中使用了更多的模块组件，例如使用 <code>dgl.nn.pytorch.GINConv</code> 模块作为图卷积层(DGL同样支持它在MXNet和TensorFlow后端里的实现)、批量归一化等。</p><h2 id="异构图上的整图分类模型的训练"><a class="markdownIt-Anchor" href="#异构图上的整图分类模型的训练"></a> 异构图上的整图分类模型的训练<a href="https://docs.dgl.ai/guide_cn/training-graph.html#id10">¶</a></h2><p>在异构图上做整图分类和在同构图上做整图分类略有不同。用户除了需要使用异构图卷积模块，还需要在读出函数中聚合不同类别的节点。</p><p>以下代码演示了如何对每种节点类型的节点表示取平均值并求和。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class RGCN(nn.Module):</span><br><span class="line">    def __init__(self, in_feats, hid_feats, out_feats, rel_names):</span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = dglnn.HeteroGraphConv(&#123;</span><br><span class="line">            rel: dglnn.GraphConv(in_feats, hid_feats)</span><br><span class="line">            for rel in rel_names&#125;, aggregate=&#x27;sum&#x27;)</span><br><span class="line">        self.conv2 = dglnn.HeteroGraphConv(&#123;</span><br><span class="line">            rel: dglnn.GraphConv(hid_feats, out_feats)</span><br><span class="line">            for rel in rel_names&#125;, aggregate=&#x27;sum&#x27;)</span><br><span class="line"></span><br><span class="line">    def forward(self, graph, inputs):</span><br><span class="line">        # inputs是节点的特征</span><br><span class="line">        h = self.conv1(graph, inputs)</span><br><span class="line">        h = &#123;k: F.relu(v) for k, v in h.items()&#125;</span><br><span class="line">        h = self.conv2(graph, h)</span><br><span class="line">        return h</span><br><span class="line"></span><br><span class="line">class HeteroClassifier(nn.Module):</span><br><span class="line">    def __init__(self, in_dim, hidden_dim, n_classes, rel_names):</span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">        self.rgcn = RGCN(in_dim, hidden_dim, hidden_dim, rel_names)</span><br><span class="line">        self.classify = nn.Linear(hidden_dim, n_classes)</span><br><span class="line"></span><br><span class="line">    def forward(self, g):</span><br><span class="line">        h = g.ndata[&#x27;feat&#x27;]</span><br><span class="line">        h = self.rgcn(g, h)</span><br><span class="line">        with g.local_scope():</span><br><span class="line">            g.ndata[&#x27;h&#x27;] = h</span><br><span class="line">            # 通过平均读出值来计算单图的表征</span><br><span class="line">            hg = 0</span><br><span class="line">            for ntype in g.ntypes:</span><br><span class="line">                hg = hg + dgl.mean_nodes(g, &#x27;h&#x27;, ntype=ntype)</span><br><span class="line">            return self.classify(hg)</span><br></pre></td></tr></table></figure><p>剩余部分的训练代码和同构图代码相同。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># etypes是一个列表，元素是字符串类型的边类型</span><br><span class="line">model = HeteroClassifier(10, 20, 5, etypes)</span><br><span class="line">opt = torch.optim.Adam(model.parameters())</span><br><span class="line">for epoch in range(20):</span><br><span class="line">    for batched_graph, labels in dataloader:</span><br><span class="line">        logits = model(batched_graph)</span><br><span class="line">        loss = F.cross_entropy(logits, labels)</span><br><span class="line">        opt.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DGL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAT浅入</title>
      <link href="/2023/10/10/AILearning/GNN/GAT%E6%B5%85%E5%85%A5/"/>
      <url>/2023/10/10/AILearning/GNN/GAT%E6%B5%85%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h2><p>在之前介绍的<a href="https://zhuanlan.zhihu.com/p/336195862">GraphSAGE</a>[3]文章中，通过融合当前节点的邻居节点来获得这个节点的特征表示，从而将GCN扩展到了归纳学习的领域。在GraphSAGE中，各个邻居节点被等同的看待，然而在实际场景中，不同的邻居节点可能对核心节点起着不同的作用。这一部分要介绍的GAT（Graph Attention Network）[1]就是通过自注意力机制（<a href="https://zhuanlan.zhihu.com/p/48508221">self-attention</a>）[2] 来对邻居节点进行聚合，实现了对不同邻居的权值自适应匹配，从而提高了模型的准确率。GAT在归纳学习和转导学习的任务中均取得了不错的效果。源代码参考：<a href="https://link.zhihu.com/?target=https%3A//github.com/PetarV-/GAT">https://github.com/PetarV-/GAT</a></p><h2 id="1-gat详解"><a class="markdownIt-Anchor" href="#1-gat详解"></a> 1. GAT详解</h2><p>和很多深度学习方法类似，GAT由若干个功能相同的block组成，这个block叫做Graph Attention Layer，首先我们先介绍Graph Attention Layer的结构。</p><h3 id="11-图注意力层"><a class="markdownIt-Anchor" href="#11-图注意力层"></a> 1.1 图注意力层</h3><p>图注意力层（Graph attention layer）的输入时节点的特征值 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7B%5Cmathbf%7Bh%7D%7D%3D%7B%5Cvec%7Bh%7D_1%2C+%5Cvec%7Bh%7D_2%2C+%5Ccdots%2C+%5Cvec%7Bh%7D_N%7D%2C+%5Cvec%7Bh%7D_i+%5Cin+%5Cmathbb%7BR%7D%5EF" alt="[公式]" /> ，其中 <img src="https://www.zhihu.com/equation?tex=N" alt="[公式]" /> 是节点的个数， <img src="https://www.zhihu.com/equation?tex=F" alt="[公式]" /> 是节点特征的维度。经过一个Graph Attention Layer后输出一个新的特征向量，假设这个特征向量的节点特征的维度为 <img src="https://www.zhihu.com/equation?tex=F'" alt="[公式]" /> （可以为任意值），这个特征可以表示为 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7B%5Cmathbf%7Bh'%7D%7D%3D%7B%5Cvec%7Bh'%7D_1%2C+%5Cvec%7Bh'%7D_2%2C+...%2C+%5Cvec%7Bh'%7D_N%7D%2C+%5Cvec%7Bh'%7D_i+%5Cin+%5Cmathbb%7BR%7D%5E%7BF'%7D" alt="[公式]" /> ，如图1所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241731141.jpeg" alt="img" />图1：GAT中的注意力层</p><p>这里使用Self-attention的目的就是提高 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7B%5Cmathbf%7Bh'%7D%7D" alt="[公式]" /> 的表达能力。在Graph Attention Layer中，首先使用一个权值矩阵 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BW%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7BF'+%5Ctimes+F%7D" alt="[公式]" /> 作用到每个节点，然后对每个节点使用self-attention来计算一个attention系数，这里使用的共享的self-attention机制，表示为 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]" /> ：</p><p><img src="https://www.zhihu.com/equation?tex=e_%7Bij%7D+%3D+a(%5Cmathbf%7BW%7D%5Cvec%7Bh_i%7D%2C+%5Cmathbf%7BW%7D%5Cvec%7Bh_j%7D)+%5Ctag1" alt="[公式]" /></p><p><img src="https://www.zhihu.com/equation?tex=+e_%7Bij%7D" alt="[公式]" /> 表示节点 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]" /> 对于节点 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]" /> 的重要性。理论上我们可以计算图中任意一个节点到中心节点的权值，GAT中为了简化计算，将节点限制在了中心节点的一跳邻居内，另外节点也将自己作为邻居节点考虑了进去。</p><p><img src="https://www.zhihu.com/equation?tex=a" alt="[公式]" /> 的选择有多种方式，论文中作者选择了一个参数为 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7Ba%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7B2F'%7D" alt="[公式]" /> 的单层前馈神经网络，然后使用了 <img src="https://www.zhihu.com/equation?tex=%5Ctext%7BLeakyReLU%7D" alt="[公式]" /> 做非线性化，因此 <img src="https://www.zhihu.com/equation?tex=e_%7Bij%7D" alt="[公式]" /> 可以写做：</p><p><img src="https://www.zhihu.com/equation?tex=+e_%7Bij%7D+%3D+%5Ctext%7BLeakyReLU%7D(%5Cvec%7B%5Cmathbf%7Ba%7D%7D%5ET%5Cleft%5B%5Cmathbf%7BW%7D+%5Cvec%7Bh%7D_i+%7C+%5Cmathbf%7BW%7D+%5Cvec%7Bh%7D_j%5Cright%5D)+%5Ctag2+" alt="[公式]" /></p><p><em>最后使用了</em> <img src="https://www.zhihu.com/equation?tex=%5Ctext%7Bsoftmax%7D" alt="[公式]" /> <em>对中心节点的邻居节点做了归一化：</em></p><p><img src="https://www.zhihu.com/equation?tex=+%5Calpha_%7Bij%7D+%3D+%5Ctext%7Bsoftmax%7Dj(e_%7Bij%7D)+%3D+%5Cfrac%7B%5Cexp(e_%7Bij%7D)%7D%7B%5Csum_%7Bk%5Cin%5Cmathcal%7BN%7Di%7D%5Cexp(e_%7Bik%7D)%7D+%5Ctag3" alt="[公式]" /></p><p>最终通过对输入特征的加权得到输出特征 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7Bh%7D_i'" alt="[公式]" /> ：</p><p><img src="https://www.zhihu.com/equation?tex=+%5Cvec%7Bh%7D_i'+%3D+%5Csigma%5Cleft(+%5Csum_%7Bj+%5Cin+%5Cmathcal%7BN%7D_i%7D+%5Calpha_%7Bij%7D+%5Cvec%7Bh%7D_j%5Cright)+%5Ctag4" alt="[公式]" /></p><p>在源码中，作者添加了Dropout以及残差结构的超参供结构调整，这一部分的核心代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">attn_head</span>(<span class="params">seq, out_sz, bias_mat, activation, in_drop=<span class="number">0.0</span>, coef_drop=<span class="number">0.0</span>, residual=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;my_attn&#x27;</span>):</span><br><span class="line">        <span class="keyword">if</span> in_drop != <span class="number">0.0</span>:</span><br><span class="line">            seq = tf.nn.dropout(seq, <span class="number">1.0</span> - in_drop)</span><br><span class="line">        seq_fts = tf.layers.conv1d(seq, out_sz, <span class="number">1</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># simplest self-attention possible</span></span><br><span class="line">        f_1 = tf.layers.conv1d(seq_fts, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        f_2 = tf.layers.conv1d(seq_fts, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        logits = f_1 + tf.transpose(f_2, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">        coefs = tf.nn.softmax(tf.nn.leaky_relu(logits) + bias_mat)</span><br><span class="line">        <span class="keyword">if</span> coef_drop != <span class="number">0.0</span>:</span><br><span class="line">            coefs = tf.nn.dropout(coefs, <span class="number">1.0</span> - coef_drop)</span><br><span class="line">        <span class="keyword">if</span> in_drop != <span class="number">0.0</span>:</span><br><span class="line">            seq_fts = tf.nn.dropout(seq_fts, <span class="number">1.0</span> - in_drop)</span><br><span class="line">        vals = tf.matmul(coefs, seq_fts)</span><br><span class="line">        ret = tf.contrib.layers.bias_add(vals)</span><br><span class="line">        <span class="comment"># residual connection</span></span><br><span class="line">        <span class="keyword">if</span> residual:</span><br><span class="line">            <span class="keyword">if</span> seq.shape[-<span class="number">1</span>] != ret.shape[-<span class="number">1</span>]:</span><br><span class="line">                ret = ret + conv1d(seq, ret.shape[-<span class="number">1</span>], <span class="number">1</span>) <span class="comment"># activation</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ret = ret + seq</span><br><span class="line">        <span class="keyword">return</span> activation(ret)  <span class="comment"># activation</span></span><br></pre></td></tr></table></figure><p>我们对上面的重点几行代码进行解读。首先是这个函数的三个输入：</p><ul><li><code>seq</code>: 输入节点的特征矩阵，维度为<code>[num_graph, num_node, fea_size]</code>；</li><li><code>out_sz</code>: 输出特征的维度，也就是 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BW%7D%5Cvec%7Bh_i%7D" alt="[公式]" /> 的维度；</li><li><code>bias_mat</code>：图经过过变换后的掩码矩阵，维度为<code>[num_node, num_node]</code>。</li></ul><p>第5行是对原始的节点特征<code>seq</code>利用卷积核大小为1的一维卷积得到维度为<code>[num_graph, num_node, out_sz]</code>的特征向量。</p><p>接着第7，8行对得到的<code>seq_fts</code>分别使用两个独立的卷积核大小为1的卷积核进行一维卷积，得到节点本身的投影<code>f_1</code>以及其邻居的投影<code>f_2</code>。这里对应的是公式1中的 <img src="https://www.zhihu.com/equation?tex=a(%5Cmathbf%7BW%7D%5Cvec%7Bh_i%7D%2C+%5Cmathbf%7BW%7D%5Cvec%7Bh_j%7D)" alt="[公式]" /> 。</p><p>第9行是使用广播机制将<code>f_2</code>转置后与<code>f_1</code>叠加，得到注意力矩阵 <img src="https://www.zhihu.com/equation?tex=%5Cvec%7B%5Cmathbf%7Ba%7D%7D%5ET%5Cleft%5B%5Cmathbf%7BW%7D+%5Cvec%7Bh%7D_i+%7C+%5Cmathbf%7BW%7D+%5Cvec%7Bh%7D_j%5Cright%5D" alt="[公式]" /> 。</p><p>最后通过第10行的<code>softmax</code>归一化便得到了注意力的权重。需要注意的是在计算<code>softmax</code>之前加了一个<code>bias_mat</code>矩阵，那么这个<code>bias_mat</code>是个什么东西呢？它的作用是让非互为邻居的注意力 <img src="https://www.zhihu.com/equation?tex=e_%7Bij%7D" alt="[公式]" /> 不要进入softmax计算。</p><p>当进行权值加权时，一个最简单的思想便是使用一个只有0，1的邻接矩阵和得到的矩阵进行单位乘的运算。但是因为softmax有exp指数运算，这种运算方式会有问题。例如一个节点的邻接向量为 <img src="https://www.zhihu.com/equation?tex=%5B1%2C+1%2C+0%5D" alt="[公式]" /> ，权值向量为 <img src="https://www.zhihu.com/equation?tex=%5B0.5%2C+1.2%2C+0.1%5D" alt="[公式]" /> ，经过mask得到 <img src="https://www.zhihu.com/equation?tex=%5B0.5%2C+1.2%2C+0%5D" alt="[公式]" /> ，再送入到softmax归一化，变为 <img src="https://www.zhihu.com/equation?tex=%5Be%5E%7B0.5%7D%2C+e%5E%7B1.2%7D%2C+e%5E0%5D" alt="[公式]" /> ，这里需要被mask掉的1.2变成了 <img src="https://www.zhihu.com/equation?tex=e%5E0%3D1" alt="[公式]" /> 。这个非邻居节点还是参与到了权值的计算。所以我们需要将非邻居节点的权值变为0，即加上了<code>bias_mat</code>矩阵。</p><p>这个矩阵的生成方式为<code>utils/process.py</code>的<code>adj_to_bias</code>函数，这个函数的解析见下面代码的注释部分：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adj_to_bias</span>(<span class="params">adj, sizes, nhood=<span class="number">1</span></span>):</span><br><span class="line">    nb_graphs = adj.shape[<span class="number">0</span>] <span class="comment"># num_graph个图</span></span><br><span class="line">    mt = np.empty(adj.shape) <span class="comment"># 输出矩阵的形状和adj相同</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 图g的转换</span></span><br><span class="line">    <span class="keyword">for</span> g <span class="keyword">in</span> <span class="built_in">range</span>(nb_graphs):</span><br><span class="line">        mt[g] = np.eye(adj.shape[<span class="number">1</span>]) <span class="comment"># 与g形状相同的对角矩阵</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(nhood): <span class="comment"># 通过self-loop构建K阶邻接矩阵，即A^(K),这里K=1</span></span><br><span class="line">            mt[g] = np.matmul(mt[g], (adj[g] + np.eye(adj.shape[<span class="number">1</span>])))</span><br><span class="line">        <span class="comment"># 大于0的置1，小于等于0的保持不变</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(sizes[g]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(sizes[g]):</span><br><span class="line">                <span class="keyword">if</span> mt[g][i][j] &gt; <span class="number">0.0</span>:</span><br><span class="line">                    mt[g][i][j] = <span class="number">1.0</span></span><br><span class="line">    <span class="comment"># mt中1的位置为0，位置为0的返回很小的负数-1e9</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1e9</span> * (<span class="number">1.0</span> - mt)</span><br></pre></td></tr></table></figure><h3 id="12-多头图注意力层"><a class="markdownIt-Anchor" href="#12-多头图注意力层"></a> 1.2 多头图注意力层</h3><p>为了提高注意力机制的泛化能力，GAT选择使用了多头注意力层，即使用K组相互独立的1.1中的单头注意力层，然后将它们的结果拼接在一起，如图2所示。</p><p><img src="https://www.zhihu.com/equation?tex=+%5Cmathbf%7Bh%7D'_i+%3D+%7C+%5E+K+_+%7Bk%3D1%7D+%5Csigma%5Cleft(+%5Csum%7Bv_j+%5Cin+%5Ctilde%7B%5Cmathcal%7BN%7D%7D(v_i)%7D+%5Calpha_%7Bij%7D%5E%7B(k)%7D%5Cmathbf%7BW%7D%5E%7Bk%7D+%5Cmathbf%7Bh%7D_j%5Cright)+%5Ctag5" alt="[公式]" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241731953.jpeg" alt="img" />图2：GAT中的多头注意力层</p><p>其中 <img src="https://www.zhihu.com/equation?tex=%7C" alt="[公式]" /> 表示拼接操作， <img src="https://www.zhihu.com/equation?tex=%5Calpha_%7Bij%7D%5E%7B(k)%7D" alt="[公式]" /> 表示第 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]" /> 组注意力机制计算出来的权重系数， <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BW%7D%5E%7B(k)%7D" alt="[公式]" /> 是第 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]" /> 个模块的权重系数。为了减少特征向量的维度，我们也可以使用平均操作代替拼接操作，如式（6）。在图2中，不同颜色的箭头代表了不同的注意力头，从图中我们可以看出 <img src="https://www.zhihu.com/equation?tex=K%3D3" alt="[公式]" /> 。为了增加多头注意力层的表达能力，我们可以使用不同形式的注意力机制。</p><p><img src="https://www.zhihu.com/equation?tex=%5Cvec%7Bh%7D_i'+%3D+%5Csigma+%5Cleft(+%5Cfrac1K+%5Csum_%7Bk%3D1%7D%5EK+%5Csum_%7Bj+%5Cin+%5Cmathcal%7BN%7Dj%7D+%5Calpha_%7Bij%7D%5Ek+%5Cmathbf%7BW%7D%5Ek+%5Cvec%7Bh%7D_j+%5Cright)+%5Ctag6" alt="[公式]" /></p><p>在作者本人的博客中[4]，它提到了在Attention的权重系数 <img src="https://www.zhihu.com/equation?tex=%5Calpha_%7Bij%7D" alt="[公式]" /> 上施加Dropout[5]将大大提升模型的泛化能力，尤其是数据集比较小的时候。这种方式本质上其实就是对邻居节点的随机采样。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">inference</span>(<span class="params">inputs, nb_classes, nb_nodes, training, attn_drop, ffd_drop, bias_mat, hid_units, n_heads, activation=tf.nn.elu, residual=<span class="literal">False</span></span>):</span><br><span class="line">    attns = []</span><br><span class="line">    <span class="comment"># GAT中预设了8层attention head</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_heads[<span class="number">0</span>]):</span><br><span class="line">        attns.append(layers.attn_head(inputs, bias_mat=bias_mat,</span><br><span class="line">            out_sz=hid_units[<span class="number">0</span>], activation=activation,</span><br><span class="line">            in_drop=ffd_drop, coef_drop=attn_drop, residual=<span class="literal">False</span>))</span><br><span class="line">    h_1 = tf.concat(attns, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 隐藏层，hid_units表示每一层attention head中的隐藏单元个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(hid_units)):</span><br><span class="line">        h_old = h_1</span><br><span class="line">        attns = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_heads[i]):</span><br><span class="line">            attns.append(layers.attn_head(h_1, bias_mat=bias_mat,</span><br><span class="line">                out_sz=hid_units[i], activation=activation,</span><br><span class="line">                in_drop=ffd_drop, coef_drop=attn_drop, residual=residual))</span><br><span class="line">        h_1 = tf.concat(attns, axis=-<span class="number">1</span>)</span><br><span class="line">    out = []</span><br><span class="line">    <span class="comment"># 输出层</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_heads[-<span class="number">1</span>]):</span><br><span class="line">        out.append(layers.attn_head(h_1, bias_mat=bias_mat,</span><br><span class="line">            out_sz=nb_classes, activation=<span class="keyword">lambda</span> x: x,</span><br><span class="line">            in_drop=ffd_drop, coef_drop=attn_drop, residual=<span class="literal">False</span>))</span><br><span class="line">    logits = tf.add_n(out) / n_heads[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure><p>推理模块由3个循环组成，第一个循环是对attention head的聚合，输入维度是<code>[batch_size, num_node, fea_size]</code>，每个注意力头的输出维度为<code>[batch_size, num_node, out_sz]</code>，将所有的节点聚合，得到的输出特征维度为<code>[batch_size, num_node, out_sz * 8]</code>。第二个循环是中间层的更新，层数是<code>len(hid_units)-1</code>，第 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]" /> 层有<code>n_heads[i]</code>个注意力头。最后一个循环是输出层，为了使输出维度是<code>[batch_size, num_node, nb_classes]</code>，因此使用了平均的聚合方式。</p><h2 id="2-gat的属性"><a class="markdownIt-Anchor" href="#2-gat的属性"></a> 2. GAT的属性</h2><p>根据我们对GAT算法的分析，我们可以总结出GAT的下述属性：</p><ul><li><strong>高效</strong>：因为注意力层的参数对于整张图是共享的，因此注意力机制的权值可以并行计算，同样节点的属性值也可以并行计算。同时因为计算中心节点的特征只需要遍历其一阶邻居节点，这也大幅减少了搜索节点需要的时间。</li><li><strong>低存储</strong>：可以使用稀疏矩阵对GAT的图进行存储，因此需要的最大存储空间为 <img src="https://www.zhihu.com/equation?tex=O(V%2BE)" alt="[公式]" /> 。同时因为GAT使用了参数共享的方式，也大幅减少了存储计算参数需要占用的存储空间。</li><li><strong>归纳学习</strong>：因为GAT是基于邻居节点的计算方式，因此也是可归纳的（Inductive）。</li><li><strong>全图访问</strong>：GraphSAGE的采样方式是采样固定数量的邻居，而GAT是采样所有的邻居节点，得到的特征更稳定以及更具表征性。</li></ul><h2 id="3-总结"><a class="markdownIt-Anchor" href="#3-总结"></a> 3. 总结</h2><p>这篇文章介绍了一个基于Attention机制的图神经网络，和NLP中的Attention机制类似，GAT的Attention也是非常直观的。同GraphSAGE一样，GAT也是一个基于空域的GNN，而且是可以进行归纳学习的。GAT的一个问题是因为只归纳了一阶邻居，导致GAT的感受野必须依赖非常深的网络才能扩展到很大，为了解决这个问题，作者在源码中也添加了一个残差机制。</p><h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> reference</h2><p>[1] Veličković, Petar, et al. “Graph attention networks.” <em>arXiv preprint arXiv:1710.10903</em> (2017).</p><p>[2] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need [C]//Advances in Neural Information Processing Systems. 2017: 5998-6008.</p><p>[3] Hamilton, Will, Zhitao Ying, and Jure Leskovec. “Inductive representation learning on large graphs.” <em>Advances in neural information processing systems</em>. 2017.</p><p>[4] <a href="https://link.zhihu.com/?target=https%3A//petar-v.com/GAT/">https://petar-v.com/GAT/</a></p><p>[5] Srivastava, Nitish, et al. “Dropout: a simple way to prevent neural networks from overfitting.” <em>The journal of machine learning research</em> 15.1 (2014): 1929-1958.</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GCN,GAT,GGNN</title>
      <link href="/2023/10/10/AILearning/GNN/GCN%20GAT%20GGNN/"/>
      <url>/2023/10/10/AILearning/GNN/GCN%20GAT%20GGNN/</url>
      
        <content type="html"><![CDATA[<h1 id="gcngatggnn"><a class="markdownIt-Anchor" href="#gcngatggnn"></a> GCN,GAT,GGNN</h1><p>GCN（Graph Convolutional Network），GAT（Graph Attention Network）和GGNN（Graph Gated Neural Network）都是用于图结构数据的深度学习模型，但它们在架构和工作原理上有一些异同点。下面是它们的异同点以及各自的优点和缺点：</p><ul><li><p>异同点：</p><p>架构：GCN和GAT是基于图卷积的模型，而GGNN是基于循环神经网络的模型。 模型目标：GCN和GAT主要用于节点级别的任务，如节点分类和节点属性预测。GGNN主要用于图级别的任务，如图分类和图生成。 信息传播方式：GCN使用固定的邻居聚集方式传播信息，GAT使用自适应的注意力机制对邻居节点进行加权聚合，GGNN通过循环神经网络在节点之间传递信息。 参数共享：GCN和GAT在不同节点之间共享参数，而GGNN在循环过程中使用不同的参数。 可扩展性：GAT和GGNN在处理大型图时可能更具可扩展性，因为它们可以根据需要选择性聚合邻居节点的信息。</p></li><li><p>优点和缺点：</p><p>GCN：</p><p>优点：简单且易于实现，具有较好的可解释性，适用于节点级别的任务，能够捕捉节点之间的局部结构信息。 缺点：在处理大型图时可能存在计算和存储的挑战，对于全局图结构的建模能力有限</p><p>GAT：</p><p>优点：能够自适应地学习节点之间的关系权重，具有更强的建模能力，适用于节点级别的任务，对于稀疏图效果较好。 缺点：计算复杂度较高，对于大型图可能存在挑战。</p><p>GGNN：</p><p>优点：能够在循环过程中对节点之间的信息进行迭代传递，适用于图级别的任务，对于具有长程依赖关系的图结构效果较好。 缺点：对于每个节点的信息传播迭代次数有限，可能较难捕捉全局图结构信息，对于大型图可能存在计算和存储的挑战。</p></li></ul><p><a href="https://github.com/calebmah/ggnn.pytorch">https://github.com/calebmah/ggnn.pytorch</a></p><p><a href="https://blog.csdn.net/Orangetc/article/details/115986351">门控图神经网络（GGNN）及代码分析_Orangetc的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/weixin_43714954/article/details/100154348">门控图神经网络及PyTorch实现_门控图序列神经网络-CSDN博客</a></p><p><a href="https://zhuanlan.zhihu.com/p/135366196">图神经网络入门（二）GRN图循环网络</a></p><p><strong><a href="https://docs.dgl.ai/en/latest/api/python/graph.html">https://docs.dgl.ai/en/latest/api/python/graph.html</a></strong></p><p><a href="https://docs.dgl.ai/guide_cn/index.html">用户指南 — DGL 1.1.2post1 documentation</a></p><h2 id="零-消息传递"><a class="markdownIt-Anchor" href="#零-消息传递"></a> <strong>零、消息传递</strong></h2><p>消息传递是指在<a href="https://so.csdn.net/so/search?q=%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020">图神经网络</a>（Graph Neural Network，GNN）中，从节点向邻居节点传递信息的过程。这个过程通常被称为“<strong>消息传递步骤</strong>”或“信息传播步骤”。</p><p>在消息传递步骤中，每个节点将自身的特征和邻居节点的特征合并，并计算出一个新的节点表示，然后将这个新的节点表示传递给下一个消息传递步骤或最终的输出层。这个过程通常由以下几个步骤组成：</p><ol><li><strong>聚合邻居节点的信息</strong>：对于每个节点，聚合其邻居节点的信息。这个过程通常可以通过计算邻居节点特征的平均值、最大值、加权平均值等方式实现。</li><li><strong>更新节点的表示</strong>：使用聚合后的邻居节点信息和当前节点自身的特征，计算出一个新的节点表示。这个过程通常可以通过一个多层感知机（MLP）来实现，其中MLP的输入是当前节点的特征和聚合后的邻居节点信息，输出是一个新的节点表示。</li><li><strong>更新图中所有节点的表示</strong>：对于图中的每个节点，都执行上述两个步骤，以更新它们的节点表示。这个过程可以通过并行计算来加速。</li><li><strong>后续处理步骤</strong>：在更新完所有节点的表示后，可以执行一些可选的后处理步骤，如归一化、dropout等操作，以进一步提高模型的性能。</li></ol><p>总体而言，消息传递步骤是<a href="https://so.csdn.net/so/search?q=GNN&amp;spm=1001.2101.3001.7020">GNN</a>中非常重要的一步，它通过邻居节点之间的信息传递来捕捉节点之间的关系，从而提高模型的性能。在实际应用中，不同的GNN模型可以使用不同的消息传递方式和后处理步骤，以适应不同的任务和数据集。</p><h2 id="一-ggnn门控图神经网络"><a class="markdownIt-Anchor" href="#一-ggnn门控图神经网络"></a> <strong>一、GGNN（门控图神经网络）</strong></h2><p>GGNN，全称Gated Graph Sequence Neural Networks，中文名为“门控图神经网络”。GGNN与通常的图神经网络网络不同之处在于<strong>其消息传递步骤中使用了GRU单元。具体来说，在GGNN中，每个节点在每一次迭代时都会接收来自邻居节点的消息，这些消息会经过GRUcell进行整合和更新</strong>。在每次迭代之后，节点的表示也会根据当前状态进行更新。GRUcell在这个过程中扮演了重要的角色，<strong>通过门控机制来控制信息的流动和筛选</strong>。</p><p>以下为<a href="https://so.csdn.net/so/search?q=GRU&amp;spm=1001.2101.3001.7020">GRU</a>简介：</p><p>GRU（Gated Recurrent Unit）是一种递归神经网络（RNN）的变体，用于处理序列数据。与标准的RNN相比，GRU具有更少的参数和更好的性能。GRU中的核心组件是GRU单元，它是一种门控单元。</p><p>GRU单元包含三个门控：重置门（reset gate）、更新门（update gate）和候选隐藏状态（candidate hidden state）。每个门控都是一个向量，其中每个元素都是介于0和1之间的实数，表示门控的打开和关闭程度。</p><p>在每个时间步，GRU单元会根据当前输入、前一时刻的隐藏状态和当前时刻的候选隐藏状态来计算更新门和重置门，从而更新当前时刻的隐藏状态。</p><p>同时，GRU具有<strong>记忆性</strong>，GRU中的重置门（reset gate）和更新门（update gate）能够控制前一时刻的状态是否需要被遗忘或更新，从而实现记忆功能。当重置门打开时，前一时刻的状态可以被快速遗忘，而当更新门打开时，前一时刻的状态可以被更新和传递到当前时刻。这种门控机制能够有效地处理梯度消失和梯度爆炸问题，从而能够更好地捕捉长序列的依赖关系和保留历史信息，实现记忆功能。<strong>因此，GRU具有记忆性，能够在处理时序数据时捕捉时间信息，并根据时间序列的演化变化自适应地更新和维护历史状态信息。</strong></p><p>使用GRUcell来实现消息传递步骤具有以下优势：</p><ol><li><strong>可以学习不同节点之间的相互关系</strong>。GRUcell通过门控机制来控制信息的流动和筛选，能够学习不同节点之间的相互关系，从而更好地捕捉节点之间的依赖关系。</li><li><strong>具有时间递归性质</strong>。GRUcell能够在每个迭代步骤中更新节点的状态，从而具有时间递归性质。这种递归性质能够让模型<strong>更好地处理图中的时序信息</strong>。</li><li><strong>可以处理变长输入</strong>。GRUcell能够处理变长输入，可以自适应地对每个节点的输入进行处理，从而能够处理不同大小和形状的图数据。</li><li><strong>计算效率高</strong>。GRUcell具有较少的参数量和计算量，能够在较短的时间内完成消息传递步骤的计算。这种计算效率在处理大规模图数据时特别有优势。</li></ol><p>如果将其应用于<strong>入侵检测系统</strong>，由于GRU具有记忆性，GGNN具有时间递归性质，能够在每个迭代步骤中更新节点的状态和特征表示，从而<strong>能够捕捉网络流的时间演化特征，能够有效地利用历史信息</strong>，提高入侵检测的准确性和实用性。</p><h2 id="二-gcn图卷积神经网络"><a class="markdownIt-Anchor" href="#二-gcn图卷积神经网络"></a> <strong>二、GCN（图卷积神经网络）</strong></h2><p>相比于普通的图神经网络，GCN能够利用节点特征和邻居特征、保留全局结构信息、具有较好的可扩展性、适用于半监督和无监督学习、具有较好的鲁棒性等特点，能够更好地处理图数据的任务。</p><p>GCN通过图卷积操作，能够利用节点的特征和邻居的特征进行信息传递和特征更新。这种方式能够在一定程度上<strong>捕捉节点之间的结构和依赖关系</strong>，从而更好地表示节点的特征。</p><p>GCN能够<strong>保留整个图的全局结构信息</strong>，从而能够更好地捕捉节点之间的关系和依赖关系。这种全局结构信息的保留能够使得模型更加稳定，同时也能够避免过度拟合。</p><p>GCN具有<strong>较好的鲁棒性</strong>，能够在图数据中处理缺失节点、噪声和异常节点等情况。这得益于GCN中的图卷积操作和正则化机制，能够在一定程度上平滑节点的特征，并对模型进行正则化，从而提高模型的鲁棒性。</p><p><strong>有关GCN的构建：</strong></p><ul><li>图卷积操作：GCN中最重要的组件是图卷积操作，用于在节点之间传递信息以更新它们的表示向量。这种操作使用图的邻接矩阵来计算每个节点的聚合向量，以及一个可学习的权重矩阵来将节点表示向量映射到一个新的表示空间中。</li><li>节点特征表示：GCN通常假设每个节点都具有一个固定的特征向量，作为节点的初始表示。在某些情况下，这些特征向量可能是从外部输入的，而在其他情况下，可以通过对节点的邻居节点特征向量进行聚合来计算每个节点的特征向量。</li><li>图的规范化：为了在GCN中执行有效的卷积操作，需要对邻接矩阵进行规范化。通常使用对称规范化或左规范化来保持特定性质，例如捕捉节点度数的影响，或者防止梯度爆炸或消失问题。</li><li>层间连接方式：在普通的图神经网络中，层间节点的连接通常是全连接的，即每个节点都与前一层中的所有节点连接。而在GCN中，每个节点的连接只限于其邻居节点，这有助于减少参数量，并更好地捕捉图的局部结构。</li><li>激活函数：在普通的图神经网络中，通常使用ReLU作为激活函数。在GCN中，由于传统的ReLU无法保持特定性质，例如正则化性质和图形同构性，因此通常使用针对图卷积操作的特定激活函数，例如GraphSAGE中使用的Maxpooling。</li></ul><hr /><p>相比于普通图神经网络，图卷积神经网络（GCN）应用于<strong>入侵检测系统</strong>的优势主要为拥有<strong>强大的建模能力</strong>，能够有效地捕捉节点和边的关系，并从整体上理解网络拓扑结构和演化过程。在入侵检测系统中，网络流量数据可以看作是一个复杂的图结构，GCN能够更好地建模这种图形结构，从而提高检测准确率和性能。</p><p>GCN能够对每个节点或边的权重进行解释，从而<strong>提高了入侵检测的可解释性和可理解性</strong>。在入侵检测中，对于每个节点或边的权重解释，有助于理解哪些节点或边对于攻击检测有更重要的贡献。</p><p>GCN在训练过程中使用图结构信息，这使得它<strong>对于图形结构的变化或攻击具有一定的稳健性</strong>，这是普通神经网络所没有的。这种稳健性在入侵检测系统中是非常重要的，因为攻击者可能会试图欺骗检测系统，通过修改流量数据中的节点或边来逃避检测。</p><p>GCN能够在多个不同网络流量数据集之间进行<strong>数据共享</strong>，这有助于提高模型的泛化能力和效率，并降低数据量的需求。这在实际应用中非常重要，因为安全数据集通常是非常稀缺和昂贵的。</p><h2 id="三-gat图注意力神经网络"><a class="markdownIt-Anchor" href="#三-gat图注意力神经网络"></a> <strong>三、GAT（图注意力神经网络）</strong></h2><p>相比于普通GNN，GAT引入了<strong>注意力机制和非线性特征转换</strong>，使得网络更加<strong>灵活和可解释</strong>，能够更好地捕捉节点之间的关系，并且具有更好的<strong>泛化能力和表达能力</strong>。这些特点使得GAT在很多应用中都能取得较好的表现，例如推荐系统、社交网络分析、图像分类和语音识别等领域。其特点具体如下：</p><ol><li>细粒度的节点注意力：与GNN只考虑节点的局部信息不同，GAT引入了基于注意力机制的节点表示方法，通过学习每个节点之间的权重，使得每个节点都能够更好地捕捉周围节点的信息。</li><li>多头注意力机制：GAT引入了多头注意力机制，可以让不同的头关注不同的节点和边，从而提高了网络的泛化能力和表达能力。</li><li>每层特征重用：在GAT中，每一层的特征都能够被下一层的注意力机制所重用，从而增强了模型的表达能力和稳定性。</li><li>非线性特征转换：GAT在每个注意力机制之前引入了非线性的特征转换，从而使得网络更好地适应不同的数据分布和特征表达。</li></ol><hr /><p>在实际实现中，我们通常将特征转换函数、注意力函数和聚合函数定义为可训练的参数，使用梯度下降算法来优化参数。同时，为了提高模型的泛化能力，我们可以使用正则化方法，如Dropout等。</p><ol><li>定义特征转换函数：对于每个节点的特征，我们需要将其转换为一个低维度的向量表示。可以采用线性变换（即矩阵乘法）或者多层感知器（MLP）来进行特征转换。</li><li>定义注意力函数：注意力函数是GAT的核心，它根据节点之间的关系和特征权重计算出节点之间的相对重要性，从而为节点分配不同的权重。注意力函数可以采用单头或者多头注意力机制，其中每个头都有自己的特征转换函数和权重矩阵。</li><li>定义聚合函数：聚合函数用于将周围节点的信息汇总到当前节点的表示中，常用的聚合函数有加和、平均值和最大值等。</li><li>定义输出层：将聚合函数得到的节点表示输入到输出层，常用的输出层包括全连接层和Softmax层等。</li></ol><p>需要注意的是，GAT适用于处理稠密图，因此在使用GAT时需要<strong>将稀疏的邻接矩阵转化为稠密矩阵</strong>，这可以使用基于邻接矩阵的度矩阵和归一化矩阵来实现。</p><hr /><p>图注意力神经网络在处理图数据方面具有明显的优势，尤其在<strong>入侵检测系统</strong>中应用能够更好地<strong>捕捉网络流的时间演化特征和异常事件</strong>，提高网络的检测准确率和效率。</p><p>GAT采用自适应的注意力机制来为每个节点分配不同的权重，可以针对每个节点选择最有用的邻居节点来传递信息。这种注意力机制能够充分利用图数据中的信息，从而更加准确地捕捉网络中的时间和空间演化特征。</p><p>由于GAT使用邻接矩阵的度矩阵和归一化矩阵来处理稀疏矩阵，因此可以处理不同规模和稀疏性的图数据。这使得GAT在处理大规模网络数据时具有较高的效率和准确性。</p><p>能够学习到节点之间的交互关系：GAT中的注意力机制能够从节点的特征和其邻居节点的关系中学习到节点之间的交互关系。这有助于更好地捕捉网络中的演化特征和异常事件。</p><p>GAT支持多头注意力机制，可以在不同的注意力头之间共享节点表示。这有助于提高模型的泛化能力和学习能力，并能够更好地捕捉网络中的复杂关系。</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GCN浅入</title>
      <link href="/2023/10/10/AILearning/GNN/GCN%E6%B5%85%E5%85%A5/"/>
      <url>/2023/10/10/AILearning/GNN/GCN%E6%B5%85%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="gcn"><a class="markdownIt-Anchor" href="#gcn"></a> GCN</h1><p>GCN的公式看起来还是有点吓人的，论文里的公式更是吓破了我的胆儿。但后来才发现，其实90%的内容根本不必理会，只是为了从数学上严谨地把事情给讲清楚，但是完全不影响我们的理解，尤其对于我这种“追求直觉，不求甚解”之人。</p><p>下面进入正题，我们直接看看GCN的核心部分是什么样子：</p><p>假设我们手头有一批图数据，其中有N个节点（node），每个节点都有自己的特征，我们设这些节点的特征组成一个N×D维的矩阵X，然后各个节点之间的关系也会形成一个N×N维的矩阵A，也称为邻接矩阵（adjacency matrix）。X和A便是我们模型的输入。</p><p>GCN也是一个神经网络层，它的层与层之间的传播方式是：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730114.png" alt="img" /></p><p>这个公式中：</p><ul><li>A波浪=A+I，I是单位矩阵</li><li>D波浪是A波浪的度矩阵（degree matrix），公式为</li><li>H是每一层的特征，对于输入层的话，H就是X</li><li>σ是非线性激活函数</li></ul><p>我们先不用考虑为什么要这样去设计一个公式。我们现在只用知道：</p><p>这个部分，是可以事先算好的，因为D波浪由A计算而来，而A是我们的输入之一。</p><p>所以对于不需要去了解数学原理、只想应用GCN来解决实际问题的人来说，你只用知道：哦，这个GCN设计了一个牛逼的公式，用这个公式就可以很好地提取图的特征。这就够了，毕竟不是什么事情都需要知道内部原理，这是根据需求决定的。</p><p>为了直观理解，我们用论文中的一幅图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730115.jpg" alt="img" /></p><p>上图中的GCN输入一个图，通过若干层GCN每个node的特征从X变成了Z，但是，无论中间有多少层，node之间的连接关系，即A，都是共享的。</p><p>假设我们构造一个两层的GCN，激活函数分别采用ReLU和Softmax，则整体的正向传播的公式为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730119.png" alt="img" /></p><p>最后，我们针对所有带标签的节点计算cross entropy损失函数：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730118.png" alt="img" /></p><p>就可以训练一个node classification的模型了。由于即使只有很少的node有标签也能训练，作者称他们的方法为半监督分类。</p><p>当然，你也可以用这个方法去做graph classification、link prediction，只是把损失函数给变化一下即可。</p><p>三、GCN 为什么是这个样子</p><p>我前后翻看了很多人的解读，但是读了一圈，最让我清楚明白为什么GCN的公式是这样子的居然是作者Kipf自己的博客：<a href="http://tkipf.github.io/graph-convolutional-networks/">http://tkipf.github.io/graph-convolutional-networks/</a> 推荐大家一读。</p><p>作者给出了一个由简入繁的过程来解释：</p><p>我们的每一层GCN的输入都是邻接矩阵A和node的特征H，那么我们直接做一个内积，再乘一个参数矩阵W，然后激活一下，就相当于一个简单的神经网络层嘛，是不是也可以呢？</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730123.png" alt="img" /></p><p>实验证明，即使就这么简单的神经网络层，就已经很强大了。这个简单模型应该大家都能理解吧，这就是正常的神经网络操作。</p><p>但是这个简单模型有几个局限性：</p><ul><li>只使用A的话，由于A的对角线上都是0，所以在和特征矩阵H相乘的时候，只会计算一个node的所有邻居的特征的加权和，该node自己的特征却被忽略了。因此，我们可以做一个小小的改动，给A加上一个单位矩阵 I ，这样就让对角线元素变成1了。</li><li>A是没有经过归一化的矩阵，这样与特征矩阵相乘会改变特征原本的分布，产生一些不可预测的问题。所以我们对A做一个标准化处理。首先让A的每一行加起来为1，我们可以乘以一个D的逆，D就是度矩阵。我们可以进一步把D的拆开与A相乘，得到一个对称且归一化的矩阵 ：。</li></ul><p>通过对上面两个局限的改进，我们便得到了最终的层特征传播公式：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730124.png" alt="img" /></p><p>其中</p><p>公式中的与对称归一化拉普拉斯矩阵十分类似，而在谱图卷积的核心就是使用对称归一化拉普拉斯矩阵，这也是GCN的卷积叫法的来历。原论文中给出了完整的从谱卷积到GCN的一步步推导，我是看不下去的，大家有兴趣可以自行阅读。</p><p>。</p><p>四、GCN 有多牛</p><p>在看了上面的公式以及训练方法之后，我并没有觉得GCN有多么特别，无非就是一个设计巧妙的公式嘛，也许我不用这么复杂的公式，多加一点训练数据或者把模型做深，也可能达到媲美的效果呢。</p><p>但是一直到我读到了论文的附录部分，我才顿时发现：GCN原来这么牛啊！</p><p>为啥呢？</p><p>因为即使不训练，完全使用随机初始化的参数W，GCN提取出来的特征就以及十分优秀了！这跟CNN不训练是完全不一样的，后者不训练是根本得不到什么有效特征的。</p><p>我们看论文原文：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730287.jpg" alt="img" /></p><p>然后作者做了一个实验，使用一个俱乐部会员的关系网络，使用随机初始化的GCN进行特征提取，得到各个node的embedding，然后可视化：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730300.jpg" alt="img" /></p><p>可以发现，在原数据中同类别的node，经过GCN的提取出的embedding，已经在空间上自动聚类了。</p><p>而这种聚类结果，可以和DeepWalk、node2vec这种经过复杂训练得到的node embedding的效果媲美了。</p><p>说的夸张一点，比赛还没开始，GCN就已经在终点了。看到这里我不禁猛拍大腿打呼：“NB！”</p><p>还没训练就已经效果这么好，那给少量的标注信息，GCN的效果就会更加出色。</p><p>作者接着给每一类的node，提供仅仅一个标注样本，然后去训练，得到的可视化效果如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241730313.gif" alt="img" /></p><p>这是整片论文让我印象最深刻的地方。</p><p>其他：</p><ol><li>对于很多网络，我们可能没有节点的特征，这个时候可以使用GCN吗？答案是可以的，如论文中作者对那个俱乐部网络，采用的方法就是用单位矩阵 I 替换特征矩阵 X。</li><li>我没有任何的节点类别的标注，或者什么其他的标注信息，可以使用GCN吗？当然，就如前面讲的，不训练的GCN，也可以用来提取graph embedding，而且效果还不错。</li><li>GCN网络的层数多少比较好？论文的作者做过GCN网络深度的对比研究，在他们的实验中发现，GCN层数不宜多，2-3层的效果就很好了</li></ol>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GNNExplainer</title>
      <link href="/2023/10/10/AILearning/GNN/GNNExplainer/"/>
      <url>/2023/10/10/AILearning/GNN/GNNExplainer/</url>
      
        <content type="html"><![CDATA[<h2 id="gnnexplainer-generating-explanations-for-graph-neural-networks"><a class="markdownIt-Anchor" href="#gnnexplainer-generating-explanations-for-graph-neural-networks"></a> GNNExplainer: Generating Explanations for Graph Neural Networks</h2><h2 id="1-contribution-本文贡献"><a class="markdownIt-Anchor" href="#1-contribution-本文贡献"></a> 1. Contribution 本文贡献</h2><ul><li>提出第一款通用，模型无关的(model-agnostic)对于GNN模型的解释器<strong>GNNEXPLAINER</strong></li><li>形式化描述<strong>GNNEXPLAINER</strong>为最大化互信息的优化任务</li><li>抽取重要的子图结构及节点特征子集，作为模型解释。</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241750221.png" alt="image-20231211103857083" /></p><h2 id="2-background-背景信息"><a class="markdownIt-Anchor" href="#2-background-背景信息"></a> 2. Background 背景信息</h2><p>对于非图结构的神经网络，解释方法主要有如下两个方向：</p><p>1.为整个网络构建简单的代替模型</p><p>常为模型无关的(model-agnostic)，在待解释样本点的局部建立可信的估计。</p><p>E.g., 线性模型如<em>LIME</em>，规则集合如<em>ANN_DT</em></p><p>2.识别模型计算过程中的重要层面</p><p>E.g. 关注特征梯度(feature gradients)等。</p><p>对于图神经网络设计解释方法，除去节点特征外，还需要结合考虑<strong>图的结构特征</strong>。</p><h2 id="3-problem-formulation-问题定义"><a class="markdownIt-Anchor" href="#3-problem-formulation-问题定义"></a> 3. Problem Formulation 问题定义</h2><h3 id="31-gnn回顾"><a class="markdownIt-Anchor" href="#31-gnn回顾"></a> 3.1 GNN回顾</h3><p>抽象GNN基本操作如下：</p><p>给定GNN模型 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Φ</mi></mrow><annotation encoding="application/x-tex">\Phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Φ</span></span></span></span> , 对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span></span></span></span> 层节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span></span></span>的特征表达求取，共经过如下3步。</p><ol><li><p>与其邻居节点进行信息传递：</p><p><img src="imgs/image-20231211113756040.png" alt="image-20231211113756040" /></p></li><li><p>聚合邻居节点信息：</p></li></ol><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>M</mi><mi>i</mi><mi>l</mi></msubsup><mo>=</mo><mi mathvariant="normal">AGG</mi><mo>⁡</mo><mo stretchy="false">(</mo><mrow><msubsup><mi>m</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mi mathvariant="normal">∣</mi><msub><mi>v</mi><mi>j</mi></msub><mo>∈</mo><mi mathvariant="script">N</mi><mo>∗</mo><mrow><mi>v</mi><mo>∗</mo><mi>i</mi></mrow></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">M_{i}^{l}=\operatorname{AGG} ( {m_{i j}^{l} | v_{j} \in \mathcal{N}*{v*{i}}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.107772em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.441336em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-0.394772em;"></span><span class="mop"><span class="mord mathrm">A</span><span class="mord mathrm">G</span><span class="mord mathrm">G</span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault">i</span></span></span></span><span class="mclose">)</span></span></span></span></p><ol start="3"><li>结合自身节点上层表达，生成本层节点表达</li></ol><h3 id="32-gnnexplainer-problem-formulation"><a class="markdownIt-Anchor" href="#32-gnnexplainer-problem-formulation"></a> 3.2 GNNEXPLAINER: Problem formulation</h3><h2 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> <strong>摘要</strong></h2><p>三段话总结 gnn-explainer 做了什么。</p><ul><li>背景是：针对<strong>同质图</strong>的可解释性操作，和GNN模型结构无关，主要是分析 <strong>node feature 和节点信息聚合过程链路</strong>对模型预测的影响。模型支持单点解释和群体解释。</li><li>模型的输入输出：以节点预测为例，单点解释也就是输入一个node，返回预测该node任务中贡献最大的子图+子图中节点特征，也就是可解释性输出的内容。群体解释就是输入一类节点，同样还是返回可解释性输出的内容。模型优化函数：优化整个 graph 的预测结果和 subgraph 的预测差，找到预测差最大的subgraph，即是解释出来的重要子图。</li><li>评估：最终在合成数据集/真实数据集上进行评估，这里的评估方式是通过挖掘出和groundtruth类似的子图结构用于计算准确率。</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241746183.png" alt="img" /></p><p>举个实例，上图这个<strong>同质图分类任务</strong>，如果预测的人群类别是左图左上的篮球，那么GNN-explainer会抓出对打篮球这个预测结果贡献度最高的红色子图，也就是红色标明的球类运动，诸如排球/足球等；如果预测的人群类别是左图右下的航行，GNN-explainer会抓出对航行这个预测结果贡献度最高的绿色子图，也就是绿色标明的海边运动，诸如皮划艇/沙滩排球等。</p><h2 id="问题定义"><a class="markdownIt-Anchor" href="#问题定义"></a> 问题定义</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241747285.png" alt="image-20240424174740235" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241746108.png" alt="img" /></p><h2 id="gnnexplainer"><a class="markdownIt-Anchor" href="#gnnexplainer"></a> GNNExplainer</h2><h3 id="单例解释"><a class="markdownIt-Anchor" href="#单例解释"></a> 单例解释</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241747653.png" alt="image-20240424174701585" /></p><blockquote><p>后续还可以根据预测任务的不同类别，修改为条件期望</p></blockquote><h3 id="结合节点特征的单例解释"><a class="markdownIt-Anchor" href="#结合节点特征的单例解释"></a> 结合节点特征的单例解释</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241747863.png" alt="image-20240424174721821" /></p><h3 id="单类群体解释"><a class="markdownIt-Anchor" href="#单类群体解释"></a> 单类群体解释</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241748597.png" alt="image-20240424174816564" /></p><h2 id="实验结果分析"><a class="markdownIt-Anchor" href="#实验结果分析"></a> 实验结果分析</h2><blockquote><p>所有论文的实验过程和结果分析还是非常值得一看的，毕竟这是吹牛逼的核心区域，也是用来检验吹的好不好的唯一标准。 - 鲁迅</p></blockquote><p>图可解释的方向，如何量化可解释性的效果是一个大难题。</p><p>本篇作为图可解释性的开篇之作，使用的评估方式是在<strong>合成数据集和真实数据集上，和attention类/grad梯度类的解释工作对比解释的子图结构的准确率。</strong></p><p>终于到了讲解封面图的时候了！！！！！</p><p>如下图的合成数据集上，这里主要对比的是子图的结构，直接看下面A|B的实例说明，可以看到最右边的groundtruth给出的图结构中，仅有本篇论文做到了结构的完全解释，而grad/att得方法都是不全甚至完全不同结构的，自然得到的准确率非常低。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241746130.png" alt="img" /></p><p>在真实数据集上，就没有量化指标惹，只能直接看实例，可以看到和合成数据集类似，本方法把groundtruth得结构都完整顺利得识别出来了。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241746138.webp" alt="img" /></p><p>在节点特征维度实例分析来看，可以看到att方法没有给出对应的节点特征维度，本篇方法同样是最佳的。同样，这里没有给出量化指标说明。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241746140.png" alt="img" /></p><h2 id="结论与延伸"><a class="markdownIt-Anchor" href="#结论与延伸"></a> 结论与延伸</h2><p>作为开篇之作还是提供了非常完善的可解释性思路，并且拥有扩展性可以复用到不同的图任务图结构上。</p><p>可以改进的点粗略看下来有几条：</p><ul><li>首先，全篇看下来应该是在同质图上的可解释性方法，可以转化到异质图上尝试效果。</li><li>其次，优化函数仅考虑到了结构的差异，可以尝试引入 attention 结构进行辅助优化。</li><li>最后，评估部分有缺陷，目前只在合成数据集上给出了量化指标，且评估方式仅是通过比较结构的相似性。</li></ul>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>拉普拉斯矩阵</title>
      <link href="/2023/10/10/AILearning/GNN/Laplace/"/>
      <url>/2023/10/10/AILearning/GNN/Laplace/</url>
      
        <content type="html"><![CDATA[<h3 id="解读laplace矩阵"><a class="markdownIt-Anchor" href="#解读laplace矩阵"></a> 解读Laplace矩阵</h3><ol><li><p>什么是Laplace矩阵？</p><p>“拉普拉斯矩阵(Laplacian matrix) 也叫做导纳矩阵、基尔霍夫矩阵或离散拉普拉斯算子，主要应用在图论中，作为一个图的矩阵表示。”</p></li><li><p>常见的Laplace矩阵<br />Reference</p></li><li><p>什么是Laplace矩阵？<br />拉普拉斯矩阵(Laplacian matrix) 也叫做导纳矩阵，这次笔记主要是记录下GCN学习时的注意点，在图论（Graph theory）中，对于图 G=(V,E)：</p><pre><code>Laplacian 矩阵的定义为 L = D - A （其中 L 是Laplacian 矩阵， D=diag(d)是对角矩阵，d=rowSum(A)，对角线上元素依次为各个顶点的度， A 则是图的邻接矩阵）</code></pre></li></ol><p>若只考虑无向图，那么L就是对称矩阵。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729213.png" alt="在这里插入图片描述" /></p><p>对于无向图的Laplace矩阵，它有哪些性质？</p><p>半正定矩阵（特征值非负，且是对称矩阵）；<br />对称矩阵（一定有n个线性无关的特征向量）；<br />对称矩阵的不同特征值对应的特征向量相互正交，这些正交的特征向量构成的矩阵为正交矩阵；<br />由于是半正定矩阵，所以是对称阵，那么能特征值分解（EVD）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729218.png" alt="img" /></p><p>由于 U 是正交矩阵，即UUT=I，所以特征值分解又可以写成：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729217.png" alt="在这里插入图片描述" /></p><h3 id="常见的laplace矩阵"><a class="markdownIt-Anchor" href="#常见的laplace矩阵"></a> 常见的Laplace矩阵</h3><p>2.1 一般形式</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729221.png" alt="L= D - A" /></p><p>2.2 对称归一化形式</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729222.png" alt="在这里插入图片描述" /></p><p>2.3 随机游走归一化形式</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241729224.png" alt="在这里插入图片描述" /></p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VGAE浅入</title>
      <link href="/2023/10/10/AILearning/GNN/VGAE%E6%B5%85%E5%85%A5/"/>
      <url>/2023/10/10/AILearning/GNN/VGAE%E6%B5%85%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<h2 id="1数学定义"><a class="markdownIt-Anchor" href="#1数学定义"></a> 1.数学定义</h2><ul><li>图网络： <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BG%7D%3D(%5Cnu%2C+%5Cxi)" alt="[公式]" /> , 其中节点的数量 <img src="https://www.zhihu.com/equation?tex=N%3D%5Cleft%7C+%5Cnu+%5Cright%7C" alt="[公式]" /> 。对于当前的图网络他的邻接矩阵是 <img src="https://www.zhihu.com/equation?tex=A" alt="[公式]" /> 。某一个节点的特征用 <img src="https://www.zhihu.com/equation?tex=x_%7Bi%7D" alt="[公式]" /> 表示， 矩阵<img src="https://www.zhihu.com/equation?tex=%5Cbm%7BX%7D%5Cin+R%5E%7BN%5Ctimes+D%7D" alt="[公式]" /> 是整个图网络的节点特征的矩阵表示。</li><li>随机的潜在变量：某一个随机潜在变量用 <img src="https://www.zhihu.com/equation?tex=z_%7Bi%7D" alt="[公式]" /> 表示，矩阵 <img src="https://www.zhihu.com/equation?tex=%5Cbm%7BZ%7D%5Cin+R%5E%7BN%5Ctimes+F%7D" alt="[公式]" />表示图网络的所有节点被编码之后的潜在变量。</li></ul><h2 id="2-方法"><a class="markdownIt-Anchor" href="#2-方法"></a> 2. 方法</h2><h3 id="21推断模型其实我觉得叫做编码模型更加合适"><a class="markdownIt-Anchor" href="#21推断模型其实我觉得叫做编码模型更加合适"></a> 2.1推断模型（其实我觉得叫做编码模型更加合适）</h3><p>1）首先用图卷积网络求出每个节点的高斯分布的均值和方差:</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbm%5Cmu%3DGCN_%7B%5Cmu%7D(%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)" alt="[公式]" /></p><p><img src="https://www.zhihu.com/equation?tex=log(%5Cbm%5Csigma)%3DGCN_%7B%5Csigma%7D(%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)" alt="[公式]" /></p><p>其中<img src="https://www.zhihu.com/equation?tex=GCN(%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)%3D%5Cbm%7B%5Ctilde%7BA%7D%7DReLU(%5Cbm%7B%5Ctilde%7BA%7D%7D%5Cbm%7BX%7D%5Cbm%7BW_%7B0%7D%7D)%5Cbm%7BW_%7B1%7D%7D" alt="[公式]" /> ，其是一个两层的网络， <img src="https://www.zhihu.com/equation?tex=%5Cbm%7B%5Ctilde%7BA%7D%7D%3D%5Cbm%7BD%7D%5E%7B-1%2F2%7D%5Cbm%7BA%7D%5Cbm%7BD%7D%5E%7B-1%2F2%7D" alt="[公式]" /> 是归一化的邻接矩阵。</p><p>2）根据所求得的节点特征编码的均值和方差，我们可以得到推断模型：</p><p><img src="https://www.zhihu.com/equation?tex=q(%5Cbm%7BZ%7D%7C%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)%3D%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cmathcal%7BN%7D(z_%7Bi%7D%7C%5Cbm%7B%5Cmu_%7Bi%7D%7D%2C+diag(%5Cbm%7B%5Csigma_%7Bi%7D%5E%7B2%7D%7D))" alt="[公式]" /> （个人理解，之所以用乘积连接各个不同的分布，旨在求得N个独立的变量的联合分布）</p><p>这样每一个节点都有一个具有特定均值和方差的高斯分布去表示。</p><h3 id="22生成模型"><a class="markdownIt-Anchor" href="#22生成模型"></a> 2.2生成模型</h3><p><img src="https://www.zhihu.com/equation?tex=p(%5Cbm%7BA%7D%7C%5Cbm%7BZ%7D)%3D%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cprod_%7Bj%3D1%7D%5E%7BN%7Dp(%5Cbm%7BA%7D_%7Bi%2Cj%7D%7C%5Cbm%7Bz%7D_%7Bi%2C+%5Cbm%7Bz_%7Bj%7D%7D%7D)" alt="[公式]" /> , 且 <img src="https://www.zhihu.com/equation?tex=p(%5Cbm%7BA%7D_%7Bi%2Cj%7D%3D1%7C%5Cbm%7Bz%7D_i%2C+%5Cbm%7Bz%7D_j)%3D%5Csigma(%7B%5Cbm%7Bz%7D_i%5E%7B%5Ctop%7D%5Cbm%7Bz%7D_j%7D)" alt="[公式]" /> （这里有个问题，当 <img src="https://www.zhihu.com/equation?tex=%5Cbm%7BA%7D_%7Bi%2Cj%7D%5Cne1" alt="[公式]" /> 时候 <img src="https://www.zhihu.com/equation?tex=p(%5Ccdot)" alt="[公式]" /> 是什么呢？）</p><h3 id="23目标函数"><a class="markdownIt-Anchor" href="#23目标函数"></a> 2.3目标函数</h3><p><img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%3D%5Cbegin%7Bmatrix%7D+%5Cunderbrace%7BE_%7Bq(%5Cbm%7BZ%7D%7C%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)%7D%5B%5Clog+p(%5Cbm%7BA%7D%7C%5Cbm%7BZ%7D)%5D%7D+%5C%E6%9C%9F%E6%9C%9B%E9%A1%B9+%5Cend%7Bmatrix%7D-%5Cbegin%7Bmatrix%7D+%5Cunderbrace%7BKL%5Bq(%5Cbm%7BZ%7D%7C%5Cbm%7BX%7D%2C+%5Cbm%7BA%7D)%7C%7Cp(%5Cbm%7BZ%7D)%5D%7D+%5C%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9+%5Cend%7Bmatrix%7D" alt="[公式]" /></p><p>最大化这个<a href="https://link.zhihu.com/?target=https%3A//bluefisher.github.io/2020/02/06/%E7%90%86%E8%A7%A3-Variational-Lower-Bound/">variational lower bound</a>目标函数， 从而优化GCN的层参数 <img src="https://www.zhihu.com/equation?tex=%5Cbm%7BW_0%7D" alt="[公式]" /> 和 <img src="https://www.zhihu.com/equation?tex=%5Cbm%7BW%7D_1" alt="[公式]" /> 。</p><p>注：目标函数中的期望项只包括了标签为1的node，而标签为0的node是不予考虑的。在代码里是这样的操作的（见代码解读部分）：在计算交叉熵损失的时候，给标签为1的正样本很高的权重，从而让其主导训练的过程。</p><hr /><h2 id="代码解读httpsgithubcomtkipfgae"><a class="markdownIt-Anchor" href="#代码解读httpsgithubcomtkipfgae"></a> 代码解读：<a href="https://link.zhihu.com/?target=https%3A//github.com/tkipf/gae">https://github.com/tkipf/gae</a></h2><h3 id="1gae"><a class="markdownIt-Anchor" href="#1gae"></a> 1.GAE</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241735273.jpg" alt="img" /></p><p><strong>2.VGAE</strong></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241735275.jpg" alt="img" /></p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图神经网络</title>
      <link href="/2023/10/10/AILearning/GNN/%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2023/10/10/AILearning/GNN/%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="1-什么是图神经网络"><a class="markdownIt-Anchor" href="#1-什么是图神经网络"></a> 1 什么是图神经网络</h2><p>图神经网络（Graph Neu做ral Networks, GNNs）是一种基于图结构的深度学习方法，从其定义中可以看出图神经网络主要由两部分组成，即“图”和“神经网络”。这里的“图”是图论中的图数据结构，“神经网络”是我们熟悉的深度学习NN结构，如MLP，CNN，RNN等。要了解图神经网络我们需要先回顾一下“图”和“神经网络”的基本概念。</p><h3 id="11图的定义"><a class="markdownIt-Anchor" href="#11图的定义"></a> 1.1图的定义</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726881.png" alt="image-20210416110800777" /></p><h3 id="12典型神经网络"><a class="markdownIt-Anchor" href="#12典型神经网络"></a> 1.2典型神经网络</h3><p>典型的神经网络结构有两条主线，一条主线是卷积神经网络，简称CNN，主要用于图像类数据的处理。另一条主线是循环神经网络，简称RNN，主要用于时序类数据的处理。由于神经网络结构的介绍不是本篇的重点，因此在这里不做重点介绍。只展示如下两图典型的CNN和RNN的结构：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726886.png" alt="img" /></p><p>下图展示了当前的主流神经网络结构以及适用的场景：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726887.png" alt="img" /></p><h3 id="13-图神经网络"><a class="markdownIt-Anchor" href="#13-图神经网络"></a> 1.3 图神经网络</h3><p>根据上述对图和神经网络的回顾，我们可以看出，图神经网络就是借助神经网络的“能力”如深度特征抽取等来处理图结构的数据，因此对于图神经网络，其直观的结构应该如下图：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726892.png" alt="img" /></p><p>其中图结构的数据有许多，如社交网络图、交通路线图、人物关系图、分子结构图、计算结网络拓扑图等等。这些数据都可以作为图神经网络的输入。之后经过特定的神经网络结构，如MLP，CNN，RNN等的基于图结构的运算，可以完成对于<strong>图表示的分类，图的节点或边的预测等功能。</strong></p><h2 id="2-为什么需要图神经网络"><a class="markdownIt-Anchor" href="#2-为什么需要图神经网络"></a> 2 为什么需要图神经网络</h2><p>近年来，深度学习已经彻底改变了许多机器学习任务，从图像分类和视频处理，到语音识别和自然语言理解，这些任务中的数据通常表示在欧几里得空间中。然而，在越来越多的应用程序中，数据是从非欧几里得域生成的，并表示为具有复杂关系和对象之间相互依赖的图形。图数据的复杂性给现有的机器学习算法带来了巨大的挑战。下图左为图像（欧几里得空间），右为图（非欧几里得空间）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726891.png" alt="img" /></p><p>传统的神经网络结构如CNN、RNN等都是接受欧几里得空间的数据作为输入，他们无法处理非欧几里得空间的数据结构，比如图和流行结构。因此对于此类数据，图神经网络就更加适合处理。近年来图神经网络的研究热度也不断提升，如下图所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726898.png" alt="img" /></p><h2 id="3-图神经网络典型的应用场景"><a class="markdownIt-Anchor" href="#3-图神经网络典型的应用场景"></a> 3 图神经网络典型的应用场景</h2><p>本章节基于图神经网络近年来的一些研究进展，展示一下图神经网络当前典型的应用场景以及一些典型的任务。</p><p>将图结构和节点内容信息作为模型的输入，GNNs的输出可以通过以下机制之一专注于不同的图分析任务:</p><ul><li>Node-level输出用于点回归和分类任务。</li><li>Edge-level输出与边分类和链路预测任务相关。</li><li>Graph-level输出和图分类任务相关，比如图表示。</li></ul><p>下面以典型论文为例介绍几个GNNs的典型任务：</p><h3 id="31图分类"><a class="markdownIt-Anchor" href="#31图分类"></a> 3.1图分类</h3><p>我们知道很多有机物或者化合物的分子结构都是可以用图结构来表示的，比如下图的4-nitroindole，该GNN的作用是训练一个图神经网络，接收一个分子结构来判断该分子结构会不会导致发生突变。在训练的过程中如果有现存的已标注的可导致发生突变的分子结构，我们就可以训练该图神经网络，然后用他来预测一个新的未知的分子会不会导致突变。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726139.png" alt="img" /></p><h3 id="32图生成"><a class="markdownIt-Anchor" href="#32图生成"></a> 3.2图生成</h3><p>我们知道在图像和语言的领域里分别有embedding和generation技术，比如常见的图像和语言生成技术，比如动态静态的预训练和词嵌入技术。相应的在图领域，我们也有图的嵌入表示比如graph embedding representation和图的generation技术。比如下图的graphvae，变分图自编码器就是一个图生成模型，其主要是为图中节点找寻合适的 Embedding 向量，并通过 Embedding 向量实现图重构。其中获取到的节点 Embedding 可以用于支撑下游任务。比如在新的分子结构生成发现中可以使用该技术来加快分子发现速度。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726156.png" alt="img" /></p><h3 id="33社交网络分析"><a class="markdownIt-Anchor" href="#33社交网络分析"></a> 3.3社交网络分析</h3><p>在社交网络分析中，实体之间的关系往往会是非常重要的特征，图结构就能很好的表示这种关系特征。如下图的社交网络图中，每个实体的关系可以用边来描述，这样在进行实体分类或者关系分类时，利用图数据结构，完成特定任务的标注，就可以训练出一个图神经网络来完成此类任务。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726168.png" alt="img" /></p><h3 id="34网络拓扑分析"><a class="markdownIt-Anchor" href="#34网络拓扑分析"></a> 3.4网络拓扑分析</h3><p>网络的拓扑天然就是图结构的表示，计算机网络中的路由技术就是以图论为基础的算路技术。同时网络中每两个节点之间也会有时延，丢包，抖动等网络KPI信息。这些点对之间的KPI往往是动态变化的，这就影响到了实时路由决策和优化的问题。比如当前链路的时延或者丢包过大，路由算法就需要选择新的路径进行数据包传递。图神经网络在这个问题中就可以接收底层的网络拓扑、网络配置信息和流量矩阵信息来实时预测每一个点对，每一条流的实验丢包抖动，这样就可以更好的配合路由和优化算法，使能网络的自动驾驶。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726177.png" alt="img" /></p><h2 id="4-图神经网络典型训练框架"><a class="markdownIt-Anchor" href="#4-图神经网络典型训练框架"></a> 4 图神经网络典型训练框架</h2><h3 id="41semi-supervised-learning-for-node-level-classification"><a class="markdownIt-Anchor" href="#41semi-supervised-learning-for-node-level-classification"></a> 4.1Semi-supervised learning for node-level classification：</h3><p>给定一个网络，其中部分节点被标记，其他节点未标记，ConvGNNs可以学习一个鲁棒模型，有效地识别未标记节点的类标签。为此，可以通过叠加一对图卷积层，然后是用于多类分类的softmax层来构建端到端框架。见图(a)</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726187.png" alt="img" /></p><h3 id="42supervised-learning-for-graph-level-classification"><a class="markdownIt-Anchor" href="#42supervised-learning-for-graph-level-classification"></a> 4.2Supervised learning for graph-level classification：</h3><p><mark>图级分类的目的是预测整个图的类标签</mark>。该任务的端到端学习可以结合图卷积层、图池层和/或readout层来实现。图卷积层负责精确的高级节点表示，图池层则扮演下采样的角色，每次都将每个图粗化成一个子结构。readout层将每个图的节点表示折叠成一个图表示。通过在图表示中应用一个多层感知器和一个softmax层，我们可以建立一个端到端图分类框架。见图(b)</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726198.png" alt="img" /></p><h3 id="43unsupervised-learning-for-graph-embedding"><a class="markdownIt-Anchor" href="#43unsupervised-learning-for-graph-embedding"></a> 4.3Unsupervised learning for graph embedding：</h3><p>当图中没有可用的类标签时，我们可以学习在端到端框架中以完全无监督的方式嵌入图。这些算法以两种方式利用边缘级信息。一种简单的方法是采用自编码器框架，编码器使用图卷积层将图嵌入到潜在表示中，在潜在表示上使用解码器重构图结构。另一种常用的方法是利用负采样方法(negative sampling)，即对图中有链接的部分节点对进行负采样，而对图中有链接的节点对进行正采样。然后应用逻辑回归层对的正负配对进行区分。见图©</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241726364.png" alt="img" /></p><p>参考文献<br />[1]. <a href="https://mp.weixin.qq.com/s/PSrgm7frsXIobSrlcoCWxw">https://mp.weixin.qq.com/s/PSrgm7frsXIobSrlcoCWxw</a></p><p>[2]. <a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML2020/GNN.pdf">http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML2020/GNN.pdf</a></p><p>[3]. <a href="https://persagen.com/files/misc/scarselli2009graph.pdf">https://persagen.com/files/misc/scarselli2009graph.pdf</a></p><p>[4]. <a href="https://arxiv.org/pdf/1802.03480.pdf">https://arxiv.org/pdf/1802.03480.pdf</a></p><p>[5]. <a href="https://arxiv.org/abs/1901.00596">https://arxiv.org/abs/1901.00596</a></p><p>[6]. <a href="https://arxiv.org/abs/1910.01508">https://arxiv.org/abs/1910.01508</a></p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图与中心性</title>
      <link href="/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%9A%84%E4%B8%AD%E5%BF%83%E6%80%A7/"/>
      <url>/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%9A%84%E4%B8%AD%E5%BF%83%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="一-度中心性-degree-centrality"><a class="markdownIt-Anchor" href="#一-度中心性-degree-centrality"></a> <strong>一、度中心性 Degree Centrality</strong></h2><p>在网络中，一个节点的度越大，就意味着这个节点的度中心性就越高，就说明在网络中这个节点越重要。</p><p><img src="https://www.zhihu.com/equation?tex=%E5%BA%A6%E4%B8%AD%E5%BF%83%E6%80%A7%3D%5Cfrac%7BN_%7Bdegree%7D+%7D%7Bn-1%7D+" alt="[公式]" /></p><p>其中，n表示节点的数量， <img src="https://www.zhihu.com/equation?tex=N_%7Bdegree%7D+" alt="[公式]" /> 表示该节点的度。</p><h2 id="二-特征向量中心性-eigenvector-centrality"><a class="markdownIt-Anchor" href="#二-特征向量中心性-eigenvector-centrality"></a> <strong>二、特征向量中心性 Eigenvector Centrality</strong></h2><p>一个节点的重要性取决于其邻居节点的数量（即该节点的度），也取决与其邻居节点的重要性。与之相连的邻居节点越重要，则该节点就越重要。</p><p>特征向量中心性的计算公式如下：</p><p>假设 <img src="https://www.zhihu.com/equation?tex=x_%7Bi%7D+" alt="[公式]" /> 表示节点i的重要性，则 <img src="https://www.zhihu.com/equation?tex=EC_%7Bi%7D%3Dx_%7Bi%7D%3Dc%5Csum_%7Bj%3D1%7D%5E%7Bn%7D+a_%7Bij%7Dx_%7Bj%7D" alt="[公式]" /></p><p>其中，c为比例常数，记 <img src="https://www.zhihu.com/equation?tex=x%3D%5Cleft+%5B++x_%7B1%7D%2Cx_%7B2%7D%2Cx_%7B3%7D%2C...%2Cx_%7Bn%7D%5Cright+%5D+%5ET" alt="[公式]" /> ,经过多次迭代达到稳态时，可以写成如下矩阵形式：</p><p>x=c<strong>Ax.</strong></p><p>这里x表示的是矩阵A的特征值 <img src="https://www.zhihu.com/equation?tex=c%5E%7B-1%7D" alt="[公式]" /> 对应的特征向量，也可以表示成 <img src="https://www.zhihu.com/equation?tex=Ax%3D%5Clambda+x" alt="[公式]" /> 这种形式。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">（哎，百度出来的，其实自己也没看明白，多次迭代到稳态是什么意思啊。。。）</span><br></pre></td></tr></table></figure><p>于是自己又在b站上面看了个视频。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241700139.jpg" alt="img" /></p><p>如图，先求出该图所表示的邻接矩阵的特征值。选最大的一个特征值2.48，求出对应的特征向量。将其乘以-1，是没有影响的。于是得到了图中所示的特征向量中心性</p><p>{1：0.53，2：0.358, 3:0.358 , 4:0.427 ,5:0.53}</p><p>可以看到，1和5节点的特征向量中心性是比较大的，因为其本身的度就比较大。</p><p>其次是2，3，4节点，它们自身的度都是2，但是特征向量中心性不一样。2连接了1，3连接了5，但是4连接了1和5，特征向量中心性与该节点的邻居节点重要性相关，所以4的特征向量中心性比2和3的大。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">于是写到这样，勉强理解了特征向量中心性吧。</span><br></pre></td></tr></table></figure><h2 id="三-中介中心性-between-centrality"><a class="markdownIt-Anchor" href="#三-中介中心性-between-centrality"></a> <strong>三、中介中心性 Between Centrality</strong></h2><p>以经过某个节点的最短路径数目来刻画节点的重要性指标。</p><p>计算公式： <img src="https://www.zhihu.com/equation?tex=BC%3D%5Csum+%5Cfrac%7Bd_%7Bst%7D()%7D%7Bd_%7Bst%7D%7D+" alt="[公式]" /> ，</p><p>其中dst表示s到t的最短路径数量，dst()表示从s到t的最短路径中经过节点的数量。若需要进行标准化，在如上公式基础上，除以（n-1)(n-2)，n为节点数量。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241700143.jpg" alt="img" /></p><p><img src="https://www.zhihu.com/equation?tex=BC_%7B4%7D%3D%5Cfrac%7B(0%2B1%2B1%2B0.5)%2B(1%2B1%2B1%2B1)%2B(0%2B1%2B0%2B1)%2B(1%2B1%2B1%2B1)%2B(0.5%2B0%2B1%2B1)%7D%7B20%7D+%3D15%2F20" alt="[公式]" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241700146.jpg" alt="img" /></p><p><img src="https://www.zhihu.com/equation?tex=BC_%7B3%7D%3D%5Cfrac%7B0.5%2B0.5%7D%7B20%7D+" alt="[公式]" /></p><p>以上举例了节点3和4，其余的同理。</p><h2 id="四-紧密中心性-closeness-centrality"><a class="markdownIt-Anchor" href="#四-紧密中心性-closeness-centrality"></a> 四、紧密中心性 Closeness Centrality</h2><p>反映在网络中某一节点与其他节点之间的接近程度。如果一个节点离其他的节点都很近，那么传递信息的时候就不需要依赖其他的节点，说明这个节点很重要。</p><p>计算公式： <img src="https://www.zhihu.com/equation?tex=d_%7Bi%7D%3D%5Cfrac%7B1%7D%7Bn-1%7D%5Csum_%7Bj%5Cne+i%7D%5E%7B%7D+d_%7Bij%7D" alt="[公式]" /></p><p><img src="https://www.zhihu.com/equation?tex=CC_%7Bi%7D%3D%5Cfrac%7B1%7D%7Bd_%7Bi%7D%7D+%3D%5Cfrac%7Bn-1%7D%7B%5Csum_%7Bj%5Cne+i%7D%5E%7B%7D+d_%7Bij%7D%7D+" alt="[公式]" /></p><p>这个点的紧密中心性是基于该节点到网络中其余所有节点的最短路径之和，如果进行归一化处理，就是求这个节点到其他所有节点的平均最短距离。一个节点的平均最短距离越小，那么这个进行的紧密中心性就越大。如果节点i和节点j之间没有路径可达，则定义dij为无穷大，其倒数为0.</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图的基本概念</title>
      <link href="/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%9A%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/"/>
      <url>/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%9A%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="一-图的逻辑结构"><a class="markdownIt-Anchor" href="#一-图的逻辑结构"></a> 一、图的逻辑结构</h2><h3 id="一图的定义"><a class="markdownIt-Anchor" href="#一图的定义"></a> （一）图的定义</h3><p>图是由顶点的有穷非空集合和顶点之间边的集合组成，通常表示为：G=(V，E)</p><p>ps：G表示一个图，V是图G中顶点的集合，E是图G中顶点之间边的集合。</p><h3 id="二基本概念"><a class="markdownIt-Anchor" href="#二基本概念"></a> （二）基本概念</h3><p>1.无向边：顶点vi和vj之间的边没有方向，表示为(vi,vj)。</p><p>2.无向图：顶点vi和vj之间的边没有方向，表示为(vi,vj)。</p><p>3.有向边：从顶点vi到vj的边有方向，表示为&lt;vi,vj&gt;。</p><p>4.有向图：图的任意两个顶点之间的边都是有向边。</p><p>5.简单图：若不存在顶点到其自身的边，且同一条边不重复出现。</p><p>6.邻接、依附：无向图中，对于任意两个顶点vi和顶点vj，若存在边(vi，vj)，则称顶点vi和</p><p>顶点vj互为邻接点，同时称边(vi，vj)依附于顶点vi和顶点vj。</p><p>7.无向完全图：在无向图中，如果任意两个顶点之间都存在边，则称该图为无向完全图。</p><p>8.有向完全图：在有向图中，如果任意两个顶点之间都存在方向相反的两条弧，则称该图</p><p>为有向完全图。</p><h3 id="三基本术语"><a class="markdownIt-Anchor" href="#三基本术语"></a> （三）基本术语</h3><p>1.稀疏图：称边数很少的图为稀疏图；</p><p>2.稠密图：称边数很多的图为稠密图。</p><p>3.顶点的度：在无向图中，顶点v的度是指依附于该顶点的边数，通常记为TD (v)。</p><p>4.顶点的入度：在有向图中，顶点v的入度是指以该顶点为弧头的弧的数目，记为ID (v)；</p><p>5.顶点的出度：在有向图中，顶点v的出度是指以该顶点为弧尾的弧的数目，记为OD (v)。</p><p>6.权：是指对边赋予的有意义的数值量。</p><p>7.网：边上带权的图，也称网图。</p><p>8.路径：在无向图G=(V, E)中，从顶点vp到顶点vq之间的路径是一个顶点序列(vp=vi0,vi1,vi2, …,vim=vq)，其中，(vij-1,vij)∈E（1≤j≤m）。若G是有向图，则路径也是有方向的，顶点序列</p><p>满足&lt;vij-1,vij&gt;∈E。</p><p>9.路径长度：对于非带权图是路径上边的个数；对于带权图是路径上各边的权之和</p><p>10.回路（环）：第一个顶点和最后一个顶点相同的路径。</p><p>11.简单路径：序列中顶点不重复出现的路径。</p><p>12.简单回路（简单环）：除了第一个顶点和最后一个顶点外，其余顶点不重复出现的回</p><p>路。</p><p>13.子图：若图G=（V，E），G’=（V’，E’），如果V’ÍV 且E’ Í E ，则称图G’是G的子图。</p><p>14.连通图：在无向图中，如果从一个顶点vi到另一个顶点vj(i≠j)有路径，则称顶点vi和vj是</p><p>连通的。如果图中任意两个顶点都是连通的，则称该图是连通图。</p><p>15.连通分量：非连通图的极大连通子图称为连通分量。</p><p>16.强连通图：在有向图中，对图中任意一对顶点vi和vj (i≠j)，若从顶点vi到顶点vj和从顶点</p><p>vj到顶点vi均有路径，则称该有向图是强连通图。</p><p>17.强连通分量：非强连通图的极大强连通子图。</p><p>18.生成树：n个顶点的连通图G的生成树是包含G中全部顶点的一个极小连通子图。</p><p>19.生成森林：在非连通图中，由每个连通分量都可以得到一棵生成树，这些连通分量的生成树就组成了一个非连通图的生成森林。</p><h3 id="四图的遍历操作"><a class="markdownIt-Anchor" href="#四图的遍历操作"></a> （四）图的遍历操作</h3><h4 id="深度优先遍历-dfs"><a class="markdownIt-Anchor" href="#深度优先遍历-dfs"></a> 深度优先遍历 （DFS）</h4><p>基本思想：</p><p>⑴ 访问顶点v；</p><p>⑵ 从v的未被访问的邻接点中选取一个顶点w，从w出发进行深度优先遍历；</p><p>⑶ 重复上述两步，直至图中所有和v有路径相通的顶点都被访问到。</p><h4 id="广度优先遍历-bfs"><a class="markdownIt-Anchor" href="#广度优先遍历-bfs"></a> 广度优先遍历 （BFS）</h4><p>基本思想：</p><p>⑴ 访问顶点v；</p><p>⑵ 依次访问v的各个未被访问的邻接点v1, v2, …, vk；</p><p>⑶ 分别从v1，v2，…，vk出发依次访问它们未被访问的邻接点，并使“先被访问顶点的邻接点”先于“后被访问顶点的邻接点”被访问。直至图中所有与顶点v有路径相通的顶点都被访问到。</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图类型</title>
      <link href="/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%B1%BB%E5%9E%8B/"/>
      <url>/2023/10/10/AILearning/GNN/%E5%9B%BE%E7%B1%BB%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h4 id="最重要的4类图数据"><a class="markdownIt-Anchor" href="#最重要的4类图数据"></a> 最重要的4类图数据：</h4><ul><li><p>同构图（Homogeneous Graph）</p></li><li><p>异构图（Heterogeneous Graph）</p></li><li><p>属性图（Property Graph）</p></li><li><p>非显式图（Graph Constructed from Non-relational Data）。</p></li></ul><p>（1）同构图：<br />同构图是指图中的节点类型和关系类型都仅有一种。同构图是实际图数据的一种最简化的情况，如由超链接关系所构成的万维网，这类图数据的信息全部包含在邻接矩阵里。</p><p>同构图：在图里面，节点的类型和边的类型只有一种的图，<br />举个例子，像社交网络中只存在一种节点类型，用户节点和一种边的类型，用户-用户之间的连边。</p><p>（2）异构图：<br />与同构图相反，异构图是指图中的节点类型或关系类型多于一种。在现实场景中，我们通常研究的图数据对象是多类型的，对象之间的交互关系也是多样化的。因此，异构图能够更好地贴近现实。</p><p>异构图：在图里面，节点的类型+边的类型&gt;2的一种图，<br />举个例子，论文引用网络中，存在着作者节点和paper节点，边的关系有作者-作者之间的共同创作关系连边，作者-论文之间的从属关系，论文-论文之间的引用关系。</p><p>（3）属性图：<br />相较于异构图，属性图给图数据增加了额外的属性信息，如下图所示。对于一个属性图而言，节点和关系都有标签（Label）和属性（Property），这里的标签是指节点或关系的类型，如某节点的类型为“用户”，属性是节点或关系的附加描述信息，如“用户”节点可以有“姓名”“注册时间”“注册地址”等属性。属性图是一种最常见的工业级图数据的表示方式，能够广泛适用于多种业务场景下的数据表达。</p><p>属性图：图的节点上存在着初始属性attribute，可以用作后续节点的特征</p><p>（4）非显式图：<br />非显式图是指数据之间没有显式地定义出关系，需要依据某种规则或计算方式将数据的关系表达出来，进而将数据当成一种图数据进行研究。比如计算机3D视觉中的点云数据，如果我们将节点之间的空间距离转化成关系的话，点云数据就成了图数据。</p><p>其他：<br />动态图：图中的节点或者边都是随着时间变化的，可能增加或减少，一般是图的构成是按照时间片来构成，每一个时间片一个图的表示，例如t1时刻的图是初始图，t2时刻的图就是节点或连边变化后的图一直到tn时刻</p><p>关系图：图表示了一种节点之间的隐含关系，举个例子 知识图谱</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN中的注意力</title>
      <link href="/2022/12/18/AILearning/CNN/CNN-%E6%B3%A8%E6%84%8F%E5%8A%9B/"/>
      <url>/2022/12/18/AILearning/CNN/CNN-%E6%B3%A8%E6%84%8F%E5%8A%9B/</url>
      
        <content type="html"><![CDATA[<p>注意力机制最初在 2014年作为 RNN（Recurrent Neural Network）中编码器-解码器框架的一部分来编码长的输入语句，后续被广泛运用在RNN中。</p><h2 id="1单路注意力"><a class="markdownIt-Anchor" href="#1单路注意力"></a> 1.单路注意力</h2><h4 id="se-netsqueeze-and-excitation"><a class="markdownIt-Anchor" href="#se-netsqueeze-and-excitation"></a> SE-NET（Squeeze and Excitation）</h4><blockquote><p>HU J，SHEN L，SUN G.Squeeze-and-excitation networks[J].</p></blockquote><p>2018年 ，CVPR（计算机视觉和模式识别）收录的论文中提出了 SE-Net（挤压和励磁网络）是 Momenta 胡杰团队 （WMW）提出的新的网络结构，该团队利用 SE网络获得 了ImageNet 2017年竞赛图像分类任务的冠军，在ImageNet数据集上将 top-5错误降低到 2.251%，对比于以往的最 好成绩 2.991%有了较大的提升。</p><p>SE-Net中的关键结构SE-Netblock利用了注意力机制的思想，显式地建模特征图之间的相互依赖关系，并通过学习的方式来自适应地获取到每张特征图的重要性，然后依照这个重要程度去对原数据进行更新。SE-Net通过这种方式提升有用的特征重要程度同时降低无用特征的重要性，并以不同通道的重要性为指导，将计算资源合理地投入不同通道当中。</p><p>通俗地来说SENet的核心思想在于通过网络根据损失函数值loss去学习特征权重，使得对于任务更为效果明显的特征图权重变大，无效果或效果不明显的特征图权重变小的方式来训练模型从而达到更好的结果。SE-Netblock并不是一个完整的网络结构，而是一个即插即用的轻量级模块，通过将此模块嵌入网络之中，可以在小幅度提升参数量的代价下更加合理地分配神经网络的计算资源，大幅提升网络性能。</p><p>在SE-Netblock中，<mark>每张特征图通过全局平均池化操作进行挤压</mark>，<mark>将每一张特征图挤压成一个实数</mark>（见公式（1）），这个实数具有特征图上的全局信息，<mark>每张特征图的挤压结果组合成一个向量作为每组特征图的权重，其中H和W分别为特征图的高和宽，</mark><strong>u为卷积后的结果，z为对应特征图的全局注意力信息，将此向量通过全连接层与激活函数</strong>（见公式（2）），训练结果用来放大对于识别任务更加重要特征图的权重，缩小不重要特征图的权重，其中σ为relu激活函数，δ代表sigmoid激活函数，W1与W2代表两个不同的全连接操作。得到的向量s代表每张特征图的重要性程度。向量s通过公式（3）激励原特征图，指导特征图不断向着有利于识别任务的方向更新，挤压激励操作结构如图2所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651509.png" alt="image-20220711094328585" style="zoom:80%;" /><p>[1].张宸嘉, 朱磊与俞璐, 卷积神经网络中的注意力机制综述. 计算机工程与应用, 2021. 57(20): 第64-72页.</p><h4 id="eca-netefficient-channel-attention"><a class="markdownIt-Anchor" href="#eca-netefficient-channel-attention"></a> ECA-Net（Efficient Channel Attention）</h4><p>2020年，CVPR收录的论文中提出了ECA-Net[14]（EfficientChannelAttentionNetwork）来对SE-Net进行改进，它实现了对SE-Net block的改进，提出了<mark>一种不降维的局部跨信道交互策略（ECAblock）和自适应选择一维卷积核大小的方法</mark>，通过一维卷积层汇总跨信道信息的方法获取更加精确的注意力信息。ECA block的思想建立在作者认为<mark>跨通道的信息交互是很有必要的</mark>，而SE-Net block只注重通道内部信息的综合，没有考虑到相邻信道信息的重要性。ECA block的结构如图3所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651503.png" alt="image-20220711095517412" style="zoom:80%;" /><p>公式（4）表示最终的权重是<mark>综合了各个相邻通道的信息获得</mark>，其中σ为激活函数，yi代表通道，wi为通道yi的权重，Ω代表与yi相邻的k个通道，<mark>k的值是随着学习自适应变化的</mark>。为了实现这一想法，作者利用了一维卷积层来进行实现，通过核为k的一维卷积对通道与其相邻的k-1个通道信息进行综合，如公式（5）所示，C1Dk表示核为k的一维卷积操作，y表示通道。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651502.png" alt="image-20220711100235954" /></p><h2 id="2多路注意力"><a class="markdownIt-Anchor" href="#2多路注意力"></a> 2.多路注意力</h2><h4 id="sk-netselective-kernel-networks"><a class="markdownIt-Anchor" href="#sk-netselective-kernel-networks"></a> SK-Net（Selective Kernel Networks）</h4><p>2019年，CVPR收录的论文中提出了SK-Net（Selective Kernel Networks），SK-Net<mark>基于卷积核的注意力机制</mark>，即卷积核的重要性，即不同的图像经过不同卷积核的重要性是不同的，其结构如图4所示。整个SK-Net结构由<mark>Split、Fuse、Select</mark>三部分组成[15]。Split的任务是将输入的<strong>特征图X进行不同卷积核大小的卷积操作</strong>。如图4所示，对X进行<strong>Kernel3×3和Kernel5×5</strong>的卷积操作，得到输出U1与U2。而在Fuse部分将对U1与U2进行element-wise summation，得到输出特征图U，<mark>通过全局平均池化与全连接层获取特征图的注意力信息</mark>，并创建了一个紧凑的特征z∈Rd×1，以便为精确和自适应选择提供指导如公式（6）所示，其中δ是ReLU函数，B表示批量标准化，W表示全连接层且W∈Rd×C。公式（7）表明为了研究d对模型效率的影响，文章使用<mark>下降参数r来控制其值</mark>，L表示d的最小值。在Select部分中，将这个紧凑特征z向量重新分为两个（本文情况）或多个（更多的情况）特征向量，然后分别与相应的split之后的特征图进行相应通道的相乘操作，然后再通过这种加权共同构成输入到下一个神经元的特征向量。两个特征向量ac、bc的生成如公式（8）、（9）所示，其中A,B∈RC×d,a、b分别表示U1与U2的注意力向量，Ac∈R1×d表示A的第c行，ac表示a的第c个元素值，对于向量B同理。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651515.png" alt="image-20220711104648704" style="zoom:80%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651508.png" alt="image-20220711104719907" style="zoom:80%;" /><h4 id="resnest"><a class="markdownIt-Anchor" href="#resnest"></a> ResNeSt</h4><p>2020年，亚马逊、加州大学戴维斯分校的张航、李沐、 Smola等研究者进一步改进了 ResNet[16]（Deep Residual Network），提出了ResNeSt，其中利用ResNet、SE-Net与SKNet的思想，提出了 <mark>Split- Attention block</mark>[17]。在 ResNeSt block中，整体大框架运用了残差网络的结构，通过将网络的输入 Input输入 k个 Cardinal分支当中，公式（10）表 述了每个 Cardinal的输入，其中 R代表每个 Cardinal中 split后的分支数，k代表第 k个 Cardinal，U代表着 split 后每个分支的输入。公式（11）表述了每个 Cardinal模块 的输出，V代表携带了通道权重的 Cardinal输出，a© 是由 softmax计算得到的权重，计算方法如公式（12）所 示，其中 G代表每个 split的权重。在经过 Cardinal模块 后对最后的 k个输出进行拼接，以达到综合 k个 Cardinal 输出信息的目的，如公式（13）所示，并将拼接后的输出 与原本的输入进行 element-wise summation，得到最后 的输出，其结构如图 5所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651521.png" alt="image-20220711172340306" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651028.png" alt="image-20220711172359420" /></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651074.png" alt="image-20220711104622217" style="zoom:80%;" /><p>在每个Cardinal中，又利用了SE-Net与SK-Net的思想，使用Split模块对每个Cardinal的输入切分为r个分支，通过SE-Net中的挤压激励操作获取每个分支的注意力信息作为Fuse模块，最后在Select模块中使得具有注意力信息的向量与其对应的分支特征图相乘，并通过element-wisesummation综合r个分支的输出作为最终的Cardinal输出，Cardinal结构如图6所示。</p><h4 id="cbamconvolutional-block-attention-module"><a class="markdownIt-Anchor" href="#cbamconvolutional-block-attention-module"></a> CBAM（Convolutional Block Attention Module）</h4><p>2018年，ECCV（European Conference on Computer Vision）收录的论文中提出了卷积注意力模块 CBAM （Convolutional Block Attention Module Network），它的创新在于，它==<strong>认为对于卷积网络中的特征图来说，不仅通道中蕴含着丰富的注意力信息[18]，通道内部，即特征图像素点间也具有大量的注意力信息，而以往的注意力机制只关注了通道上的注意力信息，这对于空间上的注意力信息是一种浪费</strong>==[19]。CBAM通过构建两个子模 块，==空间注意力模块 SAM（Spatial Attention Module）， 通道注意力模块 CAM（Channel Attention Module）==分别汇总空间和通道两方面的注意力信息，并将信息进行一定程度的综合，从而获得更全面可靠的注意力信息[20]，对计算资源的分配进行更合理的指导，其结构如图7所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651084.png" alt="image-20220711184905172" style="zoom:80%;" /><p>通道注意力模块将输入的特征图F(H×W×C)分别经过基于宽和高的global max pooling（全局最大池化）和global average pooling（全局平均池化），得到两个1×1×C的特征图，接着，再将它们分别送入一个两层的神经网络（MLP），第一层神经元个数为C/r（r为减少率），激活函数为Relu，第二层神经元个数为C，这个两层的神经网络是共享的。而后，将MLP输出的特征进行基于element-wise的加和操作，再经过sigmoid激活操作，生成最终的通道注意力特征，即公式（14）中的Mc(F)，其中Favg为特征图经过全局平均池化的结果，Fmax为经过全局最大池化的结果，整个通道门注意力模块结构如图8所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651096.png" alt="image-20220711185157839" style="zoom:80%;" /><p>空间注意力模块将通道注意力模块输出的特征图F作为本模块的输入特征图[21]。首先做一个基于通道的全局最大池化和全局平均池化，得到两个尺寸为H×W×1的特征图，然后将这两个特征图基于通道做拼接操作。然后经过一个7×7卷积操作，降维为H×W×1，再经过sigmoid生成空间注意力特征，即公式（15）中的Ms(F)，其中f代表卷积操作，[]代表通道拼接操作，最后将该向量和该模块的输入特征图做乘操作，得到最终生成的特征。整个空间注意力模块结构如图9所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651114.png" alt="image-20220711185251497" style="zoom:80%;" /><h4 id="双注意力网络dual-attention-network"><a class="markdownIt-Anchor" href="#双注意力网络dual-attention-network"></a> 双注意力网络（Dual Attention Network）</h4><p>2019年CVPR收录的论文中提出了DA-Net（Dual AttentionNetwork），==与CBAM相似的是，它的思想也是综合通道和空间两路的注意力信息，但不同的是CBAM的两路注意力信息的获取是串行的，而DA-Net中的两路注意力信息的获取是并行的，且获取注意力信息的方式也有很大差别。==DA-Net从通道与空间两个分支通过对特征图进行矩阵操作构建特征图的相关性矩阵S和X，两个矩阵分别用来表征通道之间的相关性和通道内像素点之间的相关性，用此矩阵对特征图的更新进行引导，增大关键特征的权重，使得将更多的注意力放在更易于进行区分的优秀特征之上。双注意力模块结构如图10所示。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651131.png" alt="image-20220711190049358" style="zoom:80%;" /><p>其中<mark>PAM（Position Attention Module）是空间分支</mark>，其结构如图11所示，CAM（ChannelAttentionModule）是通道分支，其结构如图12所示，这两个分支通过对于特征图的处理分别构建出了关于<mark>特征图通道与空间位置的相关性矩阵X</mark>（尺寸为C×C）与S（尺寸为(H×W)×(H×W))，其中H、W、C分别为特征图的高、宽与通道数，并用此两个相关性矩阵来引导特征图不同通道与空间位置权重的更新方向，DA-Net捕捉了空间和通道维度中的全局特征依赖关系，==使用位置注意力模块来学习特征的空间相互依赖性，==通道注意力模块来模拟通道相互依赖性[22]。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651265.png" alt="image-20220711190125197" style="zoom:80%;" /><h4 id="金字塔特征注意力网络pyramid-feature-attention-network"><a class="markdownIt-Anchor" href="#金字塔特征注意力网络pyramid-feature-attention-network"></a> 金字塔特征注意力网络（Pyramid Feature Attention Network）</h4><p>2019年CVPR收录的论文中提出了金字塔特征注意力网络==，同样是利用特征图在通道间与通道内部像素点都富含大量的注意力信息的思想==[23]，其结构如图13所示。其中CA模块（ChannelAttentionModule）为通道注意力模块，CA分支的结构与SE-Net的思想是相同的，都是通过全局平均池化提取通道注意力信息，利用全连接获取各个通道的权重，如图14所示，SA模块（SpatialAttentionModule）为空间注意力模块，它利用了交替的卷积核相同的卷积层来提取通道内部像素位置之间的注意力信息，获得通道内部不同像素位置之间的相关性与重要程度等信息[24]，其结构如图15所示。两个模块分别从通道与空间两个方向提取特征图中的注意力信息，提取不同通道与空间中不同像素位置的权重信息，并对特征图进行自适应的更新。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651331.png" alt="image-20220711190217722" /></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241651360.png" alt="image-20220711190306707" style="zoom:80%;" /><h2 id="卷积网络中注意力机制展望"><a class="markdownIt-Anchor" href="#卷积网络中注意力机制展望"></a> 卷积网络中注意力机制展望</h2><p>近几年，注意力机制的思想被广泛应用在各种深度学习任务中，如计算机视觉、图像分割、自然语言处理等[25]。大量实验证明了注意力机制是行之有效且节省资源的，当注意力机制的思想运用于卷积神经网络中时，需要着眼于卷积网络中所特有的特征图中的关键信息。当前注意力机制的主流方法是将特征图中的潜在注意力信息进行深度挖掘，最常见的是通过各种手段获取各个特征图通道间的通道注意力信息与特征图内部像素点之间的空间注意力信息，获取的方法也包括但不仅限于卷积操作，矩阵操作构建相关性矩阵等，其共同的目的是更深层次、更全面地获取特征图中完善的注意力信息[26]，于是如何更深地挖掘，从哪里去挖掘特征图的注意力信息，将极有可能会成为未来注意力方法发展的方向之一。</p><p>目前，<mark>获取注意力的方法基本基于通道间的注意力信息、空间像素点之间的注意力信息和卷积核选择的注意力信息</mark>，是否能够从新的方向去获取特征图更丰富的注意力信息，或者<mark>以新的方式或手段去获取更精准的注意力信息</mark>也是未来需要关注的一个重点[27]。</p><p>ECA-Net论文中的实验证明了跨通道的信息交互对于注意力信息的获取是有积极作用的，这也从侧面验证了不同通道之间并不是相互独立的，其内部是存在许多有利的有价值的信息的[28]，那么着眼于不同通道内部的其他信息的提取，如不同特征图中像素点的空间注意力信息或其他跨通道信息是否对于获取更加精准的注意力分布有着正确的导向作用也是一个值得探索的方向[29]。</p><p>注意力机制作为一个轻量级的模块[30]，有着即插即用的特点，但是即使其本身参数量并不高[31]，在深度学习一些任务当中，注意力模块往往会被反复多次的调用，当注意力模块调用次数过多时仍然会对网络整体造成一定的负担[32]，如何优化模块结构，降低模块参数量或减少模块调用次数，更快地获取更精准的注意力信息，对于以后注意力机制在其他任务中的推广有着举足轻重的作用[33]，也是未来需要研究的重要内容之一。</p><p>卷积网络中的注意力机制的核心在于<mark>深度挖掘特征图中所含有的信息</mark>[34]，而目前所发现的注意力获取渠道相对较少，但是注意力机制已经被广泛证明其针对大量深度学习任务不仅具有参数量小[35]，即插即用的便捷性[36]，还可以较为明显地提升任务效果。说明未来对于注意力机制的深度研究是必要且意义非凡的[37]，将对深度学习任务产生重大的影响。</p><p>随着信息技术的不断发展，人类必将面临着大量而繁杂的信息，针对如此庞杂的信息去完成各项深度学习任务将变得更为困难[38]。当数据量无法任意改变的情况下，如何高效率地完成任务就变得尤为重要[39]。注意力机制便是提升深度学习任务效率的重要方法之一。当深度学习方法较为低效时，在深度学习任务中引入注意力机制将会实现“曲线救国”[40]，利用其低成本、高收益[41]的特点，大幅提升信息处理的效率，在未来的深度学习任务中大放异彩</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Attention </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DGL计算中心性</title>
      <link href="/2022/12/18/AILearning/GNN/DGL%E8%AE%A1%E7%AE%97%E4%B8%AD%E5%BF%83%E6%80%A7/"/>
      <url>/2022/12/18/AILearning/GNN/DGL%E8%AE%A1%E7%AE%97%E4%B8%AD%E5%BF%83%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<p>在DGL中，可以使用<code>dgl.degree</code>、<code>dgl.in_degree</code>和<code>dgl.out_degree</code>函数来计算图的度、入度和出度。此外，DGL还提供了一些其他库和函数来计算不同类型的中心性度量。以下是几种常见的中心性度量及其计算方法：</p><ul><li>度中心性（Degree Centrality）：度中心性衡量一个节点与图中其他节点之间的连接数量。可以使用<code>dgl.degree</code>函数计算节点的度。</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="comment"># 计算节点的度中心性</span></span><br><span class="line">degree_centrality = dgl.degree(g).<span class="built_in">float</span>() / (g.number_of_nodes() - <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Degree Centrality:&quot;</span>, degree_centrality)</span><br></pre></td></tr></table></figure><ul><li>介数中心性（Betweenness Centrality）：介数中心性衡量一个节点在图中的最短路径中充当桥梁的频率。可以使用<code>dgl.contrib.sampling.sampler.BetweennessCentrality</code>类来计算介数中心性。</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> dgl.contrib.sampling.sampler <span class="keyword">as</span> sampler</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"><span class="comment"># 计算节点的介数中心性</span></span><br><span class="line">betweenness_centrality = sampler.BetweennessCentrality()(g)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Betweenness Centrality:&quot;</span>, betweenness_centrality)</span><br></pre></td></tr></table></figure><ul><li>接近中心性（Closeness Centrality）：接近中心性衡量一个节点与图中其他节点之间的平均最短路径长度。可以使用<code>dgl.contrib.sampling.sampler.ClosenessCentrality</code>类来计算接近中心性。</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> dgl.contrib.sampling.sampler <span class="keyword">as</span> sampler</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"><span class="comment"># 计算节点的接近中心性</span></span><br><span class="line">closeness_centrality = sampler.ClosenessCentrality()(g)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Closeness Centrality:&quot;</span>, closeness_centrality)</span><br></pre></td></tr></table></figure><ul><li>特征向量中心性（Eigenvector Centrality）：特征向量中心性衡量一个节点在图中的重要性，取决于它与其他重要节点的连接程度。可以使用<code>torch.eig</code>函数计算特征值和特征向量，然后提取特征值中的实部作为特征向量中心性的度量。</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"><span class="comment"># 计算节点的特征向量中心性</span></span><br><span class="line">eigenvalues, eigenvectors = torch.eig(g.adjacency_matrix().to_dense(), eigenvectors=<span class="literal">True</span>)</span><br><span class="line">eigenvector_centrality = eigenvalues[:, <span class="number">0</span>].real</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Eigenvector Centrality:&quot;</span>, eigenvector_centrality)</span><br></pre></td></tr></table></figure><p>请注意，在计算特征向量中心性时，我们将图的邻接矩阵转换为稠密矩阵，然后使用<code>torch.eig</code>函数计算特征值和特征向量。这可能在处理大型图时导致内存问题，因此需要根据具体情况进行调整。</p>]]></content>
      
      
      <categories>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DGL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IR分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-IR/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-IR/</url>
      
        <content type="html"><![CDATA[<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>编译器和静态分析的关系</li><li>AST vs IR</li><li>IR:3-地址代码（3AC）</li><li>实际静态分析器的3AC—Soot（Java）</li><li>SSA-静态单赋值</li><li>基本块（BB）</li><li>控制流图（CFG）</li></ol><h2 id="1编译器和静态分析的关系"><a class="markdownIt-Anchor" href="#1编译器和静态分析的关系"></a> 1.编译器和静态分析的关系</h2><p>源码-&gt;（Scanner - 词法Lexical分析-Regular Expression）-&gt;（Parser- 语法Syntax分析-Context-Free Grammar）， 生成AST -&gt;（Type Checker - 语义Semantic分析 - Attribute Grammar），生成 Decorated AST  -&gt; Translator，生成IR，进行静态分析 -&gt; Code Generator</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015129.webp" alt="img" /></p><p>1-1-编译器原理.png</p><h2 id="2ast-vs-ir"><a class="markdownIt-Anchor" href="#2ast-vs-ir"></a> 2.AST vs IR</h2><p><strong>AST</strong> ：高级，更接近于语法结构，依赖于语言种类，适用于快速类型检查，缺少控制流信息</p><p><strong>IR</strong>：低级，更接近于机器码，不依赖语言种类，压缩且简洁，包含控制流信息。是静态分析的基础</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015072.webp" alt="img" /></p><p>1-2-AST&amp;IR.png</p><h2 id="3ir3-地址代码3ac"><a class="markdownIt-Anchor" href="#3ir3-地址代码3ac"></a> 3.IR:3-地址代码（3AC）</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 最多1个操作符</span></span><br><span class="line">a+b+<span class="number">3</span>  -&gt;  t1 = a+b</span><br><span class="line">                 t2 = t1+<span class="number">3</span></span><br><span class="line">Address：</span><br><span class="line">    Name:a、b</span><br><span class="line">    Constant: <span class="number">3</span></span><br><span class="line">    编译器的临时变量：t1、t2</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015124.webp" alt="img" /></p><p>1-3-常用3地址码.png</p><h2 id="4实际静态分析器的3acsootjava"><a class="markdownIt-Anchor" href="#4实际静态分析器的3acsootjava"></a> 4.实际静态分析器的3AC—Soot（Java）</h2><p>Soot-常用的Java静态分析框架</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// java IR（Jimple）基本知识</span></span><br><span class="line">invokespecial：call constructor, call superclass methods, call <span class="keyword">private</span> methods</span><br><span class="line">invokevirtual: instance methods <span class="title function_">call</span> <span class="params">(virtual dispatch)</span></span><br><span class="line">invokeinterface: cannot optimization, checking <span class="keyword">interface</span> <span class="title class_">implementation</span></span><br><span class="line">invokestation:call <span class="keyword">static</span> methods</span><br><span class="line"></span><br><span class="line">Java <span class="number">7</span>: invokedynamic -&gt; Java <span class="keyword">static</span> typing, dynamic language runs on JVM</span><br><span class="line"></span><br><span class="line">method signature: <span class="keyword">class</span> <span class="title class_">name</span>, <span class="keyword">return</span> type, method <span class="title function_">name</span><span class="params">(parameter1 type, parameter2 type)</span></span><br></pre></td></tr></table></figure><h2 id="5ssa-静态单赋值"><a class="markdownIt-Anchor" href="#5ssa-静态单赋值"></a> 5.SSA-静态单赋值</h2><p><strong>定义</strong>：给每一个定义变量一个新的名字，传递到接下来的使用当中，每个变量有1个定义（赋值的目标变量）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015273.webp" alt="img" /></p><p>1-4-SSA.png</p><p><strong>优点</strong>：唯一的变量名可以间接体现程序流信息，简化分析过程；清楚的Define-Use信息。</p><p><strong>缺点</strong>：引入很多变量和phi-function；转换为机器码时效率变低（引入很多拷贝操作）。</p><h2 id="6基本块bb"><a class="markdownIt-Anchor" href="#6基本块bb"></a> 6.基本块（BB）</h2><p><strong>定义</strong>：只有1个开头入口和1个结尾出口的最长3-地址指令序列。</p><p><strong>识别基本块的算法</strong>：首先确定入口指令，第一条指令是入口；任何跳转指令的目标地址是入口；任何跟在跳转指令之后的指令是入口。然后构造基本块，任何基本块包含1个入口指令和其接下来的指令。</p><p><strong>我的想法</strong>：对于下1条指令，若该指令不是入口，则可以加入；若该指令有多个出口，则停止加入，否则继续判断下一条指令。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015127.webp" alt="img" /></p><p>1-5-基本块算法.png</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015902.png" alt="image-20210507093627625" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015392.png" alt="image-20210507094011702" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015444.png" alt="image-20210507093932573" /></p><h2 id="7控制流图cfg"><a class="markdownIt-Anchor" href="#7控制流图cfg"></a> 7.控制流图（CFG）</h2><p><strong>控制流边</strong>：基本块A的结尾有跳转指令跳转到基本块B；原始指令序列中，B紧跟着A，且A的结尾不是无条件跳转。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015647.webp" alt="img" /></p><p>1-6-控制流边.png</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015485.png" alt="image-20210507094447334" /></p><p>添加Entry / Exit：没有块跳转到该块 / 没有跳转到其他块。</p><p>作者：bsauce<br />链接：<a href="https://www.jianshu.com/p/acb73f72cf46">https://www.jianshu.com/p/acb73f72cf46</a><br />来源：简书<br />著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>指针分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>Motivation</li><li>指针分析介绍</li><li>影响指针分析的关键要素</li><li>分析哪些语句</li></ol><h3 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点：</h3><p>什么是指针分析？影响指针分析的关键因素是什么？指针分析要分析哪些指令？</p><hr /><h1 id="1motivation"><a class="markdownIt-Anchor" href="#1motivation"></a> 1.Motivation</h1><p><strong>指针分析必要性</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012597.webp" alt="img" /></p><p>6-1-PTA-motivation.png</p><hr /><h1 id="2指针分析"><a class="markdownIt-Anchor" href="#2指针分析"></a> 2.指针分析</h1><p><strong>目标</strong>：分析程序指针可以指向哪些内存。对于Java等面向对象语言，主要分析指针指向哪个对象。</p><p><strong>说明</strong>：指针分析属于<mark>may analysis</mark>，分析的结果是某指针所有可能指向哪些对象，是个<mark>over-approximation</mark>集合。</p><p><strong>示例</strong>：面向对象语言中的指针指向问题。对于setB()函数，this指向<code>new A()</code>，因为是调用者是a.setB()；setB()中的b是x传过来的，所以b指向new B()，A.b指向 new B()。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012589.webp" alt="img" /></p><p>6-2-1-PTA示例.png</p><p><strong>区别</strong>：</p><ul><li>指针分析：<strong>分析指针所有可能指向的对象</strong>。</li><li>别名分析：<strong>分析两个指针是否指向相同的对象</strong>，可通过指针分析来推导得到。</li></ul><p><strong>应用</strong>：基本信息（别名分析/调用图），编译优化（嵌入虚拟调用），漏洞（空指针），安全分析（信息流）。</p><hr /><h1 id="3影响指针分析的关键要素"><a class="markdownIt-Anchor" href="#3影响指针分析的关键要素"></a> 3.影响指针分析的关键要素</h1><p><strong>指标</strong>：精度（precision）&amp; 效率（efficiency）。</p><p><strong>影响因素</strong>：本课程，我们主要分析分配点的堆抽象技术、上下文敏感/不敏感、流敏感/不敏感、全程序分析。</p><table><thead><tr><th>因素</th><th>问题</th><th>选项</th></tr></thead><tbody><tr><td>Heap abstraction</td><td>如何建模堆内存？</td><td>• <strong>Allocation-site</strong>        • Storeless</td></tr><tr><td>Context sensitivity</td><td>如何建模调用上下文？</td><td>• <strong>Context-sensitive</strong>     • <strong>Context-insensitive</strong></td></tr><tr><td>Flow sensitivity</td><td>如何建模控制流？</td><td>• Flow-sensitive     • <strong>Flow-insensitive</strong></td></tr><tr><td>Analysis scope</td><td>分析哪部分程序？</td><td>• <strong>Whole-program</strong>    • Demand-driven</td></tr></tbody></table><h4 id="1堆抽象内存建模"><a class="markdownIt-Anchor" href="#1堆抽象内存建模"></a> （1）堆抽象（内存建模）</h4><p><strong>问题</strong>：程序动态执行时，堆对象个数理论上是无穷无尽的，但静态分析无法处理这个问题。所以为保证指针分析可以终止，我们采用堆抽象技术，将无穷的具体对象抽象成有限的抽象对象。也即，将有共性的对象抽象成1个静态对象，从而限制静态分析对象的个数。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 示例</span></span><br><span class="line"><span class="keyword">for</span> (...) &#123;</span><br><span class="line">    A a = new A();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>技术概览</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012594.webp" alt="img" /></p><p>6-3-1-堆抽象技术概览.png</p><p>我们只学习<code>Allocation-Site</code>(分配，定位点)技术，最常见也最常被使用。</p><p><strong><code>Allocation-Site</code>原理</strong>：将动态对象抽象成它们的创建点（<code>Allocation-Site</code>），来表示在该点创建的所有动态对象。<code>Allocation-Site</code>个数是有限的。</p><p><strong>示例</strong>：循环创建了3个对象，我们用O2来抽象表示这3个动态对象。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012580.webp" alt="img" /></p><p>6-3-2-堆抽象示例.png</p><h4 id="2上下文敏感-context-sensitivity"><a class="markdownIt-Anchor" href="#2上下文敏感-context-sensitivity"></a> （2）上下文敏感 Context Sensitivity</h4><p><strong>问题</strong>：考虑是否区分不同call-site对同一函数的调用。</p><ul><li><p>Context-sensitive：根据某函数调用上下文的不同，多次分析同一函数。</p></li><li><p>Context-insensitive：每个函数只分析一次。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012569.webp" alt="img" /></p><p>6-3-3-上下文敏感示例.png</p></li></ul><h4 id="3流敏感-flow-sensitivity"><a class="markdownIt-Anchor" href="#3流敏感-flow-sensitivity"></a> （3）流敏感 Flow Sensitivity</h4><p><strong>问题</strong>：考虑语句顺序（控制流）的影响  vs 把程序当做无序语句的集合。</p><p><strong>方法</strong>：<strong>流敏感会在每个程序点都保存一份指针指向关系映射，而流不敏感则对整个程序保存一份指向关系映射。</strong></p><p><strong>说明</strong>：目前流敏感对Java提升不大，不过在C中很有效，本课程分析的是Java，所以重点讨论流不敏感技术。</p><p><strong>指针分析示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012567.webp" alt="img" /></p><p>6-3-4-流敏感示例.png</p><h4 id="4分析范围-analysis-scope"><a class="markdownIt-Anchor" href="#4分析范围-analysis-scope"></a> （4）分析范围 Analysis Scope</h4><p><strong>问题</strong>：分析程序的哪一部分？</p><ul><li>Whole-program 全程序：分析全程序的指向关系。</li><li>Demand-driven 需求驱动：只分析影响特定域的指针的指向关系。</li></ul><hr /><h1 id="4分析哪些语句"><a class="markdownIt-Anchor" href="#4分析哪些语句"></a> 4.分析哪些语句</h1><p><strong>问题</strong>：哪些语句会影响指针指向，那就只分析这些语句。</p><p><strong>Java指针类型</strong>：</p><ol><li><p><strong>Lacal variable: x</strong></p></li><li><p>Static field:C.f   （有时称为全局变量）——不分析</p></li><li><p><strong>Instance field: x.f</strong>    （对象的field）</p></li><li><p>Array element: array[i]  ——不分析，因为静态分析无法确定下标，所以将array中所有成员映射到一个field中，等价于<strong>Instance field</strong>，所以不重复分析。如下图所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012902.webp" alt="img" /></p><p>6-4-1-数组处理.png</p></li></ol><p><strong>影响指针指向的语句</strong>：</p><ol><li>New:      x = new T()</li><li>Assign：x = y</li><li>Store：  x.f = y</li><li>Load：   y = x.f</li><li>Call：     r = x.k(a,…)<ul><li>Static call：    C.foo()</li><li>Special call： super.foo() / x.<init>() / this.privateFoo()</li><li><strong>Virtual call</strong>：x.foo()</li></ul></li></ol><p>复杂的内存访问可以通过引入临时变量，转化为三地址代码：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">x.f.g.h = y;</span><br><span class="line"><span class="comment">// 转化为</span></span><br><span class="line">t1 = x.f;</span><br><span class="line">t2 = t1.g;</span><br><span class="line">t2.h = y;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>指针分析基础</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>指针分析规则</li><li>如何实现指针分析</li><li>指针分析算法</li><li>指针分析如何处理函数调用（过程间指针分析）</li></ol><h3 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点：</h3><p>理解指针分析的规则、指针流图PFG、指针分析算法。</p><p>理解指针分析调用函数的规则、过程间指针分析算法、实时调用图构建。</p><hr /><h1 id="1指针分析规则"><a class="markdownIt-Anchor" href="#1指针分析规则"></a> 1.指针分析规则</h1><p><strong>首先分析前4种语句</strong>：New / Assign / Store / Load。</p><p><strong>指针分析的域和相应的记法</strong>：变量/函数/对象/实例域/指针，用pt表示程序中的指向关系（映射）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012464.webp" alt="img" /></p><p>7-1-1-标记方法.png</p><p><strong>规则</strong>：采用推导形式，横线上面是条件，横线下面是结论。</p><ul><li><p>New：创建对象，将<code>new T()</code>对应的对象oi加入到x的指针集。</p></li><li><p>Assign：将y的指针集加入到x对应的指针集。</p></li><li><p>Store：让oi的field指向oj。</p></li><li><p>Load：Store的反操作。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012461.webp" alt="img" /></p><p>7-1-2-规则.png</p></li></ul><hr /><h1 id="2如何实现指针分析"><a class="markdownIt-Anchor" href="#2如何实现指针分析"></a> 2.如何实现指针分析</h1><p><strong>算法要求</strong>：全程序指针分析，要容易理解和实现。</p><p><strong>本质</strong>：在指针（变量/域）之间传递指向信息。Andersen-style分析（很普遍）——很多solving system把指针分析看作是一种包含关系，eg，<code>x = y</code>，x包含y。</p><p><strong>问题</strong>：当一个指针的指向集发生变化，必须更新与它相关的其他指针。如何表示这种传递关系？PFG。</p><p><strong>PFG</strong>：用指针流图PFG来表示指针之间的关系，PFG是<strong>有向图</strong>。</p><ul><li>Nodes：Pointer = V U (O x F)    节点n表示一个变量或抽象对象的域。</li><li>Edges：Pointer X Pointer   边x -&gt; y 表示指针x指向的对象may会流入指针y。</li></ul><p><strong>Edges添加规则</strong>：根据程序语句 + 对应的规则。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012456.webp" alt="img" /></p><p>7-2-1-PFG边规则.png</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012467.webp" alt="img" /></p><p>7-2-2-PFG示例.png</p><p><strong>PTA步骤</strong>：</p><ol><li>构造PFG（根据以上示例，PFG也受指向关系影响）</li><li>根据PFG传播指向信息</li></ol><hr /><h1 id="3指针分析算法"><a class="markdownIt-Anchor" href="#3指针分析算法"></a> 3.指针分析算法</h1><h4 id="1过程内pta算法"><a class="markdownIt-Anchor" href="#1过程内pta算法"></a> （1）过程内PTA算法</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012472.webp" alt="img" /></p><p>7-3-0-PTA算法_过程内.png</p><p><strong>符号</strong>：</p><ul><li>S：程序语句的集合。</li><li>WL：Work list，待合并的指针信息，二元组的集合，&lt;指针n，指向的对象集合pts&gt;。pts将被加入到n的指向集pt(n)中。</li><li>PFG：指针流图。</li></ul><p><strong>步骤</strong>：对每种语句都是基于第1小节的规则来实现。</p><ol><li>对S中所有类似**New <code>x = new T()</code>**的语句，将&lt;x, {oi}&gt;加入到WL。</li><li>对S中所有类似**Assign <code>x = y</code>**的语句，调用<code>AddEdge()</code>将<code>y -&gt; x</code>加入到PFG，&lt;x, pt(y)&gt;加入到WL（传播指向信息）。</li><li>遍历WL，取一个元素&lt;n, pts&gt;，除去pts中与pt(n)重复的对象得到<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012374.svg" alt="\Delta" />，调用Propagate(n,<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />)将<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />加入到pt(n)，且取出PFG中所有n指向的边<code>n-&gt;s</code>，将&lt;s, pts&gt;加入到WL（根据PFG将指向信息传递给同名指针）。</li><li>如果n表示一个变量x（x跟Store/Load指令相关），对<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />中的每个对象oi。对S中所有类似**Store <code>x.f = y</code><strong>的语句，调用<code>AddEdge()</code>将<code>y -&gt; oi.f</code>加入到PFG，&lt;oi.f, pt(y)&gt;加入到WL（传播指向信息）；对S中所有类似</strong>Load <code>y = x.f</code>**的语句，调用<code>AddEdge()</code>将<code>oi.f -&gt; y</code>加入到PFG，&lt;y, pt(oi.f)&gt;加入到WL（传播指向信息）。</li></ol><p><strong>问题</strong>：</p><ol><li>为什么要去重？避免冗余，英文叫做Differential propagation差异传播。</li><li>指针集用什么数据结构存储？混合集 Hibra-set，集合元素小于16个用hash set，大于16个用big-rector 位存储。</li><li>开源项目有哪些？<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fsable.github.io%2Fsoot%2F">Soot</a>、<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fwala.sourceforge.net%2Fwiki%2Findex.php%2FMain_Page">WALA</a>、<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fpag-www.gtisc.gatech.edu%2Fchord%2Fuser_guide%2F">Chord</a>。</li></ol><h4 id="2示例"><a class="markdownIt-Anchor" href="#2示例"></a> （2）示例</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span> b = new C(); </span><br><span class="line"><span class="number">2</span> a = b;</span><br><span class="line"><span class="number">3</span> c = new C(); </span><br><span class="line"><span class="number">4</span> c.f = a;</span><br><span class="line"><span class="number">5</span> d = c;</span><br><span class="line"><span class="number">6</span> c.f = d; </span><br><span class="line"><span class="number">7</span> e = d.f;</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">WL</th><th style="text-align:center">正处理</th><th style="text-align:center">PFG</th><th>指针集</th><th>处理语句</th><th>算法语句</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">[&lt;b, {o1}&gt;, &lt;c, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td>1，3</td><td>处理New</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">[&lt;b, {o1}&gt;, &lt;c, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td></td><td>2，4</td><td>处理Assign</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">[&lt;c, {o3}&gt;]</td><td style="text-align:center">&lt;b, {o1}&gt;</td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td>pt(b)={o1}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">[&lt;c, {o3}&gt;], &lt;a, {o1}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td></td><td></td><td>Propagate()传递，没有b.f语句</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">[&lt;a, {o1}&gt;]</td><td style="text-align:center">&lt;c, {o3}&gt;</td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td>pt©={o3}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">[&lt;a, {o1}&gt;, &lt;d, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td></td><td></td><td>Propagate()传递，有c.f语句</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">[&lt;a, {o1}&gt;, &lt;d, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；o3.f&lt;-a；o3.f&lt;-d；  <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012907.webp" alt="img" /> 7-3-1-PFG.png</td><td></td><td>4，6</td><td>处理Store/Load，添加边</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">[&lt;d, {o3}&gt;]</td><td style="text-align:center">&lt;a, {o1}&gt;</td><td style="text-align:center"></td><td>pt(a)={o1}；</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">[&lt;d, {o3}&gt;,&lt;o3.f, {o1}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递</td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">[&lt;o3.f, {o1}&gt;]</td><td style="text-align:center">&lt;d, {o3}&gt;</td><td style="text-align:center"></td><td>pt(d)={o3}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">11</td><td style="text-align:center">[&lt;o3.f, {o1}&gt;, &lt;o3.f, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递，有d.f语句</td></tr><tr><td style="text-align:center">12</td><td style="text-align:center">[&lt;o3.f, {o1}&gt;, &lt;o3.f, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；o3.f&lt;-a；o3.f&lt;-d；e&lt;-o3.f；  <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012751.webp" alt="img" /> 7-3-2-PFG.png</td><td></td><td>7</td><td>处理Load，添加边</td></tr><tr><td style="text-align:center">13</td><td style="text-align:center">[&lt;o3.f, {o3}&gt;]</td><td style="text-align:center">&lt;o3.f, {o1}&gt;</td><td style="text-align:center"></td><td>pt(o3.f)={o1}；</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">14</td><td style="text-align:center">[&lt;o3.f, {o3}&gt;, &lt;e, {o1}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递</td></tr><tr><td style="text-align:center">15</td><td style="text-align:center">[&lt;e, {o1}&gt;]</td><td style="text-align:center">&lt;o3.f, {o3}&gt;</td><td style="text-align:center"></td><td>pt(o3.f)={o1, o3}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">16</td><td style="text-align:center">[&lt;e, {o1}&gt;, &lt;e, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递</td></tr><tr><td style="text-align:center">17</td><td style="text-align:center"></td><td style="text-align:center">&lt;e, {o1}&gt;；&lt;e, {o3}&gt;</td><td style="text-align:center"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012778.webp" alt="img" /> 7-3-3-PFG.png</td><td>pt(e)={o1, o3}</td><td></td><td>while开头</td></tr></tbody></table><hr /><h1 id="4指针分析如何处理函数调用"><a class="markdownIt-Anchor" href="#4指针分析如何处理函数调用"></a> 4.指针分析如何处理函数调用</h1><p><strong>构造调用图技术对比</strong>：</p><ul><li>CHA：基于声明类型，不精确，引入错误的调用边和指针关系。</li><li>指针分析：基于pt(a)，即a指向的类型，更精确，构造更准的CG并对指针分析有正反馈（所以过程间指针分析和CG构造同时进行，很复杂）。</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">(A a)</span> &#123;   <span class="comment">// pt(a) = ???</span></span><br><span class="line">  ...</span><br><span class="line">    b = a.bar();    <span class="comment">// pt(b) = ???  把a的指向分析清楚了，就能确定a.bar()到底调用哪个对象的bar()函数，那么b的指向也明确了。</span></span><br><span class="line">    ... </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="1调用语句规则"><a class="markdownIt-Anchor" href="#1调用语句规则"></a> （1）调用语句规则</h4><p><strong>call语句规则</strong>：主要分为4步。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012806.webp" alt="img" /></p><p>7-4-1-call规则.png</p><ol><li><strong>找目标函数m</strong>：Dispatch(oi, k)——找出pt(x)，也即oi类型对象中的k函数。</li><li><strong>receiver object</strong>：把x指向的对象（<code>pt(x)</code>）传到m函数的this变量，即mthis</li><li><strong>传参数</strong>：pt(aj), 1&lt;=j&lt;=n  传给m函数，即p(mpj), 1&lt;=j&lt;=n。<strong>建立PFG边</strong>，a1-&gt;mp1，…，an-&gt;mpn。</li><li><strong>传返回值</strong>：pt(mret)传给pt®。<strong>建立PFG边</strong>，r&lt;-mret。</li></ol><p><strong>问题</strong>：为什么PFG中不添加x-&gt;mthis边？因为mthis只和自己这个对象相关，而可能有pt(x)={new A, new B, new C}，指定对象的x只流向对应的对象，是无法跨对象传递的。</p><h4 id="2过程间pta算法"><a class="markdownIt-Anchor" href="#2过程间pta算法"></a> （2）过程间PTA算法</h4><p><strong>问题</strong>：由于指针分析和CG构造互相影响，所以每次迭代只分析可达的函数和语句。然后不断发现和分析新的可达函数。</p><p><strong>可达示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012783.webp" alt="img" /></p><p>7-4-2-可达示例.png</p><p><strong>算法</strong>：黄色背景的代码是和过程内分析不同的地方。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012835.webp" alt="img" /></p><p>7-4-3-PTA算法_过程间.png</p><p><strong>符号</strong>：</p><ul><li>mentry：入口main函数</li><li>Sm：函数m中的语句</li><li>S：可达语句的集合（就是RM中的语句）</li><li>RM：可达函数的集合</li><li>CG：调用图的边</li></ul><p><strong>步骤</strong>：基于调用规则来实现。</p><ol><li>首先调用<strong>AddReachable(mentry)</strong>，将入口函数mentry的语句加到S中。处理**New <code>x = new T()</code><strong>语句，把&lt;x, {oi}&gt;加入到WL；处理</strong>Assign <code>x = y</code>**语句，调用<code>AddEdge(y, x)</code>加入边到PFG。</li><li>跟过程内指针分析一样，遍历WL，取一个元素&lt;n, pts&gt;，除去pts中与pt(n)重复的对象得到<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />，调用Propagate(n,<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />)将<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />加入到pt(n)，且取出PFG中所有n指向的边<code>n-&gt;s</code>，将&lt;s, pts&gt;加入到WL（根据PFG将指向信息传递给同名指针）。</li><li>如果n表示一个变量x（x跟Store/Load指令相关），对<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />中的每个对象oi。对S中所有类似**Store <code>x.f = y</code><strong>的语句，调用<code>AddEdge()</code>将<code>y -&gt; oi.f</code>加入到PFG，&lt;oi.f, pt(y)&gt;加入到WL（传播指向信息）；对S中所有类似</strong>Load <code>y = x.f</code>**的语句，调用<code>AddEdge()</code>将<code>oi.f -&gt; y</code>加入到PFG，&lt;y, pt(oi.f)&gt;加入到WL（传播指向信息）。</li><li>最后调用<strong>ProcessCall(x, oi)</strong>，处理与x相关的<strong>call指令</strong>。取出S中类似<code>r = x.k(a1,...,an)</code>的调用语句L，首先调用Dispatch(oi, k)解出调用的目标函数m，把&lt;mthis, {oi}&gt;加入到WL（传递接收对象，上下文敏感分析将用到），将<code>L-&gt;m</code>这条调用边加入到CG；调用**AddReachable(m)**将新的语句加入到S，并处理New/Assign语句；调用AddEdge()将<code>实参-&gt;形参</code>、<code>返回值-&gt;r</code>边加入到PFG（传递参数、返回值），并将<code>&lt;形参,pt(实参)&gt;</code>、<code>&lt;r,pt(返回值)&gt;</code>加入到WL。</li></ol><p><strong>问题</strong>：为什么ProcessCall(x, oi)中，要判断<code>L-&gt;m</code>这条边是否已经加入到CG？因为x可能指向多个对象，就会多次处理L这个调用指令，可能x中别的对象oj早就已经将这条边加入进去了。</p><h4 id="3示例"><a class="markdownIt-Anchor" href="#3示例"></a> （3）示例</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span> &#123;</span></span><br><span class="line"><span class="number">2</span>   <span class="type">static</span> <span class="type">void</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="number">3</span>       A a = new A();</span><br><span class="line"><span class="number">4</span>       A b = new B();</span><br><span class="line"><span class="number">5</span>       A c = b.foo(a);</span><br><span class="line"><span class="number">6</span>   &#125;</span><br><span class="line"><span class="number">7</span>   A <span class="title function_">foo</span><span class="params">(Ax)</span>&#123;...&#125;</span><br><span class="line"><span class="number">8</span> &#125;</span><br><span class="line"><span class="number">9</span> <span class="class"><span class="keyword">class</span> <span class="title">B</span> <span class="title">extends</span> <span class="title">A</span> &#123;</span>  </span><br><span class="line"><span class="number">10</span>  A <span class="title function_">foo</span><span class="params">(A y)</span> &#123;</span><br><span class="line"><span class="number">11</span>      A r=newA();</span><br><span class="line"><span class="number">12</span>      <span class="keyword">return</span> r;</span><br><span class="line"><span class="number">13</span>      &#125;</span><br><span class="line"><span class="number">14</span>  &#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">WL</th><th style="text-align:center">正处理</th><th style="text-align:center">PFG</th><th style="text-align:center">指针集</th><th style="text-align:center">RM</th><th style="text-align:center">CG</th><th style="text-align:center">语句</th><th>算法语句</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">[]</td><td style="text-align:center"></td><td style="text-align:center">{}</td><td style="text-align:center"></td><td style="text-align:center">{}</td><td style="text-align:center">{}</td><td style="text-align:center"></td><td>初始化</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">[]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">{A.main()}</td><td style="text-align:center"></td><td style="text-align:center">1，2</td><td>AddReachable(mentry)</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">[&lt;a,{o3}&gt;, &lt;b,{o4}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">3，4</td><td></td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">[&lt;b,{o4}&gt;]</td><td style="text-align:center">&lt;a,{o3}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(a)={o3}；</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">[]</td><td style="text-align:center">&lt;b,{o4}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(b)={o4}</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">[]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">5</td><td>ProcessCall(b, o4)</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">[&lt;B.foothis, {o4}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">{5-&gt;B.foo(A)}</td><td style="text-align:center"></td><td>m=Dispatch(o4, foo())=B.foo()；添加到调用图</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">[&lt;B.foothis, {o4}&gt;, &lt;r, o11&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">{A.main(), B.foo()}</td><td style="text-align:center"></td><td style="text-align:center"></td><td>AddReachable(B.foo())；添加到可达函数</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">[&lt;B.foothis, {o4}&gt;, &lt;r, o11&gt;, &lt;y, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">{a-&gt;y, r-&gt;c}    <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012987.webp" alt="img" /></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>AddEdge()；添加参数边、返回值边</td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">[&lt;r, o11&gt;, &lt;y, {o3}&gt;]</td><td style="text-align:center">&lt;B.foothis, {o4}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(B.foothis)={o4}；</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头，B.foothis没有调用任何函数</td></tr><tr><td style="text-align:center">11</td><td style="text-align:center">[&lt;y, {o3}&gt;, &lt;c, {o11}&gt;]</td><td style="text-align:center">&lt;r, o11&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt®={o11}；</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr><tr><td style="text-align:center">12</td><td style="text-align:center"></td><td style="text-align:center">&lt;y, {o3}&gt;, &lt;c, {o11}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(y)={o3}；pt©={o11}</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr></tbody></table><p>如果是CHA的话，CG={5-&gt;B.foo(A), <strong>5-&gt;A.foo(A)</strong>}，错误识别为调用边。</p><p><strong>结果</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012023.webp" alt="img" /></p><p>7-4-5-result.png</p><p><strong>问题</strong>：没有入口函数的？如对库函数处理，生成调用库函数的程序。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据流分析2</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%902/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%902/</url>
      
        <content type="html"><![CDATA[<p>关于这一节<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Fhahahaqwe123">zcc</a>的笔记已经够完美了，我就直接在他基础上记录了。</p><h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>迭代算法-另一个角度</li><li>偏序（Partial Order）</li><li>上下界（Upper and Lower Bounds）</li><li>格（Lattice），半格（Semilattice），全格和格点积（Complete and Product Lattice）</li><li>数据流分析框架（via Lattice）</li><li>单调性与不动点定理（Monotonicity and Fixed Point Theorem）</li><li>迭代算法转化为不动点理论</li><li>从lattice的角度看may/must分析</li><li>分配性（Distributivity）和MOP</li><li>常量传播</li><li>Worklist算法</li></ol><h3 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点：</h3><p>上节课是介绍了3种数据流分析迭代算法，本节课将从数学理论的角度来讨论数据流分析，加深对数据流分析算法的理解。</p><hr /><h2 id="1迭代算法-另一个角度"><a class="markdownIt-Anchor" href="#1迭代算法-另一个角度"></a> 1.迭代算法-另一个角度</h2><p><strong>本质</strong>：常见的数据流迭代算法，目的是通过迭代计算，最终得到一个稳定的不变的解。</p><h4 id="1理论"><a class="markdownIt-Anchor" href="#1理论"></a> （1）理论</h4><p><strong>定义1</strong>：给定有k个节点（基本块）的CFG，迭代算法就是在每次迭代时，更新每个节点n的OUT[n]。</p><p><strong>定义2</strong>：设数据流分析的值域是V，可定义一个<strong>k-元组</strong>： (OUT[n1], OUT[n2], … , OUT[nk])。是集合 (V1 <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\times" /> V2 … <img src="https://math.jianshu.com/math?formula=%5Ctimes" alt="\times" /> Vk) （幂集，记为Vk）的一个元素，表示每次迭代后k个节点整体的值。</p><p><strong>定义3</strong>：每一次迭代可看作是Vk映射到新的Vk，通过转换规则和控制流来映射，记作函数F：Vk <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\rightarrow" /> Vk。</p><p><strong>迭代算法本质</strong>：通过不断迭代，直到相邻两次迭代的<strong>k-元组</strong>值一样，算法结束。</p><h4 id="2图示"><a class="markdownIt-Anchor" href="#2图示"></a> （2）图示</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002572.webp" alt="img" /></p><p>4-1-迭代算法数学化.png</p><p><strong>不动点</strong>：当Xi = F(Xi)时，就是不动点。</p><p><strong>问题</strong>：</p><ul><li>迭代算法是否一定会停止（到达不动点）？</li><li>迭代算法如果会终止，会得到几个解（几个不动点）？</li><li>迭代几次会得到解（到达不动点）？</li></ul><hr /><h2 id="2偏序partial-order"><a class="markdownIt-Anchor" href="#2偏序partial-order"></a> 2.偏序（Partial Order）</h2><p><strong>定义</strong>：给定偏序集(P, <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\sqsubseteq" />)，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />是集合P上的二元关系，若满足以下性质则为偏序集：</p><ul><li>∀<em>x</em>∈<em>P</em>,<em>x</em>⊑<em>x</em>                          自反性Reflexivity</li><li>∀<em>x</em>,<em>y</em>∈<em>P</em>, <em>x</em>⊑<em>y</em>∧<em>y</em>⊑<em>x</em> ⇒ <em>x</em>=y     对称性Antisymmetry</li><li>∀<em>x</em>,<em>y</em>∈<em>P</em>, <em>x</em>⊑<em>y</em>∧<em>y</em>⊑<em>z</em> ⇒ <em>x</em>⊑<em>z</em>     传递性Transitivity</li></ul><p><strong>例子</strong>：</p><ul><li>P是整数集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\leq" />，是偏序集；若<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示&lt;，则显然不是偏序集。</li><li>P是英文单词集合，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示子串关系（可以存在两个元素不具有偏序关系，不可比性），是偏序集。</li></ul><hr /><h2 id="3上下界upper-and-lower-bounds"><a class="markdownIt-Anchor" href="#3上下界upper-and-lower-bounds"></a> 3.上下界（Upper and Lower Bounds）</h2><h5 id="1定义"><a class="markdownIt-Anchor" href="#1定义"></a> （1）定义</h5><p><strong>定义</strong>：给定偏序集(P, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />)，且有P的子集S⊆P：</p><ul><li>∀<em>x</em>∈<em>S</em>, <em>x</em>⊑<em>u</em>, 其中<em>u</em>∈<em>P</em>，则u是子集S的上界 （<strong>注意，u并不一定属于S集</strong>）</li><li>∀<em>x</em>∈<em>S</em>, <em>l</em>⊑<em>x</em>, 其中<em>l</em>∈<em>P</em>，则l是S的下界</li></ul><p><strong>最小上界</strong>：least upper bound（lub 或者称为join），用⊔S表示。上确界？</p><p>定义：对于子集S的任何一个上界u，均有⊔S⊑u。</p><p><strong>最大下界</strong>：greatest lower bound（glb 或者称为meet），用⊓S表示。下确界？</p><p>定义：对于子集S的任何一个下界l，均有l⊑⊓S。</p><h5 id="2示例"><a class="markdownIt-Anchor" href="#2示例"></a> （2）示例</h5><p>若S只包含两个元素，a、b（S = {a, b}）那么上界可以表示为a⊔b，下界可以表示为a⊓b。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002554.webp" alt="img" /></p><p>4-3-1-上下确界示例.png</p><h5 id="3特性"><a class="markdownIt-Anchor" href="#3特性"></a> （3）特性</h5><ul><li>并非每个偏序集都有上下确界。</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002553.webp" alt="img" /></p><p>4-3-2-无下确界.png</p><ul><li><p>如果存在上下确界，则是唯一的。</p><p>利用传递性和反证法即可证明。</p></li></ul><hr /><h2 id="4格lattice半格semilattice全格格点积complete-and-product-lattice"><a class="markdownIt-Anchor" href="#4格lattice半格semilattice全格格点积complete-and-product-lattice"></a> 4.格（Lattice），（半格）Semilattice，全格，格点积（Complete and Product Lattice）</h2><p>都是基于上下确界来定义的。</p><h4 id="1格"><a class="markdownIt-Anchor" href="#1格"></a> （1）格</h4><p><strong>定义</strong>：给定一个偏序集(P,⊑)，∀a,b∈P，如果存在a⊔b和a⊓b，那么就称该偏序集为格。偏序集中的<strong>任意两个元素</strong>构成的集合均<strong>存在最小上界和最大下界</strong>，那么该偏序集就是格。</p><p><strong>例子</strong>：</p><ul><li>(S, ⊑)中S是整数子集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />是<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\leq" />，是格点；</li><li>(S, ⊑)中S是英文单词集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示子串关系，不是格点，因为单词pin和sin就没有上确界；</li><li>(S, ⊑)中S是{a, b, c}的幂集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\subseteq" />子集，是格点。</li></ul><h4 id="2半格"><a class="markdownIt-Anchor" href="#2半格"></a> （2）半格</h4><p><strong>定义</strong>：给定一个偏序集(P,⊑)，∀a,b∈P：<br />当且仅当a⊔b存在（上确界），该偏序集叫做 join semilatice；</p><p>当且仅当a⊓b存在（下确界），该偏序集叫做 meet semilatice</p><h4 id="3全格"><a class="markdownIt-Anchor" href="#3全格"></a> （3）全格</h4><p><strong>定义</strong>：对于格点 (S, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />) （前提是格点）的任意子集S，⊔<em>S</em>上确界和⊓S下确界都存在，则为全格complete lattice。</p><p><strong>例子</strong>：</p><ul><li>P是整数集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />是<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\leq" />，不是全格，因为P的子集正整数集没有上确界。</li><li>(S, ⊑)中S是{a, b, c}的幂集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\subseteq" />子集，是全格。</li></ul><p><strong>符号</strong>：<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\top" /> = <img src="mdPics/math" alt="\sqcup" />P ，叫做top；<img src="mdPics/math" alt="\perp" /> = <img src="mdPics/math" alt="\sqcap" />P，叫做bottom。</p><p><strong>性质</strong>：有穷的格点必然是complete lattice。全格一定有穷吗？ 不一定，如实数界[0, 1]。</p><h4 id="4格点积"><a class="markdownIt-Anchor" href="#4格点积"></a> （4）格点积</h4><p><strong>定义</strong>：给定一组格，L1=(P1, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />1)，L2=(P2, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />2)，… ，Ln=(Pn, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />n)，都有上确界<img src="mdPics/math" alt="\sqcup" />i和下确界<img src="mdPics/math" alt="\sqcap" />i，则定义格点积 Ln = (P, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />)：</p><ol><li>P = P1 <img src="https://math.jianshu.com/math?formula=%5Ctimes" alt="\times" /> … <img src="https://math.jianshu.com/math?formula=%5Ctimes" alt="\times" /> Pn</li><li>(x1, … xn) <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" /> (y1, … yn) <img src="mdPics/math" alt="\Leftrightarrow" /> (x1 <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" /> y1) <img src="mdPics/math" alt="\wedge" /> … <img src="https://math.jianshu.com/math?formula=%5Cwedge" alt="\wedge" /> (xn <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" /> yn)</li><li>(x1, … xn) <img src="mdPics/math" alt="\sqcup" /> (y1, … yn) = (x1 <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup" /> y1, …, xn <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup" /> yn)</li><li>(x1, … xn) <img src="mdPics/math" alt="\sqcap" /> (y1, … yn) = (x1 <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> y1, …, xn <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> yn)</li></ol><p><strong>性质</strong>：格点积也是格点；格点都是全格，则格点积也是全格。</p><hr /><h2 id="5数据流分析框架via-lattice"><a class="markdownIt-Anchor" href="#5数据流分析框架via-lattice"></a> 5.数据流分析框架（via Lattice）</h2><p>数据流分析框架(D, L, F) ：</p><ul><li>D—方向</li><li>L—格点（值域V，meet <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> 或 join <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup" /> 操作）</li><li>F—转换规则V <img src="mdPics/math" alt="\rightarrow" /> V。</li></ul><p>数据流分析可以看做是<strong>迭代算法</strong>对<strong>格点</strong> 利用<strong>转换规则</strong>和 <strong>meet/join操作</strong>。</p><hr /><h2 id="6单调性与不动点定理monotonicity-and-fixed-point-theorem"><a class="markdownIt-Anchor" href="#6单调性与不动点定理monotonicity-and-fixed-point-theorem"></a> 6.单调性与不动点定理（Monotonicity and Fixed Point Theorem）</h2><p>目标问题：迭代算法一定会停止（到达不动点）吗？</p><p>（1）单调性</p><p><strong>定义</strong>：函数f: L <img src="mdPics/math" alt="\rightarrow" /> L，满足∀x,y∈L，x⊑y⇒f(x)⊑f(y)，则为单调的。</p><p>（2）不动点理论</p><p><strong>定义</strong>：给定一个<strong>完全lattice(L,⊑)</strong>，如果f:L→L是<strong>单调</strong>的，并且<strong>L有限</strong></p><p>那么我们能得到最小不动点，通过迭代：f(⊥),f(f(⊥)),…,fk(⊥)直到找到最小的一个不动点。</p><p>同理 我们能得到最大不动点，通过迭代：f(⊤),f(f(⊤)),…,fk(⊤)直到找到最大的一个不动点。</p><p>（3）证明</p><p>不动点的存在性；</p><p>最小不动点证明。</p><hr /><h2 id="7迭代算法转化为不动点理论"><a class="markdownIt-Anchor" href="#7迭代算法转化为不动点理论"></a> 7.迭代算法转化为不动点理论</h2><p><strong>问题</strong>：我们如何在理论上证明<strong>迭代算法有解</strong>、<strong>有最优解</strong>、<strong>何时到达不动点</strong>？那就是将迭代算法转化为<strong>不动点理论</strong>。因为不动点理论已经证明了，单调、有限的完全lattice，存在不动点，且从⊤开始能找到最大不动点，从⊥开始能找到最小不动点。</p><p><strong>目标</strong>：证明迭代算法是一个<strong>完全lattice(L, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />)</strong>，是<strong>有限</strong>的，<strong>单调</strong>的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002789.webp" alt="img" /></p><p>4-7-1-迭代算法.png</p><h4 id="1完全lattice证明"><a class="markdownIt-Anchor" href="#1完全lattice证明"></a> （1）完全lattice证明</h4><p>根据第5小节，迭代算法每个<strong>节点（基本块）的值域</strong>相当于一个<strong>lattice</strong>，每次迭代的<strong>k个基本块的值域</strong>就是一个<strong>k-元组</strong>。k-元组可看作<strong>lattice积</strong>，根据格点积性质：若Lk中每一个lattice都是完全的，则Lk也是<strong>完全</strong>的。</p><h4 id="2l是有限的"><a class="markdownIt-Anchor" href="#2l是有限的"></a> （2）L是有限的</h4><p>迭代算法中，值域是0/1，是有限的，则lattice有限，则Lk也有限。</p><h4 id="3f是单调的"><a class="markdownIt-Anchor" href="#3f是单调的"></a> （3）F是单调的</h4><p>函数F：BB中转换函数fi：L → L   +    BB分支之间的控制流影响（汇聚是join <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup" /> / meet <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> 操作，分叉是拷贝操作）。</p><ol><li>转换函数：BB的gen、kill是固定的，值域一旦变成1，就不会变回0，显然单调。</li><li>join/meet操作：L × L → L 。证明：∀x,y,z∈L，且有x⊑y需要证明x⊔z⊑y⊔z。</li></ol><p><strong>总结</strong>：迭代算法是完全lattice，且是有限、单调的，所以一定有解、有最优解。</p><h4 id="4算法何时到达不动点"><a class="markdownIt-Anchor" href="#4算法何时到达不动点"></a> （4）算法何时到达不动点？</h4><p><strong>定义</strong>：<strong>lattice高度</strong>—从lattice的top到bottom之间最长的路径。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002813.webp" alt="img" /></p><p>4-7-3-lattice高度定义.png</p><p><strong>最坏情况迭代次数</strong>：设有n个块，每次迭代只有1个BB的OUT/IN值的其中1位发生变化（则从top→bottom这1位都变化），则最多迭 (<strong>n × h</strong>) 次。</p><hr /><h2 id="8从lattice的角度看maymust分析"><a class="markdownIt-Anchor" href="#8从lattice的角度看maymust分析"></a> 8.从lattice的角度看may/must分析</h2><p><strong>说明</strong>：may 和 must 分析算法都是从不安全到安全（是否安全取决于safe-aprroximate过程），从准确到不准确。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002848.webp" alt="img" /></p><p>4-8-1-must_may分析特点.png</p><h4 id="1may分析"><a class="markdownIt-Anchor" href="#1may分析"></a> （1）may分析</h4><p>以 Reaching Definitions分析为例：</p><ol><li>从<img src="mdPics/math" alt="\perp" /> 开始，<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" /> 表示所有定义都不可达，是<strong>不安全</strong>的结果（因为这个分析的应用目的是为了查错，查看变量是否需要初始化。首先在Entry中给每个变量一个假定义，标记所有变量为都为未初始化状态，<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" />表示所有的假定义都无法到达，说明所有变量在中间都进行了赋值，那就不需要对任何变量进行初始化，这是不安全的，可能导致未初始化错误）。</li><li><img src="mdPics/math" alt="\top" />表示所有Entry中的假定义都可达，从查错角度来说，需要对每个变量都进行初始化，非常<strong>安全</strong>！但是这句话没有用，我都要初始化的话还做这个分析干嘛？</li><li>Truth：表明最准确的验证结果，假设{a,c}是truth，那么包括其以上的都是safe的，以下的都是unsafe，就是上图的阴影和非阴影。</li></ol><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002864.webp" alt="img" /></p><p>4-8-2-Truth示例.png</p><ol><li>从<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" /> 到<img src="mdPics/math" alt="\top" /> ，得到的<strong>最小不动点</strong>最准确，离Truth最近。上面还有多个不动点，越往上越不准。</li></ol><h4 id="2must分析"><a class="markdownIt-Anchor" href="#2must分析"></a> （2）must分析</h4><p>以available expressions分析为例：</p><ol><li>从<img src="mdPics/math" alt="\top" />开始，表示所有表达式可用。如果用在表达式计算优化中，那么有很多已经被重定义的表达式也被优化了（实际上不能被优化），那么该优化就是错误的，<strong>不安全</strong>！</li><li><img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" />表示没有表达式可用，都不需要优化，很<strong>安全</strong>！但没有用。</li><li>从<img src="mdPics/math" alt="\top" />到<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" />，就是从不安全到安全，存在一个Truth，代表准确的结果。</li><li>从<img src="mdPics/math" alt="\top" />到<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" />，达到一个<strong>最大不动点</strong>，离truth最近的最优解。</li></ol><p>迭代算法转化到lattice上，may/must分析分别初始化为最小值<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" />和最大值<img src="mdPics/math" alt="\top" />，最后求最小上界/最大下界。</p><hr /><h2 id="9分配性distributivity和mop"><a class="markdownIt-Anchor" href="#9分配性distributivity和mop"></a> 9.分配性（Distributivity）和MOP</h2><p><strong>目的</strong>：MOP（meet-over-all-paths）衡量迭代算法的精度。</p><h4 id="1概念"><a class="markdownIt-Anchor" href="#1概念"></a> （1）概念</h4><p><strong>定义</strong>：最终将所有的路径一起来进行join/meet操作。</p><p><strong>路径P</strong> = 在cfg图上从entry到基本块si的一条路径（P = Entry → s1 → s2 → … → s~i ）。</p><p><strong>路径P上的转移函数Fp</strong>：该路径上所有语句的转移函数的组合fs1，fs2，… ，fsi-1，从而构成FP。</p><p><strong>MOP</strong>：从entry到si所有路径的FP的meet操作。本质—求这些值的最小上界/最大下界。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002877.webp" alt="img" /></p><p>4-9-1-MOP公式.png</p><p><strong>MOP准确性</strong>：有些路径不会被执行，所以不准确；若路径包含循环，或者路径爆炸，所以实操性不高，只能作为理论的一种衡量方式。</p><h4 id="2mop-vs-迭代算法"><a class="markdownIt-Anchor" href="#2mop-vs-迭代算法"></a> （2）MOP vs 迭代算法</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002942.webp" alt="img" /></p><p>4-9-2-MOP与迭代算法比较.png</p><p>对于以上的CFG，抽象出itter和MOP公式。</p><p><strong>证明</strong>：</p><ol><li>根据最小上界的定义，有x⊑x⊔y和 y⊑x⊔y。</li><li>由于转换函数是单调的，则有F(x)⊑F(x⊔y)和F(y)⊑F(x⊔y)，所以F(x⊔y)就是F(x)和F(y)的上界。</li><li>根据定义，F(x)⊔F(y)是F(x)和F(y)的最小上界。</li><li>所以<em>F</em>(<em>x</em>)⊔<em>F</em>(<em>y</em>)⊑<em>F</em>(<em>x</em>⊔<em>y</em>)</li></ol><p><strong>结论</strong>：所以，MOP更准确。若F满足分配律，则迭代算法和MOP精确度一样 <em>F</em>(<em>x</em>⊔<em>y</em>)=<em>F</em>(<em>x</em>)⊔<em>F</em>(<em>y</em>)。一般，对于控制流的join/meet，是进行集合的交或并操作，则满足分配律。</p><hr /><h2 id="10常量传播-constant-propagation"><a class="markdownIt-Anchor" href="#10常量传播-constant-propagation"></a> 10.常量传播 (constant propagation)</h2><p><strong>问题描述</strong>：在程序点p处的变量x，判断x是否一定指向常量值。</p><p><strong>类别</strong>：<strong>must分析</strong>，因为要考虑经过p点所有路径上，x的值必须都一样，才算作一定指向常量。</p><p><strong>表示</strong>：CFG每个节点的OUT是pair（x, v）的集合，表示变量x是否指向常数v。</p><h4 id="数据流分析框架d-l-f"><a class="markdownIt-Anchor" href="#数据流分析框架d-l-f"></a> 数据流分析框架（D, L, F）</h4><p>（1）D：forward更直观</p><p>（2）L：lattice</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002090.webp" alt="img" /></p><p>4-10-1-UNDEF_NAC.png</p><p><strong>变量值域</strong>：所有实数。must分析，所以<img src="mdPics/math" alt="\top" />是UNDEF未定义（unsafe），<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" /> 是NAC非常量（safe）。</p><p><strong>meet操作</strong>：must分析， <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" />。在每个路径汇聚点PC，对流入的所有变量进行meet操作，但并非常见的交和并，所以<strong>不满足分配律</strong>。</p><ul><li>NAC <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> v = NAC</li><li>UNDEF <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> v = v  未初始化的变量不是我们分析的目标。</li><li>c <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> v = ?                   c <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> c = c          c1 <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> c2 =NAC</li></ul><p>（3）<strong>F转换函数</strong></p><p>OUT[s] = gen U (IN[s] - {(x, _})</p><p>输出 = BB中新被赋值的 U 输入 - BB中相关变量值已经不是f常量的部分。</p><p>对所有的赋值语句进行分析（不是赋值语句则不管，用val(x)表示x指向的值）：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002116.webp" alt="img" /></p><p>4-10-2-赋值语句操作.png</p><p>（4）<strong>性质</strong>：不满足分配律</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002132.webp" alt="img" /></p><p>4-10-3-不满足分配律.png</p><p>可以发现，MOP更准确。F(X<img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" />Y) <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" /> F(X) <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> F(Y)，但是是单调的。</p><hr /><h2 id="11worklist算法"><a class="markdownIt-Anchor" href="#11worklist算法"></a> 11.Worklist算法</h2><p><strong>本质</strong>：对迭代算法进行优化，采用队列来存储需要处理的基本块，减少大量的冗余的计算。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002166.webp" alt="img" /></p><p>4-11-worklist.png</p><p>作者：bsauce<br />链接：<a href="https://www.jianshu.com/p/d314b316b332">https://www.jianshu.com/p/d314b316b332</a><br />来源：简书<br />著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据流分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>数据流分析总览</li><li>预备知识</li><li>Reaching Definitions Analysis (may analysis)</li><li>Live Variables Analysis (may analysis)</li><li>Available Expressions Analysis (must analysis)</li></ol><h3 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点：</h3><ul><li>理解3种数据流分析的含义，如何设计类似的算法，如何优化</li><li>理解3种数据流分析的共性与区别</li><li>理解迭代算法并弄懂算法为什么能停止</li></ul><hr /><h2 id="1数据流分析总览"><a class="markdownIt-Anchor" href="#1数据流分析总览"></a> 1.数据流分析总览</h2><blockquote><p>may analysis：输出可能正确的信息（需做over-approximation优化，才能成为Safe-approximation安全的近似，可以有误报-completeness），注意大多数静态分析都是may analysis</p><p>must analysis：输出必须正确的信息（需做under-approximation优化，才能成为Safe-approximation安全的近似，可以有漏报-soundness）</p></blockquote><p>Nodes (BBs/statements)、Edges (control flows)、CFG (a program)</p><p><strong>例如</strong>：</p><blockquote><p>application-specific Data &lt;- <code>abstraction</code> (+/-/0)</p><p>Nodes &lt;- <code>Transfer function</code></p><p>Edges &lt;- <code>Control-flow handling</code></p></blockquote><p>不同的数据流分析 有 不同的数据<strong>抽象表达</strong> 和 不同的<strong>安全近似策略</strong>，如 不同的 <strong>转换规则</strong> 和 <strong>控制流</strong>处理。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000785.webp" alt="img" /></p><p>2-1-数据流分析总览.png</p><hr /><h2 id="2预备知识"><a class="markdownIt-Anchor" href="#2预备知识"></a> 2.预备知识</h2><p><strong>输入/输出状态</strong>：程序执行前/执行后的状态（本质就是抽象表达的数据的状态，如变量的状态）。</p><p><strong>数据流分析的结果</strong>：最终得到，每一个程序点对应一个数据流值(data-flow value)，表示该点所有可能程序状态的一个抽象。例如，我只关心x、y的值，我就用抽象来表示x、y所有可能的值的集合（输入/输出的值域/约束），就代表了该程序点的程序状态。</p><blockquote><p>Forward Analysis前向分析：按程序执行顺序的分析。OUT[s]=fs(IN[s])，s-statement</p><p>Backward Analysis反向分析：逆向分析。IN[s]=fs(OUT[s])</p></blockquote><p><strong>控制流约束</strong>：约束求解做的事情，推断计算输入到输出，或反向分析。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000769.webp" alt="img" /></p><p>2-2-控制流约束.png</p><hr /><h2 id="3reaching-definitions-analysis-may-analysis"><a class="markdownIt-Anchor" href="#3reaching-definitions-analysis-may-analysis"></a> 3.Reaching Definitions Analysis (may analysis)</h2><p><strong>问题定义</strong>：给变量v一个定义d（赋值），存在一条路径使得程序点p能够到达q，且在这个过程中不能改变v的赋值。</p><p><strong>应用举例</strong>：检测未定义的变量，若v可达p且v没有被定义，则为未定义的变量。</p><p><strong>抽象表示</strong>：设程序有n条赋值语句，用n位向量来表示能reach与不能reach。</p><h4 id="1公式分析"><a class="markdownIt-Anchor" href="#1公式分析"></a> （1）公式分析</h4><p>什么是definition？ <code>D: v = x op y</code>    类似于赋值。</p><p><strong>Transfer Function</strong>：OUT[B] = genB U (IN[B] - killB) ——怎么理解，就是基于转换规则而得到。</p><p><strong>解释</strong>：基本块B的输出 = 块B内的所有变量v的定义（赋值/修改）语句  U （块B的输入 - 程序中其它所有定义了变量v的语句）。本质就是本块与前驱修改变量的语句 作用之和（去掉前驱的重复修改语句）。</p><p><strong>Control Flow</strong>：IN[B] = Up a_predecesso_of_B Out[P] ——怎么理解，就是基于控制流而得到。</p><p><strong>解释</strong>：基本块B的输入 = 块B所有前驱块P的输出的并集。注意，所有前驱块意味着只要有一条路径能够到达块B，就是它的前驱，包括条件跳转与无条件跳转。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000762.webp" alt="img" /></p><p>2-3-1-Reaching_Definition.png</p><h4 id="2算法"><a class="markdownIt-Anchor" href="#2算法"></a> （2）算法</h4><p><strong>目的</strong>：输入CFG，计算好每个基本块的killB（程序中其它块中定义了变量v的语句）和genB（块B内的所有变量v的定义语句），输出每个基本块的IN[B]和OUT[B]。</p><p><strong>方法</strong>：首先所有基本块的OUT[B]初始化为空。遍历每一个基本块B，按以上两个公式计算块B的IN[B]和OUT[B]，只要这次遍历时有某个块的OUT[B]发生变化，则重新遍历一次（因为程序中有循环存在，只要某块的OUT[B]变了，就意味着后继块的IN[B]变了）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000773.webp" alt="img" /></p><p>2-3-2-可达性分析算法.png</p><h4 id="3实例"><a class="markdownIt-Anchor" href="#3实例"></a> （3）实例：</h4><p><strong>抽象表示</strong>：设程序有n条赋值语句，用n位向量来表示能reach与不能reach。</p><p><strong>说明</strong>：红色-第1次遍历；蓝色-第2次遍历；绿色-第3次遍历。</p><p><strong>结果</strong>：3次遍历之后，每个基本块的OUT[B]都不再变化。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000780.webp" alt="img" /></p><p>2-3-3遍历实例.png</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000686.png" alt="image-20210507134806554" /></p><p>现在，我们可以回想一下，数据流分析的目标是，最后得到了，每个程序点关联一个数据流值（该点所有可能的程序状态的一个抽象表示，也就是这个n位向量）。在这个过程中，我们对个基本块，不断利用基于转换规则的语义（也就是transfer functions，构成基本块的语句集）-<code>OUT[B]</code>、控制流的约束-<code>IN[B]</code>，最终得到一个稳定的安全的近似约束集。</p><h4 id="4算法会停止吗"><a class="markdownIt-Anchor" href="#4算法会停止吗"></a> （4）算法会停止吗？</h4><p>OUT[B] = genB U (IN[B] - killB)</p><p><strong>大致理解</strong>：genB和 killB是不变的，只有IN[B]在变化，所以说OUT[B]只会增加不会减少，n向量长度是有限的，所以最终肯定会停止。具体涉及到不动点证明，后续课程会讲解。</p><hr /><h2 id="4live-variables-analysis-may-analysis"><a class="markdownIt-Anchor" href="#4live-variables-analysis-may-analysis"></a> 4.Live Variables Analysis (may analysis)</h2><p><strong>问题定义</strong>：某程序点p处的变量v，从p开始到exit块的CFG中是否有某条路径用到了v，如果用到了v，则v在p点为live，否则为dead。其中有一个隐含条件，在点p和引用点之间不能重定义v。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000030.webp" alt="img" /></p><p>2-4-1-live_variables定义.png</p><p><strong>应用场景</strong>：可用于寄存器分配，如果寄存器满了，就需要替换掉不会被用到的变量。</p><p><strong>抽象表示</strong>：程序中的n个变量用长度为n bit的向量来表示，对应bit为1，则该变量为live，反之为0则为dead。</p><h4 id="1公式分析-2"><a class="markdownIt-Anchor" href="#1公式分析-2"></a> （1）公式分析</h4><p><strong>Control Flow</strong>：OUT[B] = US a_successor_of_BIN[S]</p><p><strong>理解</strong>：我们是前向分析，只要有一条子路是live，父节点就是live。</p><p><strong>Transfer Function</strong>：IN[B] = useB U (OUT[B] - defB)</p><p><strong>理解</strong>：IN[B] = 本块中use出现在define之前的变量 U （OUT[B]出口的live情况 - 本块中出现了define的变量）。define指的是定义/赋值。</p><p><strong>特例分析</strong>：如以下图所示，第4种情况，v=v-1，实际上use出现在define之前，v是使用的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000096.webp" alt="img" /></p><p>2-4-2-公式推导.png</p><h4 id="2算法-2"><a class="markdownIt-Anchor" href="#2算法-2"></a> （2）算法</h4><p><strong>目的</strong>：输入CFG，计算好每个基本块中的defB（重定义）和useB（出现在重定义之前的使用）。输出每个基本块的IN[B]和OUT[B]。</p><p><strong>方法</strong>：首先初始化每个基本块的IN[B]为空集。遍历每一个基本块B，按以上两个公式计算块B的OUT[B]和IN[B]，只要这次遍历时有某个块的IN[B]发生变化，则重新遍历一次（因为有循环，只要某块的IN[B]变了，就意味前驱块的OUT[B]变了）。</p><p><strong>问题</strong>：遍历基本块的顺序有要求吗？ 没有要求，但是会影响遍历的次数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000117.webp" alt="img" /></p><p>2-4-3-live_variables算法.png</p><p><strong>初始化规律</strong>：一般情况下，may analysis 全部初始化为空，must analysis全部初始化为all。</p><h4 id="3实例-2"><a class="markdownIt-Anchor" href="#3实例-2"></a> （3）实例</h4><p><strong>抽象表示</strong>：程序中的n个变量用长度为n bit的向量来表示，对应bit为1，则该变量为live，反之为0则为dead。</p><p><strong>说明</strong>：从下往上遍历基本块，黑色-初始化；红色-第1次；蓝色-第2次；绿色-第3次。</p><p><strong>结果</strong>：3次遍历后，IN[B]不再变化，遍历结束。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000125.webp" alt="img" /></p><p>2-4-4-算法运行示例.png</p><hr /><h2 id="5available-expressions-analysis-must-analysis"><a class="markdownIt-Anchor" href="#5available-expressions-analysis-must-analysis"></a> 5.Available Expressions Analysis (must analysis)</h2><p><strong>问题定义</strong>：程序点p处的表达式<code>x op y</code>可用需满足2个条件，一是从entry到p点必须经过<code>x op y</code>，二是最后一次使用<code>x op y</code>之后，没有重定义操作数x、y。（如果重定义了x 或 y，如x = <code>a op2 b</code>，则原来的表达式<code>x op y</code>中的x或y就会被替代）。</p><p><strong>应用场景</strong>：用于优化，检测全局公共子表达式。</p><p><strong>抽象表示</strong>：程序中的n个表达式，用长度为n bit的向量来表示，1表示可用，0表示不可用。</p><p><strong>说明</strong>：属于forward分析。</p><h4 id="1公式分析-3"><a class="markdownIt-Anchor" href="#1公式分析-3"></a> （1）公式分析</h4><p><strong>Transfer Function</strong>：OUT[B] = genB U (IN[B] - killB)</p><p><strong>理解</strong>：genB—基本块B中所有新的表达式（并且在这个表达式之后，不能对表达式中出现的变量进行重定义）–&gt;加入到OUT；killB—从IN中删除变量被重新定义的表达式。</p><p><strong>Control Flow</strong>：IN[B] = <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000045.svg" alt="\cap" />P a_predecessor_of_B OUT[P]</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000045.svg" alt="IN[B] = \cap_{P}\ _{a\ predecessor\ of\ B}OUT[P]" /></p><p><strong>理解</strong>：从entry到p点的所有路径都必须经过该表达式。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000140.webp" alt="img" /></p><p>2-5-1-可用表达式定义.png</p><p><strong>问题</strong>：该分析为什么属于must analysis呢？因为我们允许有漏报，不能有误报，比如以上示例中，改为x=3，去掉 b=e16*x，该公式会把该表达式识别为不可用。但事实是可用的，因为把x=3替换到表达式中并不影响该表达式的形式。这里虽然漏报了，但是不影响程序分析结果的正确性。</p><h4 id="2算法-3"><a class="markdownIt-Anchor" href="#2算法-3"></a> （2）算法</h4><p><strong>目的</strong>：输入CFG，提前计算好genB和killB。</p><p><strong>方法</strong>：首先将OUT[entry]初始化为空，所有基本块的OUT[B]<strong>初始化为1…1</strong>。遍历每一个基本块B，按以上两个公式计算块B的IN[B]和OUT[B]，只要这次遍历时有某个块的OUT[B]发生变化，则重新遍历一次（因为有循环，只要某块的OUT[B]变了，就意味后继块的IN[B]变了）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000334.webp" alt="img" /></p><p>2-5-2-可用表达式算法.png</p><h4 id="3实例-3"><a class="markdownIt-Anchor" href="#3实例-3"></a> （3）实例</h4><p><strong>抽象表示</strong>：程序中的n个表达式，用长度为n bit的向量来表示，1表示可用，0表示不可用。</p><p><strong>说明</strong>：黑色-初始化；红色-第1次；蓝色-第2次。</p><p><strong>结果</strong>：2次遍历后，OUT[B]不再变化，遍历结束。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000364.webp" alt="img" /></p><p>2-5-3-算法运行示例.png</p><hr /><h2 id="6三种分析技术对比"><a class="markdownIt-Anchor" href="#6三种分析技术对比"></a> 6.三种分析技术对比</h2><table><thead><tr><th></th><th>Reaching Definitions</th><th>Live Variables</th><th>Available Expressions</th></tr></thead><tbody><tr><td><strong>Domain</strong></td><td>赋值语句</td><td>变量</td><td>表达式</td></tr><tr><td><strong>Direction</strong></td><td>forward</td><td>backward</td><td>forward</td></tr><tr><td><strong>May/Must</strong></td><td>May</td><td>May</td><td>Must</td></tr><tr><td><strong>Boundary</strong></td><td>OUT[Entry]=Φ</td><td>IN[Exit]=Φ</td><td>OUT[Entry]=Φ</td></tr><tr><td><strong>Initialization</strong></td><td>OUT[B]=Φ</td><td>IN[B]=Φ</td><td>OUT[B]=Π</td></tr><tr><td><strong>Transfer function</strong></td><td>OUT=gen U (IN - kill)</td><td>same</td><td>same</td></tr><tr><td><strong>Meet</strong></td><td>U</td><td>U</td><td>Π</td></tr></tbody></table><p><strong>问题</strong>：怎样判断是May还是Must？</p><p>Reaching Definitions表示只要从赋值语句到点p<strong>存在1条路径</strong>，则为reaching，结果不一定正确；Live Variables表示只要从点p到Exit<strong>存在1条路径</strong>使用了变量v，则为live，结果不一定正确；Available Expressions表示从Entry到点p的<strong>每一条路径</strong>都经过了该表达式，则为available，结果肯定正确。</p><p>作者：bsauce<br />链接：<a href="https://www.jianshu.com/p/45eb5e5565d5">https://www.jianshu.com/p/45eb5e5565d5</a><br />来源：简书<br />著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>过程间分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E8%BF%87%E7%A8%8B%E9%97%B4%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E8%BF%87%E7%A8%8B%E9%97%B4%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>Motivation</li><li>调用图构建</li><li>过程间控制流分析</li><li>过程间数据流分析</li></ol><h3 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点：</h3><p>学习如何利用类层级分析来构建调用图；过程间控制流/数据流分析；过程间的常量传播。</p><hr /><h2 id="1motivation"><a class="markdownIt-Anchor" href="#1motivation"></a> 1.Motivation</h2><p><strong>问题</strong>：<mark>过程内的分析未考虑函数调用，导致分析不精确</mark>。</p><p><strong>过程间分析</strong>：Inter-procedural Analysis，考虑函数调用，又称为全程序分析（Whole Program Analysis），需要构建调用图，加入Call edges和Return edges。</p><hr /><h2 id="2调用图构建"><a class="markdownIt-Anchor" href="#2调用图构建"></a> 2.调用图构建</h2><h4 id="1调用图"><a class="markdownIt-Anchor" href="#1调用图"></a> （1）调用图</h4><p><strong>定义</strong>：本质是调用边的集合，从调用点（call-sites）到目标函数（target methods / callees）的边。</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953225.webp" alt="img" /></p><p>5-2-1-call_graph.png</p><p><strong>应用</strong>：是所有过程间分析（跨函数分析）的基础，程序优化，程序理解，程序调试。</p><h4 id="2面向对象语言的调用图构造java"><a class="markdownIt-Anchor" href="#2面向对象语言的调用图构造java"></a> （2）面向对象语言的调用图构造（Java）</h4><p><strong>代表性算法</strong>：从上往下精度变高，速度变慢，重点分析第1、4个算法。</p><ul><li>Class hierarchy analysis(CHA)</li><li>Rapid type analysis(RTA)</li><li>Variable type analysis(VTA)</li><li>Pointer analysis(k-CFA)</li></ul><p><strong>Java调用分类</strong>：</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:center"><strong>Static call</strong></th><th style="text-align:center"><strong>Special call</strong></th><th style="text-align:center"><strong>Virtual call</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>指令</strong></td><td style="text-align:center">invokestatic</td><td style="text-align:center">invokespecial</td><td style="text-align:center">invokeinterface、 invokevirtual</td></tr><tr><td style="text-align:left">Receiver objects（返回后赋值的目标对象）</td><td style="text-align:center">×</td><td style="text-align:center">✓</td><td style="text-align:center">✓</td></tr><tr><td style="text-align:left"><strong>目标函数</strong></td><td style="text-align:center">Static函数</td><td style="text-align:center">构造函数、 私有函数、父类的实例函数</td><td style="text-align:center">其他实例函数</td></tr><tr><td style="text-align:left"><strong>目标函数个数</strong></td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">≥1 (<strong>polymorphism</strong>多态性)</td></tr><tr><td style="text-align:left"><strong>何时确定</strong></td><td style="text-align:center">编译时</td><td style="text-align:center">编译时</td><td style="text-align:center">运行时</td></tr></tbody></table><p><strong>Method Dispatch</strong>：最难的是<strong>Virtual call</strong>，其中关键步骤是Method Dispatch，就是<strong>找到最终调用的实际函数</strong>。</p><p>virtual call在程序运行时才能得到，基于2个要素得到：</p><ol><li><p>reciever object的具体类型：<strong>c</strong></p></li><li><p>调用点的函数签名：<strong>m</strong>。（通过signature可以唯一确定一个函数）</p><ol><li>signature = 函数所在的类 + 函数名 + 描述符</li><li>描述符 = 返回类型 + 参数类型</li></ol><p>简记为C.foo(P, Q, R)</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953263.webp" alt="img" /></p><p>5-2-2-virtual_call.png</p></li></ol><h4 id="3method-dispatchvirtual-call"><a class="markdownIt-Anchor" href="#3method-dispatchvirtual-call"></a> （3）Method Dispatch（virtual call）</h4><p><strong>定义</strong>：用Dispatch(c, m)来模拟动态Method Dispatch过程，c表示reciever object，m表示函数签名。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953239.webp" alt="img" /></p><p>5-2-3-Method_Dispatch.png</p><p><strong>解释</strong>：若该类的非抽象方法（实际可执行的函数主体）中包含和m相同名字、传递/返回参数的m‘，则直接返回；否则到c的父类中找。</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953264.webp" alt="img" /></p><p>5-2-4-Dispatch示例.png</p><h4 id="4class-hirarchy-analysis-cha-类层级分析"><a class="markdownIt-Anchor" href="#4class-hirarchy-analysis-cha-类层级分析"></a> （4）Class Hirarchy Analysis (CHA)  类层级分析</h4><p><strong>目的</strong>：根据每个virtual call 的 receiver varible 的<strong>声明类型</strong>来求解所有可能调用的目标函数。如 <code>A a = ... ;</code>  <code>a.foo();</code> 这个a就是receiver varible，声明类型就是A。假定a可以指向A以及A所有子类对象，CHA的过程就是从A和子类中去找目标函数。</p><p><strong>算法</strong>：Resolve(cs)——利用CHA算法找到调用点所有可能的调用目标。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953362.webp" alt="img" /></p><p>5-2-5-CHA算法.png</p><p><strong>算法示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953350.webp" alt="img" /></p><p>5-2-6-CHA算法示例.png</p><p><strong>算法应用</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953907.webp" alt="img" /></p><p>5-2-7-CHA应用.png</p><p><strong>错误</strong>：以上b.foo()的调用目标 C.foo()和D.foo()是错误的，因为<strong>已经指定了是B类型</strong>，所以b.foo()根本不会调用C、D的foo()。因为CHA只考虑声明类型，也就是B，导致准确度下降。多态性就是说，父类可以引用子类的对象，如<code>B b=new C()</code>。</p><p>优缺点：CHA优点是速度快，只考虑声明类型，忽略数据流和控制流；缺点是准确度低。</p><p>总结：本类中有同名函数就在本类和子类找，没有就从父类找，接着找父类的子类中的同名函数（CHA分析）。</p><h4 id="5利用cha构造调用图"><a class="markdownIt-Anchor" href="#5利用cha构造调用图"></a> （5）利用CHA构造调用图</h4><p><strong>算法</strong>：<mark>遍历每个函数中的每个调用指令</mark>，调用CHA的Resolve()找到对应的目标函数和调用边，函数+调用边=调用图。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953911.webp" alt="img" /></p><p>5-2-8-调用图构造算法.png</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953930.webp" alt="img" /></p><p>5-2-9-调用图算法示例.png</p><hr /><h2 id="3过程间控制流分析"><a class="markdownIt-Anchor" href="#3过程间控制流分析"></a> 3.过程间控制流分析</h2><p><strong>定义</strong>：过程间控制流图ICFG = CFG + (Call edges + Return edges)。</p><ul><li>Call edges：连接调用点和目标函数入口</li><li>Return edges：从return语句连到Return site（Call site后面一条语句）</li></ul><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953991.webp" alt="img" /></p><p>5-3-ICFG示例.png</p><hr /><h2 id="4过程间数据流分析"><a class="markdownIt-Anchor" href="#4过程间数据流分析"></a> 4.过程间数据流分析</h2><p><strong>说明</strong>：对ICFG进行数据流分析，没有标准的一套算法。</p><p><strong>对比</strong>：</p><table><thead><tr><th></th><th><strong>Intra</strong>procedural</th><th><strong>Inter</strong>procecdural</th></tr></thead><tbody><tr><td><strong>程序表示</strong></td><td>CFG</td><td>ICFG = CFGs + call &amp; return edges</td></tr><tr><td><strong>转换规则</strong></td><td>Node transfer</td><td>Node transfer + edge transfer</td></tr></tbody></table><p><strong>常量传播数据流分析</strong>：</p><ul><li>Node transfer：与过程内分析相同，对每个调用点，将等号左边部分去掉。</li><li>Call edge transfer：传参</li><li>Return edge transfer：传返回值</li></ul><p><strong>常量传播示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953005.webp" alt="img" /></p><p>5-4-ICFG常量传播示例.png</p><p><strong>说明</strong>：黄色背景边必须有，从<code>b = addOne(a)</code>到<code>c=b-3</code>，a通过此边传递，b通过addOne()传递。若a也通过addOne()传递，会额外消耗系统资源。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 过程间分析 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
