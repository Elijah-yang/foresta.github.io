<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>C/C++漏洞数据集</title>
      <link href="/2024/04/18/Security/C_C++%E6%BC%8F%E6%B4%9E%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
      <url>/2024/04/18/Security/C_C++%E6%BC%8F%E6%B4%9E%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/qq_44370676/article/details/118198912#2_136">C/C++漏洞数据集-CSDN博客</a></p><h4 id="漏洞数据集"><a class="markdownIt-Anchor" href="#漏洞数据集"></a> 漏洞数据集</h4><ul><li>[1.常用数据集]</li><li><ul><li>[1.1.Big-Vul]</li><li>[1.2.Reveal]</li><li>[1.3.FFMPeg+Qemu]</li><li>[1.4.D2A]</li></ul></li><li>[2.数据集质量研究]</li></ul><h2 id="1常用数据集"><a class="markdownIt-Anchor" href="#1常用数据集"></a> 1.常用数据集</h2><h3 id="11big-vul"><a class="markdownIt-Anchor" href="#11big-vul"></a> 1.1.Big-Vul</h3><p>论文地址：<a href="https://dl.acm.org/doi/10.1145/3379597.3387501">A C/C++ Code Vulnerability Dataset with Code Changes and CVE Summaries</a></p><p><a href="https://github.com/ZeoVan/MSR_20_Code_vulnerability_CSV_Dataset">github地址</a></p><p>该数据集存储为csv格式。包含了漏洞行号信息，详细参考github地址。</p><p><a href="https://github.com/ZeoVan/MSR_20_Code_vulnerability_CSV_Dataset">https://github.com/ZeoVan/MSR_20_Code_vulnerability_CSV_Dataset</a></p><h3 id="12reveal"><a class="markdownIt-Anchor" href="#12reveal"></a> 1.2.Reveal</h3><p>Reveal本为一个DLVD（Deep Learning Vulnerbility Detection）方法，可以参考<a href="https://blog.csdn.net/qq_44370676/article/details/118223852">Reveal</a>。而作者收集了一个数据集。从Linux <a href="https://so.csdn.net/so/search?q=Debian&amp;spm=1001.2101.3001.7020">Debian</a> Kernel 和Chromium的vulnerabilitiy fixed patches中构造。</p><p>论文地址：<a href="https://arxiv.org/abs/2009.07235">Deep Learning based Vulnerability Detection:Are We There Yet?</a></p><p><a href="https://drive.google.com/drive/folders/1KuIYgFcvWUXheDhT--cBALsfy1I4utOy">数据集下载地址</a></p><p>包含2个json，vulnerables.json和non-vulnerables.json。json的key包括</p><ul><li>code:源代码内容</li><li>hash</li><li>project</li><li>size</li></ul><p>遗憾的是，该数据集不包括漏洞行号信息。</p><h3 id="13ffmpegqemu"><a class="markdownIt-Anchor" href="#13ffmpegqemu"></a> 1.3.FFMPeg+Qemu</h3><p>又称Devign数据集</p><p><a href="https://drive.google.com/file/d/1x6hoF7G-tSYxg8AFybggypLZgMGDNHfF/edit">数据集下载地址</a></p><p>数据集为一个function.json，包括4个key。</p><ul><li>project：FFmpeg或者Qemu</li><li>commit_id</li><li>target：0或者1，是否有漏洞</li><li>func：一个函数的代码内容，包括函数定义那一行</li></ul><p>遗憾的是，该数据集也不包括漏洞行号信息。</p><h3 id="14d2a"><a class="markdownIt-Anchor" href="#14d2a"></a> 1.4.D2A</h3><p>论文地址：<a href="https://arxiv.org/pdf/2102.07995.pdf">D2A: A Dataset Built for AI-Based Vulnerability<br />Detection Methods Using Differential Analysis</a></p><p>github地址：<a href="https://github.com/ibm/D2A">D2A</a></p><p><a href="https://developer.ibm.com/exchanges/data/all/d2a/">数据集下载地址</a></p><p>数据集下下来为pickle文件，需要注意的是，这里的标记并不是简单的将一个function标为0或1，而是有一个trace，记录bug触发的路径，会涉及到多个function。</p><p>以libtiff Sample Dataset为例，加载2020-09-10_libtiff_labeler_1.pickle文件，打开发现是一个dict，有下面几个key</p><ul><li>id：值为libtiff_d888dddf8807829fc0f9f3bbdb0a64871c29b05b_1</li><li>label：值为1，该文件全是标记为1的数据</li><li>label_source：auto_labeler</li><li>bug_type：PULSE_MEMORY_LEAK</li><li>project：libtiff</li><li>bug_info：为1个dict，key包括<ul><li>qualifier：bug信息</li><li>file：源文件</li><li>procedure</li><li>line</li><li>column</li><li>url</li></ul></li><li>adjusted_bug_loc</li><li>bug_loc_trace_index</li><li>versions</li><li>sample_type：before_fix</li><li>trace：为1个list，记录该fix涉及到的function行号</li><li>functions：记录bug trace的function完整的代码</li><li>commit</li><li>compiler_args：为dict，记录每个文件用什么编译器编译</li><li>zipped_bug_report：由Infer产生的原始bug报告。</li></ul><p>论文给出的示例如下：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;   </span><br><span class="line">   <span class="attr">&quot;id&quot;:</span> <span class="string">&quot;httpd_9b3a5f0ffd8ec787cf645f97902582acb3234d96_1&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;label&quot;:</span> <span class="number">1</span>,   </span><br><span class="line">   <span class="attr">&quot;label_source&quot;:</span> <span class="string">&quot;auto_labeler&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;bug_type&quot;:</span> <span class="string">&quot;BUFFER_OVERRUN_U5&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;project&quot;:</span> <span class="string">&quot;httpd&quot;</span>,   </span><br><span class="line">   <span class="attr">&quot;bug_info&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;qualifier&quot;:</span> <span class="string">&quot;Offset: [0, +oo] Size: 10 by call to ...&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;loc&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c:178:31&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;url&quot;:</span> <span class="string">&quot;https://github.com/apache/httpd/blob/...&quot;</span>   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;versions&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;before&quot;:</span> <span class="string">&quot;545d85acdaa384a25ee5184a8ee671a18ef5582f&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;after&quot;:</span> <span class="string">&quot;2c70ed756286b2adf81c55473077698d6d6d16a1&quot;</span>   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;trace&quot;:</span> [   </span><br><span class="line">     &#123;   </span><br><span class="line">       <span class="attr">&quot;description&quot;:</span> <span class="string">&quot;Array declaration&quot;</span>,   </span><br><span class="line">       <span class="attr">&quot;loc&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c:178:31&quot;</span>,   </span><br><span class="line">       <span class="attr">&quot;func_key&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c@167:1-203:2&quot;</span>,   </span><br><span class="line">     &#125;   </span><br><span class="line">   ],   </span><br><span class="line">   <span class="attr">&quot;functions&quot;:</span> &#123;   </span><br><span class="line">     <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c@167:1-203:2&quot;</span><span class="string">:</span> &#123;   </span><br><span class="line">       <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;fix_cgivars&quot;</span>,   </span><br><span class="line">       <span class="attr">&quot;touched_by_commit&quot;:</span> <span class="literal">true</span>,   </span><br><span class="line">       <span class="attr">&quot;code&quot;:</span> <span class="string">&quot;static void fix_cgivars(request_rec *r, ...&quot;</span>   </span><br><span class="line">     &#125;   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;commit&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;url&quot;:</span> <span class="string">&quot;https://github.com/apache/httpd/commit/2c70ed7&quot;</span>,   </span><br><span class="line">     <span class="attr">&quot;changes&quot;:</span> [   </span><br><span class="line">       &#123;   </span><br><span class="line">         <span class="attr">&quot;before&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c&quot;</span>,   </span><br><span class="line">         <span class="attr">&quot;after&quot;:</span> <span class="string">&quot;modules/proxy/mod_proxy_fcgi.c&quot;</span>,   </span><br><span class="line">         <span class="attr">&quot;changes&quot;:</span> [<span class="string">&quot;177,1^^177,5&quot;</span>]   </span><br><span class="line">       &#125;   </span><br><span class="line">     ]   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;compiler_args&quot;:</span> &#123;   </span><br><span class="line">     <span class="attr">&quot;modules/proxy/mod_proxy_fcgi.c&quot;:</span> <span class="string">&quot;-D_REENTRANT -I./server ...&quot;</span>,   </span><br><span class="line">   &#125;,   </span><br><span class="line">   <span class="attr">&quot;zipped_bug_report&quot;:</span> <span class="string">&quot;...&quot;</span>   </span><br><span class="line">&#125; </span><br><span class="line"><span class="number">1234567891011121314151617181920212223242526272829303132333435363738394041424344</span></span><br></pre></td></tr></table></figure><h2 id="2数据集质量研究"><a class="markdownIt-Anchor" href="#2数据集质量研究"></a> 2.数据集质量研究</h2><p>在ICSE 23关于漏洞数据集的paper <a href="https://arxiv.org/pdf/2301.05456.pdf">Data Quality for Software Vulnerability Datasets</a>中，调研的数据集如下表所示：</p><table><thead><tr><th>数据集</th><th>标注来源</th><th>function数量</th><th>漏洞function占比</th></tr></thead><tbody><tr><td>Big-Vul</td><td>CVE databas</td><td>188636</td><td>5.78%</td></tr><tr><td>Devign</td><td>开发者标注</td><td>27318</td><td>45.61%</td></tr><tr><td>D2A</td><td>工具标注</td><td>1295623</td><td>1.44%</td></tr><tr><td>Juliet</td><td>合成</td><td>253002</td><td>36.77%</td></tr></tbody></table><p>作者统计了可能导致标注不准确的原因：</p><ul><li>Irrelevant code change: 数据集标注器假设漏洞修复（vulnerability-fix）所涉及的代码是易受攻击的代码（function）。然而，漏洞修复commit可能不一定只包括修复补丁。可能还存在非功能性更改，如样式更改、重构和代码迁移，可能会混淆数据标记过程。比如FFMpeg中<a href="https://github.com/FFmpeg/FFmpeg/commit/8b2fce0d3f5a56c40c28899c9237210ca8f9cf75#diff73395d3a1e02aad201d2af860c5bf0fc9cb6a68c9c711ff226eeb24ea0d409a5L400">libswscale/swscale.c</a>的commit仅仅是将常量变成定义的宏。</li><li>Cleanup changes: 漏洞修复可能包括增加、删除或者修改变量，这些是与漏洞修复相关的功能更改，但是它们并没有指示触发行的位置。</li><li>Inaccurate vulnerability fix identification: 如果标注器无法识别漏洞修复，那么随后的代码片段自然不会是漏洞。像Big Vul这样从外部漏洞报告中跟踪漏洞修复的数据集可能会在这个过程中引入错误。比如<ul><li>作者发现<a href="https://so.csdn.net/so/search?q=Chromium&amp;spm=1001.2101.3001.7020">Chromium</a>项目的大多数漏洞报告都被不正确地跟踪，因为这个存储库不是通过GitHub自然托管的。</li><li>而此外，有些标注器（Devign和D2A）试图直接从提交commit历史记录中识别漏洞修复的数据集，这个过程同样可能导致错误标注。D2A用静态分析工具Infer标注数据集同样可能引入错误。</li></ul></li></ul><p>对于来源自真实环境的数据集，作者的分析结果如下：</p><table><thead><tr><th>数据集</th><th>Irrelevant</th><th>Cleanup</th><th>Inaccurate</th></tr></thead><tbody><tr><td>Big-Vul</td><td>25%</td><td>28.1%</td><td>46.9%</td></tr><tr><td>Devign</td><td>42.9%</td><td>21.4%</td><td>35.7%</td></tr><tr><td>D2A</td><td>0</td><td>0</td><td>100%</td></tr></tbody></table><ul><li>Devign由于引入人工校验，所以不准确度相对低，但是其数据量也很小。</li><li>Big-Vul的主要问题是从commit中提取了不相关的code change，尤其是来自Chromium的commit，36%的entry都来自Chromium。</li><li>D2A所标注的commit大部分都不是真正的漏洞commit。</li></ul><p>除了对数据集的准确性评估，作者还评估了数据集独特性（存不存在重复样本）、一致性（存不存在标签冲突的样本）、完整性问题。</p>]]></content>
      
      
      <categories>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cross-domain vulnerability detection using graph embedding and domain adaptation</title>
      <link href="/2023/12/19/Papers/Vul/Cross-domain%20vulnerability%20detection%20using%20graph%20embedding%20and%20domain%20adaptation/"/>
      <url>/2023/12/19/Papers/Vul/Cross-domain%20vulnerability%20detection%20using%20graph%20embedding%20and%20domain%20adaptation/</url>
      
        <content type="html"><![CDATA[<p>a山东省计算机网络重点实验室，山东省计算机科学中心（济南国家超级计算机中心），齐鲁工业大学（山东科学院），济南250014，中国b北京邮电大学网络空间安全学院，北京100876，中国c公共大数据国家重点实验室，贵州大学计算机科学与技术学院，贵阳550025</p><h1 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h1><p>漏洞检测是维护网络空间安全的有效手段。机器学习方法由于其准确性和自动化的优势，在软件安全领域引起了人们的广泛关注。<strong>然而，目前的研究主要集中在训练数据和测试数据属于同一域的域内漏洞检测上。<strong>由于应用场景、编码习惯等因素，不同软件项目中的漏洞可能服从不同的概率分布。当机器学习方法应用于一个全新的项目时，这种差异会影响它们的性能。为了解决这个冷启动问题，我们</strong>提出了一个使用图嵌入和深度域自适应（VulGDA）的跨域漏洞检测框架。<strong>它以多种跨域方式工作，包括</strong>零样本方式</strong>，即目标域中没有标记数据可用于训练。将VulGDA分解为图嵌入和域自适应。在图嵌入阶段，我们将源代码中的样本转换为图表示，其中元素根据其语法和语义关系直接连接。然后，我们将来自图中定义的邻居和边的信息聚合为实值向量。通过图形嵌入，VulGDA提取了全面的漏洞特征，并解决了长期依赖性的挑战。针对训练数据和测试数据之间的差异，使用域自适应来训练特征生成器。该特征生成器将嵌入的图映射到一个“深层”特征，该特征对漏洞检测具有鉴别性，并且对域之间的移动保持不变。我们进行了一项系统实验来验证VulGDA的有效性。结果表明，将图嵌入和深域自适应相结合，提高了VulGDA在跨域漏洞检测中的性能。与最先进的方法相比，我们的方法在冷启动条件下具有更好的性能。</p><h1 id="1-contributions"><a class="markdownIt-Anchor" href="#1-contributions"></a> 1 Contributions</h1><p>主要问题就是目前的研究针对某一数据集或是某些特定的漏洞，没有在跨域问题上提出适当的解决方法；</p><ul><li><p>提出了一个结合了图嵌入和域自适应的跨域漏洞检测框架VulGDA，VulGDA以ZeroShot方式工作，这是跨域检测中最严格的方式。VulGDA通过将目标域中的监督信息添加到训练数据中，也适用于few-shot和域内方式。</p></li><li><p>提出了一种提取综合漏洞特征的图嵌入方法；减少噪声对漏洞特征的影响</p></li><li><p>提出了一种神经网络来学习特征生成器。该特征生成器通过减少分类损失和域差异来进行优化。最后，该特征生成器将学习到的源域中的漏洞模式传输到目标域。</p></li><li><p>实现了一个原型并进行了系统的实验。结果表明，图嵌入和域自适应的应用提高了VulGDA的性能。与现有方法相比，VulGDA在跨域漏洞检测方面取得了更好的性能。</p></li></ul><h1 id="2-method"><a class="markdownIt-Anchor" href="#2-method"></a> 2 Method</h1><p>VulGDA旨在检测现实世界软件中的漏洞。为了实用，本文考虑了最严格的条件。也就是说，应用在源域中训练的检测模型来检测目标域中的漏洞，并且该模型在训练期间无法从目标域获得任何监督信息（零样本）。这一假设使VulGDA具有良好的泛化能力，并易于应用于其他跨域检测情况，例如历史漏洞数据很少（很少发生）或丰富（Indomain）的项目。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191701536.png" alt="image-20231219170117488" /></p><p>问题定义：假设我们的检测架构可以访问源域中的标记数据集<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo><msubsup><mo stretchy="false">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo>∼</mo><mo stretchy="false">(</mo><msub><mi>D</mi><mi>s</mi></msub><msup><mo stretchy="false">)</mo><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">S=\{(x_{i},y_{i})\}_{i=1}^{n}\sim(D_{s})^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.008664em;vertical-align:-0.258664em;"></span><span class="mopen">{</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>  和目标域中的未标记数据集 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><msubsup><mo stretchy="false">}</mo><mrow><mi>i</mi><mo>=</mo><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mo>∼</mo><mo stretchy="false">(</mo><msubsup><mi>D</mi><mi>T</mi><mi>X</mi></msubsup><msup><mo stretchy="false">)</mo><mrow><mi>N</mi><mo>−</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">T=\{({x}_{i})\}_{i=n+1}^{N}\sim(D_{T}^{X})^{N-n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.158326em;vertical-align:-0.316995em;"></span><span class="mopen">{</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathdefault">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.316995em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1166619999999998em;vertical-align:-0.275331em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.424669em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">X</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.275331em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>是训练样本的总数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>D</mi><mi>T</mi><mi>X</mi></msubsup></mrow><annotation encoding="application/x-tex">D_T^X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1166619999999998em;vertical-align:-0.275331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.424669em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">X</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.275331em;"><span></span></span></span></span></span></span></span></span></span>是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">D_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span>上的边缘分布。</p><p>最终目标是建立一个预测<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>η</mi><mo>:</mo><mi>X</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">η:X→Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>：最小<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><msub><mi>D</mi><mi>T</mi></msub></msub><mo stretchy="false">(</mo><mi>η</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">*</mi><mo>⁡</mo><msub><mrow><mi>P</mi><mi>r</mi></mrow><mrow><mo stretchy="false">(</mo><mi>x</mi><mi>y</mi><mo stretchy="false">)</mo><mo>∼</mo><msub><mi>D</mi><mi>T</mi></msub></mrow></msub><mo stretchy="false">(</mo><mi>η</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">≠</mi><mi>y</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">R_{D_T}(η)=\operatorname*{Pr}_{(x y)\sim D_{T}}(\eta(x)\neq y),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.000305em;vertical-align:-0.250305em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.250305em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mop"><span class="mord mathrm">*</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span>，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">D_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中没有监督信息。</p><p><strong>VuLGDA有两个阶段组成：</strong></p><p><strong>图嵌入：</strong></p><p>图嵌入阶段的目的是将源代码中的漏洞样本转换为可由机器学习模型处理的实值向量。因此，通过句法和语义分析，图嵌入阶段首先将样本转换为CPG，即图结构中的中间表示。在CPG中，语法和语义相关的元素被直接连接在一起，这缓解了长期的依赖问题和域之间的分歧。然后，利用预训练的单词嵌入生成标记嵌入和节点嵌入。最后，我们使用GGNN通过传播和聚合来自CPG中定义的邻居的信息来获得嵌入向量。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191747401.png" alt="image-20231219174742348" /></p><p><strong>域自适应：</strong></p><p>域自适应阶段旨在学习在域之间转换分布的特征生成器。提出了一种由特征生成器、分类器和瓶颈组成的神经网络来学习该特征生成器。将源域中的特征作为输入的分类器产生分类损失。瓶颈度量源域和目标域中的特征之间的差异。通过最小化分类损失和领域差异来优化特征生成器。检测结果由生成的“深层”特征训练的分类器报告。经过上述阶段后，VulGDA可以在目标域中检测跨域漏洞，而无需标记数据。</p><p>本文的创新点主要在于领域自适应：</p><p>传统的机器学习方法假设训练数据和测试数据服从相同的特征分布。然而，由于编程风格和应用场景的不同，不同领域的漏洞特征可能服从不同的分布，从而影响模型的检测性能。在本节中，使用来自源域和目标域的数据，我们构建了一个特征生成器G f:XG→XF。G f将嵌入XG的图转换为“深度”特征向量XF，该向量对漏洞检测具有判别性，并且随着域之间的移动而不变。因此，目标函数定义为：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>f</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><mi mathvariant="normal">*</mi><mo>⁡</mo><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mfrac><mn>1</mn><mi>B</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>λ</mi><mi>R</mi><mo stretchy="false">(</mo><msub><mi>B</mi><mi>S</mi></msub><mo separator="true">,</mo><msub><mi>B</mi><mi>T</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f^{*}=\arg\operatorname*{min}\frac{1}{B}\sum_{i=1}^{B}\ell(f(x_{i}),y_{i})+\lambda R(B_{S},B_{T})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.933136em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mord mathrm">*</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">λ</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>其中B表示批次大小，（f（xi），yi）表示分类损失，BS和BT分别在源域和目标域中为2个批次，R（∗，∗）测量域差异。λ用于调整分类损失和域差异的权重。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312192225166.png" alt="image-20231219222546132" /></p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Conv2d</title>
      <link href="/2023/12/19/AILearning/pytorch/conv2d/"/>
      <url>/2023/12/19/AILearning/pytorch/conv2d/</url>
      
        <content type="html"><![CDATA[<h4 id="1-用法"><a class="markdownIt-Anchor" href="#1-用法"></a> 1 用法</h4><ul><li>Conv2d(in_channels, out_channels, kernel_size, stride=1,padding=0, dilation=1, groups=1,bias=True, padding_mode=‘zeros’)</li></ul><h4 id="2-参数"><a class="markdownIt-Anchor" href="#2-参数"></a> 2 参数</h4><ul><li><p>in_channels：输入的通道数目 【必选】</p></li><li><p>out_channels： 输出的通道数目 【必选】</p></li><li><p>kernel_size：卷积核的大小，类型为int 或者元组，当卷积是方形的时候，只需要一个整数边长即可，卷积不是方形，要输入一个元组表示 高和宽。【必选】</p></li><li><p>stride： 卷积每次滑动的步长为多少，默认是 1 【可选】</p></li><li><p>padding： 设置在所有边界增加 值为 0 的边距的大小（也就是在feature map 外围增加几圈 0 ），例如当 padding =1 的时候，如果原来大小为 3 × 3 ，那么之后的大小为 5 × 5 。即在外围加了一圈 0 。【可选】</p></li><li><p>dilation：控制卷积核之间的间距（什么玩意？请看例子）【可选】</p></li><li><p>groups：控制输入和输出之间的连接。（不常用）【可选】</p><p>举例来说：<br />比如 groups 为1，那么所有的输入都会连接到所有输出<br />当 groups 为 2的时候，相当于将输入分为两组，并排放置两层，每层看到一半的输入通道并产生一半的输出通道，并且两者都是串联在一起的。这也是参数字面的意思：“组” 的含义。<br />需要注意的是，in_channels 和 out_channels 必须都可以整除 groups，否则会报错（因为要分成这么多组啊，除不开你让人家程序怎么办？）</p></li><li><p>bias： 是否将一个 学习到的 bias 增加输出中，默认是 True 。【可选】</p></li><li><p>padding_mode ： 字符串类型，接收的字符串只有 “zeros” 和 “circular”。【可选】</p></li></ul><h4 id="3-相关形状"><a class="markdownIt-Anchor" href="#3-相关形状"></a> 3 相关形状</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191632440.png" alt="image-20231219163239412" /></p>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch入门</title>
      <link href="/2023/12/19/AILearning/pytorch/pytorch/"/>
      <url>/2023/12/19/AILearning/pytorch/pytorch/</url>
      
        <content type="html"><![CDATA[<h1 id="1torchnn简介"><a class="markdownIt-Anchor" href="#1torchnn简介"></a> 1.torch.nn简介</h1><p>1.1torch.nn相关库的导入</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#环境准备</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np              <span class="comment"># numpy数组库</span></span><br><span class="line"><span class="keyword">import</span> math                     <span class="comment"># 数学运算库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 画图库</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> torch             <span class="comment"># torch基础库</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn    <span class="comment"># torch神经网络库</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure><h3 id="12-torchnn概述"><a class="markdownIt-Anchor" href="#12-torchnn概述"></a> 1.2 torch.nn概述</h3><blockquote><p>Pytorch提供了几个设计得非常棒的模块和类，比如 torch.nn，torch.optim，Dataset 以及 DataLoader，来帮助程序员设计和训练神经网络。</p></blockquote><p>nn是Neural Network的简称，帮助程序员方便执行如下的与神经网络相关的行为：</p><ul><li><p>创建神经网络</p></li><li><p>训练神经网络</p></li><li><p>保存神经网络</p></li><li><p>恢复神经网络</p></li></ul><p>包括五大基本功能模块</p><ul><li>torch.nn是专门为神经网络设计的模块化接口</li><li>nn构建于autograd之上，可以用来定义和运行神经网络<ul><li>nn.Parameter</li><li>nn.Linear</li><li>nn.functional</li><li>nn.Module</li><li>nn.Sequential</li></ul></li></ul><h1 id="2nnlinear类全连接层"><a class="markdownIt-Anchor" href="#2nnlinear类全连接层"></a> 2.nn.Linear类（全连接层）</h1><h3 id="21函数功能"><a class="markdownIt-Anchor" href="#21函数功能"></a> 2.1函数功能</h3><p>用于创建一个多输入、多输出的全连接层。</p><p>nn.Linear本身并不包含激活函数（Functional）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635002.png" alt="image-20231219163552911" /></p><h3 id="22函数说明"><a class="markdownIt-Anchor" href="#22函数说明"></a> 2.2函数说明</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629041.png" alt="image-20211203155643310" /></p><ul><li>in_featrues：<ul><li>指输入的二维张量的大小，即输入的[batch_size, size]中的size</li><li>in_features的数量，决定的参数的个数Y=WX+b，X的维度就是in_features，X的维度决定W的维度，总参数的个数 = in_features + 1</li></ul></li><li>out_featrues<ul><li>指的是输出的二维张量的大小，<mark>即输出的二维张量的形状为[batch_size output_size].</mark></li><li>out_features的数量，决定了全连接层中神经元的个数，因为每个神经元只有一个输出。<strong>多少个输出，就需要多少个神经元</strong>。</li><li><mark>从输入输出的张量的shape角度来理解，相当于一个输入为[batch_size, in_features]的张量变换成了[batch_size, out_features]的输出张量。</mark></li></ul></li></ul><h3 id="23多个全连接层构建全连接网络"><a class="markdownIt-Anchor" href="#23多个全连接层构建全连接网络"></a> 2.3多个全连接层构建全连接网络</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629046.png" alt="image-20211203160715687" /></p><ul><li>使用nn.Linear类创建全连接层</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nn.Linear</span></span><br><span class="line"><span class="comment"># 建立单层的多输入、多输出全连接层</span></span><br><span class="line"><span class="comment"># in_features由输入张量的形状决定，out_features则决定了输出张量的形状 </span></span><br><span class="line">full_connect_layer = nn.Linear(in_features = <span class="number">28</span> * <span class="number">28</span> * <span class="number">1</span>, out_features = <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;full_connect_layer:&quot;</span>, full_connect_layer)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;parameters        :&quot;</span>, full_connect_layer.parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假定输入的图像形状为[28,28,1]</span></span><br><span class="line">x_input = torch.randn(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将四维张量转换为二维张量之后，才能作为全连接层的输入</span></span><br><span class="line">x_input = x_input.view(<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span> * <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_input.shape:&quot;</span>, x_input.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用全连接层</span></span><br><span class="line">y_output = full_connect_layer(x_input) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_output.shape:&quot;</span>, y_output.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_output:&quot;</span>, y_output)</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629071.png" alt="image-20211203163313390" /></p><h2 id="3-nnfunctional常见函数"><a class="markdownIt-Anchor" href="#3-nnfunctional常见函数"></a> 3 nn.functional（常见函数）</h2><h3 id="31-nnfunctional概述"><a class="markdownIt-Anchor" href="#31-nnfunctional概述"></a> 3.1 nn.functional概述</h3><blockquote><p>nn.functional定义了创建神经网络所需要的一些常见的处理函数。如没有激活函数的神经元，各种激活函数等。</p></blockquote><ul><li>包含torch.nn库中所有函数，包含大量loss和activation function<ul><li>torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)</li><li>nn.functional.xxx是函数接口</li><li>nn.functional.xxx无法与nn.Sequential结合使用</li><li>没有学习参数的(eg. maxpool, loss_ func, activation func)<a href="http://xn--nn-gy2c4vz4a856fs0ap4ztl4ad2mv07c.functional.xn--xxxnn-zm6j.Xxx">等根据个人选择使用nn.functional.xxx或nn.Xxx</a></li><li>需要特别注意dropout层</li></ul></li></ul><h3 id="32-nnfunctional函数分类"><a class="markdownIt-Anchor" href="#32-nnfunctional函数分类"></a> 3.2 nn.functional函数分类</h3><p>nn.functional包括神经网络前向和后向处理所需要到的常见函数</p><ul><li>神经元处理函数</li><li>激活函数</li></ul><h3 id="33-激活函数案例"><a class="markdownIt-Anchor" href="#33-激活函数案例"></a> 3.3 激活函数案例</h3><ul><li>relu案例</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nn.functional.relu( )</span></span><br><span class="line"><span class="built_in">print</span>(y_output)</span><br><span class="line">out = nn.functional.relu(y_output)</span><br><span class="line"><span class="built_in">print</span>(out.shape)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br></pre></td></tr></table></figure><h2 id="4-nnxxx和nnfunctionalxxx比较"><a class="markdownIt-Anchor" href="#4-nnxxx和nnfunctionalxxx比较"></a> 4 nn.xxx和nn.functional.xxx比较</h2><h3 id="41-相同点"><a class="markdownIt-Anchor" href="#41-相同点"></a> 4.1 相同点</h3><ul><li><code>nn.Xxx</code>和<code>nn.functional.xxx</code>的实际功能是相同的，即<code>nn.Conv2d</code>和<code>nn.functional.conv2d</code> 都是进行卷积，<code>nn.Dropout</code> 和<code>nn.functional.dropout</code>都是进行dropout，。。。。。；</li><li>运行效率也是近乎相同。</li></ul><h3 id="42-不同点"><a class="markdownIt-Anchor" href="#42-不同点"></a> 4.2 不同点</h3><ul><li><code>nn.functional.xxx</code>是API函数接口，而<code>nn.Xxx</code>是对原始API函数<code>nn.functional.xxx</code>的类封装。</li><li>所有<code>nn.Xxx</code>都继承于于共同祖先<code>nn.Module</code>。这一点导致<code>nn.Xxx</code>除了具有<code>nn.functional.xxx</code>功能之外，内部附带了<code>nn.Module</code>相关的属性和方法，例如<code>train(), eval(),load_state_dict, state_dict</code> 等。</li><li><code>nn.Xxx</code>继承于<code>nn.Module</code>， 能够很好的与<code>nn.Sequential</code>结合使用， 而<code>nn.functional.xxx</code>无法与<code>nn.Sequential</code>结合使用。</li><li><code>nn.Xxx</code> 需要先实例化并传入参数，然后以函数调用的方式调用实例化的对象并传入输入数据。<code>nn.functional.xxx</code>同时传入输入数据和<code>weight, bias</code>等其他参数 。</li><li><code>nn.Xxx</code>不需要你自己定义和管理weight；而<code>nn.functional.xxx</code>需要你自己定义weight，每次调用的时候都需要手动传入weight, 不利于代码复用。</li></ul><h2 id="5-nnparameter类"><a class="markdownIt-Anchor" href="#5-nnparameter类"></a> 5 nn.Parameter类</h2><h3 id="51-nnparameter概述"><a class="markdownIt-Anchor" href="#51-nnparameter概述"></a> 5.1 nn.Parameter概述</h3><blockquote><p>Parameter实际上也是tensor，也就是说是一个多维矩阵，是Variable类的一个特殊类。</p><p>当我们创建一个model时，nn会自动创建相应的参数parameter，并会自动累加到模型的Parameter 成员列表中。</p></blockquote><h3 id="52-单个全连接层中参数的个数"><a class="markdownIt-Anchor" href="#52-单个全连接层中参数的个数"></a> 5.2 单个全连接层中参数的个数</h3><p>in_features的数量，决定的参数的个数   Y = WX + b,  X的维度就是in_features，X的维度决定的W的维度， 总的参数个数 = in_features + 1</p><p>out_features的数量，决定了全连接层中神经元的个数，因为每个神经元只有一个输出。</p><p>多少个输出，就需要多少个神经元。</p><p>总的W参数的个数=  in_features * out_features</p><p>总的b参数的个数=  1 * out_features</p><p>总的参数（W和B）的个数=  (in_features + 1) * out_features</p><h3 id="53-使用参数创建全连接层"><a class="markdownIt-Anchor" href="#53-使用参数创建全连接层"></a> 5.3 使用参数创建全连接层</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nn.functional.linear( )</span></span><br><span class="line">x_input = torch.Tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_input.shape:&quot;</span>, x_input.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_input      :&quot;</span>, x_input)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line">Weights1 = nn.Parameter(torch.rand(<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights.shape:&quot;</span>, Weights1.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights      :&quot;</span>, Weights1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line">Bias1 = nn.Parameter(torch.rand(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Bias.shape:&quot;</span>, Bias1.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Bias      :&quot;</span>, Bias1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line">Weights2 = nn.Parameter(torch.Tensor(<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights.shape:&quot;</span>, Weights2.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Weights      :&quot;</span>, Weights2)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nfull_connect_layer&quot;</span>)</span><br><span class="line">full_connect_layer = nn.functional.linear(x_input, Weights1)</span><br><span class="line"><span class="built_in">print</span>(full_connect_layer)</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191629076.png" alt="image-20211203165921227" /></p><h2 id="6-nnmodule类"><a class="markdownIt-Anchor" href="#6-nnmodule类"></a> 6 nn.Module类</h2><ul><li>抽象概念，既可以表示神经网络中的某个层layer，也可以表示一个包含很多层的神经网络</li><li>modle.parameters()</li><li>modle.buffers()</li><li>modle.state_dict()</li><li>modle.modules()</li><li>forward(),to()</li></ul><h2 id="7-利用nnsequential类创建神经网络继承与nnmodule类"><a class="markdownIt-Anchor" href="#7-利用nnsequential类创建神经网络继承与nnmodule类"></a> 7 利用nn.Sequential类创建神经网络（继承与nn.Module类）</h2><blockquote><p>nn.Sequential是一个有序的容器，该类将按照传入构造器的顺序，依次创建相应的函数，并记录在Sequential类对象的数据结构中，同时以神经网络模块为元素的有序字典也可以作为传入参数。</p><p>因此，Sequential可以看成是有多个函数运算对象，串联成的神经网络，其返回的是Module类型的神经网络对象。</p></blockquote><h2 id="8自定义神经网络模型类继承于module类"><a class="markdownIt-Anchor" href="#8自定义神经网络模型类继承于module类"></a> 8.自定义神经网络模型类（继承于Module类）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义网络模型：带relu的两层全连接神经网络</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自定义新的神经网络模型的类&quot;</span>)</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NetC</span>(torch.nn.Module):</span><br><span class="line">    <span class="comment"># 定义神经网络</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_feature, n_hidden, n_output</span>):</span><br><span class="line">        <span class="built_in">super</span>(NetC, self).__init__()</span><br><span class="line">        self.h1 = nn.Linear(n_feature, n_hidden)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.out = nn.Linear(n_hidden, n_output)</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#定义前向运算</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 得到的数据格式torch.Size([64, 1, 28, 28])需要转变为（64,784）</span></span><br><span class="line">        x = x.view(x.size()[<span class="number">0</span>],-<span class="number">1</span>) <span class="comment"># -1表示自动匹配</span></span><br><span class="line">        h1 = self.h1(x)</span><br><span class="line">        a1 =  self.relu1(h1)</span><br><span class="line">        out = self.out(a1)</span><br><span class="line">        a_out = self.softmax(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n实例化神经网络模型对象&quot;</span>)</span><br><span class="line">model = NetC(<span class="number">28</span>*<span class="number">28</span>, <span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n显示网络模型参数&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model.parameters)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n定义神经网络样本输入&quot;</span>)</span><br><span class="line">x_input = torch.randn(<span class="number">2</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x_input.shape)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n使用神经网络进行预测&quot;</span>)</span><br><span class="line">y_pred = model.forward(x_input)</span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习率衰减方法</title>
      <link href="/2023/12/19/AILearning/pytorch/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/"/>
      <url>/2023/12/19/AILearning/pytorch/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="pytorch"><a class="markdownIt-Anchor" href="#pytorch"></a> <a href="https://so.csdn.net/so/search?q=Pytorch&amp;spm=1001.2101.3001.7020">Pytorch</a> 学习率衰减方法</h3><h1 id="1什么是学习率衰减"><a class="markdownIt-Anchor" href="#1什么是学习率衰减"></a> 1.什么是学习率衰减</h1><p><a href="https://so.csdn.net/so/search?q=%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D&amp;spm=1001.2101.3001.7020">梯度下降</a>算法需要我们指定一个学习率作为权重更新步幅的控制因子，常用的学习率有0.01、0.001以及0.0001等，学习率越大则权重更新。一般来说，<strong>我们希望在训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些，使得网络更好的收敛到最优解。</strong><br />Pytorch中有两种学习率调整(衰减)方法：<br />（1）使用<a href="https://so.csdn.net/so/search?q=%E5%BA%93%E5%87%BD%E6%95%B0&amp;spm=1001.2101.3001.7020">库函数</a>进行调整；<br />（2）手动调整。</p><h1 id="2使用库函数进行调整"><a class="markdownIt-Anchor" href="#2使用库函数进行调整"></a> 2.使用库函数进行调整</h1><p>Pytorch学习率调整策略通过 <a href="https://so.csdn.net/so/search?q=torch&amp;spm=1001.2101.3001.7020">torch</a>.optim.lr_sheduler 接口实现。pytorch提供的学习率调整策略分为三大类，分别是：<br />（1）有序调整：等间隔调整(Step)，多间隔调整(MultiStep)，指数衰减(Exponential)，余弦退火(CosineAnnealing);<br />（2）自适应调整：依训练状况伺机而变，通过监测某个指标的变化情况(loss、accuracy)，当该指标不怎么变化时，就是调整学习率的时机(ReduceLROnPlateau);<br />（3）自定义调整：通过自定义关于epoch的lambda函数调整学习率(LambdaLR)。<br />在每个epoch的训练中，使用scheduler.step()语句进行学习率更新</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=<span class="number">30</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        ......</span><br><span class="line">        y_ = model(x)</span><br><span class="line">        loss = criterion(y_,y)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        ......</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    train(...)</span><br><span class="line">    test(...)</span><br><span class="line">    scheduler.step()</span><br><span class="line"><span class="number">12345678910111213141516</span></span><br></pre></td></tr></table></figure><h2 id="21有序调整"><a class="markdownIt-Anchor" href="#21有序调整"></a> 2.1.有序调整</h2><h3 id="211等间隔调整学习率"><a class="markdownIt-Anchor" href="#211等间隔调整学习率"></a> 2.1.1等间隔调整学习率</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=<span class="number">0.1</span>, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>每训练step_size个epoch，学习率调整为lr=lr*gamma.<br />以下内容中都将epoch和step对等，因为每个epoch中只进行一次scheduler.step()，实则该step指scheduler.step()中的step, 即step_size指scheduler.step()进行的次数。<br />参数</p><ul><li>optimizer: 神经网络训练中使用的优化器，如optimizer=torch.optim.SGD(…)</li><li>step_size(int): 学习率下降间隔数，单位是epoch，而不是iteration.</li><li>gamma(float):学习率调整倍数，默认为0.1</li><li>last_epoch(int)：上一个epoch数，这个变量用来指示学习率是否需要调整。当last_epoch符合设定的间隔时，就会对学习率进行调整；当为-1时，学习率设置为初始值。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635978.png" alt="img" /></li></ul><h3 id="212多间隔调整学习率"><a class="markdownIt-Anchor" href="#212多间隔调整学习率"></a> 2.1.2.多间隔调整学习率</h3><p>跟2.1类似，但学习率调整的间隔并不是相等的，如epoch=10时调整一次，epoch=30时调整一次，epoch=80时调整一次…</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_shceduler.MultiStepLR(optimizer, milestones, gamma=<span class="number">0.1</span>, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>milestone(list): 一个列表参数，表示多个学习率需要调整的epoch值，如milestones=[10, 30, 80].</li><li>其它参数同(1)。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635994.png" alt="img" /></li></ul><h3 id="213指数衰减调整学习率-exponentiallr"><a class="markdownIt-Anchor" href="#213指数衰减调整学习率-exponentiallr"></a> 2.1.3.指数衰减调整学习率 ExponentialLR</h3><p>学习率呈指数型衰减，每训练一个epoch，lr=lr×γepoch</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>gamma(float)：学习率调整倍数的底数，指数为epoch，初始值我lr, 倍数为γepoch</li><li>其它参数同上。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635065.png" alt="img" /></li></ul><h3 id="214余弦退火函数调整学习率"><a class="markdownIt-Anchor" href="#214余弦退火函数调整学习率"></a> 2.1.4.余弦退火函数调整学习率</h3><p>学习率呈余弦函数型衰减，并以2×Tmax为余弦函数周期，epoch=0对应余弦型学习率调整曲线的x=0，ymax=lr，epoch=Tmax对应余弦型学习率调整曲线的x=Π，ymin=etamin处，随着epoch&gt;Tmax，学习率随epoch增加逐渐上升，整个走势同cos(x)。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=<span class="number">0</span>, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>Tmax(int):学习率下降到最小值时的epoch数，即当epoch=T_max时，学习率下降到余弦函数最小值，当epoch&gt;T_max时，学习率将增大；</li><li>etamin: 学习率调整的最小值，即epoch=Tmax时，lrmin=etamin, 默认为0.</li><li>其它参数同上。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635073.png" alt="img" /></li></ul><h2 id="22根据指标调整学习率reducelronplateau"><a class="markdownIt-Anchor" href="#22根据指标调整学习率reducelronplateau"></a> 2.2.根据指标调整学习率ReduceLROnPlateau</h2><p>当<strong>某指标(loss或accuracy)在最近几个epoch中都没有变化(下降或升高超过给定阈值)时</strong>，调整学习率。<br />如当验证集的loss不再下降是，调整学习率；或监察验证集的accuracy不再升高时，调整学习率。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">&#x27;min&#x27;</span>, factor=<span class="number">0.1</span>,</span><br><span class="line"> patience=<span class="number">10</span>,verbose=<span class="literal">False</span>, threshold=<span class="number">0.0001</span>, threshold_mode=<span class="string">&#x27;rel&#x27;</span>, cooldown=<span class="number">0</span>, </span><br><span class="line"> min_lr=<span class="number">0</span>, eps=<span class="number">1e-08</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>mode(str): 模式选择，有min和max两种模式，min表示当指标不再降低(如监测loss)，max表示当指标不再升高(如监测accuracy)。</li><li>factor(float): 学习率调整倍数，同前面的gamma，当监测指标达到要求时，lr=lr×factor。</li><li>patience(int): 忍受该指标多少个epoch不变化，当忍无可忍时，调整学习率。</li><li>verbose(bool): 是否打印学习率信息，print( ‘Epoch {:5d} reducing learning rate of group {} to {:.4e}.’.format(epoch, i, new_lr), 默认为False, 即不打印该信息。</li><li>threshold_mode (str): 选择判断指标是否达最优的模式，有两种模式：rel 和 abs.<br />当threshold_mode == rel, 并且 mode == max时，dynamic_threshold = best * (1 + threshold);<br />当threshold_mode == rel, 并且 mode == min时，dynamic_threshold = best * (1 - threshold);<br />当threshold_mode == abs, 并且 mode == max时，dynamic_threshold = best + threshold;<br />当threshold_mode == abs, 并且 mode == min时，dynamic_threshold = best - threshold;<br />threshold(float): 配合threshold_mode使用。</li><li>cooldown(int): “冷却时间”，当调整学习率之后，让学习率调整策略冷静一下，让模型在训练一段时间，再重启监测模式</li><li>min_lr(float or list): 学习率下限，可为float，或者list，当有多个参数组时，可用list进行设置。</li><li>eps(float): 学习率衰减的最小值，当学习率的变化值小于eps时，则不调整学习率。</li></ul><h2 id="23自定义调整学习率"><a class="markdownIt-Anchor" href="#23自定义调整学习率"></a> 2.3.自定义调整学习率</h2><p>为不同参数组设定不同学习率调整策略。调整规则为：<br />lr = base_lr * lambda(self.last_epoch)<br />在fine-tune中特别有用，<strong>我们不仅可以为不同层设置不同的学习率，还可以为不同层设置不同的学习率调整策略。</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>lr_lambda(function or list): 自定义计算学习率调整倍数的函数，通常时epoch的函数，当有多个参数组时，设为list.</li><li>其它参数同上。</li></ul><h1 id="3手动调整学习率"><a class="markdownIt-Anchor" href="#3手动调整学习率"></a> 3.手动调整学习率</h1><p>手动调整学习率，通常可以定义如下函数：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adjust_learning_rate</span>(<span class="params">optimizer, epoch</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Sets the learning rate to the initial LR decayed by 10 every 30 epochs&quot;&quot;&quot;</span></span><br><span class="line">    lr = args.lr * (<span class="number">0.1</span> ** (epoch // <span class="number">30</span>))</span><br><span class="line">    <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">        param_group[<span class="string">&#x27;lr&#x27;</span>] = lr</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>又如：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adjust_learning_rate</span>(<span class="params">epoch, lr</span>):</span><br><span class="line">    <span class="keyword">if</span> epoch &lt;= <span class="number">81</span>:  <span class="comment"># 32k iterations</span></span><br><span class="line">      <span class="keyword">return</span> lr</span><br><span class="line">    <span class="keyword">elif</span> epoch &lt;= <span class="number">122</span>:  <span class="comment"># 48k iterations</span></span><br><span class="line">      <span class="keyword">return</span> lr/<span class="number">10</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">return</span> lr/<span class="number">100</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>该函数通过修改每个epoch下，各参数组中的lr来进行学习率手动调整，用法如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    lr = adjust_learning_rate(optimizer, epoch)  <span class="comment"># 调整学习率</span></span><br><span class="line">    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">5e-4</span>)</span><br><span class="line">    ......</span><br><span class="line">    optimizer.step()  <span class="comment"># 采用新的学习率进行参数更新</span></span><br></pre></td></tr></table></figure><p>梯度下降算法需要我们指定一个学习率作为权重更新步幅的控制因子，常用的学习率有0.01、0.001以及0.0001等，学习率越大则权重更新。一般来说，<strong>我们希望在训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些</strong>，使得网络更好的收敛到最优解。下图展示了随着迭代的进行动态调整学习率的4种策略曲线：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635068.jpg" alt="img" /></p><p>上述4种策略为自己根据资料整理得到的衰减类型：指数衰减、固定步长的衰减、多步长衰、余弦退火衰减。下面逐一介绍其性质，及pytorch对应的使用方式，需要注意学习率衰减策略很大程度上是<strong>依赖于经验与具体问题的</strong>，不能照搬参数。</p><p>*<strong>1、指数衰减*</strong></p><p>学习率按照指数的形式衰减是比较常用的策略，我们首先需要确定需要针对哪个优化器执行学习率动态调整策略，也就是首先定义一个优化器：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">optimizer_ExpLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br></pre></td></tr></table></figure><p>定义好优化器以后，就可以给这个优化器绑定一个指数衰减学习率控制器：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ExpLR = torch.optim.lr_scheduler.ExponentialLR(optimizer_ExpLR, gamma=0.98)</span><br></pre></td></tr></table></figure><p>其中<strong>参数gamma表示衰减的底数，选择不同的gamma值可以获得幅度不同的衰减曲线</strong>，如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635071.jpg" alt="img" /></p><p>*<strong>2、固定步长衰减*</strong></p><p>有时我们希望学习率每隔一定步数（或者epoch）就减少为原来的gamma分之一，使用固定步长衰减依旧先定义优化器，再给优化器绑定StepLR对象：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">optimizer_StepLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br><span class="line">StepLR = torch.optim.lr_scheduler.StepLR(optimizer_StepLR, step_size=step_size, gamma=0.65)</span><br></pre></td></tr></table></figure><p>其中gamma参数表示衰减的程度，step_size参数表示每隔多少个step进行一次学习率调整，下面对比了不同gamma值下的学习率变化情况：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635399.jpg" alt="img" /></p><p>*<strong>3、多步长衰减*</strong></p><p>上述固定步长的衰减的虽然能够按照固定的区间长度进行学习率更新**，但是有时我们希望不同的区间采用不同的更新频率，或者是有的区间更新学习率，有的区间不更新学习率**，这就需要使用MultiStepLR来实现动态区间长度控制：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">optimizer_MultiStepLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br><span class="line">torch.optim.lr_scheduler.MultiStepLR(optimizer_MultiStepLR,</span><br><span class="line">                    milestones=[200, 300, 320, 340, 200], gamma=0.8)</span><br></pre></td></tr></table></figure><p>其中milestones参数为表示学习率更新的起止区间，在区间[0. 200]内学习率不更新，而在[200, 300]、[300, 320]…[340, 400]的右侧值都进行一次更新；gamma参数表示学习率衰减为上次的gamma分之一。其图示如下：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635419.jpg" alt="img" /></p><p>从图中可以看出，学习率在区间[200， 400]内快速的下降，这就是milestones参数所控制的，在milestones以外的区间学习率始终保持不变。</p><p>*<strong>4、余弦退火衰减*</strong></p><p>严格的说，余弦退火策略不应该算是学习率衰减策略，因为它使得学习率按照周期变化，其定义方式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">optimizer_CosineLR = torch.optim.SGD(net.parameters(), lr=0.1)</span><br><span class="line">CosineLR = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_CosineLR, T_max=150, eta_min=0)</span><br></pre></td></tr></table></figure><p>其包含的参数和余弦知识一致，参数T_max表示余弦函数周期；eta_min表示学习率的最小值，默认它是0表示学习率至少为正值。确定一个余弦函数需要知道最值和周期，其中周期就是T_max，最值是初试学习率。下图展示了不同周期下的余弦学习率更新曲线：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191635437.jpg" alt="img" /></p><p>*<strong>5、上述4种学习率动态更新策略的说明*</strong></p><p>4个负责学习率调整的类：StepLR、ExponentialLR、MultiStepLR和CosineAnnealingLR，其完整对学习率的更新都是在其step()函数被调用以后完成的，这个step表达的含义可以是一次迭代，当然更多情况下应该是一个epoch以后进行一次scheduler.step()，这根据具体问题来确定。此外，根据pytorch官网上给出的说明，scheduler.step()函数的调用应该在训练代码以后：</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">scheduler = ...</span><br><span class="line">&gt;&gt;&gt; for epoch in range(100):</span><br><span class="line">&gt;&gt;&gt;     train(...)</span><br><span class="line">&gt;&gt;&gt;     validate(...)</span><br><span class="line">&gt;&gt;&gt;     scheduler.step()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 学习率 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>torch tensor 计算</title>
      <link href="/2023/12/19/AILearning/pytorch/tensor%E8%AE%A1%E7%AE%97/"/>
      <url>/2023/12/19/AILearning/pytorch/tensor%E8%AE%A1%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<h4 id="torchmean"><a class="markdownIt-Anchor" href="#torchmean"></a> torch.mean()</h4><blockquote><p>mean()函数的参数：dim=0,按行求平均值，返回的形状是（1，列数）；dim=1,按列求平均值，返回的形状是（行数，1）,默认不设置dim的时候，返回的是所有元素的平均值。</p></blockquote><h4 id="torchpow"><a class="markdownIt-Anchor" href="#torchpow"></a> torch.pow()</h4><blockquote><p>功能: 实现张量和标量之间逐元素求指数操作, 或者在可广播的张量之间逐元素求指数操作.</p></blockquote><h4 id="torchstack"><a class="markdownIt-Anchor" href="#torchstack"></a> torch.stack()</h4><blockquote><p>官方解释：沿着一个新维度对输入张量序列进行连接。 序列中所有的张量都应该为相同形状。</p><p>注：<code>python</code>的序列数据只有<code>list</code>和<code>tuple</code>。</p><p>浅显说法：把多个2维的张量凑成一个3维的张量；多个3维的凑成一个4维的张量…以此类推，也就是在增加新的维度进行堆叠。</p><p>outputs = torch.stack(inputs, dim=?) → Tensor</p></blockquote><h4 id="torchclamp"><a class="markdownIt-Anchor" href="#torchclamp"></a> torch.clamp()</h4><blockquote><p>torch.clamp(input, min, max, out=None) → Tensor</p><p>将输入<code>input</code>张量每个元素的夹紧到区间 [min,max][min,max]，并返回结果到一个新张量。</p></blockquote><h4 id="torchbmm"><a class="markdownIt-Anchor" href="#torchbmm"></a> torch.bmm()</h4><blockquote><p>计算两个tensor的矩阵乘法，torch.bmm(a,b),tensor a 的size为(b,h,w),tensor b的size为(b,w,m) 也就是说两个tensor的第一维是相等的，然后第一个数组的第三维和第二个数组的第二维度要求一样，对于剩下的则不做要求，输出维度 （b,h,m）;</p></blockquote><h4 id="torchsqueeze函数"><a class="markdownIt-Anchor" href="#torchsqueeze函数"></a> torch.squeeze()函数</h4><blockquote><p>torch.squeeze(input, dim=None, out=None)</p><p>squeeze()函数的功能是维度压缩。返回一个tensor（张量），其中 input 中大小为1的所有维都已删除。</p><p>举个例子：如果 input 的形状为 (A×1×B×C×1×D)，那么返回的tensor的形状则为 (A×B×C×D)</p><p>当给定 dim 时，那么只在给定的维度（dimension）上进行压缩操作。</p><p>举个例子：如果 input 的形状为 (A×1×B)，squeeze(input, 0)后，返回的tensor不变；squeeze(input, 1)后，返回的tensor将被压缩为 (A×B)</p></blockquote><h4 id="torchunsqueeze"><a class="markdownIt-Anchor" href="#torchunsqueeze"></a> torch.unsqueeze()</h4><blockquote></blockquote><h4 id="torchspmm"><a class="markdownIt-Anchor" href="#torchspmm"></a> torch.spmm</h4><blockquote><p>torch.spmm只支持 sparse 在前，dense 在后的矩阵乘法，两个sparse相乘或者dense在前的乘法不支持，当然两个dense矩阵相乘是支持的。</p></blockquote><h4 id="torchsum"><a class="markdownIt-Anchor" href="#torchsum"></a> torch.sum</h4><blockquote><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191625912.png" alt="img" /></p><p>在dim这个维度上，对里面的tesnor 进行加和，如果keepdim=False，返回结果会删去dim这个维度。因为在dim上加和之后，dim=1，所以可以直接删去。</p></blockquote><h4 id="torchdiag"><a class="markdownIt-Anchor" href="#torchdiag"></a> torch.diag</h4><blockquote><p>对角矩阵</p></blockquote><h4 id="torchconcat"><a class="markdownIt-Anchor" href="#torchconcat"></a> torch.concat</h4><blockquote><p>torch.cat ( (A, B), dim=0)接受一个由两个（或多个）tensor组成的元组，按行拼接，所以两个（多个）tensor的列数要相同。</p><p>torch.cat ( (A, B), dim=1)是按列拼接，所以两个tensor的行数要相同。</p></blockquote><h4 id="torchview"><a class="markdownIt-Anchor" href="#torchview"></a> torch.view</h4><blockquote><p>在PyTorch中<strong>view</strong>函数作用为重构张量的维度，相当于numpy中的resize()的功能，但是用法不太一样;</p><p>torch.view(参数a,参数b,…)，其中参数a=3,参数b=2决定了将一维的tt1重构成3*2维的张量。<br />有时候会出现torch.view(-1)或者torch.view(参数a,-1)这种情况。则-1参数是需要估算的。</p><p><strong>view()函数的功能与reshape类似，用来转换size大小。x = x.view(batchsize, -1)中batchsize指转换后有几行，而-1指在不告诉函数有多少列的情况下，根据原tensor数据和batchsize自动分配列数。</strong></p><p>之前对于pytorch的网络编程学习都是大致理解每一层的概念，有些语法语句没有从原理上弄清楚，就比如标题的x = x.view(x.size(0), -1)  。</p><p>这句话一般出现在model类的forward函数中，具体位置一般都是在调用分类器之前。分类器是一个简单的nn.Linear()结构，输入输出都是维度为一的值，x = x.view(x.size(0), -1)  这句话的出现就是为了将前面多维度的tensor展平成一维。</p></blockquote><h4 id="torchpermute"><a class="markdownIt-Anchor" href="#torchpermute"></a> torch.permute</h4><blockquote><p>permute（dims）<br />参数dims用矩阵的维数代入，一般默认从0开始。即第0维，第1维等等<br />也可以理解为，第0块，第1块等等。当然矩阵最少是两维才能使用permute<br />如是两维，dims分别为是0和1<br />可以写成permute（0,1）这里不做任何变化，维数与之前相同<br />如果写成permute（1,0）得到的就是矩阵的转置<br />如果三维是permute(0,1,2)<br />0代表共有几块维度：本例中0对应着3块矩阵<br />1代表每一块中有多少行：本例中1对应着每块有2行<br />2代表每一块中有多少列：本例中2对应着每块有5列<br />所以是3块2行5列的三维矩阵</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> tensor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>torch tensor操作</title>
      <link href="/2023/12/19/AILearning/pytorch/tensor%E6%93%8D%E4%BD%9C/"/>
      <url>/2023/12/19/AILearning/pytorch/tensor%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="一-张量的基本操作"><a class="markdownIt-Anchor" href="#一-张量的基本操作"></a> 一、张量的基本操作</h1><p>Pytorch 中，张量的操作分为<strong>结构操作和数学运算</strong>，其理解就如字面意思。结构操作就是改变张量本身的结构，数学运算就是对张量的元素值完成数学运算。</p><ul><li>常使用的张量结构操作：维度变换（tranpose、view 等）、合并分割（split、chunk等）、索引切片（index_select、gather 等）。</li><li>常使用的张量数学运算：标量运算、向量运算、矩阵运算。</li></ul><h1 id="二-维度变换"><a class="markdownIt-Anchor" href="#二-维度变换"></a> 二、维度变换</h1><h2 id="21-squeeze-vs-unsqueeze-维度增减"><a class="markdownIt-Anchor" href="#21-squeeze-vs-unsqueeze-维度增减"></a> <strong>2.1 squeeze vs unsqueeze 维度增减</strong></h2><ul><li><strong>squeeze()</strong>：对 tensor 进行维度的压缩，去掉维数为 1 的维度。用法：torch.squeeze(a) 将 a 中所有为 1 的维度都删除，或者 a.squeeze(1) 是去掉 a中指定的维数为 1 的维度。</li><li><strong>unsqueeze()</strong>：对数据维度进行扩充，给指定位置加上维数为 1 的维度。用法：torch.unsqueeze(a, N)，或者 a.unsqueeze(N)，在 a 中指定位置 N 加上一个维数为 1 的维度。</li></ul><p>squeeze 用例程序如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.squeeze(a)</span><br><span class="line">c = a.squeeze(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(b.shape)</span><br><span class="line"><span class="built_in">print</span>(c.shape)</span><br></pre></td></tr></table></figure><p>程序输出结果如下：</p><blockquote><p>torch.Size([3, 3]) torch.Size([1, 3, 3])</p></blockquote><p>unsqueeze 用例程序如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.rand(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">y1 = torch.unsqueeze(x, <span class="number">0</span>)</span><br><span class="line">y2 = x.unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(y1.shape)</span><br><span class="line"><span class="built_in">print</span>(y2.shape)</span><br></pre></td></tr></table></figure><p>程序输出结果如下：</p><blockquote><p>torch.Size([1, 3, 3]) torch.Size([1, 3, 3])</p></blockquote><h2 id="22-transpose-vs-permute-维度交换"><a class="markdownIt-Anchor" href="#22-transpose-vs-permute-维度交换"></a> <strong>2.2 transpose vs permute 维度交换</strong></h2><p>torch.transpose() 只能交换两个维度，而 .permute() 可以自由交换任意位置。函数定义如下：</p><ul><li>transpose(dim0, dim1) → Tensor # See torch.transpose()</li><li>permute(*dims) → Tensor # dim(int). Returns a view of the original tensor with its dimensions permuted.</li></ul><p>在 CNN 模型中，我们经常遇到交换维度的问题，举例：四个维度表示的 tensor：[batch, channel, h, w]（nchw），如果想把 channel 放到最后去，形成[batch, h, w, channel]（nhwc），如果使用 torch.transpose() 方法，至少要交换两次（先 1 3 交换再 1 2 交换），而使用 .permute() 方法只需一次操作，更加方便。例子程序如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">b = torch.rand(<span class="number">1</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">32</span>)</span><br><span class="line"><span class="comment"># torch.Size([1, 3, 28, 32]</span></span><br><span class="line"><span class="built_in">print</span>(b.transpose(<span class="number">1</span>, <span class="number">3</span>).shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 32, 28, 3])</span></span><br><span class="line"><span class="built_in">print</span>(b.transpose(<span class="number">1</span>, <span class="number">3</span>).transpose(<span class="number">1</span>, <span class="number">2</span>).shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 28, 32, 3])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(b.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 28, 32, 3]</span></span><br></pre></td></tr></table></figure><h2 id="23-reshape-vs-view"><a class="markdownIt-Anchor" href="#23-reshape-vs-view"></a> <strong>2.3 reshape vs view</strong></h2><blockquote><p>view只适合对满足连续性条件（contiguous）的tensor进行操作，而reshape同时还可以对不满足连续性条件的tensor进行操作，具有更好的鲁棒性。view能干的reshape都能干，如果view不能干就可以用reshape来处理。更多可看[1]</p></blockquote><h2 id="24-einsum"><a class="markdownIt-Anchor" href="#24-einsum"></a> <strong>2.4 einsum</strong></h2><p>首先看下 einsum 实现矩阵乘法的例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 语义解析：</span></span><br><span class="line"><span class="comment"># 输入a：2阶张量，下标为ik</span></span><br><span class="line"><span class="comment"># 输入b: 2阶张量，下标为kj</span></span><br><span class="line"><span class="comment"># 输出o: 2阶张量，下标为i和j</span></span><br><span class="line">c = torch.einsum(<span class="string">&quot;ik,kj-&gt;ij&quot;</span>, [a, b])</span><br><span class="line"><span class="comment"># 等价操作 torch.mm(a, b)</span></span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="number">60.</span>).reshape(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">b = np.arange(<span class="number">24.</span>).reshape(<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 语义解析：</span></span><br><span class="line"><span class="comment"># 输入a：3阶张量，下标为ijk</span></span><br><span class="line"><span class="comment"># 输入b: 3阶张量，下标为jil</span></span><br><span class="line"><span class="comment"># 输出o: 2阶张量，下标为k和l</span></span><br><span class="line">c = np.einsum(<span class="string">&#x27;ijk,jil-&gt;kl&#x27;</span>, a, b)</span><br></pre></td></tr></table></figure><p>这个方法可以实现矩阵乘法，但是也可以用来更换维度</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 语义解析:</span></span><br><span class="line"><span class="comment"># 当后面只有一个张量时，就是对自己维度进行变换</span></span><br><span class="line"><span class="comment"># 比较常用的就是将chanel换到最后</span></span><br><span class="line">x = torch.einsum(<span class="string">&#x27;nchw-&gt;nhwc&#x27;</span>, x)</span><br></pre></td></tr></table></figure><blockquote><p>更多可看[2]</p></blockquote><h1 id="三-索引切片"><a class="markdownIt-Anchor" href="#三-索引切片"></a> 三、索引切片</h1><h2 id="31-规则索引切片方式"><a class="markdownIt-Anchor" href="#31-规则索引切片方式"></a> <strong>3.1 规则索引切片方式</strong></h2><p>张量的索引切片方式和 numpy、python 多维列表几乎一致，都可以通过索引和切片对部分元素进行修改。切片时支持缺省参数和省略号。实例代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.randint(<span class="number">1</span>,<span class="number">10</span>,[<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t</span><br><span class="line">tensor([[<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">5</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">9</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>] <span class="comment"># 第 1 行数据</span></span><br><span class="line">tensor([<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">2</span>][<span class="number">2</span>]</span><br><span class="line">tensor(<span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>:<span class="number">3</span>,:]  <span class="comment"># 第1至第3行，全部列</span></span><br><span class="line">tensor([[<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">5</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">9</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>:<span class="number">2</span>,:]  <span class="comment"># 第1行至第2行</span></span><br><span class="line">tensor([[<span class="number">8</span>, <span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">5</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">1</span>:,-<span class="number">1</span>]  <span class="comment"># 第2行至最后行，最后一列</span></span><br><span class="line">tensor([<span class="number">9</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">1</span>:,::<span class="number">2</span>] <span class="comment"># 第1行至最后行，第0列到最后一列每隔两列取一列</span></span><br><span class="line">tensor([[<span class="number">2</span>, <span class="number">9</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">9</span>]])</span><br></pre></td></tr></table></figure><p>以上切片方式相对规则，对于不规则的切片提取,可以使用 torch.index_select, torch.take, torch.gather, torch.masked_select。</p><h2 id="32-gather-和-torchindex_select-算子"><a class="markdownIt-Anchor" href="#32-gather-和-torchindex_select-算子"></a> <strong>3.2 gather 和 torch.index_select 算子</strong></h2><blockquote><p>gather 算子的用法比较难以理解，在翻阅了官方文档和网上资料后，我有了一些自己的理解。</p></blockquote><p>1，gather 是不规则的切片提取算子（Gathers values along an axis specified by dim. 在指定维度上根据索引 index 来选取数据）。函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.gather(<span class="built_in">input</span>, dim, index, *, sparse_grad=<span class="literal">False</span>, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p><strong>参数解释：</strong></p><ul><li>input (Tensor) – the source tensor.</li><li>dim (int) – the axis along which to index.</li><li>index (LongTensor) – the indices of elements to gather.</li></ul><p>对于 3D tensor，output 值的定义如下： gather 的官方定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out[i][j][k] = <span class="built_in">input</span>[index[i][j][k]][j][k]  <span class="comment"># if dim == 0</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][index[i][j][k]][k]  <span class="comment"># if dim == 1</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][j][index[i][j][k]]   <span class="comment"># if dim == 2</span></span><br></pre></td></tr></table></figure><p>下面结合 2D 和 3D tensor 的用例来直观理解算子用法。<br />（1）对于 2D tensor 的例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">0</span>, <span class="number">16</span>).view(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">        [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">        [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]])  <span class="comment"># 选取对角线元素</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.gather(a, <span class="number">0</span>, index)</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>]])</span><br></pre></td></tr></table></figure><p>output 值定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 按照 index = tensor([[0, 1, 2, 3]])顺序作用在行上索引依次为0,1,2,3</span></span><br><span class="line">a[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">a[<span class="number">1</span>][<span class="number">1</span>] = <span class="number">5</span></span><br><span class="line">a[<span class="number">2</span>][<span class="number">2</span>] = <span class="number">10</span></span><br><span class="line">a[<span class="number">3</span>][<span class="number">3</span>] = <span class="number">15</span></span><br></pre></td></tr></table></figure><p>（2）索引更复杂的 2D tensor 例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.gather(t, <span class="number">1</span>, torch.tensor([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>]]))</span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">3</span>]])</span><br></pre></td></tr></table></figure><p>output 值的计算如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">output[i][j] = <span class="built_in">input</span>[i][index[i][j]]  <span class="comment"># if dim = 1</span></span><br><span class="line">output[<span class="number">0</span>][<span class="number">0</span>] = <span class="built_in">input</span>[<span class="number">0</span>][index[<span class="number">0</span>][<span class="number">0</span>]] = <span class="built_in">input</span>[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">output[<span class="number">0</span>][<span class="number">1</span>] = <span class="built_in">input</span>[<span class="number">0</span>][index[<span class="number">0</span>][<span class="number">1</span>]] = <span class="built_in">input</span>[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">output[<span class="number">1</span>][<span class="number">0</span>] = <span class="built_in">input</span>[<span class="number">1</span>][index[<span class="number">1</span>][<span class="number">0</span>]] = <span class="built_in">input</span>[<span class="number">1</span>][<span class="number">1</span>] = <span class="number">4</span></span><br><span class="line">output[<span class="number">1</span>][<span class="number">1</span>] = <span class="built_in">input</span>[<span class="number">1</span>][index[<span class="number">1</span>][<span class="number">1</span>]] = <span class="built_in">input</span>[<span class="number">1</span>][<span class="number">0</span>] = <span class="number">3</span></span><br></pre></td></tr></table></figure><p>总结：<strong>可以看到 gather 是通过将索引在指定维度 dim 上的值替换为 index 的值，但是其他维度索引不变的情况下获取 tensor 数据</strong>。直观上可以理解为对矩阵进行重排，比如对每一行(dim=1)的元素进行变换，比如 torch.gather(a, 1, torch.tensor([[1,2,0], [1,2,0]])) 的作用就是对 矩阵 a 每一行的元素，进行 permtute(1,2,0) 操作。</p><p>2，理解了 gather 再看 index_select 就很简单，函数作用是返回沿着输入张量的指定维度的指定索引号进行索引的张量子集。函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.index_select(<span class="built_in">input</span>, dim, index, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p>函数返回一个新的张量，它使用数据类型为 LongTensor 的 index 中的条目沿维度 dim 索引输入张量。返回的张量具有与原始张量（输入）相同的维数。 维度尺寸与索引长度相同； 其他尺寸与原始张量中的尺寸相同。实例代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">        [-<span class="number">0.4664</span>,  <span class="number">0.2647</span>, -<span class="number">0.1228</span>, -<span class="number">1.1068</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>indices = torch.tensor([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">0</span>, indices)</span><br><span class="line">tensor([[ <span class="number">0.1427</span>,  <span class="number">0.0231</span>, -<span class="number">0.5414</span>, -<span class="number">1.0009</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>, -<span class="number">0.6571</span>,  <span class="number">0.7230</span>, -<span class="number">0.6004</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.index_select(x, <span class="number">1</span>, indices)</span><br><span class="line">tensor([[ <span class="number">0.1427</span>, -<span class="number">0.5414</span>],</span><br><span class="line">        [-<span class="number">0.4664</span>, -<span class="number">0.1228</span>],</span><br><span class="line">        [-<span class="number">1.1734</span>,  <span class="number">0.7230</span>]])</span><br></pre></td></tr></table></figure><h1 id="四-合并分割"><a class="markdownIt-Anchor" href="#四-合并分割"></a> 四、合并分割</h1><h2 id="41-torchcat-和-torchstack"><a class="markdownIt-Anchor" href="#41-torchcat-和-torchstack"></a> <strong>4.1 torch.cat 和 torch.stack</strong></h2><p>可以用 torch.cat 方法和 torch.stack 方法将多个张量合并，也可以用 torch.split方法把一个张量分割成多个张量。torch.cat 和 torch.stack 有略微的区别，torch.cat 是连接，不会增加维度，而 torch.stack 是堆叠，会增加一个维度。两者函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.</span></span><br><span class="line">torch.cat(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br><span class="line"><span class="comment"># Concatenates a sequence of tensors along **a new** dimension. All tensors need to be of the same size.</span></span><br><span class="line">torch.stack(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure><p>torch.cat 和 torch.stack 用法实例代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">0</span>,<span class="number">9</span>).view(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.arange(<span class="number">10</span>,<span class="number">19</span>).view(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = torch.arange(<span class="number">20</span>,<span class="number">29</span>).view(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cat_abc = torch.cat([a,b,c], dim=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(cat_abc.shape)</span><br><span class="line">torch.Size([<span class="number">9</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(cat_abc)</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">        [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line">        [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">        [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">        [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>],</span><br><span class="line">        [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>],</span><br><span class="line">        [<span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">        [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>stack_abc = torch.stack([a,b,c], axis=<span class="number">0</span>)  <span class="comment"># torch中dim和axis参数名可以混用</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(stack_abc.shape)</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(stack_abc)</span><br><span class="line">tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">         [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">         [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>],</span><br><span class="line">         [<span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">         [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>chunk_abc = torch.chunk(cat_abc, <span class="number">3</span>, dim=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>chunk_abc</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">         [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">         [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]]),</span><br><span class="line"> tensor([[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>]]),</span><br><span class="line"> tensor([[<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>],</span><br><span class="line">         [<span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">         [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>]]))</span><br></pre></td></tr></table></figure><h2 id="42-torchsplit-和-torchchunk"><a class="markdownIt-Anchor" href="#42-torchsplit-和-torchchunk"></a> <strong>4.2 torch.split 和 torch.chunk</strong></h2><p>torch.split() 和 torch.chunk() 可以看作是 torch.cat() 的逆运算。split() 作用是将张量拆分为多个块，每个块都是原始张量的视图。split() 函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Splits the tensor into chunks. Each chunk is a view of the original tensor.</span></span><br><span class="line"><span class="string">If split_size_or_sections is an integer type, then tensor will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by split_size.</span></span><br><span class="line"><span class="string">If split_size_or_sections is a list, then tensor will be split into len(split_size_or_sections) chunks with sizes in dim according to split_size_or_sections.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">torch.split(tensor, split_size_or_sections, dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>chunk() 作用是将 tensor 按 dim（行或列）分割成 chunks 个 tensor 块，返回的是一个元组。chunk() 函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.chunk(<span class="built_in">input</span>, chunks, dim=<span class="number">0</span>) → <span class="type">List</span> of Tensors</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Splits a tensor into a specific number of chunks. Each chunk is a view of the input tensor.</span></span><br><span class="line"><span class="string">Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by chunks.</span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    input (Tensor) – the tensor to split</span></span><br><span class="line"><span class="string">    chunks (int) – number of chunks to return</span></span><br><span class="line"><span class="string">    dim (int) – dimension along which to split the tensor</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>实例代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">10</span>).reshape(<span class="number">5</span>,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">        [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">        [<span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.split(a, <span class="number">2</span>)</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">3</span>]]),</span><br><span class="line"> tensor([[<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">          [<span class="number">6</span>, <span class="number">7</span>]]),</span><br><span class="line"> tensor([[<span class="number">8</span>, <span class="number">9</span>]]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.split(a, [<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>]]),</span><br><span class="line"> tensor([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">         [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">         [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">         [<span class="number">8</span>, <span class="number">9</span>]]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.chunk(a, <span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">(tensor([[<span class="number">0</span>],</span><br><span class="line">        [<span class="number">2</span>],</span><br><span class="line">        [<span class="number">4</span>],</span><br><span class="line">        [<span class="number">6</span>],</span><br><span class="line">        [<span class="number">8</span>]]), </span><br><span class="line">tensor([[<span class="number">1</span>],</span><br><span class="line">        [<span class="number">3</span>],</span><br><span class="line">        [<span class="number">5</span>],</span><br><span class="line">        [<span class="number">7</span>],</span><br><span class="line">        [<span class="number">9</span>]]))</span><br></pre></td></tr></table></figure><h1 id="五-卷积相关算子"><a class="markdownIt-Anchor" href="#五-卷积相关算子"></a> 五、卷积相关算子</h1><h2 id="51-上采样方法总结"><a class="markdownIt-Anchor" href="#51-上采样方法总结"></a> <strong>5.1 上采样方法总结</strong></h2><p>上采样大致被总结成了三个类别：</p><ol><li>基于线性插值的上采样：最近邻算法（nearest）、双线性插值算法（bilinear）、双三次插值算法（bicubic）等，这是传统图像处理方法。</li><li>基于深度学习的上采样（转置卷积，也叫反卷积 Conv2dTranspose2d等）</li><li>Unpooling 的方法（简单的补零或者扩充操作）<br />计算效果：最近邻插值算法 &lt; 双线性插值 &lt; 双三次插值。计算速度：最近邻插值算法 &gt; 双线性插值 &gt; 双三次插值。</li></ol><h2 id="52-finterpolate-采样函数"><a class="markdownIt-Anchor" href="#52-finterpolate-采样函数"></a> <strong>5.2 F.interpolate 采样函数</strong></h2><blockquote><p>Pytorch 老版本有 nn.Upsample 函数，新版本建议用 torch.nn.functional.interpolate，一个函数可实现定制化需求的上采样或者下采样功能，。</p></blockquote><p>F.interpolate() 函数全称是 torch.nn.functional.interpolate()，函数定义如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">interpolate</span>(<span class="params"><span class="built_in">input</span>, size=<span class="literal">None</span>, scale_factor=<span class="literal">None</span>, mode=<span class="string">&#x27;nearest&#x27;</span>, align_corners=<span class="literal">None</span>, recompute_scale_factor=<span class="literal">None</span></span>):  <span class="comment"># noqa: F811</span></span><br><span class="line">    <span class="comment"># type: (Tensor, <span class="type">Optional</span>[<span class="built_in">int</span>], <span class="type">Optional</span>[<span class="type">List</span>[<span class="built_in">float</span>]], <span class="built_in">str</span>, <span class="type">Optional</span>[<span class="built_in">bool</span>], <span class="type">Optional</span>[<span class="built_in">bool</span>]) -&gt; Tensor</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>参数解释如下：</p><ul><li>input(Tensor)：输入张量数据；</li><li>size： 输出的尺寸，数据类型为 tuple： ([optional D_out], [optional H_out], W_out)，和 scale_factor 二选一；</li><li>scale_factor：在高度、宽度和深度上面的放大倍数。数据类型既可以是 int——表明高度、宽度、深度都扩大同一倍数；也可是tuple——指定高度、宽度、深度等维度的扩大倍数；</li><li>mode： 上采样的方法，包括最近邻（nearest），线性插值（linear），双线性插值（bilinear），三次线性插值（trilinear），默认是最近邻（nearest）；</li><li>align_corners： 如果设为True，输入图像和输出图像角点的像素将会被对齐（aligned），这只在mode = linear, bilinear, or trilinear才有效，默认为False。</li></ul><p>例子程序如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x = torch.rand(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">y = F.interpolate(x * <span class="number">2</span>, scale_factor=(<span class="number">2</span>, <span class="number">2</span>), mode=<span class="string">&#x27;bilinear&#x27;</span>).squeeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(y.shape)   <span class="comment"># torch.Size([3, 224, 224])</span></span><br></pre></td></tr></table></figure><h2 id="53-nnconvtranspose2d-反卷积"><a class="markdownIt-Anchor" href="#53-nnconvtranspose2d-反卷积"></a> <strong>5.3 nn.ConvTranspose2d 反卷积</strong></h2><p>转置卷积（有时候也称为反卷积，个人觉得这种叫法不是很规范），它是一种特殊的卷积，先 padding 来扩大图像尺寸，紧接着跟正向卷积一样，旋转卷积核 180 度，再进行卷积计算。</p><h1 id="引用"><a class="markdownIt-Anchor" href="#引用"></a> 引用</h1><p>[0] <a href="http://zhuanlan.zhihu.com/p/">zhuanlan.zhihu.com/p/</a><br />[1] <a href="https://blog.csdn.net/Flag_ing/article/details/109129752">https://blog.csdn.net/Flag_ing/article/details/109129752</a><br />[2] <a href="https://zhuanlan.zhihu.com/p/361209187">https://zhuanlan.zhihu.com/p/361209187</a></p>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> tensor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>torch环境</title>
      <link href="/2023/12/19/Programmer/python/torch%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"/>
      <url>/2023/12/19/Programmer/python/torch%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191226420.png" alt="image-20231219122612389" /></p><h1 id="1安装对应的torch-torchvision"><a class="markdownIt-Anchor" href="#1安装对应的torch-torchvision"></a> 1.安装对应的torch、torchvision</h1><p>网址：<a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a></p><p>搜索对应CUDA版本的安装命令（cu110代表CUDA11.0），在终端中复制命令安装。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191135284.png" alt="image-20231219113547226" /></p><p>查看是否安装成功</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.__version__) </span><br><span class="line"><span class="built_in">print</span>(torch.version.cuda) </span><br></pre></td></tr></table></figure><h1 id="2安装torch-geometric"><a class="markdownIt-Anchor" href="#2安装torch-geometric"></a> 2.安装torch-geometric</h1><p>网址：<a href="https://pytorch-geometric.com/whl/">https://pytorch-geometric.com/whl/</a></p><p>找到对应pytorch版本：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191137168.png" alt="image-20231219113754141" /></p><p>四个库（cluster,scatter,sparse,spline-conv）分别：wget 网页中对应的链接并 pip install 下载好的whl包，即完成安装：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191139386.png" alt="image-20231219113927345" /></p><p>注意自己环境的python版本以及linux/win就行</p><p>安装完上面四个库后执行 pip install torch-geometric</p><p>以上安装完成。</p><p>完成之后 import torch-geometric 发现报错，报错信息：<strong>“No module named 'torch.profiler”</strong></p><p>原因是torch1.10以上的版本才有<strong>torch.profiler</strong>这个库，但是Torch网址CUDA11.0兼容的选项没有torch1.10以上，那怎么办呢？</p><p>解决：</p><p>找到报错路径里的文件<strong><a href="http://profile.py">profile.py</a></strong></p><p>作如下修改：（原文件是第八行，改成了第九行）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191140609.png" alt="image-20231219114012578" /></p><h1 id="3-dgl安装"><a class="markdownIt-Anchor" href="#3-dgl安装"></a> 3 DGL安装</h1><p>安装DGL无需安装torch-geometric，需要安装那四个依赖库</p><p><a href="https://www.dgl.ai/pages/start.html">Deep Graph Library (dgl.ai)</a></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n mVul python=3.7</span><br><span class="line"></span><br><span class="line">pip install torch==1.5.0+cu102 torchvision==0.6.0+cu102 torchaudio==0.5.0 -f https://download.pytorch.org/whl/cu102/torch_stable.html</span><br><span class="line"></span><br><span class="line">torch 1.5.0</span><br><span class="line">torchgeometric</span><br><span class="line">pip install networkx==2.5</span><br><span class="line">pip install dgl -f https://data.dgl.ai/wheels/cu102/repo.html</span><br><span class="line">https://data.dgl.ai/wheels/cu113/repo.html</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 环境 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python环境</title>
      <link href="/2023/12/19/Programmer/python/python%E7%8E%AF%E5%A2%83/"/>
      <url>/2023/12/19/Programmer/python/python%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h1 id="1-conda虚拟环境"><a class="markdownIt-Anchor" href="#1-conda虚拟环境"></a> 1 conda虚拟环境</h1><h4 id="conda常用命令"><a class="markdownIt-Anchor" href="#conda常用命令"></a> conda常用命令</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda list # 查看当前虚拟环境已经安装的包（激活虚拟环境后使用）</span><br><span class="line">conda env list # 查看当前存在哪些虚拟环境</span><br><span class="line">conda update # conda 检查更新当前conda</span><br></pre></td></tr></table></figure><h4 id="conda创建虚拟环境"><a class="markdownIt-Anchor" href="#conda创建虚拟环境"></a> conda创建虚拟环境</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda create -n xxx python=3.6</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">xxx为所创建虚拟环境的名字</span></span><br></pre></td></tr></table></figure><h4 id="conda激活和退出虚拟环境windows"><a class="markdownIt-Anchor" href="#conda激活和退出虚拟环境windows"></a> conda激活和退出虚拟环境（windows）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda activate xx # (虚拟环境名称）</span><br><span class="line"></span><br><span class="line">conda deactivate</span><br></pre></td></tr></table></figure><h4 id="conda为当前虚拟环境安装新的包"><a class="markdownIt-Anchor" href="#conda为当前虚拟环境安装新的包"></a> conda为当前虚拟环境安装新的包</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda install -n package_name==所需版本 #（版本不指定则默认最新版）</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可使用临时镜像安装加快速度，例如安装numpy：</span></span><br><span class="line"></span><br><span class="line">conda install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy</span><br></pre></td></tr></table></figure><h4 id="conda删除虚拟环境或者虚拟环境中的某个包"><a class="markdownIt-Anchor" href="#conda删除虚拟环境或者虚拟环境中的某个包"></a> conda删除虚拟环境或者虚拟环境中的某个包</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda remove -n name --all</span><br><span class="line">conda remove --name env_name package_name </span><br></pre></td></tr></table></figure><h4 id="conda环境复制"><a class="markdownIt-Anchor" href="#conda环境复制"></a> conda环境复制</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda create -n new_name --clone path</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">path为所需要复制的环境路径，可根据conda <span class="built_in">env</span> list查看路径</span></span><br></pre></td></tr></table></figure><h1 id="2-安装依赖库"><a class="markdownIt-Anchor" href="#2-安装依赖库"></a> 2 安装依赖库</h1><h2 id="pip"><a class="markdownIt-Anchor" href="#pip"></a> pip</h2><p>pip 是最为广泛使用的 Python 包管理器，可以帮助我们获得最新的 Python 包并进行管理。常用命令如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install [package-name]              # 安装名为[package-name]的包</span><br><span class="line">pip install [package-name]==X.X         # 安装名为[package-name]的包并指定版本X.X</span><br><span class="line">pip install [package-name] --proxy=代理服务器IP:端口号         # 使用代理服务器安装</span><br><span class="line">pip install [package-name] --upgrade    # 更新名为[package-name]的包</span><br><span class="line">pip uninstall [package-name]            # 删除名为[package-name]的包</span><br><span class="line">pip list                                # 列出当前环境下已安装的所有包</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">代码示例：</span></span><br><span class="line">pip install spyder -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line">-i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下面介绍常见的国内源镜像：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清华：https://pypi.tuna.tsinghua.edu.cn/simple</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">阿里云：http://mirrors.aliyun.com/pypi/simple/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">华中理工大学：http://pypi.hustunique.com/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">山东理工大学：http://pypi.sdutlinux.org/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">豆瓣：http://pypi.douban.com/simple/</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="conda"><a class="markdownIt-Anchor" href="#conda"></a> conda</h2><p>conda 包管理器是 Anaconda 自带的包管理器，可以帮助我们在 conda 环境下轻松地安装各种包。相较于 pip 而言，conda 的通用性更强（不仅是 Python 包，其他包如 CUDA Toolkit 和 cuDNN 也可以安装），但 conda 源的版本更新往往较慢。常用命令如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda install [package-name]        # 安装名为[package-name]的包</span><br><span class="line">conda install [package-name]=X.X    # 安装名为[package-name]的包并指定版本X.X</span><br><span class="line">conda update [package-name]         # 更新名为[package-name]的包</span><br><span class="line">conda remove [package-name]         # 删除名为[package-name]的包</span><br><span class="line">conda list                          # 列出当前环境下已安装的所有包</span><br><span class="line">conda search [package-name]         # 列出名为[package-name]的包在conda源中的所有可用版本</span><br></pre></td></tr></table></figure><p><strong>conda镜像</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看conda当前设置</span></span><br><span class="line">conda config --show channels</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重置默认镜像源</span></span><br><span class="line">conda config --remove-key channels</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除单个镜像源</span></span><br><span class="line">conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/peterjc123/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">国内镜像</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清华大学镜像</span></span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">中科大镜像</span></span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/menpo/</span><br><span class="line">conda config --add channels http://mirrors.ustc.edu.cn/anaconda/cloud/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">阿里镜像</span></span><br><span class="line">conda config --add channels http://mirrors.aliyun.com/pypi/simple/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 环境 </tag>
            
            <tag> pip </tag>
            
            <tag> conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Latex OCR</title>
      <link href="/2023/12/18/Tools/Latex-OCR/"/>
      <url>/2023/12/18/Tools/Latex-OCR/</url>
      
        <content type="html"><![CDATA[<blockquote><p>LaTeX-OCR 是一个开源的光学字符识别（OCR）软件，专为 LaTeX 文档提供支持。其主要目的是帮助用户将扫描的文档转换为 LaTeX 编辑器可以使用的可编辑文本，从而方便进行修改、编辑和排版。</p></blockquote><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206456.png" alt="image-20231219121553484" /></p><h1 id="1安装"><a class="markdownIt-Anchor" href="#1安装"></a> 1.安装</h1><p>LaTeX-OCR可以从源码进行安装，也可以直接用pip来安装，源码地址：<a href="https://github.com/lukas-blecher/LaTeX-OCR">https://github.com/lukas-blecher/LaTeX-OCR</a> ，这里直接使用pip安装，为了方便管理环境，使用conda创建虚拟环境。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n latex python=3.10</span><br><span class="line">conda activate latex</span><br><span class="line">pip install &quot;pix2tex[gui]&quot;</span><br><span class="line">pip install &quot;pix2tex[gui]&quot; -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>注：使用pip清华镜像源更快哦~</p><h1 id="2启动与使用"><a class="markdownIt-Anchor" href="#2启动与使用"></a> 2.启动与使用</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在虚拟环境下执行</span><br><span class="line">pix2tex</span><br></pre></td></tr></table></figure><p>首次执行会下载依赖模型；</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206433.png" alt="image-20231219000535903" /></p><p>期间可能报错，连接断开，尝试重试；</p><p>使用：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206418.png" alt="image-20231219000831872" /></p><p>输入h 回车查看帮助：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206473.png" alt="image-20231219000913782" /></p><p>可以看到windows或macos下可以非常丝滑地使用，只需要：</p><ul><li>截图或复制一个图片到memory，可以理解为复制到剪贴板；</li><li>回到终端按回车，即可看到公式：<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202206447.png" alt="image-20231219001159694" /></li><li>复制内容到LaTex块即可；</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>G</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>Y</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">m i n\sum_{i=1}^{n}{\mathcal{L}}(f(G_{i},Y_{i}|V_{i}))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Ω</mi><mi>j</mi></msub><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">W</mi><mi>h</mi></msub><mrow><mo fence="true">(</mo><msub><mi mathvariant="bold">r</mi><mi>j</mi></msub><mo>⊙</mo><msub><mi mathvariant="normal">Ω</mi><mi>S</mi></msub><mo fence="true">)</mo></mrow><mo>+</mo><mrow><mo fence="true">[</mo><msub><mi mathvariant="normal">∇</mi><mi>h</mi></msub><msub><mi mathvariant="normal">e</mi><mi>j</mi></msub><mo>+</mo><msub><mi mathvariant="normal">b</mi><mi>h</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Omega_{j}=tanh({\bf W}_{h}\left({\bf r}_{j}\odot\Omega_{S}\right)+\left[\nabla_{h}\mathrm{e}_{j}+\mathrm{b}_{h}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">r</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathrm">e</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">b</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p><p>工具很好用，无限制，非常良心，简直是福祉。</p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LaTex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git修改remote地址</title>
      <link href="/2023/12/18/Programmer/git/git%E4%BF%AE%E6%94%B9remote%E5%9C%B0%E5%9D%80/"/>
      <url>/2023/12/18/Programmer/git/git%E4%BF%AE%E6%94%B9remote%E5%9C%B0%E5%9D%80/</url>
      
        <content type="html"><![CDATA[<p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312202212006.png" alt="image-20231220221159980" /></p><h1 id="git修改remote地址"><a class="markdownIt-Anchor" href="#git修改remote地址"></a> git修改remote地址</h1><p>方式1、直接修改：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git remote set-url origin xxxxx.git</span><br></pre></td></tr></table></figure><p>方式2、先删后加 ：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git remote rm origin</span><br><span class="line">git remote add origin xxxxx.git</span><br></pre></td></tr></table></figure><p>修改默认pull和push分支：</p><p>git branch --set-upstream-to=origin/develop develop<br /><code>origin/develop develop</code>为要设置的默认分支</p><h4 id="给本地和远程仓库重命名"><a class="markdownIt-Anchor" href="#给本地和远程仓库重命名"></a> 给本地和远程仓库重命名</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">### 1.重命名本地分支</span><br><span class="line">git branch -m new-name  #如果当前在要重命名的分支</span><br><span class="line">git branch -m old-name new-name #如果当前不在要重命名的分支</span><br><span class="line"></span><br><span class="line">### 2.删除远程旧名称分支并且push新名称分支</span><br><span class="line">git push origin :old-name new-name</span><br><span class="line"></span><br><span class="line">### 3.关联新名称的本地分支和远程分支</span><br><span class="line"> git push origin -u new-name123456789</span><br></pre></td></tr></table></figure><h3 id="修改远程仓库地址"><a class="markdownIt-Anchor" href="#修改远程仓库地址"></a> 修改远程仓库地址</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git remote set-url origin [url]1</span><br></pre></td></tr></table></figure><h4 id="分别查看仓库-local-global-system-的配置信息"><a class="markdownIt-Anchor" href="#分别查看仓库-local-global-system-的配置信息"></a> 分别查看仓库 local global system 的配置信息</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --local --list</span><br><span class="line">git config --global --list</span><br><span class="line">git config --system --list123</span><br></pre></td></tr></table></figure><h4 id="仓库配置增加用户"><a class="markdownIt-Anchor" href="#仓库配置增加用户"></a> 仓库配置增加用户</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --local --add user.name yourname</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决“无法加载文件&#92;WindowsPowerShell&#92;profile.ps1，因为在此系统上禁止运行脚本”</title>
      <link href="/2023/12/18/issues/powershell/"/>
      <url>/2023/12/18/issues/powershell/</url>
      
        <content type="html"><![CDATA[<h3 id="解决无法加载文件-windowspowershellprofileps1因为在此系统上禁止运行脚本"><a class="markdownIt-Anchor" href="#解决无法加载文件-windowspowershellprofileps1因为在此系统上禁止运行脚本"></a> 解决“无法加载文件 ***\WindowsPowerShell\profile.ps1，因为在此系统上禁止运行脚本”</h3><p>在VScode使用anaconda时，提示</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">. : 无法加载文件 C:\Users\47370\Documents\WindowsPowerShell\profile.ps1，因为在此系统上禁止运行脚本。有关详</span><br><span class="line">细信息，请参阅 https:/go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies。</span><br></pre></td></tr></table></figure><p>想了解计算机上的现用执行策略，打开 PowerShell 然后输入：</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">&gt;&gt; get-executionpolicy</span><br><span class="line">Restricted</span><br></pre></td></tr></table></figure><p>更改执行策略，以管理员身份打开 PowerShell 输入：</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">&gt;&gt; set-executionpolicy remotesigned</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404031041877.webp" alt="img" /></p><p>选择“是”，即可。</p><p>如果要更改回Windows 客户端计算机的默认执行策略，则设置为restricted：</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">set-executionpolicy restricted</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> windows </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PowerShell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tree-sitter安装与基本使用</title>
      <link href="/2023/12/18/Security/CA%20Tool/%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
      <url>/2023/12/18/Security/CA%20Tool/%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="初始化tree-sitter"><a class="markdownIt-Anchor" href="#初始化tree-sitter"></a> 初始化tree-sitter</h1><h2 id="安装tree-sitter"><a class="markdownIt-Anchor" href="#安装tree-sitter"></a> 安装tree-sitter</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install tree-sitter</span><br></pre></td></tr></table></figure><h2 id="语言支持"><a class="markdownIt-Anchor" href="#语言支持"></a> 语言支持</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">针对要解析的语言，创建文件夹，并从github的tree-sitter仓库下载语言支持</span></span><br><span class="line">mkdir vendor</span><br><span class="line">cd vendor</span><br><span class="line">git clone https://github.com/tree-sitter/tree-sitter-cpp</span><br><span class="line">git clone https://github.com/tree-sitter/tree-sitter-c</span><br></pre></td></tr></table></figure><h2 id="创建build文件夹"><a class="markdownIt-Anchor" href="#创建build文件夹"></a> 创建build文件夹</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">build于vendor是同级文件夹</span></span><br><span class="line">mkdir build</span><br></pre></td></tr></table></figure><p>创建language_build.py，生成.so文件，该文件相当于自定义的编译器，用于解析代码生成语法树</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tree_sitter <span class="keyword">import</span> Language, Parser</span><br><span class="line">Language.build_library(</span><br><span class="line">  <span class="comment"># Store the library in the `build` directory</span></span><br><span class="line">  <span class="string">&#x27;my-languages.so&#x27;</span>,</span><br><span class="line">  <span class="comment"># Include one or more languages</span></span><br><span class="line">  [</span><br><span class="line">    <span class="string">&#x27;../vendor/tree-sitter-c&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;../vendor/tree-sitter-cpp&#x27;</span></span><br><span class="line">  ]</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>运行该文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python language_build.py</span><br></pre></td></tr></table></figure><h1 id="使用初探"><a class="markdownIt-Anchor" href="#使用初探"></a> 使用初探</h1><h2 id="基本过程"><a class="markdownIt-Anchor" href="#基本过程"></a> 基本过程</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入依赖</span></span><br><span class="line"><span class="keyword">from</span> tree_sitter <span class="keyword">import</span> Language, Parser</span><br><span class="line"><span class="comment"># so文件路径和语言配置</span></span><br><span class="line">CPP_LANGUAGE = Language(<span class="string">&#x27;../build/my-languages.so&#x27;</span>, <span class="string">&#x27;cpp&#x27;</span>)</span><br><span class="line">C_LANGUAGE = Language(<span class="string">&#x27;../build/my-languages.so&#x27;</span>, <span class="string">&#x27;c&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 举一个CPP例子</span></span><br><span class="line">cpp_parser = Parser()</span><br><span class="line">cpp_parser.set_language(CPP_LANGUAGE)</span><br><span class="line"></span><br><span class="line">file_path = <span class="string">&quot;dot/177755_CVE-2015-7540_CWE-399_vul.c&quot;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    code = file.read()</span><br><span class="line">tree = cpp_parser.parse(<span class="built_in">bytes</span>(code, <span class="string">&quot;utf8&quot;</span>))</span><br><span class="line"><span class="comment"># tree = parser.parse(source.encode(&#x27;utf-8&#x27;).decode(&#x27;unicode_escape&#x27;).encode())</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(tree))</span><br></pre></td></tr></table></figure><h2 id="遍历tree"><a class="markdownIt-Anchor" href="#遍历tree"></a> 遍历tree</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_tree</span>(<span class="params">node, indent=<span class="number">0</span></span>):</span><br><span class="line">    code = node.text.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span> * indent, node.<span class="built_in">type</span>, code)</span><br><span class="line">    <span class="keyword">for</span> child <span class="keyword">in</span> node.children:</span><br><span class="line">        print_tree(child, indent + <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print_tree(tree.root_node)</span><br></pre></td></tr></table></figure><h2 id="tree节点属性"><a class="markdownIt-Anchor" href="#tree节点属性"></a> tree节点属性</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 孩子节点【节点数、节点列表】</span></span><br><span class="line">root_node.child_count: <span class="built_in">int</span></span><br><span class="line">root_node.children: <span class="built_in">list</span>[Node]| <span class="literal">None</span></span><br><span class="line"><span class="comment"># 该语法树节点对应代码字符串位置【左闭右开】</span></span><br><span class="line">root_node.start_byte: <span class="built_in">int</span></span><br><span class="line">root_node.end_byte: <span class="built_in">int</span></span><br><span class="line"><span class="comment"># 语法树节点对应代码 (行, 列) 位置元组</span></span><br><span class="line">root_node.start_point: <span class="built_in">tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line">root_node.end_point: <span class="built_in">tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">以上的行、列以及字符串位置都是以0开始</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 语法树命名节点、命名类型 以及 语法树对应的文本</span></span><br><span class="line"><span class="comment"># 因为具体语法树有代码所有的标记，所以一些符号可能没有类型</span></span><br><span class="line"><span class="comment"># 我猜测该属性可以用于区别具体语法树符号节点，构建抽象语法树</span></span><br><span class="line">root_node.is_named: <span class="built_in">bool</span></span><br><span class="line">root_node.<span class="built_in">type</span>: <span class="built_in">str</span> <span class="comment"># 没有类型时，这里显示代码原始标记</span></span><br><span class="line">root_node.text: <span class="built_in">bytes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 语法树父节点</span></span><br><span class="line">root_node.parent: Node| <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 语法树左兄弟、左命名兄弟</span></span><br><span class="line">root_node.prev_sibling: Node| <span class="literal">None</span></span><br><span class="line">root_node.prev_named_sibling: Node| <span class="literal">None</span></span><br><span class="line"><span class="comment"># 语法树右兄弟、右命名兄弟</span></span><br><span class="line">root_node.next_sibling: Node| <span class="literal">None</span></span><br><span class="line">root_node.next_named_sibling: Node| <span class="literal">None</span></span><br></pre></td></tr></table></figure><h3 id="附属性和方法"><a class="markdownIt-Anchor" href="#附属性和方法"></a> 附：属性和方法</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;tree_sitter.Tree&#x27;</span>&gt;</span><br><span class="line"><span class="comment"># print(dir(tree))</span></span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>, <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__init_subclass__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__module__&#x27;</span>, <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>, <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;changed_ranges&#x27;</span>, <span class="string">&#x27;edit&#x27;</span>, <span class="string">&#x27;included_ranges&#x27;</span>, <span class="string">&#x27;root_node&#x27;</span>, <span class="string">&#x27;root_node_with_offset&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;walk&#x27;</span>]</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;tree_sitter.Node&#x27;</span>&gt;</span><br><span class="line"><span class="comment"># print(dir(tree.root_node))</span></span><br><span class="line">[<span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>, <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__init_subclass__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__module__&#x27;</span>, <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>, <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;byte_range&#x27;</span>, <span class="string">&#x27;child&#x27;</span>, <span class="string">&#x27;child_by_field_id&#x27;</span>, <span class="string">&#x27;child_by_field_name&#x27;</span>, <span class="string">&#x27;child_count&#x27;</span>, <span class="string">&#x27;children&#x27;</span>, <span class="string">&#x27;children_by_field_id&#x27;</span>, <span class="string">&#x27;children_by_field_name&#x27;</span>, <span class="string">&#x27;descendant_count&#x27;</span>, <span class="string">&#x27;descendant_for_byte_range&#x27;</span>, <span class="string">&#x27;descendant_for_point_range&#x27;</span>, <span class="string">&#x27;edit&#x27;</span>, <span class="string">&#x27;end_byte&#x27;</span>, <span class="string">&#x27;end_point&#x27;</span>, <span class="string">&#x27;field_name_for_child&#x27;</span>, <span class="string">&#x27;grammar_id&#x27;</span>, <span class="string">&#x27;grammar_name&#x27;</span>, <span class="string">&#x27;has_changes&#x27;</span>, <span class="string">&#x27;has_error&#x27;</span>, <span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;is_error&#x27;</span>, <span class="string">&#x27;is_extra&#x27;</span>, <span class="string">&#x27;is_missing&#x27;</span>, <span class="string">&#x27;is_named&#x27;</span>, <span class="string">&#x27;kind_id&#x27;</span>, <span class="string">&#x27;named_child&#x27;</span>, <span class="string">&#x27;named_child_count&#x27;</span>, <span class="string">&#x27;named_children&#x27;</span>, <span class="string">&#x27;named_descendant_for_byte_range&#x27;</span>, <span class="string">&#x27;named_descendant_for_point_range&#x27;</span>, <span class="string">&#x27;next_named_sibling&#x27;</span>, <span class="string">&#x27;next_parse_state&#x27;</span>, <span class="string">&#x27;next_sibling&#x27;</span>, <span class="string">&#x27;parent&#x27;</span>, <span class="string">&#x27;parse_state&#x27;</span>, <span class="string">&#x27;prev_named_sibling&#x27;</span>, <span class="string">&#x27;prev_sibling&#x27;</span>, <span class="string">&#x27;range&#x27;</span>, <span class="string">&#x27;sexp&#x27;</span>, <span class="string">&#x27;start_byte&#x27;</span>, <span class="string">&#x27;start_point&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;type&#x27;</span>, <span class="string">&#x27;walk&#x27;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">byte_range (<span class="number">0</span>, <span class="number">283</span>)</span><br><span class="line">child &lt;built-<span class="keyword">in</span> method child of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">child_by_field_id &lt;built-<span class="keyword">in</span> method child_by_field_id of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">child_by_field_name &lt;built-<span class="keyword">in</span> method child_by_field_name of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">child_count <span class="number">1</span></span><br><span class="line">children [&lt;Node <span class="built_in">type</span>=function_definition, start_point=(<span class="number">0</span>, <span class="number">0</span>), end_point=(<span class="number">12</span>, <span class="number">2</span>)&gt;]</span><br><span class="line">children_by_field_id &lt;built-<span class="keyword">in</span> method children_by_field_id of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">children_by_field_name &lt;built-<span class="keyword">in</span> method children_by_field_name of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">descendant_count <span class="number">103</span></span><br><span class="line">descendant_for_byte_range &lt;built-<span class="keyword">in</span> method descendant_for_byte_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">descendant_for_point_range &lt;built-<span class="keyword">in</span> method descendant_for_point_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">edit &lt;built-<span class="keyword">in</span> method edit of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">end_byte <span class="number">283</span></span><br><span class="line">end_point (<span class="number">12</span>, <span class="number">2</span>)</span><br><span class="line">field_name_for_child &lt;built-<span class="keyword">in</span> method field_name_for_child of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">grammar_id <span class="number">214</span></span><br><span class="line">grammar_name translation_unit</span><br><span class="line">has_changes <span class="literal">False</span></span><br><span class="line">has_error <span class="literal">False</span></span><br><span class="line"><span class="built_in">id</span> <span class="number">24860624</span></span><br><span class="line">is_error <span class="literal">False</span></span><br><span class="line">is_extra <span class="literal">False</span></span><br><span class="line">is_missing <span class="literal">False</span></span><br><span class="line">is_named <span class="literal">True</span></span><br><span class="line">kind_id <span class="number">214</span></span><br><span class="line">named_child &lt;built-<span class="keyword">in</span> method named_child of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">named_child_count <span class="number">1</span></span><br><span class="line">named_children [&lt;Node <span class="built_in">type</span>=function_definition, start_point=(<span class="number">0</span>, <span class="number">0</span>), end_point=(<span class="number">12</span>, <span class="number">2</span>)&gt;]</span><br><span class="line">named_descendant_for_byte_range &lt;built-<span class="keyword">in</span> method named_descendant_for_byte_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">named_descendant_for_point_range &lt;built-<span class="keyword">in</span> method named_descendant_for_point_range of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">next_named_sibling <span class="literal">None</span></span><br><span class="line">next_parse_state <span class="number">0</span></span><br><span class="line">next_sibling <span class="literal">None</span></span><br><span class="line">parent <span class="literal">None</span></span><br><span class="line">parse_state <span class="number">0</span></span><br><span class="line">prev_named_sibling <span class="literal">None</span></span><br><span class="line">prev_sibling <span class="literal">None</span></span><br><span class="line"><span class="built_in">range</span> &lt;Range start_point=(<span class="number">0</span>, <span class="number">0</span>), start_byte=<span class="number">0</span>, end_point=(<span class="number">12</span>, <span class="number">2</span>), end_byte=<span class="number">283</span>&gt;</span><br><span class="line">sexp &lt;built-<span class="keyword">in</span> method sexp of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br><span class="line">start_byte <span class="number">0</span></span><br><span class="line">start_point (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">text <span class="string">b&#x27;bool fun1(struct var1 *var2, bool *var3)\n &#123;\n        uint8_t var4 = 0;\n       fun2(var2, var5);\n       fun3(var2, &amp;var4);\n        if (var4 == 0xFF) &#123;\n                *var3 = true;\n       &#125; else &#123;\n               *var3 = false;\n        &#125;\n       fun4(var2);\n       return !var2-&gt;var6;\n &#125;&#x27;</span></span><br><span class="line"><span class="built_in">type</span> translation_unit</span><br><span class="line">walk &lt;built-<span class="keyword">in</span> method walk of tree_sitter.Node <span class="built_in">object</span> at <span class="number">0x7f9f1c167d70</span>&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Code Analysis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tree-sitter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flawfinder开源C/C++静态扫描分析工具安装与使用</title>
      <link href="/2023/12/18/Security/software%20security/FlawFinder_/"/>
      <url>/2023/12/18/Security/software%20security/FlawFinder_/</url>
      
        <content type="html"><![CDATA[<h2 id="flawfinder开源cc静态扫描分析工具安装与使用"><a class="markdownIt-Anchor" href="#flawfinder开源cc静态扫描分析工具安装与使用"></a> Flawfinder开源C/C++静态扫描分析工具安装与使用</h2><h2 id="flawfinder的介绍"><a class="markdownIt-Anchor" href="#flawfinder的介绍"></a> flawfinder的介绍</h2><p>Flawfinder是一款开源的关于C/C<ins>静态扫描分析工具，其根据内部字典数据库进行静态搜索，匹配简单的缺陷与漏洞，flawfinder工具不需要编译C/C</ins>代码，可以直接进行扫描分析。简单快速，最大的有点就是免费，不需要编译。flawfinder工具可以在官网进行下载。<br /><a href="https://dwheeler.com/flawfinder/#downloading">https://dwheeler.com/flawfinder/#downloading</a></p><h2 id="flawfinder的安装"><a class="markdownIt-Anchor" href="#flawfinder的安装"></a> flawfinder的安装</h2><h3 id="在线安装"><a class="markdownIt-Anchor" href="#在线安装"></a> 在线安装</h3><p>flawfinder安装比较简单，由于其是基于Python实现的一款工具，所以需要首先安装Python环境，并配置环境变量。flawfinder下载之后解压既可使用。flawfinder目前支持python2和python3，简单的方法是使用pip工具，执行以下指令进行安装。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install flawfinder</span><br></pre></td></tr></table></figure><h3 id="离线安装"><a class="markdownIt-Anchor" href="#离线安装"></a> 离线安装</h3><p>直接从flawfinder下载程序压缩包，解压完成以后，使用python直接加载flawfiner程序即可，或者直接下载flawfinder-*.whl，使用pip工具离线安装，这种通常是在一些甲方审计项目中出现，甲方客户无法协调审计设备上的管理员权限，又无法连接外网，只能使用一些免安装的工具。对于这种情况，python直接使用免安装版本，使用离线的方式使用pip安装或者使用python直接运行flawfinder,给各位审计人员一个建议，原理这些不靠谱的甲方企业。</p><h2 id="flawfinder的使用"><a class="markdownIt-Anchor" href="#flawfinder的使用"></a> flawfinder的使用</h2><p>方式一：<code>flawfinder --csv &gt; test-result.csv test.c</code><br />这种方式根据缺陷库生成一个 .csv文件  ，你只需要根据这个.csv文件就可以转换为正常Excel文件使用，转换方法自行百度。<br />方式二：<code>flawfinder --html &gt; test-result.html test.c</code></p><h2 id="案例讲解"><a class="markdownIt-Anchor" href="#案例讲解"></a> 案例讲解</h2><p>由于在日常审计过程中，项目中有其他格式的文件，通常使用linux<code>find</code>工具批量筛选.c或者.cpp文件，然后使用flawfinder进行扫描</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp --parents `find 程序目录/-name *.c`  指定扫描目录</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><ul><li>增加–parents目录主要作用是在拷贝的时候，会在目标路径中创建源文件参数中的所有父目录层级(不止是一层父目录)，然后将源文件拷贝进去。这样做的目的主要是清晰展示目录结构，方便写报告。</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flawfinder --csv &gt; result.csv 指定扫描目录</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>导出csv文件内容展示如下<br /><a href="https://hksanduo.github.io/img/flawfinder-csv.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047482.png" alt="flawfinder-csv.png" /></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-csv.png">flawfinder-csv.png</a></p><h2 id="flawfinder分析"><a class="markdownIt-Anchor" href="#flawfinder分析"></a> flawfinder分析</h2><p>Flawfinder 不是类似于fortify那样复杂的工具,它是一个简单并有意义工具。Flawfinder通过使用内置的C/C++函数数据库来工作，该数据库具有众所周知的安全风险，例如缓冲区溢出风险（例如strcpy()，strcat()，gets()，sprintf()和scanf()），格式字符串问题（printf()，snprintf()和syslog()），竞争条件（例如access()，chown()，chgrp()，chmod()，tmpfile()，tmpnam()，tempnam()和mktemp()），潜在的远程命令执行风险（大多数exec()系列，system()，popen()）和较差的随机数获取方法（例如random()）。<br />Flawfinder的好处是不必创建相关数据库，自身就拥有相关数据库。Flawfinder获取源代码，并将源代码文本与这些名称匹配，同时忽略注释和字符串中的文本。Flawfinder还支持gettext（国际化程序的公共库），并且会将通过gettext传递的常量字符串当作常量字符串对待。这减少了国际化程序中的错误命中次数。<br />Flawfinder生成按风险分类的（潜在安全漏洞）列表；默认情况下，最危险的匹配项将首先显示。风险级别不仅取决于功能，还取决于功能的参数值。例如：在许多情况下，常量字符串通常比完全可变字符串的风险要小。在某些情况下，代码审计人员可能能够确定该结构体完全没有风险，从而减少了误报。与仅在源代码上运行“ grep”相比，Flawfinder提供了更好的信息和更好的优先级。flawfinder可以忽略注释和字符串内部，并且还将检查参数以估计风险水平。但是，从根本上来说，flawfinder仅仅是一个简单的python程序。它甚至不知道函数参数的数据类型，并且当然也不进行控制流或数据流分析。由于Flawfinder很简单，因此不会被宏定义和更复杂的工具遇到的其他奇怪问题所混淆。Flawfinder可以分析无法构建的软件；在某些情况下，它可以分析甚至无法在本地编译的文件。但是需要主要一点儿，并非发现的每个问题都是一个安全漏洞，也不一定能找到所有安全漏洞。如上所述，flawfinder不能真正理解代码的语义，它主要完成简单的文本模式匹配（忽略注释和字符串），不执行数据流或控制流分析，尽管如此，flawfinder在实际代码审计项目中也可以协助安全人员发现和消除安全漏洞。</p><h2 id="错误修复"><a class="markdownIt-Anchor" href="#错误修复"></a> 错误修复</h2><h3 id="unicodedecodeerror-utf-8-codec-cant-decode-byte-0xff-in-position-0-invalid-start-byte"><a class="markdownIt-Anchor" href="#unicodedecodeerror-utf-8-codec-cant-decode-byte-0xff-in-position-0-invalid-start-byte"></a> UnicodeDecodeError: ‘utf-8’ codec can’t decode byte 0xff in position 0: invalid start byte</h3><p>在运行过程中，会出现解码出错，官方给出的建议是通过强制转换扫描文档的格式为utf-8，我们可以直接忽略<br /><code>UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte</code><br /><a href="https://hksanduo.github.io/img/flawfinder-error.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047480.png" alt="flawfinder-error.png" /></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-error.png">flawfinder-error.png</a></p><h4 id="官方修复建议"><a class="markdownIt-Anchor" href="#官方修复建议"></a> 官方修复建议</h4><p><a href="https://hksanduo.github.io/img/flawfinder-office-advice.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047486.png" alt="flawfinder-office-advice.png" /></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-office-advice.png">flawfinder-office-advice.png</a></p><p>将操作系统的编码格式设置成<code>utf-8</code>，将程序编码格式强制转换为utf-8，官方推荐的工具为<code>cvt2utf</code>，可以根据实际情况自行修改。</p><h4 id="个人修复建议"><a class="markdownIt-Anchor" href="#个人修复建议"></a> 个人修复建议</h4><p><a href="https://hksanduo.github.io/img/flawfinder-persional-advice1.png"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047489.png" alt="flawfinder-persional-advice1.png" /></a></p><p><a href="https://hksanduo.github.io/img/flawfinder-persional-advice1.png">flawfinder-persional-advice1.png</a></p><p>个人这个就有点儿暴力，直接在打开文件的那一步设定，如果出现错误直接忽略。flawfinder如果使用pip安装，安装的位置位于<code>/usr/local/bin/flawfinder</code>，其他安装方式，请根据实际情况进行查找。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241047492.png" alt="flawfinder-persional-advice2.png" /></p><p>flawfinder-persional-advice2.png</p><h3 id="unicodedecodeerror-ascii-codec-cant-decode-byte-0xe6-in-position-29-ordinal-not-in-range128"><a class="markdownIt-Anchor" href="#unicodedecodeerror-ascii-codec-cant-decode-byte-0xe6-in-position-29-ordinal-not-in-range128"></a> UnicodeDecodeError: ‘ascii’ codec can’t decode byte 0xe6 in position 29: ordinal not in range(128)</h3><h4 id="错误原因"><a class="markdownIt-Anchor" href="#错误原因"></a> 错误原因</h4><p>提示中的“ordinal not in range(128)”，意思是，字符不在128范围内，即说明不是普通的ASCII字符，超出处理能力了。</p><h4 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h4><p>找到flawfinder程序文件，用文本编辑器打开，在文件抬头加入以下代码。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&quot;utf-8&quot;)</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2><ul><li><a href="https://dwheeler.com/flawfinder/%E3%80%90flawfinder%E5%AE%98%E7%BD%91%E3%80%91">https://dwheeler.com/flawfinder/【flawfinder官网】</a></li><li><a href="https://github.com/david-a-wheeler/flawfinder%E3%80%90github%E3%80%91">https://github.com/david-a-wheeler/flawfinder【github】</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 静态分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>符号执行</title>
      <link href="/2023/12/18/Security/software%20security/Symbolic%20Execution/"/>
      <url>/2023/12/18/Security/software%20security/Symbolic%20Execution/</url>
      
        <content type="html"><![CDATA[<h1 id="符号执行"><a class="markdownIt-Anchor" href="#符号执行"></a> <strong>符号执行</strong></h1><h3 id="符号执行是什么"><a class="markdownIt-Anchor" href="#符号执行是什么"></a> 符号执行是什么</h3><p>符号执行 （Symbolic Execution）是一种程序分析技术，它可以通过分析程序来得到让特定代码区域执行的输入。顾名思义，使用符号执行分析一个程序时，该程序会使用符号值作为输入，而非一般执行程序时使用的具体值。在达到目标代码时，分析器可以得到相应的路径约束，然后通过约束求解器来得到可以触发目标代码的具体值。</p><h3 id="符号执行它的优势"><a class="markdownIt-Anchor" href="#符号执行它的优势"></a> 符号执行它的优势</h3><p>生成具体测试输入的能力是符号执行的主要优势之一：</p><p>从测试生成的角度来看，它允许创建高覆盖率的测试套件，而从bug查找的角度来看，它为开发人员提供了触发bug的具体输入，该输入可用于确认和调试打开的错误。</p><h3 id="符号执行过程"><a class="markdownIt-Anchor" href="#符号执行过程"></a> 符号执行过程</h3><p>在任何时候，符号执行引擎都维持一个状态（stmt，σ，π）。</p><ul><li><p>stmt是下一个要评估的语句。目前，我们假设stmt可以是赋值，条件分支或跳转。</p></li><li><p>σ是一个符号存储，它将程序变量与具体值或符号值αi上的表达式相关联。</p></li><li><p>π表示路径约束，即，是表示由于在执行中为了达到stmt而采取的分支而对符号αi的一组假设的公式。在分析开始时，π=真。</p></li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035360.png" alt="image-20210416135536910" /></p><p>下面是一个简单的符号执行的样例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035357.png" alt="图片" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035364.png" alt="image-20210416135605643" /></p><p>在沿着程序的执行路径的符号执行结束时，使用约束求解器来求解π以生成具体的输入值。</p><h3 id="符号执行实现的两种方案"><a class="markdownIt-Anchor" href="#符号执行实现的两种方案"></a> 符号执行实现的两种方案</h3><ul><li><p>1）基于IR的符号执行:IRs实现解释器比直接为机器代码实现符号解释器<strong>容易得多</strong>，因此这是许多系统所采用的方法,但是IR生成可能需要大量的工作, 而且<mark>解释IR要比相应二进制文件的本机执行慢得多</mark>。</p></li><li><p>2）无IR的符号执行:不是将被测程序翻译成IR然后解释，而是执行未修改的机器代码，并在运行时对其进行检测, 但是一般机器指令较多, 实现起来没有<mark>基于IR的符号执行简单</mark>。</p></li></ul><h3 id="concolic执行"><a class="markdownIt-Anchor" href="#concolic执行"></a> Concolic执行</h3><p>Concolic执行维护一个实际状态和一个符号化状态：实际状态将所有变量映射到实际值，<mark>符号状态只映射那些有非实际值的变量</mark>。Concolic执行首先用一些给定的或者随机的输入来执行程序，收集执行过程中条件语句对输入的符号化约束，然后使用约束求解器去推理输入的变化，从而将下一次程序的执行导向另一条执行路径。</p><p>简单地说来，就是在已有实际输入得到的路径上，对分支路径条件进行取反，就可以让执行走向另外一条路径。这个过程会不断地重复，加上系统化或启发式的路径选择算法，直到所有的路径都被探索，或者用户定义的覆盖目标达到，或者时间开销超过预计。</p><p>我们依旧以上面那个程序的例子来说明。我们从一个实际输入{a=0, b=7}出发，符号化执行得到第一个约束条件a0 == 0，第一次取反得到a0 != 0 ，从而得到测试输入{x=2, y=1}和新约束(a0 != 0) &amp; (b0 !=0)；第二次取反得到(a0 != 0) &amp; (b0 ==0)，从而求解出测试输入{x=1, y=0}。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035369.png" alt="image-20210416135618076" /></p><h1 id="混合模糊"><a class="markdownIt-Anchor" href="#混合模糊"></a> 混合模糊</h1><p>模糊技术可以以近乎自然的速度快速探索输入空间，但它只擅长于发现<mark>导致执行路径具有松散分支条件</mark>（如x&gt;0）的输入。相反，concolic执行擅长于找到将程序驱动到紧凑而复杂的分支条件的输入，例如x==0xdeadbeef，但是计算和解决这些约束非常昂贵且缓慢。</p><p>将模糊化和concolic执行结合起来，希望模糊程序能快速地探索琐碎的输入空间（即松散条件），concolic执行能解决复杂的分支。</p><h3 id="driller"><a class="markdownIt-Anchor" href="#driller"></a> Driller</h3><p>比较早(2016年)将符号执行和模糊测试结合的工具是Driller.Driller是基于fuzz工具AFL和符号执行工具angr来实现的，<strong>当模糊程序卡住时调用符号执行来求解能够到达新路径的输入</strong>，使得fuzz能够快速突破条件判断语句。</p><p>具体实现是，通过监测AFL的执行，可以决定什么时候开始符号执行以探索新路径。如果AFL执行了x轮后，<mark>bitmap上显示没有发现新的状态转换（也即新的代码块转移）</mark>，说明AFL卡住了，这时候调用<mark>angr</mark>进行符号执行。</p><p>每个具体输入对应于PathGroup中的单个路径， 在PathGroup的每一步中，检查每个分支以确保最新的跳转指令引入先前AFL未知的路径。当发现这样的跳转时，SMT求解器被查询以创建一个输入来驱动执行到新的跳转。这个输入反馈给AFL，AFL在未来的模糊步骤中进行变异。这个反馈循环使我们能够<mark>将昂贵的符号执行时间与廉价的模糊时间进行平衡</mark>，并且减轻了模糊对程序操作的低语义洞察力。</p><h3 id="qsym"><a class="markdownIt-Anchor" href="#qsym"></a> QSYM</h3><p>2018年一款新的混合模糊引擎QSYM被提出，它的作者观察到，他们的 concolic executors的性能瓶颈是阻止他们被复杂的实际应用所采用的主要限制因素。</p><p>下面讲述了QSYM的作者任务影响符号执行性能的因素。</p><ul><li>1)慢符号执行</li></ul><p>现有的协同执行器选择IR来大大降低它们的实现复杂度；然而，这牺牲了性能。此外，加速IR使用的优化禁止了进一步的优化机会，特别是通过以基本块粒度将程序转换为IRs。此设计不允许跳过不涉及符号执行指令的仿真指令。</p><p>首先，IR翻译本身增加了开销。在大多数情况下，机器指令的翻译会导致多条IR指令。从而产生了大量的符号模拟处理.</p><p>如果基本块不处理任何符号变量，它们就不会在模拟器中执行。虽然这有效地减少了开销，但仍有优化的空间。根据我们对libjpeg、libpng、libtiff和file等真实软件的测量，<em>符号基本块中只有30%的指令需要符号执行</em>。这个这意味着一个指令级的方法有机会减少不必要的符号执行的数量。然而，由于IR缓存的原因，当前的concolic执行器不容易采用这种方法。</p><ul><li>2)无效的快照</li></ul><p>常规concolic执行引擎使用<strong>快照技术</strong>来减少在探索目标程序的多条路径时重新执行目标程序的开销。</p><p>引擎在一个分支中备份程序的符号状态，然后探索其中一条路径。</p><p>当路径耗尽或卡住时，发动机将符号状态恢复到分支上的先前状态，并移动到另一条路径。</p><p>引擎可以探索路径，而无需支付重新执行分支程序的费用。</p><p>为什么说快照是无效的?</p><p>第一，混合模糊中的concolic执行引擎从fuzzer中获取多个测试用例，<strong>这些测试用例与程序的不同路径相关联</strong>（即，不共享公共分支）.</p><p>第二，快照机制由于打破了进程边界,快照机制成为支持外部环境的问题.</p><p>当一个程序通过fork（）发散-就像系统调用一样，内核不再维护与外部环境相关的内部状态。因此，协同执行引擎应该自己维护状态.</p><p>通过全系统的concolic执行或外部环境建模来解决这个问题，但是它们分别导致了显著的性能降低和不准确的测试，而且快照无法反映外部状态。</p><ul><li>3)缓慢而不灵活的可靠分析</li></ul><p>concolic执行试图==通过收集完整的约束来保证可靠性。==这种完整性确保满足约束的输入将导致执行到预期的路径。但是，计算完全约束在各种情况下都是昂贵的,并且有可能陷入对复杂事物的永无止境的分析逻辑.例如。下的上半部分显示了文件程序的代码片段。它卡在计算zlib解压的复杂约束，无法搜索其他有趣的代码。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035366.png" alt="image-20210416135633846" /></p><p>其次,concolic完全约束也会过度约束路径，从而限制concolic执行以找到未来路径。特别是，在默认执行之后插入的约束可能会导致过度约束问题.如图三下半部分,</p><p>首先执行到第三行生成约束{ch&gt;=0x20∧ch&lt;0x7f}</p><p>然后到第6行{ch&gt;=0x20∧ch&lt;0x7f&lt;∧ch==0x7f}</p><p>这一不可满足约束,求解这个不可满足约束是无意义的.但是第六行的逻辑不依赖于第三行的相关逻辑,因为在不考虑路径约束的情况下，由concolic执行生成的输入ch==0x7f将探索满足第六行条件的路径。</p><p>为了解决上面的一些瓶颈，QSYM被设计出来，下面讲述QSYM的设计细节。</p><p>1)概述</p><p>QSYM首先使用<mark>动态二进制翻译（DBT）和覆盖引导模糊器</mark>提供的输入运行目标程序。</p><p>DBT为本机执行生成基本块，并为符号执行修剪它们，允许我们在两个执行模型之间快速切换。</p><p>QSYM只选择性地模拟生成符号约束所需的指令，这与现有方法在受污染的基本块中模拟所有的构造不同。</p><p>通过这样做，QSYM大大减少了符号模拟的数量。</p><p>由于QSYM的高效执行，它可以重复执行符号执行，而不是使用需要外部环境建模的快照。</p><p>QSYM可以以具体的方式与外部环境进行交互，而不依赖于人为的环境模型。</p><p>为了提高约束求解的性能，QSYM应用了各种启发式算法，在严格的稳健性之间进行折中以获得更好的性能。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035374.png" alt="image-20210416135641815" /></p><p>2)指令级符号执行</p><p>原来的执行器是块级污染分析,要把整块进行模拟进行符号执行,而指令级只需要将被污染的指令进行模拟来符号执行.</p><p>对于QSYM，高效的DBT使得实现细粒度的、指令级的污点跟踪和符号执行成为可能，帮助我们避免不必要的仿真开销。</p><p>下面这个例子,如果size是一个符号,就只需要符号执行虚线框的指令,而不需要符号执行punpXXX这种复杂而没被污染的指令.</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035604.png" alt="image-20210416135651308" /></p><p>3)仅解决相关约束</p><p>QSYM通过更新一小部分初始输入来生成新的测试用例。然而，Driller生成了新的测试用例，这些用例看起来与原始输入完全不同。这表明Driller在解决模糊程序反复测试的不相关约束.</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035619.png" alt="image-20210416135658693" /></p><p>4)不使用快照</p><p>QSYM的快速concolic执行使得重新执行比为重复的concolic测试拍摄快照更容易。</p><p>由于QSYM的conclic执行器变得更快，快照的开销不再小于重新执行的开销。</p><p>5)具体的外部环境</p><p>qsym通过与外部环境的具体互动避免了由不完整或错误的环境建模.</p><p>由于建模的<mark>不完整性和正确性偏离了符号执行和本机执行</mark>，误导了进一步的探索，我们应该避免它们的进一步分析。</p><ol start="6"><li>乐观的求解<br />QSYM努力从生成的约束中生成有趣的新测试用例，通过乐观地选择和解决约束的某些部分，如果不能作为一个整体解决的话.特别是，<mark>QSYM选择路径的最后一个约束进行乐观求解</mark>，原因如下。</li></ol><p>第一，它通常有一个非常简单的形式，使得它能够有效地解决约束。</p><p>第二，从解决最后一个约束生成的测试用例可能会探索目标路径，因为它们在到达目标分支时至少满足局部约束。</p><p>由于QSYM首先消除了与最后一个约束无关的约束，因此所有不相关的约束都不会影响乐观求解的结果。</p><p>7)基本块的修剪</p><p>首先,相同代码重复生成的约束对于在真实软件中发现新的代码覆盖是没有用的。</p><p>特别是，程序中计算密集型操作生成的约束在最后不太可能是可解的（即非线性的），即使它们的约束已经形成。</p><p>更糟糕的是，这些约束倾向于阻塞探索其他不相关但足够有趣的部分的可能。</p><p>为了缓解这个问题，QSYM尝试检测具有竞争性的基本块，然后修剪它们以符号执行，并且只生成约束的子集.更具体地说，QSYM在运行时测量每个执行执行的频率，并选择重复的块来修剪.如果一个基本块执行得太频繁，QSYM将停止从它生成更多的约束.</p><p>QSYM决定使用指数回退来修剪基本块，因为它可以快速地截断过于频繁的块。</p><p>l评价</p><p>这个表展示的是在对这些程序进行测试,QSYM能找到漏洞,而只用fuzz不能找到的漏洞,其中有些空白行则是都能找到的漏洞。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035631.png" alt="image-20210416135707898" /></p><p>Driller系统调用存在的问题清单</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035643.png" alt="image-20210416135715923" /></p><p>这是测试libpng的代码覆盖率随着种子输入数量的增加而增加的条形图来对比AFL和QSYM.</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035655.png" alt="image-20210416135722567" /></p><p>这张彩色地图描绘了qsym与Driller的五分钟相对代码覆盖率：蓝色表示qsym发现的代码比Driller多，红色表示相反。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035663.png" alt="image-20210416135730633" /></p><p>下图是以初始POV作为初始种子文件的126CGC二进制文件的QSYM和Driller的平均执行时间和指令数,其中Norm是QSYM指令数乘以4.69。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035805.png" alt="image-20210416135744137" /></p><p>下图是,由于QSYM的限制，CGC挑战中没有被模拟的指令数：不支持浮点操作。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241035859.png" alt="image-20210416135756070" /></p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux 内核安全增强(一)— stack canary</title>
      <link href="/2023/12/18/Security/software%20security/stack%20canary/"/>
      <url>/2023/12/18/Security/software%20security/stack%20canary/</url>
      
        <content type="html"><![CDATA[<h1 id="linux-内核安全增强一-stack-canary"><a class="markdownIt-Anchor" href="#linux-内核安全增强一-stack-canary"></a> linux 内核安全增强(一)— stack canary</h1><h3 id="一-背景知识-aarch64的函数栈"><a class="markdownIt-Anchor" href="#一-背景知识-aarch64的函数栈"></a> 一、背景知识 —— aarch64的函数栈</h3><h4 id="1栈生长方向与pushpop操作"><a class="markdownIt-Anchor" href="#1栈生长方向与pushpop操作"></a> 1.栈生长方向与push/pop操作</h4><blockquote><p>栈是一种运算受限的线性表, 入栈的一端为栈顶，另一端则为栈底, 其生长方向和操作顺序理论上没有限定.</p></blockquote><p>在aarch64平台上，栈是向低地址方向增长的(STACK_GROWS_DOWNWARD)<br />栈的PUSH/POP通常要先移动SP:</p><ul><li>PUSH操作为PRE_DEC,即 PUSH操作为 sp = sp -4; store;</li><li>POP操作为 POST_INC,即POP操作为 read; sp=sp+4;</li></ul><h4 id="2返回地址的存储"><a class="markdownIt-Anchor" href="#2返回地址的存储"></a> 2.返回地址的存储</h4><ul><li><p>x86平台是call指令时自动push函数返回地址到栈;</p></li><li><p>ret指令自动pop函数返回地址出栈;</p></li></ul><p>这两步操作都是在callee执行前硬件自动完成的.</p><p>而在arm/aarch64平台发生函数调用时(blx),硬件负责将函数的返回地址设置到通用寄存器LR(/X30)中, callee中的代码负责将LR保存到栈中(需保存的寄存器参考AAPCS标准)</p><h4 id="3函数栈分配"><a class="markdownIt-Anchor" href="#3函数栈分配"></a> 3.函数栈分配</h4><p>在不考虑动态分配的情况下, 函数中使用的栈大小在编译阶段就已经确定了(见备注1), 一个aarch64中的典型的程序栈如下所示:</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241042333.png" alt="img" /></p><p>x86/arm平台的不同在于:<mark>x86和arm平台的函数返回地址通常都存于callee栈的栈底:</mark></p><ul><li>x86平台是硬件完成的push/pop操作,故返回地址先入栈</li><li><strong>arm平台callee函数的首指令通常是先push通用寄存器, 函数返回前最后语句pop通用寄存器</strong>如:</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">000005fc &lt;test&gt;:                                                                                                                                                                       </span><br><span class="line">5fc:   b590            push    &#123;r4, r7, lr&#125;                /* 先push通用寄存器和函数返回地址 */</span><br><span class="line">5fe:   b089            sub     sp, #36 ; 0x24              /* 再为局部变量预留存储空间 */</span><br><span class="line">600:   af00            add     r7, sp, #0</span><br><span class="line">602:   6078            str     r0, [r7, #4]</span><br><span class="line">    ......</span><br><span class="line">634:   3724            adds    r7, #36 ; 0x24</span><br><span class="line">636:   46bd            mov     sp, r7</span><br><span class="line">638:   bd90            pop     &#123;r4, r7, pc&#125;</span><br></pre></td></tr></table></figure><p>​    在此两个平台中若发生了<strong>栈溢出则直接可以覆盖到当前函数的返回地址</strong>.</p><ul><li>而aarch64通常是先预留栈再保存函数返回地址,如:</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0000000000400654 &lt;test&gt;:</span><br><span class="line">                                                                             /* 预留栈         ||  在栈顶保存函数返回地址       */            </span><br><span class="line">  400654:       a9bc7bfd        stp     x29, x30, [sp, #-64]!                /* sp = sp - 64;      sp[0] = x29; sp[1] = x30; */</span><br><span class="line">  400658:       910003fd        mov     x29, sp</span><br><span class="line">  40065c:       b9001fe0        str     w0, [sp, #28]</span><br><span class="line">  400660:       b9801fe1        ldrsw   x1, [sp, #28]</span><br><span class="line">  ......</span><br><span class="line">  400680:       a8c47bfd        ldp     x29, x30, [sp], #64                  /* x29 = sp[0]; x30 = sp[1]; sp = sp +64;  */</span><br><span class="line">  400684:       d65f03c0        ret</span><br></pre></td></tr></table></figure><p>最终的函数栈如上图所示, 由于变量是向高地址方向生长的，故:</p><ul><li>在x86/arm平台的栈上溢(向高地址溢出)通常可直接修改当前函数(这里的callee)的返回地址</li><li>在aarch64平台的栈上溢(向高地址溢出)则通常只能修改到父函数(caller)的返回地址</li></ul><h3 id="二-stack-canary简介"><a class="markdownIt-Anchor" href="#二-stack-canary简介"></a> 二、stack canary简介</h3><blockquote><p>stack canary是一个比较久远的安全特性，linux内核在2.6版本便已经引入, 在5.0又引入了增强的per-task stack canary</p></blockquote><p>其原理比较简单,即:</p><ul><li>每个函数执行前先向栈底插入一个canary值(如下图)以确保顺序的栈上溢在破坏到父函数栈帧前必须要先破坏canary</li><li>每个函数返回时检测当前栈帧中的canary是否被修改,若被修改则代表发生了溢出(报错)</li></ul><p><mark>stack canary并不能检测到所有的栈溢出问题</mark>, 只有在满足:</p><ul><li><p><strong>攻击者不知当前插入当函数栈中canary的值(无infoleak)</strong></p></li><li><p><strong>攻击者只能顺序的覆盖栈中数据，无法跳过canary覆盖数据</strong></p></li></ul><p>两个前提条件时才能检测到栈溢出,故其并非一种理论上安全的防御方式,也只能针对顺序覆盖的栈溢出提供一定的缓解。</p><h3 id="三-stack-canary基本思路与业界实现"><a class="markdownIt-Anchor" href="#三-stack-canary基本思路与业界实现"></a> 三、stack canary基本思路与业界实现</h3><p>虽然原理简单，但实现上还是要解决两个主要问题:</p><h4 id="1作为对比基准的canary来自哪里"><a class="markdownIt-Anchor" href="#1作为对比基准的canary来自哪里"></a> 1.作为对比基准的canary来自哪里?</h4><p>函数入口需要向函数栈push一个原始的canary，函数出口需要将函数栈中的canary(后续称为stack_canary)和原始值做对比，在此过程中原始值需要保持不变并且可以被代码获取到:</p><h5 id="11-原始值来自全局变量"><a class="markdownIt-Anchor" href="#11-原始值来自全局变量"></a> 1.1 原始值来自全局变量</h5><p>默认stack canary使用全局符号(变量) __stack_chk_guard 作为原始的canary(后续称为全局canary), 在gcc/clang中均使用相同的名字.</p><ul><li>全局canary的优点在于:实现简单,开启stack_canary保护的代码中只需要定义一个全局变量__stack_chk_guard 并在初始化时为其赋值一个随机数即可__</li><li>全局canary的缺点在于:<ul><li>所有进程间共享同一个全局canary,只要某进程/线程中发生了infoleak，那么整个canary机制就可以被绕过了.</li><li>全局canary(__stack_chk_guard)的值在运行期间难以改变，否则会导致已有的函数返回时直接crash</li></ul></li></ul><h5 id="12-原始值来自per-cpu变量"><a class="markdownIt-Anchor" href="#12-原始值来自per-cpu变量"></a> 1.2 原始值来自per-cpu变量</h5><p>per-cpu变量的引入是为了实现per-task的stack canary，每个cpu上同时只能运行一个进程/线程, per-cpu变量可以随进程的切换而切换，故通过一个per-cpu变量完全可以为每个进程/线程解引用到不同的canary地址(后续称为per-cpu canary)，以实现per-task的canary。</p><h5 id="per-cpu-canary的优点在于"><a class="markdownIt-Anchor" href="#per-cpu-canary的优点在于"></a> per-cpu canary的优点在于:</h5><p>每个进程/线程拥有自己的canary, 可减少infoleak的影响</p><h5 id="per-cpu-canary的缺点在于"><a class="markdownIt-Anchor" href="#per-cpu-canary的缺点在于"></a> per-cpu canary的缺点在于:</h5><p>需要依赖于硬件平台的一个per-cpu变量(如aarch64 用户态tpidr_el0,内核态sp_el0)</p><p>需要编译器增加对应支持</p><h4 id="2每个函数中pushpopcheck-canary的代码谁来写"><a class="markdownIt-Anchor" href="#2每个函数中pushpopcheck-canary的代码谁来写"></a> 2.每个函数中push/pop/check canary的代码谁来写？</h4><p>通常stack canary的桩代码都是由编译器来插入的,但对具体硬件平台, 不同编译器的支持也有所不同</p><h5 id="21-gccllvm-均支持全局canary"><a class="markdownIt-Anchor" href="#21-gccllvm-均支持全局canary"></a> 2.1 gcc/llvm 均支持全局canary:</h5><p>gcc/llvm中编译选项-fstack-protector/-fstack-protector-strong均已支持, 开启后函数出入口会从全局变量__stack_chk_guard中获取全局canary</p><h5 id="22-gccllvm-均支持aarch64的per-cpu-canary"><a class="markdownIt-Anchor" href="#22-gccllvm-均支持aarch64的per-cpu-canary"></a> 2.2 gcc/llvm 均支持aarch64的per-cpu canary:</h5><ul><li>gcc通过-mstack-protector-guard<em>系列选项可以指定某系统寄存器作为stack canary per cpu的资源(后面称为sysreg)</em></li><li><em>clang 主线目前也已支持-mstack-protector-guard</em> 系列选项,但目前尚无可用发行版[1]</li><li>clang --target=–target=aarch64-linux-android 中支持per cpu的stack canary，但其只能使用默认的 tpidr_el0系统寄存器作为索引, 偏移值也是默认的0x40</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-mstack-protector-guard*系列包含三个选项:</span><br><span class="line">  * -mstack-protector-guard=sysreg:      使用系统寄存器作为per cpu canary的索引</span><br><span class="line">  * -mstack-protector-guard-reg=sp_el0:  作为索引的系统寄存器名(必须是系统寄存器,代码中最终会生成msr/mrs作为访问指令)</span><br><span class="line">  * -mstack-protector-guard-offset=16:   偏移地址,最终canary来自 *(sp_el0 + offset)</span><br></pre></td></tr></table></figure><h5 id="23-arm-linux内核可通过gcc-plugin支持-per-cpu-canary"><a class="markdownIt-Anchor" href="#23-arm-linux内核可通过gcc-plugin支持-per-cpu-canary"></a> 2.3 arm linux内核可通过gcc plugin支持 per-cpu canary:</h5><p>​      arm linux kernel 通过一个gcc plugin(arm_ssp_per_task_plugin)基于per-cpu 寄存器sp实现了 per-task canary功能</p><h3 id="四-编译器中全局canary的实现"><a class="markdownIt-Anchor" href="#四-编译器中全局canary的实现"></a> 四、编译器中全局canary的实现</h3><p>这里以aarch64平台，gcc + -fstack-protector-strong为例,其实现逻辑如下(源码分析见备注2):</p><ul><li>函数入口将全局canary =&gt; stack_canary(stack_canary地址为编译期间预留在当前函数栈底的)</li><li>函数出口对比全局canary和stack_canary是否还一致,一致则跳转到4)</li><li>检测到栈溢出, 调用__stack_chk_fail函数</li><li>函数返回</li></ul><p>在aarch64的汇编代码如下:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//aarch64-linux-gnu-gcc -g -fstack-protector-strong test.c -S -o ./gcc/test.s</span><br><span class="line">1 test:</span><br><span class="line">2         stp     x29, x30, [sp, -64]!                    /* 分配函数栈帧 */</span><br><span class="line">3         mov     x29, sp</span><br><span class="line">4         str     w0, [sp, 28]    </span><br><span class="line">5         adrp    x0, __stack_chk_guard                   /* 获取全局canary *__stack_chk_guard */</span><br><span class="line">6         add     x0, x0, :lo12:__stack_chk_guard</span><br><span class="line">7         ldr     x1, [x0]</span><br><span class="line">8         str     x1, [sp, 56]                            /* 全局canary =&gt; stack_canary(位于栈底) */</span><br><span class="line"> </span><br><span class="line">9         .......                                         /* 函数体 */</span><br><span class="line"> </span><br><span class="line">10        adrp    x0, __stack_chk_guard                   /* 函数返回前再次获取全局canary */</span><br><span class="line">11        add     x0, x0, :lo12:__stack_chk_guard</span><br><span class="line">12        ldr     x0, [x0]</span><br><span class="line">13        ldr     x2, [sp, 56]                            /* 读取stack_canary */</span><br><span class="line">14        eor     x0, x2, x0                              /* 对比stack_canary是否被破坏 */</span><br><span class="line">15        cmp     x0, 0</span><br><span class="line">16        beq     .L3                                     /* 未破坏跳转到函数返回 */</span><br><span class="line">17        bl      __stack_chk_fail                        /* 被破坏则跳转到 __stack_chk_fail */        </span><br><span class="line">18</span><br><span class="line">19 .L3:</span><br><span class="line">20        ldp     x29, x30, [sp], 64</span><br><span class="line">21        ret</span><br></pre></td></tr></table></figure><h3 id="五-编译器中per-cpu-canary的实现"><a class="markdownIt-Anchor" href="#五-编译器中per-cpu-canary的实现"></a> 五、编译器中per-cpu canary的实现</h3><p>​    per-cpu canary时编译器会通过  *(reg + offset)的方式获取当前cpu上的canary(如下面例子中的 * (sp_el0  + 16), 而程序自身需要确保线程切换时per-cpu的canary也要随之切换, 在aarch64下的汇编代码如下(源码分析见备注2):</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/*</span><br><span class="line">    -mstack-protector-guard=sysreg:      使用系统寄存器作为per cpu canary的索引</span><br><span class="line">    -mstack-protector-guard-reg=sp_el0:  作为索引的系统寄存器名(必须是系统寄存器,代码中最终会生成msr/mrs作为访问指令)</span><br><span class="line">    -mstack-protector-guard-offset=16:   偏移地址,最终canary来自 *(sp_el0 + offset)</span><br><span class="line">*/</span><br><span class="line">//aarch64-linux-gnu-gcc -g -fstack-protector-strong -mstack-protector-guard=sysreg -mstack-protector-guard-reg=sp_el0 -mstack-protector-guard-offset=16 test.c -S -o ./gcc/test.s</span><br><span class="line">  1 test:</span><br><span class="line">  2         stp     x29, x30, [sp, -64]!    /* 分配函数栈帧 */</span><br><span class="line">  3         mov     x29, sp</span><br><span class="line">  4         str     w0, [sp, 28]</span><br><span class="line">  5         mrs     x0, sp_el0              /* x1 = *(sp_el0 + 16); 为per cpu canary值 */</span><br><span class="line">  6         add     x0, x0, 16</span><br><span class="line">  7         ldr     x1, [x0]</span><br><span class="line">  8         str     x1, [sp, 56]            /* per cpu canary =&gt; stack_canary */</span><br><span class="line">  9         ......</span><br><span class="line">10         mrs     x0, sp_el0               /* 再次获取per cpu的canary */</span><br><span class="line">11         add     x0, x0, 16</span><br><span class="line">12         ldr     x0, [x0]</span><br><span class="line">13         ldr     x1, [sp, 56]             /* 再次获取stack_canary */</span><br><span class="line">14         eor     x0, x1, x0               /* 对比匹配则正常结束,不匹配跳转到__stack_chk_fail */</span><br><span class="line">15         cmp     x0, 0</span><br><span class="line">16         beq     .L2</span><br><span class="line">17         bl      __stack_chk_fail</span><br><span class="line">18 .L2:</span><br><span class="line">19         ldp     x29, x30, [sp], 64</span><br><span class="line">20         ret</span><br></pre></td></tr></table></figure><h3 id="六-linux内核对stack-canary的支持"><a class="markdownIt-Anchor" href="#六-linux内核对stack-canary的支持"></a> 六、linux内核对stack canary的支持</h3><p>linux内核中与stack canary相关的配置项主要有三个,分别是:</p><ol><li><p>CONFIG_STACKPROTECTOR:</p><p>平台无关的编译选项,其决定是否开启 stack canary保护, 开启则默认指定编译选项 -fstack-protector，使用__stack_chk_guard 作为全局canary对比</p></li><li><p>CONFIG_STACKPROTECTOR_STRONG</p><p>平台无关的编译选项,其决定是否开启strong保护,开启则额外指定编译选项 -fstack-protector-strong.</p></li><li><p>CONFIG_STACKPROTECTOR_PER_TASK</p><p>平台相关的编译选项, 其决定是否开启内核per-task的stack canary保护(此时需编译器的per-cpu canary和对应硬件平台支持)</p></li></ol><h3 id="七-aarch64平台内核stack-canary的实现"><a class="markdownIt-Anchor" href="#七-aarch64平台内核stack-canary的实现"></a> 七、aarch64平台内核stack canary的实现</h3><h4 id="1全局canary的实现"><a class="markdownIt-Anchor" href="#1全局canary的实现"></a> 1.全局canary的实现</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">CONFIG_STACKPROTECTOR =y</span><br><span class="line">CONFIG_STACKPROTECTOR_STRONG =y</span><br><span class="line">CONFIG_STACKPROTECTOR_PER_TASK=n</span><br></pre></td></tr></table></figure><p>全局canary对于内核来说并没有太多的工作，只需要在系统启动时设置好__stack_chk_guard并定义检测失败的回调__stack_chk_fail 即可，插桩代码均由编译器实现(见四), 代码如下:</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">./arch/arm64/kernel/process.c</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(CONFIG_STACKPROTECTOR) &amp;&amp; !defined(CONFIG_STACKPROTECTOR_PER_TASK)</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/stackprotector.h&gt;</span></span></span><br><span class="line"><span class="comment">/* 这里__stack_chk_guard被定义为一个变量, 实际上定义为__ro_after_init可能更好, 此变量可写通常也不会有太大问题，因为对此变量的修改通常会直接导致内核检测到栈溢出而crash */</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> __stack_chk_guard __read_mostly;        </span><br><span class="line">EXPORT_SYMBOL(__stack_chk_guard);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">./arch/arm64/include/<span class="keyword">asm</span>/stackprotector.h</span><br><span class="line"><span class="type">static</span> __always_inline <span class="type">void</span> <span class="title function_">boot_init_stack_canary</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(CONFIG_STACKPROTECTOR)</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> canary;</span><br><span class="line"></span><br><span class="line">    get_random_bytes(&amp;canary, <span class="keyword">sizeof</span>(canary));        <span class="comment">/* 获取一个半随机数 */</span></span><br><span class="line">    canary ^= LINUX_VERSION_CODE;</span><br><span class="line">    canary &amp;= CANARY_MASK;</span><br><span class="line">    current-&gt;stack_canary = canary;</span><br><span class="line">     </span><br><span class="line">    <span class="keyword">if</span> (!IS_ENABLED(CONFIG_STACKPROTECTOR_PER_TASK))        </span><br><span class="line">        __stack_chk_guard = current-&gt;stack_canary;    <span class="comment">/* 如果没指定 per thread,则初始化全局canary */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        .......</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">./kernel/panic.c</span><br><span class="line">__visible noinstr <span class="type">void</span> __stack_chk_fail(<span class="type">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    instrumentation_begin();</span><br><span class="line">    panic(<span class="string">&quot;stack-protector: Kernel stack is corrupted in: %pB&quot;</span>,</span><br><span class="line">        __builtin_return_address(<span class="number">0</span>));</span><br><span class="line">    instrumentation_end();</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(__stack_chk_fail);</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="2per-task-canary的实现"><a class="markdownIt-Anchor" href="#2per-task-canary的实现"></a> 2.per-task canary的实现</h4><p>CONFIG_STACKPROTECTOR =y<br />CONFIG_STACKPROTECTOR_STRONG =y<br />CONFIG_STACKPROTECTOR_PER_TASK=y<br />per-task canary时内核除了初始化外还需要负责为每个进程生成随机的canary，并负责在进程切换时同步per-cpu的寄存器与进程的关系，此时内核新增的配置项和数据结构如下:</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">./arch/arm64/kernel/<span class="keyword">asm</span>-offsets.c</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_STACKPROTECTOR</span></span><br><span class="line">  <span class="built_in">DEFINE</span>(TSK_STACK_CANARY,    <span class="built_in">offsetof</span>(<span class="keyword">struct</span> task_struct, stack_canary));        <span class="comment">/* task_struct中增加per thread的canary */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">./arch/arm64/Kconfig</span><br><span class="line">config STACKPROTECTOR_PER_TASK</span><br><span class="line">    def_bool y</span><br><span class="line">    depends on STACKPROTECTOR &amp;&amp; CC_HAVE_STACKPROTECTOR_SYSREG</span><br><span class="line"></span><br><span class="line">./arch/arm64/<span class="function">Makefile</span></span><br><span class="line"><span class="function"><span class="title">ifeq</span> <span class="params">($(CONFIG_STACKPROTECTOR_PER_TASK),y)</span></span></span><br><span class="line"><span class="function">prepare: stack_protector_prepare</span></span><br><span class="line"><span class="function">/* 增加编译选项 -mstack-protector-guard=</span>sysreg -mstack-protector-guard-reg=sp_el0 -mstack-protector-guard-offset=TSK_STACK_CANARY*/</span><br><span class="line">stack_protector_prepare: prepare0                                             </span><br><span class="line">    $(eval KBUILD_CFLAGS += -mstack-protector-guard=sysreg          \        #<span class="meta"># per-task编译选项支持</span></span><br><span class="line">                -mstack-protector-guard-reg=sp_el0      \</span><br><span class="line">                -mstack-protector-guard-offset=$(shell      \</span><br><span class="line">            awk <span class="string">&#x27;&#123;if ($$2 == &quot;TSK_STACK_CANARY&quot;) print $$3;&#125;&#x27;</span> \</span><br><span class="line">                    include/generated/<span class="keyword">asm</span>-offsets.h))</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>根据编译选项可知，per-task模式下内核指定编译器通过 *(sp_el0 + TSK_STACK_CANARY) 来解引用per-cpu canary, sp_el0在内核中用来存储当前进程task_struct的指针，即对于内核来说对 *(sp_el0 + TSK_STACK_CANARY) 的解引用即相当于访问 current-&gt;stack_canary.</p><p>由于sp_el0在内核中是随着进程切换而切换的(见__switch_to)，故stack canary特性并不需要做额外的操作，其只需要在每个线程创建时为其生成新的canary即可:</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">struct</span> <span class="title class_">task_struct</span> *<span class="built_in">dup_task_struct</span>(<span class="keyword">struct</span> task_struct *orig, <span class="type">int</span> node)</span><br><span class="line">&#123;</span><br><span class="line">  ......</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_STACKPROTECTOR                        <span class="comment">/* 这里不是CONFIG_STACKPROTECTOR_PER_TASK是因为x86平台此特性兼容的历史原因，这里欠缺一点优雅 */</span></span></span><br><span class="line">    tsk-&gt;stack_canary = <span class="built_in">get_random_canary</span>();        <span class="comment">/* fork线程时总是新生成一个随机数作为新线程的canary */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>故在aarch64内核中 per-task canary的思路可整理如下:</p><ul><li>内核自身sp_el0记录task_struct(即current)地址，并随进程切换而切换</li><li>在task_struct中增加一个成员stack_canary, 则此成员总是可以通过 (sp_el0 + TSK_STACK_CANARY)找到<br />进程创建时总是为其生成一个新的canary记录到 current-&gt;stack_canary</li><li>编译器开启per-cpu canary支持，基准的canary值总是来自sp_el0 + TSK_STACK_CANARY，也就是 current-&gt;stack_canary</li></ul><p><a href="https://blog.csdn.net/lidan113lidan/article/details/120318707">(69条消息) linux 内核安全增强(一)— stack canary_ashimida@的博客-CSDN博客___stack_chk_guard</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> 漏洞分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码静态分析工具调研</title>
      <link href="/2023/12/18/Security/software%20security/%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"/>
      <url>/2023/12/18/Security/software%20security/%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/92886d979401">C/C++代码静态分析工具调研 - 简书 (jianshu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/367641334">干货|代码安全审计权威指南（附下载地址） - 知乎 (zhihu.com)</a></p><p><a href="https://zhengtianzuo.blog.csdn.net/article/details/122679768">C++代码静态分析与优化_专栏总目录_devskim-CSDN博客</a></p><h1 id="简述"><a class="markdownIt-Anchor" href="#简述"></a> 简述</h1><p>静态分析（static analysis）是指在不执行代码的情况下对其进行分析评估的过程，是软件质量和软件安全保障的重要一环。它通过词法分析、语义分析、控制流分析、数据流分析等技术对代码逐行解析暴露问题，从而协助我们将许多在运行时才会暴露的棘手麻烦扼杀于摇篮之中。</p><h1 id="典型问题示例"><a class="markdownIt-Anchor" href="#典型问题示例"></a> 典型问题示例</h1><p>代码静态分析能够识别诸多类型的漏洞或缺陷，轻至警告级的「变量未使用」，重至错误级的各类bug，这里列举几种常见的、较严重的、可静态检测的问题。</p><h4 id="缓冲区溢出"><a class="markdownIt-Anchor" href="#缓冲区溢出"></a> ■ 缓冲区溢出</h4><p>缓冲区溢出是指向缓冲区中存入超出其空间大小的数据量，导致多余的数据覆盖其他区域的合法数据，类似倒入容器中的水过多而导致溢出，流到它不该去的地方，造成不可预期的后果。从实践统计看，缓冲区溢出问题是软件中最普遍存在的漏洞问题，在C/C++这类不提供内存越界检测的语言中尤甚。通常，发生缓冲区溢出的情况有：</p><ul><li>字符串拷贝，当目标缓冲区长度小于源字串的长度时（此类的函数包括<code>strcpy</code>、<code>_mbscpy</code>、<code>strcat</code>、<code>wcscat</code>、<code>memcpy</code>、<code>strncpy</code>、<code>_mbsncpy</code>、<code>strncat</code>、<code>wcsncat</code>等）。</li></ul><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 字符串拷贝之前没有对s做长度判断，如果超过10，就会造成缓冲区溢出。</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">char</span>* s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">char</span> buf[<span class="number">10</span>];</span><br><span class="line">    <span class="built_in">strcpy</span>(buf, s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>格式化字符串处理，当参数与格式化字符串不匹配时（此类的函数包括<code>printf</code>、<code>fprintf</code>、<code>sprintf</code>、<code>swprintf</code>等）。</li></ul><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// %n将前面打印的字串长度信息写到相应地址</span></span><br><span class="line"><span class="type">int</span> <span class="built_in">len</span> = <span class="number">0</span>;</span><br><span class="line">printf(<span class="string">&quot;This is a test string.%n&quot;</span>, &amp;<span class="built_in">len</span>);</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 错误的写法，此时长度信息会写到地址为0的内存空间中</span></span><br><span class="line"><span class="type">int</span> <span class="built_in">len</span> = <span class="number">0</span>;</span><br><span class="line">printf(<span class="string">&quot;This is a test string.%n&quot;</span>, <span class="built_in">len</span>);</span><br></pre></td></tr></table></figure><ul><li>字符串读取，当缓冲区小于所要读入的字符串长度时（此类的函数包括<code>scanf</code>、<code>fscanf</code>、<code>sscanf</code>、<code>gets</code>、<code>getc</code>、<code>fgets</code>、<code>fgetc</code>等）。</li></ul><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 用户输入的字串长度不受控制，如果超过10，就会造成缓冲区溢出。</span></span><br><span class="line"><span class="type">char</span> buf[<span class="number">10</span>];</span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>, &amp;buf);</span><br></pre></td></tr></table></figure><h4 id="内存泄漏"><a class="markdownIt-Anchor" href="#内存泄漏"></a> ■ 内存泄漏</h4><p>内存泄漏一般指堆内存的泄漏（也有系统资源的泄漏），程序申请的内存资源没有被合理地释放，导致这部分内存不能被回收利用而造成资源的浪费。严重时，过多的内存泄漏会造成系统崩溃。C/C++语言没有自动回收机制，需要程序员自行确保内存使用的闭环（<code>new/delete</code>、<code>alloc/free</code>、<code>malloc/free</code>、<code>GlobalAlloc/GlobalFree</code>成对使用）。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-311849d814d36878.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/318/format/webp" alt="img" /></p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-afcd25b4580f01aa.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/318/format/webp" alt="img" /></p><p>通常，发生内存泄漏的情况有：</p><ul><li>分配内存后忘了调用相应的释放函数。</li><li>过程因达到某种条件提前结束，未能执行后面的内存释放函数。</li><li>程序设计不合理，不断分配内存，到最后才一起释放，虽然整体上不算内存泄漏，但在过程中已经酝酿了资源耗尽的可能性，无异于内存泄漏。</li></ul><h4 id="野指针"><a class="markdownIt-Anchor" href="#野指针"></a> ■ 野指针</h4><p>当指针变量未被初始化，或指向的内存已被回收时，该指针便成了野指针。其指向的内存地址是非法的，对这块非法区域进行操作将导致不可预料的后果。</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 对指针是否为空的判断看是严谨，其实是无效的。</span></span><br><span class="line"><span class="type">char</span> *p = (<span class="type">char</span>*)<span class="built_in">malloc</span>(<span class="number">10</span>);</span><br><span class="line"><span class="built_in">free</span>(p);</span><br><span class="line"><span class="keyword">if</span> (p != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">strcpy</span>(p, <span class="string">&quot;danger&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="工具调研"><a class="markdownIt-Anchor" href="#工具调研"></a> 工具调研</h1><p>根据工作需要，从可检测的语言、使用平台和授权三方面考量，调研了20余种主流的C/C++代码静态分析工具。</p><table><thead><tr><th>工具</th><th>语言</th><th>平台</th><th>授权</th></tr></thead><tbody><tr><td><a href="http://adlint.sourceforge.net/">AdLint</a></td><td>C</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>开源</td></tr><tr><td><a href="https://www.absint.com/astree/index.htm">Astrée</a></td><td>C</td><td>Windows, Linux</td><td>付费</td></tr><tr><td><a href="http://www.iste.uni-stuttgart.de/en/ps/project-bauhaus.html">Bauhaus Toolkit</a></td><td>C, C++, Java, C#, Ada</td><td>Windows, Linux, Solaris</td><td>付费</td></tr><tr><td><a href="https://forge.ispras.ru/projects/blast">BLAST</a></td><td>C</td><td>Linux</td><td>开源</td></tr><tr><td><a href="http://cppcheck.sourceforge.net/">Cppcheck</a></td><td>C, C++</td><td>Windows, Linux</td><td>开源</td></tr><tr><td><a href="http://coccinelle.lip6.fr/">Coccinelle</a></td><td>C</td><td>Linux</td><td>开源</td></tr><tr><td><a href="https://www.synopsys.com/software-integrity/resources/datasheets/coverity.html">Coverity</a></td><td>C, C++, C#, Java, JS, PHP, Python, Objective-C, Ruby, Swift, Fortran, VB</td><td>Windows, Linux, Mac OS, FreeBSD, Solaris</td><td>付费</td></tr><tr><td><a href="https://www.cppdepend.com/">CppDepend</a></td><td>C, C++</td><td>Windows, Linux</td><td>付费</td></tr><tr><td><a href="http://www.bugseng.com/eclair">ECLAIR</a></td><td>C, C++</td><td>Windows, Linux, Mac OS</td><td>付费</td></tr><tr><td><a href="https://www.dwheeler.com/flawfinder/">Flawfinder</a></td><td>C, C++</td><td>Python</td><td>开源</td></tr><tr><td><a href="http://www.lix.polytechnique.fr/Labo/Sylvie.Putot/fluctuat.html">Fluctuat</a></td><td>C, Ada</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>付费</td></tr><tr><td><a href="http://frama-c.com/">Frama-C</a></td><td>C</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>开源/付费</td></tr><tr><td><a href="https://www.grammatech.com/products/codesonar">CodeSonar</a></td><td>C, C++, Java, 二进制码</td><td>Windows, Linux, Mac OS, FreeBSD</td><td>付费</td></tr><tr><td><a href="https://www.klocwork.com/">Klocwork</a></td><td>C, C++, Java, C#</td><td>Windows, Linux, Solaris</td><td>付费</td></tr><tr><td><a href="https://ldra.com/industrial-energy/products/ldra-testbed-tbvision/">LDRA Testbed</a></td><td>C, C++, Java, Ada</td><td>Windows, Linux, Mac OS</td><td>付费</td></tr><tr><td><a href="https://www.parasoft.com/products/ctest">Parasoft C/C++test</a></td><td>C, C++</td><td>Windows, Linux, Solaris</td><td>付费</td></tr><tr><td><a href="http://www.gimpel.com/html/pcl.htm">PC-Lint</a></td><td>C, C++</td><td>Windows</td><td>付费</td></tr><tr><td><a href="https://cn.mathworks.com/products/polyspace.html">Polyspace</a></td><td>C, C++, Ada</td><td>Windows, Linux, Mac OS</td><td>付费</td></tr><tr><td><a href="http://www.prqa.com/static-analysis-software/qac-qacpp-static-analyzers/">PRQA QA·Static Analyzers</a></td><td>C, C++, Java</td><td>Windows, Linux</td><td>付费</td></tr><tr><td><a href="https://www.microsoft.com/en-us/research/project/slam/?from=http%3A%2F%2Fresearch.microsoft.com%2Fslam">SLAM</a></td><td>C</td><td>Windows</td><td>免费</td></tr><tr><td><a href="https://sparse.wiki.kernel.org/index.php/Main_Page">Sparse</a></td><td>C</td><td>Linux, Mac OS, BSD</td><td>开源</td></tr><tr><td><a href="http://lclint.cs.virginia.edu/">Splint</a></td><td>C</td><td>Linux, FreeBSD, Solaris</td><td>开源</td></tr><tr><td><a href="http://code.tencent.com/tscancode.html">TscanCode</a></td><td>C, C++, C#, Lua</td><td>Windows, Linux, Mac OS</td><td>开源</td></tr></tbody></table><p>根据以下标准，筛选出3款适用性较高的工具——Cppcheck、Flawfinder、TscanCode——进行详细调研：</p><ul><li>语言：支持C/C++代码分析</li><li>平台：支持在Windows和/或Linux平台运行</li><li>授权：免费</li></ul><p>为进行一次实践对比，从TscanCode的GitHub上抓到一组现成的C/C++编码问题示例，共94个CPP文件，考察三者的检测效果。</p><blockquote><p>运行平台：Windows<br />被测语言：C/C++<br />测试集：<a href="https://github.com/Tencent/TscanCode/tree/master/samples/cpp">TscanCode/samples/cpp</a></p></blockquote><h4 id="cppcheck"><a class="markdownIt-Anchor" href="#cppcheck"></a> ■ <a href="http://cppcheck.sourceforge.net/">Cppcheck</a></h4><blockquote><p>Cppcheck可检测的问题包括：</p><ul><li>Dead pointers</li><li>Division by zero</li><li>Integer overflows</li><li>Invalid bit shift operands</li><li>Invalid conversions</li><li>Invalid usage of STL</li><li>Memory management</li><li>Null pointer dereferences</li><li>Out of bounds checking</li><li>Uninitialized variables</li><li>Writing const data</li></ul><p>并将问题分为以下6类：</p><ul><li><strong>错误（error）</strong>：bug。</li><li><strong>警告（warning）</strong>：预防性编程方面的建议。</li><li><strong>风格警告（style）</strong>：出于对代码简洁性的考虑（函数未使用、冗余代码等）。</li><li><strong>可移植性警告（portability）</strong>：64/32位可移植性、编译器通用性等。</li><li><strong>性能警告（performance）</strong>：使代码更高效的建议，但不保证一定有明显效果。</li><li><strong>信息消息（information）</strong>：条件编译方面的警告。</li></ul></blockquote><p>安装十分简便，只需在官网下载最新的可执行安装包（本文目前为<code>cppcheck-1.83-x86-Setup.msi</code>）跟着向导「下一步」即可。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-7e2c0428206a5133.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/816/format/webp" alt="img" /></p><p>Cppcheck有GUI，选择菜单栏「Analyze」下的「文件」或「目录」即可对源代码进行静态分析。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-69215d004372d570.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp" alt="img" /></p><p>运行结果对94个例子的分析十分到位，只不过底侧的代码预览对中文注释似乎不太友好。</p><p>除了GUI，Cppcheck还支持与多种IDE（如VS、Eclipse、QtCreator等）、版本管理系统（如Tortoise SVN、Git）集成使用。</p><p>可对每次分析进行配置甚至自定义规则，并作为项目文件进行保存或重载。</p><p>分析的结果报告可保存为格式化纯文本或XML，并可借助Python pygments将XML生成为HTML。</p><h4 id="tscancode"><a class="markdownIt-Anchor" href="#tscancode"></a> ■ <a href="http://code.tencent.com/tscancode.html">TscanCode</a></h4><p>TscanCode是腾讯的开源项目，为此次调研的唯一一款本土工具，起初构建于Cppcheck的基础之上，后来进行了重新实现，并加入了对C#和Lua的支持。</p><blockquote><p>TscanCode可检测的问题包括：</p><ul><li>空指针检查，包含可疑的空指针，判空后解引用比如Crash等共3类subid检查</li><li>数据越界，Sprintf_S越界共1类subid检查</li><li>内存泄漏，分配和释放不匹配同1类subid检查</li><li>逻辑错误，重复的代码分支，bool类型和INT进行比较，表达式永远True或者false等共18类检查</li><li>可疑代码检查，if判断中含有可疑的=号，自由变量返回局部变量等共计15类检查</li><li>运算错误，判断无符号数小于0,对bool类型进行++自增等，共计11类检查</li></ul><p>并将问题分为<strong>致命</strong>、<strong>严重</strong>、<strong>警告</strong>、<strong>提示</strong>、<strong>风格</strong>5类。</p></blockquote><p>安装同样便捷，下载安装包（本文目前为<code>TscanCodeV2.14.24.windows.exe</code>）跟着向导「下一步」即可。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-7833720f633ac65b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/800/format/webp" alt="img" /></p><p>同样具有用户友好的GUI，且UI设计更时尚些。点击「扫描文件夹」或「扫描文件」选定路径后点击「开始扫描」即可使用。</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-bf4a49679a1f362a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp" alt="img" /></p><p>扫描结果，对中文注释必然友好。</p><p>TscanCode的提示信息可以说直接照搬了Cppcheck，但给出的提示数量明显少于Cppcheck，以<code>mismatchsize.cpp</code>为例：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Demo</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//分配的内存空间不匹配</span></span><br><span class="line">    <span class="type">int</span> i = <span class="built_in">malloc</span>(<span class="number">3</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https:////upload-images.jianshu.io/upload_images/30022-387ab0daf9e25b64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/658/format/webp" alt="img" /></p><p>Cppcheck对mismatchsize.cpp的检测结果有4条提示，TscanCode相应地只给出了后两条。</p><h4 id="flawfinder"><a class="markdownIt-Anchor" href="#flawfinder"></a> ■ <a href="https://www.dwheeler.com/flawfinder/">Flawfinder</a></h4><p>Flawfinder由计算机安全专家<a href="https://www.dwheeler.com/">David A. Wheeler</a>个人开发，依托于Python，自然而然拥有了跨平台性。</p><p>安装：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install flawfinder</span><br></pre></td></tr></table></figure><p>运行：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> *python_path*/Scripts</span><br><span class="line">python flawfinder *directory_with_source_code*</span><br></pre></td></tr></table></figure><p>实践表明，Flawfinder对中文注释更不友好，直接拿TscanCode的测试集跑会报编码错误，尽管这些CPP文件本来就是Flawfinder文档所建议的UTF-8格式：</p><blockquote><p>UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xaf in position 92: illegal multibyte sequence</p></blockquote><p>将测试集批量转换为ANSI格式后方可正常运行：</p><p><img src="https:////upload-images.jianshu.io/upload_images/30022-314cdadac2240642.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/677/format/webp" alt="img" /></p><p>94个示例，仅检测出11个问题。</p><p>David A. Wheeler本人也在官网特别声明Flawfinder是款相对简单的静态分析工具，不进行数据流和控制流分析，甚至不识别函数的参数类型。</p><p>Flawfinder可将结果保存为<a href="https://www.dwheeler.com/flawfinder/correct-results.txt">格式化纯文本</a>、<a href="https://www.dwheeler.com/flawfinder/correct-results.html">HTML</a>和<a href="https://www.dwheeler.com/flawfinder/correct-results.csv">CSV</a>三种格式。</p><h4 id="3款工具对比"><a class="markdownIt-Anchor" href="#3款工具对比"></a> 3款工具对比</h4><ul><li>检测能力：Cppcheck &gt; TscanCode &gt; Flawfinder</li><li>友好度：TscanCode &gt; Cppcheck &gt; Flawfinder</li><li>易用性：TscanCode &gt; Cppcheck &gt; Flawfinder</li></ul><h1 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h1><ul><li>向东, 刘海燕. C/C++静态代码安全检查工具研究[J]. 计算机工程与设计, 2005, 26(8):2110-2112.</li><li>罗琴灵. 基于静态检测的代码审计技术研究[J]. 2016.</li><li><a href="https://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis#C,_C++">List of tools for static code analysis - Wikipedia</a></li><li><a href="https://blog.csdn.net/wetest_tencent/article/details/51516347">C++代码质量扫描主流工具深度比较 - CSDN博客</a></li><li><a href="http://qa.blog.163.com/blog/static/190147002201611147530522/">C/C++静态代码检查工具对比分析 - 网易博客</a></li><li><a href="https://blog.csdn.net/liang19890820/article/details/52778149">Cppcheck 用法（上篇） - CSDN博客</a></li><li><a href="http://cppcheck.sourceforge.net/manual.pdf">Cppcheck手册</a></li><li><a href="https://www.dwheeler.com/flawfinder/flawfinder.pdf">Flawfinder文档</a></li></ul><p>作者：逸之<br />链接：<a href="https://www.jianshu.com/p/92886d979401">https://www.jianshu.com/p/92886d979401</a><br />来源：简书<br />著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 静态分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CEVulDet A Code Edge Representation Learnable Vulnerability Detector</title>
      <link href="/2023/12/18/Papers/Vul/CEVulDet/"/>
      <url>/2023/12/18/Papers/Vul/CEVulDet/</url>
      
        <content type="html"><![CDATA[<h1 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h1><p>许多研究者已开始应用深度学习算法来检测源代码的漏洞。然而，现有方法的检测结果仍然不够准确。大多数这些方法将程序源代码直接视为自然语言。这些方法可能会忽略特定于程序代码的结构信息，而这些信息是代码构成语义的关键部分。在本文中，我们提出了一种名为CEVulDet的新型漏洞检测方法。**首先，我们采用中心性分析来从PDG中去除不重要的节点，以获得保留程序重要部分的新图。其次，我们提出了一种新的程序语义提取方法，该方法获取特征向量以表示程序代码和图边信息的语义信息。它可以借助模型解释技术定位漏洞触发路径。**最后，我们的方法提取的向量被输入到CNN中训练漏洞检测器。在我们的实验中，我们评价了CEVulDet在一个包含33,360个函数的数据集上的性能，其中包括12,303个有漏洞的函数和21,057个无漏洞的函数。实验结果表明，CEVulDet远远优于基于规则的检测器，并超越了最先进的基于深度学习的检测器。CEVulDet在准确率、精确度、召回率和F1指标方面分别提高了3.2%、3.4%、5.1%和4.2%。</p><h1 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h1><h2 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h2><h2 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h2><p>我们的主要目标是准确地将一个函数代码标记为易受攻击或不易受攻击。为了做到这一点，我们以两种方式提高模型的准确性。一方面，我们需要使模型能够专注于函数的重要部分。另一方面，必须以适当的方式从源代码中提取丰富的语义。</p><p>为了让模型关注函数的重要部分。我们使用中心性分析来计算函数代码中每行代码的重要性，然后提取重要的代码行。函数代码中的不同代码行具有不同级别的语义重要性。例如，有些代码仅仅声明或定义变量，而其他代码实现了函数的核心算法。显然，后者对函数更重要，因为它们是函数语义的主要部分。获取这些关键代码（即高重要性代码）有助于模型做出更准确的判断。中心性分析计算图中节点的中心性值，这些值反映了图中节点的重要性。我们对函数进行静态分析，获取相应的PDG，然后使用中心性分析计算图中每个节点的中心性值。PDG中的每个节点对应函数中的一行代码，因此我们得到每行代码的重要性。</p><p>在这里，我们将度值视为度中心性，并计算其度中心性值，以弱点函数为示例。如图1所示，PDG中每个节点的内容是一行代码，在图中的实线和虚线表示代码之间的控制流和数据流。我们计算了图中每个节点的入度、出度和度，得到了表I。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221508383.png" alt="image-20240422150829338" style="zoom:50%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221508930.png" alt="image-20240422150839897" style="zoom:50%;" /><p>从表格I中，我们可以看到不同代码行的度基本不同，因为代码行之间有不同的关系（即控制流和数据流），这在一定程度上可以反映出代码行的重要性。为了更全面地考虑每行代码的重要性，我们使用三种不同的中心性分析（即度中心性[8]、接近中心性[8]和PageRank中心性[9]）。</p><p>从源代码中提取丰富的语义。我们提出了一个新颖的想法，可以从源代码中提取更丰富的语义意义。我们观察到，大多数先前的方法只是简单地堆叠代码行，然后将它们馈送到神经网络模型中。它们忽略了函数中的一些逻辑结构，特别是函数代码中的控制流和数据流，函数中的漏洞是基于这些流触发的。这些结构（即控制流边和数据流边）存在于与函数对应的PDG中。因此，我们提出了代码边，其中代码边对应于PDG中的一条边，由该边的两个节点组成。通过这种方式，我们可以将函数转换为代码边列表并获得语义丰富的数据。我们已经结合了这两个方面，并实施了CEVulDet，这使得能够更准确地检测函数（即易受攻击或不易受攻击）。</p><h2 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h2><p>我们使用中心性分析来拦截函数中的重要代码行，让神经网络模型专注于函数的重要部分。</p><p>我们提出了一种新颖的特征提取方法，能够从PDG中提取更丰富的语义（即控制流和数据流），并将函数转换为代码边缘列表。可解释的分析能帮助我们在一定程度上发现漏洞触发的路径。</p><p>我们实现了我们的漏洞检测器并将其与其他几种先进的检测方案进行比较。我们的方法在SARD [10]上取得了最佳结果。</p><h1 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h1><h2 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221519579.png" alt="image-20240422151938485" /></p><ul><li><p>获取代码的PDG：我们对每个函数的源代码进行规范化，然后进行静态分析以提取该函数的程序相关图。</p></li><li><p>生成中心图：PDG使用图的中心性值来删除程序相关图中的不重要节点，从而获得中心图。</p></li><li><p>生成代码边列表：我们使用中心图生成代码边缘列表，列表的每一行包含图中一个有向边的两个节点。</p></li><li><p>将代码边列表转换为向量列表：我们将一行代码视为一个句子，并遵循将句子嵌入向量的方法，同时将代码边嵌入向量中。</p></li><li><p>分类：最后，我们选择使用CNN模型构建我们的分类器，并将其用于检测漏洞。</p></li></ul><h2 id="22-method"><a class="markdownIt-Anchor" href="#22-method"></a> 2.2 Method</h2><p>代码边定义：</p><p>函数的程序依赖图包含其控制流和数据流，函数内代码行之间的逻辑关系嵌入在这两种流中。这些流（即控制流和数据流）在程序依赖图中被具体表示为有向边（例如，图1中的实线和虚线）。</p><p>考虑一个函数 f 的 PDG G = (V, E)，其中 V = {n1, …, nk} 是一组节点。一个节点对应于函数中的一行代码。E = {e1, …, ek} 是一组有向边，每条边代表一对节点之间的数据或控制依赖关系。使用代码边来表示PDG中的有向边，并且我们将有向边看作是两个节点之间的方向关系。因此，在PDG的Eei中，代码边缘ei = [nis，nie]由ei的起始节点和结束节点组成。因此，代码边在PDG中包含两个节点（即两行代码），这两个代码节点可能存在数据依赖性、控制依赖性，或者两者兼有。每个节点都包含函数中相应的代码行。请注意，这些边是有向边，这意味着节点“a”指向“b”的语义与节点“b”指向“a”的语义完全不同</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221547446.png" alt="image-20240422154739402" style="zoom:50%;" /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221552952.png" alt="image-20240422155240908" style="zoom:50%;" /><h1 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h1><h2 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h2><h2 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h2><h1 id="4-discusion"><a class="markdownIt-Anchor" href="#4-discusion"></a> 4 Discusion</h1><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CPVD Cross Project Vulnerability Detection Based on Graph Attention Network and Domain Adaptation</title>
      <link href="/2023/12/18/Papers/Vul/CPVD%20Cross%20Project%20Vulnerability%20Detection%20Based%20on%20Graph%20Attention%20Network%20and%20Domain%20Adaptation/"/>
      <url>/2023/12/18/Papers/Vul/CPVD%20Cross%20Project%20Vulnerability%20Detection%20Based%20on%20Graph%20Attention%20Network%20and%20Domain%20Adaptation/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>代码漏洞检测对于软件安全预防至关重要。大规模软件代码中的漏洞注释非常繁琐且具有挑战性，这需要领域专家花费大量时间进行注释。这项工作提供了CPVD，这是一种跨域漏洞检测方法**，基于“学习使用一个具有丰富漏洞标签的项目快速预测另一个项目的漏洞标签”的挑战CPVD使用代码属性图来表示代码，并使用图注意力网络和卷积池网络来提取图特征向量。**在跨域漏洞检测的域自适应表示学习阶段，它减少了源域和目标域数据之间的分布。在本文中，我们在不同的真实世界项目代码上相互测试。与没有域自适应的方法和基于自然语言处理的域自适应方法相比，CPVD更通用，在跨域漏洞检测任务中表现更好。具体而言，对于chr_deb、qemu、libav和sard这四个数据集，它们的F1得分分别为70.2%、81.1%、59.7%和78.1%，AUC分别为88.4%、86.3%、85.2%和88.6%。</p><p>代码属性图，跨域漏洞检测，域自适应表示学习，图注意力网络。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><p>在代码漏洞检测任务中，VulDeePecker、μVulDeePecker、SySeVR、Vuldeeplocator、Devign、BGNN4VD、Reveal和Ivdetect已经表明，使用神经网络进行自动特征提取比专家制作的特征具有更好的性能。VulDeePecker、μVulDeePecker、SySeVR和Vuldeeplocator将代码函数处理为标记序列，标记序列被处理为自然语言文本。然而，Devgin、BGNN4VD、Reveal和Ivdetect体现了通过图神经网络（以下简称GNN）提取代码函数的图结构特征。这些方法已被证明优于特征提取方法，如递归神经网络、Bi-LSTM和GRU。</p><p>然而，前面的技术都导致了漏洞识别问题中的另一个重要问题：项目中缺乏易感代码标签。数据集及其标签用于推动当前的深度学习模型。深度学习模型的预测性能由数据集的数量和质量以及它们的标记决定。由于漏洞标签的稀缺性，历史漏洞不足以训练和验证神经网络模型，尤其是对处于休眠状态的开源项目。</p><p>Vulnerability detection in large-scale software code is timeconsuming, complicated, and error-prone;</p><p>尽管源域和目标属于不同项目的漏洞代码集，但它们在相同的特征提取器后具有相似的特征空间和标签分布。尽管如此，它们的概率联合分布在跨域漏洞检测问题上更进一步。源域和目标域数据集用于漏洞分类任务，因此最终的分类目标是相同的。基于上述前提条件，可以在跨域漏洞识别中使用域自适应方法。</p><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><p>总之，本文的贡献如下：本文提出了一种将图注意力网络和域自适应表示学习相结合的跨域漏洞检测方法CPVD。这是图神经网络与领域自适应相结合进行跨领域漏洞检测的开端。基于这一想法，研究人员可以提出不同的方法来提高漏洞检测性能。本文验证了域自适应方法更适合于未标记的漏洞检测任务。本文验证了在跨域漏洞检测任务中，代码的图形表示优于令牌序列处理。本文验证了只有对源域进行重新采样才能提高漏洞检测性能。</p><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403131546258.png" alt="image-20240313154641145" /></p><h4 id="问题定义"><a class="markdownIt-Anchor" href="#问题定义"></a> 问题定义</h4><p>跨域漏洞代码检测是一个二进制分类问题，旨在将目标域代码分为易受攻击和不易受攻击。跨域漏洞代码检测有两种域分布，即源域代码分布S（C，y）和目标域代码分布T（C，？），其中C是代码函数；y表示漏洞分类标签，y∈{0,1}，0表示没有漏洞，1表示有漏洞，“？”表示未知标签。此外，这两个域分布都有域标签，d∈{S，T}，如果d=S，则xG～S（xG）；else xG～T（xG），其中xG是样本的图特征向量。跨域漏洞检测的目标是训练一个神经网络Nf（C），以不断减少源域漏洞分类损失和域分类损失，最终实现对目标域中的代码漏洞进行准确分类的目标。上述损失可以正式定义为</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403131559058.png" alt="image-20240313155919021" style="zoom:67%;" /><p>其中，L是源域漏洞分类损失，y是漏洞分类标签，Ld是域分类损失，d是域标签。</p><h4 id="代码预处理"><a class="markdownIt-Anchor" href="#代码预处理"></a> 代码预处理</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142126819.png" alt="image-20240314212644742" /></p><p>每个节点都包含一个键、代码语句和属性元素（例如Identifier、AssignmentExpression、ParameterType、ExpressionStatement），边表示节点之间的关系，边类型是对它们关系的描述，类型为IS_AST_PARENT、FLOWS_TO、DEF、USE、CONTROLS等。注意，每个函数都有不同的CPG，因为它们的语义和句法结构不同，所以函数的代码属性图不一定包含所有的边类型。改论文中使用了10种类型的边。</p><p>节点和边的类型分别用one-hot表示，语句用词嵌入技术进行表示。</p><h4 id="图特征提取"><a class="markdownIt-Anchor" href="#图特征提取"></a> 图特征提取</h4><p>图特征提取阶段的输入是标记的源域节点向量和未标记的目标域节点向量；对于标记的源域图，在预训练后输出图的特征向量，而对于未标记的目标域图，使用在源域中训练的模型来提取目标域图的向量特征。</p><p>代码预处理阶段输出的节点特征向量是独立于其他节点获得的，因此节点信息较差。代码属性图是根据代码之间的句法和语义结构构建的，每个节点都有一个语句片段，相邻节点之间存在很大的相关性和依赖性。为了最佳地表示节点特征，有必要将其相邻节点的信息映射到自身。因此使用具有双头注意力机制的图注意力网络。</p><p>由于源域代码具有标签，我们可以根据漏洞分类任务进行预训练，以获得源域图特征向量和训练后的模型。目标域图特征向量可以从训练的模型中获得。预训练损失函数是一个二分类交叉熵损失函数。</p><h4 id="领域自适应表示学习阶段"><a class="markdownIt-Anchor" href="#领域自适应表示学习阶段"></a> 领域自适应表示学习阶段</h4><p>领域自适应表示学习阶段由四个部分组成：重采样和特征映射、源领域漏洞分类器和领域分类器。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142151983.png" alt="image-20240314215125905" /></p><p><strong>Resampling and Feature Mapping</strong></p><p>重采样方法使用SMOTETopek，它是过采样和欠采样的组合。重新采样后的源域平衡数据集和目标域不平衡数据集将进入表示学习网络。</p><p><strong>Source Domain Vulnerability Classifier</strong></p><p>漏洞分类器Cy（xL，yi）的输入是源域代码和源域漏洞标签的特征向量。我们使用完全连接层作为源域漏洞分类器。在每个完全连接的层之后，Relu被用作激活函数，Dropout被用于防止过拟合。为了使目标域样本接近源域样本，除了使用分类损失函数外，我们还设计了域自适应损失函数LST，以不断减少源域和目标域之间的分布差异。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142224423.png" alt="image-20240314222420388" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142225697.png" alt="image-20240314222501665" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142226622.png" alt="image-20240314222647564" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142227904.png" alt="image-20240314222753871" /></p><p><strong>Domain Classifier</strong></p><p>在域分类器中，源域代码的标签为S，目标域代码的标记为T。因此，为了混淆源域和目标域，我们需要最大化域分类误差。域分类器Cd（xG，di）的输入是源或目标域码及其域标签，也就是说，xL∈SõT。我们使用全连接层作为域分类器，在每个全连接层之后使用Relu作为激活函数，并使用Dropout来防止过拟合。DANN[42]设计了一个梯度反转层，确保在反向传播过程中梯度方向自动反转，并在正向传播中进行身份转换。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142228944.png" alt="image-20240314222811899" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403142228852.png" alt="image-20240314222820817" /></p><p>领域自适应表示学习阶段利用领域数据分布自适应的思想，在训练过程中训练整个领域表示学习网络。因此，模型训练有两个目标：第一是减少代码漏洞分类错误，以确保源域数据的正确分类；第二是增加域分类错误，混淆两个域的代码输入。因此，这一阶段的总损失函数包括两个部分：源域漏洞分类损失和域分类损失。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><p>与没有域自适应的漏洞检测方法相比，CPVD在漏洞检测任务中的表现如何？</p><p>与适用于领域的漏洞检测方法相比，CPVD在漏洞检测任务中的表现如何？</p><p>本文中的图特征向量提取阶段的设计如何影响漏洞检测的性能？</p><p>对源域数据重新采样如何影响目标域中的漏洞检测性能？</p><p>与最先进的领域自适应方法相比，我们采用的领域自适应表示学习方法如何影响漏洞检测任务？</p><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr /><p><strong>Cross-Domain Vulnerability Detection</strong></p><p>跨域漏洞检测问题可以看作是一个训练模型并学习通过使用具有大量标签的源域代码来预测目标域代码的漏洞标签问题的问题。因为标签只有两种（漏洞或非漏洞），所以它也可以被视为二分类的问题。==跨域漏洞检测以源域和目标域的代码函数为输入。它使用距离或对抗性网络来测量源域和目标之间的相似性。==它学习目标域的漏洞预测函数F:Xt→ yt，连续训练F使其具有最小的预测误差，然后在目标域中正确地预测输入代码的漏洞分类标签。</p><p><strong>Graph-Based Code Representation</strong></p><p>图的节点表示表达式或代码语句，基于图的表示的边反映节点之间的关系，如控制流、控制依赖关系和数据依赖关系。</p><p>语法树（以下简称AST）是一种特殊类型的图结构。AST是代码解析器理解程序基本结构并检查语法错误的第一步。它可以用于将源代码表示为树。关于语法CD VulD[19]、code2vec[22]和Infercode[23]的结构的信息是以AST结构表达源代码的作品的示例。</p><p>控制流图（以下简称CFG）是一种有向图，它描述了程序中进程的所有可能的实时执行流。条件语句控制执行路径，CFG的节点是单个语句。Cheng等人[24]、Zhuang等人[25]和Yu等人[26]以CFG的形式表示源代码。代码属性图（以下简称CPG）[27]由AST、数据流图、CFG和程序依赖图组成。代码属性图的每个元素都提供了关于源代码整体语义结构的附加上下文。总之，代码属性图是有向的、边类型的属性多重图，至少有一个属性指示每个节点的类型。Devign[13]、BGNN4VD[14]和VulSnipper[28]是由CPG表示为源代码的作品的示例。</p><p><strong>Word Vector Embedding</strong></p><p>Word2vec[29]是一种将语言文本中的每个单词转换为向量的编码方法，然后可以表示单词之间的关系。skip gram模型和CBOW模型包含在Word2vec中。漏洞发现作业中最常用的单词嵌入方法是Word2vec[10]、[11]、[13]、[14]、[30]、[31]。Glove的主要想法是通过统计语料库中同时出现的单词的数量来收集有关全局单词的统计信息[32]。它是一个全局无监督对数双线性回归模型，用于描述无监督学习中的单词表示。Glove还用于表示具有代码函数[16]、[33]的单词嵌入。除了上述两个用于处理图[35]、[36]中节点中代码语句的单词嵌入之外，Doc2vec[34]还被用作程序表示的单词嵌入。研究[35]还发现，在JAVA语言漏洞检测工作中，TF-IDF[37]词向量嵌入方法的性能优于Doc2vec。</p><p><strong>Graph Neural Networks</strong></p><p>由于其卓越的性能和可解释性，图神经网络被广泛应用于推荐系统、知识图分类、文本分类等领域。由于表示学习和单词嵌入的成功，图嵌入和图神经网络已被应用于静态代码漏洞检测任务。图卷积神经网络、[38]门控图神经网络（以下简称GGNN[39]）和GAT是图神经网络的例子。GCN在图神经网络中加入了卷积层的概念，GGNN在图神经网中加入了门控递归单元，GAT在图神经网上加入了注意机制；GAT也是卷积图神经网络的一种。GGNN是一种广泛用于漏洞检测的图神经网络模型，用于提取图特征向量[13]，[14]，[15]，[40]。</p><p><strong>Domain Adaptation</strong></p><p>源域是描述领域自适应中当前先验知识的数据集，而目标域是需要算法学习新知识的数据集[41]。==域自适应的本质是源域和目标域之间的数据分布差异；==因此，数据特征分布自适应将是一个挑战。为了完成从源域到目标域的迁移操作，我们需要设计一种适当的测量方法，该方法能够自适应地估计数据分布的多样性，并不断缩小它们之间的差距。当标签明显缺失时，现在解决不同数据集之间的模型转移是一个关键概念。领域对抗性神经网络（以下简称DANN）[42]是一种领域自适应，它将对抗性机制添加到神经网络的训练中，由三部分组成：特征提取器、分类器和领域鉴别器。特征提取器，通常是神经网络模型，从源域和目标中的数据中提取特征向量；该分类器接受特征向量并将其用于下游分类任务。领域鉴别器决定输入图特征属于哪个领域。DANN有两个目标：一是减少代码分类器的分类误差，二是增加领域的分类误差。DANN被认为是在数据分布自适应的背景下进行边缘分布自适应的一种对抗性策略。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepVD Toward Class-Separation Features for Neural Network Vulnerability Detection</title>
      <link href="/2023/12/18/Papers/Vul/DeepVD%20Toward%20Class-Separation%20Features%20for%20Neural%20Network%20Vulnerability%20Detection/"/>
      <url>/2023/12/18/Papers/Vul/DeepVD%20Toward%20Class-Separation%20Features%20for%20Neural%20Network%20Vulnerability%20Detection/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>包括深度学习（DL）在内的机器学习（ML）的进步使几种方法能够隐式学习易受攻击的代码模式，从而自动检测软件漏洞。最近的一项研究表明，尽管取得了成功，但现有的基于ML/DL的漏洞检测（VD）模型在区分两类漏洞和良性代码方面的能力有限。我们提出了DEEPVD，这是一种基于图的神经网络VD模型，强调漏洞和良性代码之间的类分离特征。DEEPVD在不同的抽象级别上利用了三种类型的类分离功能：**语句类型（类似于词性标记）、后支配树（涵盖常规执行流）和异常流图（涵盖异常和错误处理流）。**我们使用13130种易受攻击的方法，在303个项目的真实世界漏洞数据集中进行了几个实验来评估DEEPVD。我们的研究结果表明，与最先进的基于ML/DL的VD相比，DEEPVD的准确率相对提高了13%–29.6%，召回率为15.6%–28.9%，F评分为16.4%–25.8%。我们的消融研究证实，我们设计的功能和组件有助于DEEPVD实现漏洞和良性代码的高度可分离性。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><p>提出了DEEPVD，这是一种基于图的神经网络VD模型，其目标是利用强调脆弱性和良性类别之间的类分离的特征。我们以以下见解设计DEEPVD。首先，当程序通过一个方法执行时，执行可以以两种方式进行：1）从方法m的开始到m的出口点的规则流，以及2）从m开始到异常/错误处理点的异常/错误操作流。漏洞的主要原因之一是对异常和错误案例的处理不当。例如，程序可能会在输入的数据验证中遗漏一个案例，从而导致通过精心编制的输入进行注入攻击（第二节）。因此，对于方法m，我们捕获从m的输入到异常/错误处理点的程序切片。这些切片被组合成一个数据结构，称为异常流图（EFG）[20]。EFG预计由关键程序元素及其依赖项组成，这些元素与异常/错误的错误处理有关，从而导致漏洞。</p><p>其次，在使用EFG来处理程序中的异常流时，我们还考虑了规则流的每个方法的后支配树（PDT）[21]。<mark>PDT是一个树，其中每个节点表示一个语句，每个边表示后优势关系。如果从s开始到方法出口点的所有路径都必须经过d，则语句d被视为另一个语句s的后支配者。虽然PDT比CFG更简单，但它可以帮助模型学习在通往出口点的规则流中s和d的执行之间的关联。如果d崩溃，s的执行路径将永远不会到达出口点。</mark></p><p>第三，根据Checkmarx[22]的漏洞分析，漏洞代码通常涉及特定的语法类型。因此，我们用一种相当于自然语言处理（NLP）中的词性（POS）标记的技术来增强EFG。POS标记已被证明可以提高下游NLP任务（文本到语音转换[23]、名称实体识别[24]等）的性能。这种标记也应用于代码补全，以实现高精度[25]。对于图表示中的每个语句节点，我们将其与一个语句类型相关联，<strong><mark>因为漏洞通常与特定的语句类型相关，例如数组声明/引用、指针声明/引用，赋值和表达式</mark></strong>[14]，[22]。语句类型补充了EFG和PDT捕获的语义依赖关系，并改进了类分离。EFG和PDT被编码并馈送到VD的标签图卷积网络（标签GCN）[26]和树LSTM[27]中。</p><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403212102060.png" alt="image-20240321210200935" /></p><p>1） 代码序列：方法M的代码标记序列在VD中很重要，因为它包含具体的词法值。我们使用lexer来解析和收集给定方法中的所有词法代码标记。我们将语句视为句子，将代码标记视为单词，并使用嵌入模型来生成所有代码标记的向量表示。在获得所有令牌的嵌入后，我们使用门控递归单元（GRU）[29]来生成整个序列的向量。然后，我们应用空间金字塔池（SPP）[30]来逐步减小GRU产生的向量的空间大小。最后，我们在给定的方法M中获得了表示代码序列的特征向量FCS。</p><p>2） AST上的长路径：作为源代码的重要组成部分，抽象语法树（AST）承载着结构和句法信息。直接使用基于树的嵌入模型的AST结构可能会产生较高的计算成本。相反，我们选择长路径而不是从方法体构建的AST。长路径是指从一个叶节点开始，到另一个叶结点结束，并通过AST的根节点的路径。如先前的工作[31]、[32]所示，可以通过AST节点上具有特定长度的路径来捕获和表示AST结构。以长路径中的节点为例，我们使用嵌入模型、基于注意力的GRU层[33]（对于AST结构），然后使用SPP[30]来构建表示给定方法的长路径的向量FLP（第IV节）。</p><p>3） 后支配树（PDT）：我们首先根据Ferrante等人[21]中的算法构建PDT。由于PDT是树形结构的，我们选择使用tree-LSTM[27]来执行PDT的表示学习，这是一种基于树的神经网络模型，已在源代码中表现良好。另一种设计是将支配后关系添加到EFG中，并使用基于图的神经网络模型来学习表示。我们不选择这种替代方案，因为基于图的模型必须学会区分PDT和EFG中的两种类型的关系。PDT中的每个节点都是一个语句。我们将标记视为单词，将语句视为句子，并使用嵌入模型来构建所有标记的向量。嵌入将经过SPP，然后使用树LSTM模型来生成该方法的特征向量FPDT（第五节）。</p><p>4） 异常流图（EFG）：我们遵循Allen和Horwitz[20]中的算法为给定的方法构建EFG。与PDT中一样，每个EFG节点代表一个语句，因此，我们使用单词嵌入模型和SPP层执行相同的过程来为每个语句生成向量。在这一步骤之后，我们获得了一个图结构，其中每个节点（语句）都由一个向量表示。最后，我们将该图结构作为LabelGCN模型的输入，以生成特征向量FEFG（第六节）。</p><p>5） 调用关系：对于方法M，我们考虑调用方/被调用方方法中的调用/被调用语句。与M中的调用/被调用语句和M的调用/被叫语句一起，我们构建了一个星形图。该图中的每个节点都表示一个语句，因此，对于节点内容，我们使用与上面相同的过程来构建语句的向量。我们还应用网络嵌入Node2Vec[34]对节点进行编码。将表示节点内容和调用结构的向量组合以产生特征向量FCR（第VII节）。最后，使用多层感知器对所有的特征向量进行分类。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403212107473.png" alt="image-20240321210748419" /></p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Devign基于GNN的源代码漏洞检测</title>
      <link href="/2023/12/18/Papers/Vul/Devign/"/>
      <url>/2023/12/18/Papers/Vul/Devign/</url>
      
        <content type="html"><![CDATA[<p>Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks：NIPS(A) 2019，Yaqin Zhou et al.</p><h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>本文提出了Devign模型，一个基于GNN的源代码漏洞检测模型，使用GNN学习丰富的代码语义信息。该模型包括一个Conv模块，其功能是提取有用的特征来进行graph-level的分类。该模型在4个大型开源C项目上进行训练和测试，结果表明Devign明显优于现有技术，平均提高了10.51%的准确率和8.68%的F1值。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><p>本文提出了一种基于复合代码表示的图神经网络模型Devign，可以对程序语义信息进行完整的提取，用以各种捕捉漏洞特征。在复合代码表示中，以AST为中心，将不同级别的数据依赖和控制依赖编码为联合图，其中不同类型的边代表不同的依赖特征。这种复合代码表征综合了各种信息，尽可能广泛的捕捉漏洞类型和漏洞模式，使得GNN能够更好的学习节点表征。</p><p>提取复合代码表征后，经过门控GNN模块，通过对邻接节点信息的聚合和传递来得到各个节点的表征。最后，经过Conv模块选择与当前任务相关的节点和特征集合，应用一维卷积和dense层来对节点特征进行提取从而实现图级别的分类。</p><p>另外，为了验证复合程序编码表征的作用，以及使用GNN进行漏洞检测的效果，本文从4个流行的C库中收集人工标记数据集来进行实验。实验结果表明，Devign比现有方法平均提高了10.51%的准确率和8.68%的F1值，而Conv模块带来了4.66%的精度和6.37%的F1值，将Devign应用到从4个项目中收集到的40个最新的CVE中，得到了74.11%的准确率，在发现新漏洞方面体现了该模型的可用性。</p><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062129788.png" alt="image-20240306212907717" /></p><p>上图是Devign的整体架构，包含三个顺序的部分，首先是复合代码语义embedding层，该层将源代码编码为具有多种代码语义的联合图结构；**第二部分是GNN层，该层通过聚集和传递图中相邻节点的信息来学习节点的特征；**第三部分是Conv模块，提取有意义的节点表征用于图级别的分类预测。</p><ul><li>复合代码表征</li></ul><p>程序分析中的各种程序表示被用来显示程序的内在信息，比如AST，CFG，DFG（数据流图）等等捕捉了源代码的语法和语义关系。很多漏洞不考虑复合代码语义就无法发现，比如有研究表明，仅仅使用AST可以查找不安全参数的漏洞，而将AST与CFG结合则可以查找资源泄露和释放后使用漏洞。进一步，将AST，CFG，DFG联合使用，则可以检测多种类型的漏洞。</p><p>除了以上的三种经典的代码结构，Devign还考虑了源代码序列本身，因为它的flatten结构能以一种“人类可读”的方式捕获代码token之间的联系。接下来分别介绍各种类型的代码表示，以及如何将个各种子图表示为一个联合图。下图(a)是整数溢出代码示例，(b)是图表示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062139644.png" alt="image-20240306213943562" /></p><ul><li>GNN层</li></ul><p>图神经网络的核心思想是通过对相邻节点的信息进行聚合来embedding节点表征，本文使用门控递归图网络来学习节点表征。和正常的GNN一样，通过邻接矩阵来对邻接节点的信息进行聚合，将聚合节点和当前节点一起经过GRU网络得到下一时刻的当前节点。以此类推，经过T时刻，生成所有节点的最终的节点表征。</p><ul><li>Conv层</li></ul><p>图分类的标准方法是将所有的节点特征线性的输入到MLP中然后通过softmax分类，这种方法没有注重重点。Conv模块用来选择与当前任务相关的节点和特征集合，应用一维卷积和dense层来对节点特征进行提取从而实现图级别的分类。</p><h3 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h3><ul><li>Q1：Devign相比其他源代码漏洞检测方法，效果如何？</li><li>Q2：Conv模块与普通的flatten的节点融合相比，有什么优势？</li><li>Q3：复合图特征学习相比单一图有哪些优势？</li><li>Q4：在真实场景中，相比于静态分析器，Devign是否有更好的性能？</li><li>Q5：在CVE公开报告的最新漏洞上，Devign的表现如何？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062148291.png" alt="image-20240306214821244" /></p><p>上图是本文使用的数据集示例，本文评估了从4个大型C语言开源项目中收集的手工标记的函数，这些项目在开发人员中很流行，并且功能多样，例如Linux Kernel, QEMU, Wireshark和FFmpeg。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062149478.png" alt="image-20240306214938378" /></p><p>本文利用基于代码属性图的C/C++开源代码分析平台Joern来提取数据集中所有函数的AST和CFG，上图中的Ggrn意思是普通的flatten的节点融合。将DFG图分为3个子图，DFG_C表示变量的定义，DFG_R表示变量的最近一次读，DFG_W表示变量的最后一次写。下图展示了Devign模型与BiLSTM，BiLSTM-Attention，CNN，以及两种静态方法进行比较的实验结果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062149491.png" alt="image-20240306214951439" /></p><p>下面回答之前提出的5个问题：</p><ul><li>Q1：可见Devign相比其他的模型，准确率和F1值都有明显的提高</li><li>Q2：Devign模型与Ggrn模型相比，准确率平均提高3.23%，F1值平均提高3.92%，说明Conv模块提取了更多相关节点和特征用于图级分类</li><li>Q3：对于Ggrn模型，复合图和单一图的区别不大，而对于Devign模型，复合图的效果优于单一图</li><li>Q4：本文创建了一个具有10%漏洞的不平衡数据集，将Devign与著名的开源静态分析工具Cppcheck、Flawfinder和商业工具CXXX进行比较，Devign的F1平均值显著提高，提升幅度达到了27.99%</li><li>Q5：本文分别提取了各个项目的最近的10个CVE漏洞来检查Devign是否可以识别0-day漏洞。通过对40个CVE漏洞的提交修复提取得到112个漏洞函数，将这些函数输入到经过训练的Devign模型中，平均准确率达到了74.11%，显示了Devign在实际应用中发现新漏洞的潜力。</li></ul><h3 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h3><p>本文提出了一种基于复合代码表示的图神经网络漏洞检测模型Devign, 该模型首先生成联合图提取图节点的复合代码表征，然后通过GNN对邻接节点的信息进行聚合来学习节点特征，最后通过Conv模块选择与当前任务相关的节点和特征集合，通过一维卷积和dense层来进行图级别的分类检测。以函数为检测粒度，针对C代码。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HyVulDect A hybrid semantic vulnerability mining system based on graph neural network</title>
      <link href="/2023/12/18/Papers/Vul/HyVulDect%20A%20hybrid%20semantic%20vulnerability%20mining%20system%20based%20on%20graph%20neural%20network/"/>
      <url>/2023/12/18/Papers/Vul/HyVulDect%20A%20hybrid%20semantic%20vulnerability%20mining%20system%20based%20on%20graph%20neural%20network/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>提出了一个基于混合语义的图神经网络漏洞挖掘系统HyVulDect，该系统基于漏洞的原因构建了一个复合语义代码属性图用于代码表示。使用门控图神经网络来提取深层语义信息。由于大多数漏洞都与数据流相关，我们使用污点分析来提取污点传播链，使用BiLSTM模型来提取上下文的令牌级特征，最后使用分类器对融合特征进行分类。我们引入了一种双重关注机制，使模型能够专注于与漏洞相关的代码，使其更适合于漏洞挖掘任务。实验结果表明，HyVulDect优于现有的最先进的方法，在基准数据集上可以实现92%的准确率。与基于规则的静态挖掘工具Flawfinder、RATS和Cppcheck相比，它具有更好的性能，可以有效地检测实际的CVE源代码漏洞。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><p>现有的软件往往是大规模和复杂的，项目的代码量急剧增加。简单使用手动审计代码的成本非常高，而且很难发现触发条件复杂的漏洞。机器学习和深度学习的发展也被广泛用于软件漏洞挖掘。基于传统机器学习的方法需要手动提取漏洞的特征，并依赖于大量的专家知识。基于深度学习方法，将源代码视为一个自然语言序列，并使用现有的自然语言处理方法进行特征表示，总结漏洞的特征进行检测和分类。这些方法可以有效地捕获源代码中由漏洞触发的上下文信息。然而，**没有考虑源代码的结构特征，**此外，在代码表示中丢失了许多语义信息。尽管图神经网络可以处理代码图表示等非欧几里得数据，但现有的方法将源代码表示为AST和CFG，缺乏源代码的数据依赖性信息，不利于漏洞的检测。同时，直接使用程序源代码作为图神经网络的输入，引入了大量冗余代码，不利于模型的学习。</p><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><p>我们提出了一种基于混合语义的图神经网络漏洞挖掘系统，该系统利用门控图神经网络和具有双重注意力机制的BiLSTM网络来提取源代码图级和令牌级特征。融合两个维度的深层功能可以有效地用于检测漏洞。</p><p>我们改进了基于API调用的程序切片算法（Li et al.，2021），补充了程序切片的结构，在提取漏洞上下文信息的同时保留了代码的结构信息。</p><p>基于该设计方案的实验表明，HyVulDect的检测性能优于传统的静态扫描工具。与最先进的探测器相比，Devign、VUDDY和BGNN4VD的精度分别提高了27.6%、14.2%和4.9%。同时，它可以有效地检测现有的CVE漏洞。</p><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403052145289.png" alt="image-20240305214500170" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403052230552.png" alt="image-20240305223038459" /></p><p>图7（a）是该程序的源代码，它调用wcscpy函数将宽字符串从源复制到目标。首先，我们定位API函数wcscpy函数，它有两个参数数据和SOURCE_STRING。对于属于用户定义函数F ree_Pointer（）的参数数据，该函数的内部切片由五条语句组成，即程序的第17、18、20、21、23行。第23行的badSink（）函数是一个用户定义的函数，用于接收外部参数数据，该函数的内部切片由四行语句组成，即程序的第0、4、6和12行。对于参数SOURCE_STRING，相关联的语句是第15行、第21行。通过参数数据得到的最终切片序列为：17-&gt;18-&gt;20-&gt;21-&gt;23-&gt;0-&gt;4-&gt;6-&gt;12。通过参数SOURCE_STRING得到的最终切片序列为：15-&gt;21。将两个切片序列按照原来的代码顺序组合起来，去掉重复的代码行，基于API函数wcscpy（）的最终切片代码序列为：0-&gt;4-&gt;6-&gt;12-&gt;15&gt;17-&gt;18-&gt;20-&gt;21-&gt;21-&gt;23-&gt;23。图7（c）显示了基于API函数生成的代码切片，可以看出它有效地减少了代码行数。为了减少语料库的规模，我们一对一地替换用户定义的函数和变量（例如badSink（）-&gt;f unc_0（），data-&gt;var_0）。图7（d）显示了变量命名标准化后的程序切片，有效地减少了令牌的数量。尽管之前的操作有效地提取了与漏洞相关的代码行，并删除了不相关的代码，但源代码的结构不再完整。为了补充源代码的结构信息，我们补充了程序片的结构。我们根据程序源代码的结构来补充代码片的结构。算法1详细描述了程序片结构的补充过程。在解析源代码时，提取代码中用户定义的函数和控制块，以补充切片代码。完成切片后，首先从上到下扫描代码切片。如果这行代码是自定义函数，在这行代码下面加上结构代码“{”，继续向下扫描，直到遇到一行不属于自定义函数的代码，在它前面加上“}”，就完成了对函数结构的补充。对于控制结构，有四种主要结构：if条件语句、switch条件语句、For循环语句和while循环语句。补充逻辑与功能相同。在切片结构的补充过程中，我们遵循这样的原则：首先，完成结构的函数；然后，控制结构，因为控制结构通常包含在功能体中。如图7（e）所示，是最终生成的程序切片。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr /><p>污点分析是一种通过程序跟踪和分析污点信息流的技术（Zheng et al., 2019）。 污点是被污染的消息。 在程序分析中，来自外部和进入程序的信息被视为污染信息。 根据分析的需要，程序内部使用的数据也可以作为污点信息，并可以分析与其对应的信息流。 根据污点分析时程序是否运行，可分为静态污点分析和动态污点分析。</p><p>污点分析主要包括污点的来源、污点的汇聚点和消毒剂。污点源是指将污点数据引入到系统中； 污点聚合点是指系统将污点数据输出到敏感数据区或外界，导致敏感数据区被非法改写或隐私数据泄露； sanitizer是指数据传输不再通过数据加密或重新分配等操作损害系统的完整性和机密性。</p><p>污点分析的过程就是识别程序中污点信息的产生点，并对污点信息进行标记； 利用特定的规则来追踪和分析程序中污点信息的传播过程； 并检查关键操作是否会受到某些关键程序点的污点信息的影响。 污点信息的产生点称为源点，污点信息的检查点称为宿点。</p><p>在漏洞分析中，污点分析技术用于将感兴趣的数据（通常来自程序的外部输入，假设所有输入都是危险的）标记为污点数据。 然后通过跟踪与受污染数据相关的信息流，可以了解它们是否会影响某些关键程序操作并探索程序漏洞。 程序是否存在漏洞的问题转化为该操作是否会使用宿点上的污染信息。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trvd Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding</title>
      <link href="/2023/12/18/Papers/Vul/Enhancing%20vulnerability%20detection%20via%20AST%20decomposition%20and%20neural%20sub-tree%20encoding/"/>
      <url>/2023/12/18/Papers/Vul/Enhancing%20vulnerability%20detection%20via%20AST%20decomposition%20and%20neural%20sub-tree%20encoding/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>软件漏洞的爆炸性增长对系统安全构成了严重威胁，已成为当今亟待解决的问题之一。然而，现有的漏洞检测方法在达到检测准确性、效率和适用性之间的平衡方面仍然面临局限性。遵循分而治之的策略，本文提出了TrVD（基于抽象语法树分解的漏洞检测器）来揭示源代码片段中隐含的指示语义，以实现准确高效的漏洞检测。为了便于捕捉细微的语义特征，TrVD使用一种新的分解算法将代码片段的AST转换为大小和深度受限的有序子树集。因此，通过精心设计的树结构神经网络，可以有效地收集每个子树的语义。最后，使用Transformer风格的编码器将所有子树的长程上下文语义聚合到一个特定于漏洞的向量中，以表示目标代码片段。在由不同的真实世界和合成漏洞样本组成的五个大型数据集上进行的广泛实验证明了TrVD在检测漏洞存在和确定漏洞类型方面相对于SOTA方法的性能优势。消融研究也证实了TrVD核心设计的有效性。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h3 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h3><h4 id="可用性"><a class="markdownIt-Anchor" href="#可用性"></a> 可用性</h4><p>其他被广泛采用的代码表示包括CFG、PDG和各种基于图形的变体。这些表示更明确地描述了代码元素之间的控制或数据依赖关系，然而，当面对不可执行或不完整的代码片段时，很难精确推导出这些依赖关系。因此，它们可能并不总是适用于漏洞检测。按照约定，AST可以很容易地为任何代码片段构建，例如文件、函数或单个语句。</p><h4 id="效率"><a class="markdownIt-Anchor" href="#效率"></a> 效率</h4><p>与需要相对复杂和耗时的控制或依赖性分析的代码表示（例如CFG、PDG和代码小工具）相比，从代码构建AST要简单得多，重量轻，从而有助于提高整个检测方法的效率。</p><h4 id="语义综合性"><a class="markdownIt-Anchor" href="#语义综合性"></a> 语义综合性</h4><p>那些人工创建的代码表示（例如，PDG和XFG）倾向于强调代码的特定方面，例如控制流或数据依赖关系。然而，它们经常在转换过程中丢失一些重要信息，这会导致语义损失，尤其是在表示不完整的代码片段时。不同的是，AST使源代码具有高度结构化的性质，其中关于语句和表达式的底层语法是直接可用的；也就是说，AST提供了更全面、更丰富、更精确的代码语义，使TrVD不遗漏任何可疑的漏洞含义，提高了检测的准确性。</p><h3 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h3><p>如前所述，为了充分利用AST的潜力并有效应对其使用带来的挑战（这对漏洞检测能力产生了重大影响），TrVD遵循了经典的分而治之策略。</p><p>Divide</p><p>使用基于图/树的神经网络编码整个AST，如GCN、GAT、tree LSTM和TBCNN，在处理大型/深层树结构时，使用过平滑嵌入捕获长程依赖性可能会大大降低。由于资源限制，这些耗费时间和内存的模型直接处理这样大/深的AST也是非常不可行的。在这方面，<mark>TrVD选择通过分解算法将整个AST划分为有序的子树集，每个子树对应于原始代码片段中的细粒度完整代码单元</mark>。这产生了两个优点：（1）每个子树包含有限（小得多）数量的节点和可控的树深度，并且可以由通用树或图神经网络以成本低廉的方式进行操作；以及（2）更重要的是，这提供了一个机会，通过关注大小受限的本地代码单元来更好地掌握指示漏洞信息的微妙语义，否则可能很容易被忽视。</p><p>Conquer</p><p>TrVD采用“先综合获取后关键点聚焦”的方案，实现对指示性和可疑漏洞语义的有效提取。具体来说，TrVD首先用新设计的树结构神经网络处理每个子树，将其对应代码单元的语义映射到数字向量中。基于所学习的子树嵌入，TrVD然后利用基于Transformer的主干来不同地关注越来越不重要的子树，以发现具有自注意机制的漏洞模式，并将所有子树的长程上下文语义融合到密集的、特定于漏洞的数字向量中，以表示目标代码片段。从这个意义上说，TrVD在代码表示学习中的方式类似于基于切片的方法，其中通过根据兴趣点对相关语句进行切片而生成的代码小工具（例如，库/API函数）通过常规NLP模型（例如LSTM）容纳有助于学习局部特征和帮助精确定位漏洞模式的信息。但是，在TrVD中细化的子树更结构化，不那么模糊，而为注意力增强子树聚合而设计的Transformer能够更好地嵌入上下文，以提高漏洞检测性能。</p><h3 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h3><ul><li>我们提出了一种新的漏洞检测方法，称为TrVD，在每个公式化阶段都经过精心设计，使其成为一种准确、高效、更实用的方法，适用于代码片段。具体而言，为了提高其检测隐藏良好的漏洞和特定漏洞类型的能力，它结合了新的AST分解、注意力增强子树编码和上下文感知语义聚合，从而能够从目标代码片段中提取微妙但特定于漏洞的语义，据我们所知，在基于DL的漏洞检测工作中尚属首次。</li><li>我们进行了大量的实验来评估TrVD的性能、不同组成模块的有效性以及运行时开销。实证研究表明，在大多数数据集上，TrVD在检测漏洞的存在或识别特定漏洞类型方面的准确性、F1和精度优于最先进的基于DL的方法。TrVD核心设计的优势，如AST分解和子树编码，也通过消融研究得到了证实。</li><li>我们提供了一个新的数据集来促进漏洞检测研究。该数据集包含264822个C/C++函数，每个函数都标有特定的CWE ID或非易受攻击的基本事实。TrVD实现的数据集和源代码已在https://github.com/XUPT-SSS/TrVD，以促进未来的基准测试或比较。</li></ul><p>AST分解，注意力增强子树编码，上下文感知语义聚合，</p><p>新数据集</p><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h3 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403042035978.png" alt="image-20240304203524892" /></p><p>目标源代码片段依次通过五个主要模块进行处理：</p><p>（1）AST生成器，它以语义保持的方式对代码片段进行规范化，并使用解析器构建其AST；</p><p>（2） AST分解器，使用分解算法将AST转换为有序的子树集；</p><p>（3） 综合语义收集器，通过树结构的神经编码器，将每个子树中传递的语义迭代提取为实值向量；</p><p>（4） 可疑语义焦点，它将所有收集到的子树语义聚合到一个上下文化的嵌入向量中，该嵌入向量通过基于Transformer的模型处理更具漏洞特定性的语义；</p><p>（5） 漏洞检测器，它实现了一个多层感知器（MLP），该感知器具有用交叉熵损失训练的softmax层来预测输出。</p><h4 id="ast-decomposer"><a class="markdownIt-Anchor" href="#ast-decomposer"></a> AST decomposer</h4><h4 id="单个令牌序列"><a class="markdownIt-Anchor" href="#单个令牌序列"></a> 单个令牌序列。</h4><p>遍历算法通常用于将AST展平为记号序列，包括前序遍历（Tang，Shen et al.，2022；Zhang，Wang，Zhang，Sun，&amp;Liu，2020）和中序遍历（Svyatkovskiy，赵，Fu，&amp;Sundaresan，2019）。为了避免信息丢失，SBT（Hu，Li，Xia，Lo，&amp;Jin，2018）和SPT（Niu et al.，2022）通过添加额外的符号来指示父子关系，进一步改进了这些方法，以确保线性化的序列可以明确地映射回AST，然而，这会使序列变得更大。另一种方法code2seq（Alon，Levy，&amp;Yahav，2019）将叶节点之间收集的采样路径连接起来，形成单个令牌序列，该序列通常太长，神经编码器无法有效处理语义提取，尤其是漏洞检测任务。</p><h4 id="令牌序列集"><a class="markdownIt-Anchor" href="#令牌序列集"></a> 令牌序列集。</h4><p>PathTrans（Kim，赵，Tian，&amp;Chandra，2021）将AST映射到一组根路径，每个根路径由通过从叶节点向上遍历根或从根向下遍历叶节点而获得的令牌组成（Jiang，Zheng，Lyu，Li，&amp;Lyu，2021），并指出特定代码元素（即叶节点）所在的纵向上下文。根路径可以用作学习令牌嵌入的输入；然而，由于每条路径只包含零碎的代码元素，从中学习到的不完整语义可能会降低训练和检测性能。</p><h4 id="子树"><a class="markdownIt-Anchor" href="#子树"></a> 子树。</h4><p>ASTNN（Zhang et al.，2019）和Infercode（Bui，Yu，&amp;Jiang，2021）等方法不是将AST线性化为标记序列，而是将其分解为一组子树，以利用句法结构。采用不同的粒度来分割AST，其中ASTNN生成与代码语句相对应的非重叠子树，而Infercode生成与表达式等较小代码元素相对应的具有重叠的子树。</p><p>该论文的分解器：</p><p>给定根节点，它通过访问者和构造函数递归地划分子树。访问者沿着AST执行先序遍历，将每个节点传递给构造函数，用于节点类型检查、复合语句分解和子树构建，其中构建的子树按顺序附加到集合中。这里，最终集合中每个子树的顺序由其对应代码在原始代码片段中的位置决定。图中给出了一个示例。3有助于理解我们的AST分解算法及其与ASTNN的区别。更具体地说，以图3（a）中的归一化代码为输入，我们的算法将其AST分解为12个子树，按其在代码中的出现顺序排列。与ASTNN相比，我们的算法的差异也得到了说明：对于代码中从第6行到第10行的if复合语句，我们的方法生成一个集成子树，而ASTNN将其拆分为三个子语句的平凡子树，如图中蓝色虚线所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403192205858.png" alt="image-20240319220539749" /></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404182057753.png" alt="image-20240418205716678" style="zoom: 50%;" /><h4 id="算法解释"><a class="markdownIt-Anchor" href="#算法解释"></a> 算法解释</h4><p><strong>输入参数：</strong></p><ul><li><p>T：输入的抽象语法树（AST）。</p></li><li><p>α：子树的最大深度限制。</p></li><li><p>β：子树中允许的最大节点数限制。</p></li><li><p>C：一个包含特定类型语句的列表，这些语句被认为是复合语句。</p></li></ul><p><strong>输出：</strong></p><ul><li>D：一个有序的子树集合。</li></ul><p>TREESPLITTING 函数：这是算法的核心函数，它递归地遍历AST，并根据给定的参数将树分解成子树。</p><p><strong>初始化：</strong></p><ul><li>node：从当前树 t 获取根节点。</li></ul><p><strong>处理语句节点：</strong></p><ul><li>如果 node 是一个语句节点（即不是复合语句），并且它不在复合语句类型列表 C 中：<ul><li>如果节点的大小（trSize(node)）小于 α 并且深度（trDepth(node)）小于 β：<ul><li>构造一个以 node 为根的子树，并将其添加到子树集合 D。</li><li>使用 subTreeConstructor 函数构造子树。</li></ul></li><li>否则：<ul><li>构造一个以 node.header 为根的子树，并将其添加到 D。</li></ul></li></ul></li></ul><p><strong>递归处理子节点：</strong></p><ul><li>对于 node 的每个子节点 child：<ul><li>递归调用 TreeSplitting 函数，将 child、D、α、β 和 C 作为参数。</li></ul></li></ul><p><strong>处理复合语句节点：</strong></p><ul><li>如果 node 是复合语句（即在列表 C 中）：<ul><li>对于 node 的每个子节点 child：<ul><li>递归调用 TreeSplitting 函数。</li></ul></li></ul></li></ul><p><strong>结束函数：</strong></p><ul><li>函数结束时返回子树集合 D。</li></ul><p><strong>复合语句类型列表</strong> C 包含了被认为是复合语句的类型，如函数定义、if、for、while、do-while、switch、try 和 catch。</p><p><strong>算法调用：</strong></p><p>最后，算法通过调用 TreeSplitting(T, D, α, β, C) 来启动，其中 T 是初始的AST。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IVDetect</title>
      <link href="/2023/12/18/Papers/Vul/IVDetect/"/>
      <url>/2023/12/18/Papers/Vul/IVDetect/</url>
      
        <content type="html"><![CDATA[<h2 id="一背景"><a class="markdownIt-Anchor" href="#一背景"></a> 一.背景</h2><p>现有的漏洞检测方法大部分只是根据给定代码片段，确认该片段是否包含漏洞（分类）。而并没有指出哪些statement有问题。因此作者提出了IVDetect。主要包括</p><ul><li>用一个新的代码表示方法。作者基于PDG对代码进行表示（源代码用图结构表示），并从PDG提取不同的信息将其向量化。并使用FA-GCN（Graph Convolution Network with feature-attention）对其进行分类。</li><li>用可解释方法（GNNExplainer）对FA-GCN的分类结果进行解释。GNNExplainer基于edge-mask对输入图选取子图进行解释。作者试图找出是哪些statement决定了分类结果。</li></ul><p>作者用三个数据集进行测试： Fan，Reveal，FFMPeg+Qemu</p><h2 id="二motivation"><a class="markdownIt-Anchor" href="#二motivation"></a> 二.motivation</h2><p>example：</p><p>下面展示了linux 4.6的<code>ec_device_ioctl_xcmd</code>方法。这个方法为CromeOS设备构造I/O控制命令。编号为CVE-2016-6156</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">long</span> <span class="title function_">ec_device_ioctl_xcmd</span><span class="params">(<span class="keyword">struct</span> cros_ec_dev *ec, <span class="type">void</span> __user *arg)</span>&#123;</span><br><span class="line"><span class="type">long</span> ret;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cros_ec_command</span> <span class="title">u_cmd</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cros_ec_command</span> *<span class="title">s_cmd</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (copy_from_user(&amp;u_cmd, arg, <span class="keyword">sizeof</span>(u_cmd)))</span><br><span class="line"><span class="keyword">return</span> -EFAULT;</span><br><span class="line"><span class="keyword">if</span> ((u_cmd.outsize &gt; EC_MAX_MSG_BYTES) || (u_cmd.insize &gt; EC_MAX_MSG_BYTES))</span><br><span class="line"><span class="keyword">return</span> -EINVAL;</span><br><span class="line">s_cmd = kmalloc(<span class="keyword">sizeof</span>(*s_cmd) + max(u_cmd.outsize, u_cmd.insize), GFP_KERNEL);</span><br><span class="line"><span class="keyword">if</span> (!s_cmd)</span><br><span class="line"><span class="keyword">return</span> -ENOMEM;</span><br><span class="line"><span class="keyword">if</span> (copy_from_user(s_cmd, arg, <span class="keyword">sizeof</span>(*s_cmd) + u_cmd.outsize)) &#123;</span><br><span class="line">ret = -EFAULT;</span><br><span class="line"><span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">&#125;</span><br><span class="line">+   <span class="keyword">if</span> (u_cmd.outsize != s_cmd-&gt;outsize ||u_cmd.insize != s_cmd-&gt;insize) &#123;</span><br><span class="line">+    ret = -EINVAL;</span><br><span class="line">+      <span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">+   &#125;</span><br><span class="line">s_cmd-&gt;command += ec-&gt;cmd_offset;</span><br><span class="line">ret = cros_ec_cmd_xfer(ec-&gt;ec_dev, s_cmd);</span><br><span class="line"><span class="comment">/* Only copy data to userland if data was received. */</span></span><br><span class="line"><span class="keyword">if</span> (ret &lt; <span class="number">0</span>)</span><br><span class="line"><span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">-   <span class="keyword">if</span> (copy_to_user(arg, s_cmd, <span class="keyword">sizeof</span>(*s_cmd) + u_cmd.insize))</span><br><span class="line">+   <span class="keyword">if</span> (copy_to_user(arg, s_cmd, <span class="keyword">sizeof</span>(*s_cmd) + s_cmd-&gt;insize))</span><br><span class="line"> ret = -EFAULT;</span><br><span class="line"><span class="built_in">exit</span>:</span><br><span class="line"> kfree(s_cmd);</span><br><span class="line"> <span class="keyword">return</span> ret;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>commit信息显示：At line 6 and line 13, the driver fetches user space data by pointer <code>arg</code> via <code>copy_from_user().</code> The first fetched value (stored in <code>u_cmd</code>) (line6) is used to get the <code>in_size</code> and <code>out_size</code> elements and allocation a buffer (<code>s_cmd</code>) at line 10 so as to copy the whole message to driver later at line 13, which means the copy size of the whole message(<code>s_cmd</code>) is based on the old value (<code>u_cmd.outsize</code>) from the first fetch. Besides, the whole message copied at the second fetch also contains the elements of <code>in_size</code> and <code>out_size</code>, which are the new values. The new values from the second fetch might be changed by another user thread under race condition, which will result in a double-fetch bug when the inconsistent values are used.（内核代码看不太懂，大家见谅，希望有大佬能补充下，大概意思就是可能造成double-fetch，一个fetch就是一次获取用户数据（<code>copy_from_user()</code>））</p><p>修复这个bug需要保证在这两次获取用户输入之间变量<code>u_cmd.outsize</code>和<code>u_cmd.insize</code>不会由于条件竞争而改变。</p><p>针对上述问题，DL-based方法可以将上述函数进行分类（是否包含漏洞），但不能定位到一个具体的行（statement），因此作者在这里用可解释的方法对分类结果进行解释。它会提供一个PDG的子图（几个重要的statement）来解释。</p><p>比如：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619008.png" alt="在这里插入图片描述" /></p><p>针对example代码，框出来的即为可解释方法选出的有问题的代码行。同时，针对没问题的代码，可解释方法也会提供相应的信息。</p><h2 id="三key-ideas-and-architecture-overview"><a class="markdownIt-Anchor" href="#三key-ideas-and-architecture-overview"></a> 三.Key Ideas and Architecture Overview</h2><p>IVDetect架构如下图所示：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619001.png" alt="在这里插入图片描述" /></p><p>作者用GNNExplainer作为其解释模型，GNNExplainer会选取关键的子图和子特征（比如一个结点特征向量100维，选取其中5维，不过这需要这个特征向量具备好的解释性，比如词袋向量比word2vec好解释）作为解释。</p><ul><li>对于子特征，如果mask掉node的某些特征会对分类结果造成明显影响，那么该这些特征应该包括在解释结果里</li><li>选取子图的选择是，mask掉子图会影响分类结果（有漏洞变没漏洞），子图由一些关键statement和相应控制依赖和数据依赖组成。</li></ul><h3 id="31-representation-learning"><a class="markdownIt-Anchor" href="#31-representation-learning"></a> 3.1 Representation Learning</h3><p>对于PDG结点（一个statement）的向量表示，作者设置了几组向量特征，一个图结点的最终向量表示由这几组拼接而成。</p><ul><li>Sequence of Sub-tokens of a Statement<br />这里将statement转化成sub-token序列，即将某些token再切分为sub-token，和BERT的tokenizer有些类似。这里作者在sub-token序列中只保存变量名（variables），函数名（method names）和类名（class names）。token会根据CamelCase或者Hungarian convention来进行sub-token，并删除单字符sub-token。比如，对于代码<code>if (copy_to_user(arg, s_cmd, sizeof(*s_cmd) + u_cmd.insize))</code>。sub-token序列为<code>copy, to, user, arg, etc</code>。可以看到并没有<code>if,_,(</code>等token。 之后，用glove来<a href="https://so.csdn.net/so/search?q=%E5%90%91%E9%87%8F%E5%8C%96&amp;spm=1001.2101.3001.7020">向量化</a>单个token，并用GRU将整个statement的序列向量化成向量 F 1 F_1F1​。</li><li>Code Structure of a Statement<br />从AST中捕获一个statement的AST子树，并用Tree-LSTM将其向量化为向量 F 2 F_2F2​。</li><li>Variables and Types<br />对于每个node（statement），收集其中的变量名和变量类型。并用和sub-token同样的向量化方式来进行向量化。比如<code>struct cros_ec_command *s_cmd;</code>中变量名<code>s_cmd</code>，类型<code>cros_ec_command</code>。（这块没太看懂，可能要看下代码了）。得到的向量记为 F 3 F_3F3​。</li><li>Surrounding Contexts<br />将跟该statement存在数据依赖和控制依赖的其它结点分别向量化，并用GRU和glove将这些向量统一计算成 F 4 F_4F4​ 和 F 5 F_5F5​（具体操作还得看代码）。</li><li>Attention-based Bidirectional GRU<br />最后，用Bi-GRU + attention模型将上面得到的 F 1 ， F 2 ， . . , F 5 F_1， F_2， … , F_5F1​，F2​，…,F5​ 转化成 最终结点向量（真的太复杂了）。流程如下图所示</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619044.png" alt="在这里插入图片描述" /></p><h3 id="32-vulnerability-detection-with-fa-gcn"><a class="markdownIt-Anchor" href="#32-vulnerability-detection-with-fa-gcn"></a> 3.2 Vulnerability Detection with FA-GCN</h3><p>下图展示了作者如何用FA-GCN来进行分类任务，FA-GCN在处理稀疏特征以及潜在噪声时非常好用。</p><p>下图中，join layer层之前的操作都是 3.1 中的内容，join layer将所有statement的向量拼成一个矩阵 Feature Matrix。之后就是卷积过程（数学不好没看懂），最终就是通过Classifier分类。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619063.png" alt="在这里插入图片描述" /></p><h3 id="33-graph-based-interpretation-model"><a class="markdownIt-Anchor" href="#33-graph-based-interpretation-model"></a> 3.3 Graph-Based Interpretation Model</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061620149.png" alt="image-20240406162046101" /></p><h2 id="四实验目标"><a class="markdownIt-Anchor" href="#四实验目标"></a> 四.实验目标</h2><p>作者的目标还挺多了，又分类又解释还要挖掘漏洞pattern。</p><h3 id="41-comparison-on-the-method-level-vulnerability-detection"><a class="markdownIt-Anchor" href="#41-comparison-on-the-method-level-vulnerability-detection"></a> 4.1 Comparison on the Method-Level Vulnerability Detection</h3><p>用IVDetect和其它漏洞分类方法进行比较，有VulDeepecker，SySeVR，Reveal，Devign还有token-based方法。作者这里还使用了AutoML来调参。</p><p>评估指标</p><ul><li>Precision ( P )</li><li>Recall ( R )</li><li>F score ( F )</li><li>Mean Average Precision ( MAP )<br />这个指标需要先理解PR曲线，这里有篇从PR-&gt;MAP都有的<a href="https://blog.csdn.net/xys430381_1/article/details/90770520?ops_request_misc=%7B%22request%5Fid%22%3A%22162643753116780269846149%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=162643753116780269846149&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-12-90770520.pc_search_result_cache&amp;utm_term=MAP+%E6%8C%87%E6%A0%87&amp;spm=1018.2226.3001.4187">讲解</a>。</li><li>Normalized DCG<br />貌似是推荐系统用的指标，不是很清楚</li><li>First Ranking ( FR )<br />我也没太看懂这个是用来衡量什么的</li><li>Accuracy under curve ( AUC )<br />AUC曲线，可以参考<a href="https://blog.csdn.net/liweibin1994/article/details/79462554?ops_request_misc=%7B%22request%5Fid%22%3A%22162643810616780255247871%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=162643810616780255247871&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-1-79462554.pc_search_result_cache&amp;utm_term=AUC&amp;spm=1018.2226.3001.4187">这篇</a></li></ul><h3 id="42-comparison-with-other-interpretation-models-for-fine-grained-vd-interpretation"><a class="markdownIt-Anchor" href="#42-comparison-with-other-interpretation-models-for-fine-grained-vd-interpretation"></a> 4.2 Comparison with other Interpretation Models for Fine-grained VD Interpretation</h3><p>这里作者拿GNNExplainer和其它解释方法进行了对比，对比的方法有</p><ul><li>ATT<br />用来衡量边的重要性的Graph attention机制</li><li>Grad<br />基于梯度的方法</li></ul><p>因为解释方法的对比需要有定位到漏洞行号的数据集，因此只有Fan数据集可以使用，其它两个只有哪些方法有漏洞的信息，并没有fix。这里，作者用在Reveal和FFMPeg+Qemu数据集上训练的FA-GCN模型来对Fan数据集分类。</p><p>对于错误分类（标签1，预测0）的作者不考虑进行解释。而同时，由于标签0的函数没有fix信息，解释出来也没法评估，所以作者只考虑标签1预测1的（TPR）。</p><p>Evaluation Metrics：</p><p>对于一个解释子图 G M G_MGM。S SS 为从vulnerable版本的代码中删除和修改的statement的集合。修改的目的是修复漏洞。如果 S ∈ G M S \in G_MS∈GM，那么解释结果算正确，否则错误。也就是所有的vul statement都要包括才行。</p><p>对于fixed版本，S ′ S^{’}S′ 为添加的statement的集合。而此时 G M G_MGM 包含任意一个 S ′ S^{’}S′ 中的statement，就算正确，否则失误。</p><p>作者还用了Mean First Ranking (MFR)和 Mean Average Ranking (MAR)来评估解释结果，不过没太看懂这两个指标。</p><p>需要注意的是作者并没有用fidelity和sparsity这2个指标，也许不符合人的直觉吧。</p><h3 id="43-vulnerable-code-patterns-and-fixing-patterns"><a class="markdownIt-Anchor" href="#43-vulnerable-code-patterns-and-fixing-patterns"></a> 4.3 Vulnerable Code Patterns and Fixing Patterns</h3><p>对于用GNNExplainer产生的一系列解释子图，作者用挖掘算法从这些子图中挖掘出漏洞pattern以及从fixed版本中挖掘fix pattern。这里并没有客观评价指标。</p><h3 id="44-sensitivity-analysis-for-internal-features"><a class="markdownIt-Anchor" href="#44-sensitivity-analysis-for-internal-features"></a> 4.4 Sensitivity Analysis for Internal Features</h3><p>作者在前面提到了对于图结点向量表示用了4种特征（token sequence, AST, type, 控制依赖和数据依赖算一种）。这里作者从只用其中一个特征（token）对statement向量化开始，一步一步添加特征，评估不同特征对结果的影响。</p><p>评估指标和4.1相同。</p><h3 id="45-sensitivity-analysis-on-training-data"><a class="markdownIt-Anchor" href="#45-sensitivity-analysis-on-training-data"></a> 4.5 Sensitivity Analysis on Training Data</h3><p>分别用(80%, 10%,10%), (70%, 15%, 15%), (60%, 20%, 20%)和(50%, 25%, 25%)的(training, tuning, testing)数据集划分比率来研究效果。</p><h3 id="46-time-complexity"><a class="markdownIt-Anchor" href="#46-time-complexity"></a> 4.6 Time Complexity</h3><p>评估实际训练和测试用时。</p><h2 id="五实验结果"><a class="markdownIt-Anchor" href="#五实验结果"></a> 五.实验结果</h2><h3 id="51-comparison-on-the-method-level-vulnerability-detection"><a class="markdownIt-Anchor" href="#51-comparison-on-the-method-level-vulnerability-detection"></a> 5.1 Comparison on the Method-Level Vulnerability Detection</h3><p>这里作者做的对比实验还挺多的，并且分别在FFMPeg+Qemu，Fan，Reveal数据集上分别测试的。</p><p>先看看precision, recall, F1 3个指标<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619015.png" alt="在这里插入图片描述" /></p><p>其它指标</p><p>FFMPeg+Qemu数据集<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619035.png" alt="在这里插入图片描述" /><br />Fan数据集<br /><img src="https://img-blog.csdnimg.cn/20210717150915119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" /><br />Reveal数据集<br /><img src="https://img-blog.csdnimg.cn/20210717150932483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" /></p><h3 id="52-comparison-with-other-interpretation-models-for-fine-grained-vd-interpretation"><a class="markdownIt-Anchor" href="#52-comparison-with-other-interpretation-models-for-fine-grained-vd-interpretation"></a> 5.2 Comparison with other Interpretation Models for Fine-grained VD Interpretation</h3><p>作者对比了3种解释方法的效果（GNNExplainer, Graph Attention, Grad）。用到的指标上面也提到了，accuracy是与分类的类似（correct or incorrect。correct定义上面说过）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619519.png" alt="在这里插入图片描述" /></p><h3 id="53-vulnerable-code-pattern-analysis"><a class="markdownIt-Anchor" href="#53-vulnerable-code-pattern-analysis"></a> 5.3 Vulnerable Code Pattern Analysis</h3><p>作者从前面的解释任务中收集了700+解释子图。作者先用与VulDeepecker和SySeVR相似的符号化（把变量名用VAR替代等待）方式预处理解释子图，然后用下面参考文献1提到的子图pattern挖掘算法配上不同的size限制来挖掘不同大小的子图pattern。</p><p>作者在此进行人工验证。不过没评估好坏，只是数个数。</p><p><img src="https://img-blog.csdnimg.cn/20210717152227969.png" alt="在这里插入图片描述" /><br />作者还贴上了2个example</p><p>下图展现了2个不同的漏洞pattern。第一个属于api误用，包括<code>is_link,exit,cop_file</code>，第二个调用了<code>udf_get_filename</code>这个有漏洞的函数，这个漏洞可以通过添加第5个参数得到修复。<br /><img src="https://img-blog.csdnimg.cn/20210717152339673.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" /></p><p>下图则是fixing pattern。第一个是为了修复多线程下数据加锁类问题，可以看到修复方式就是加锁。第二个图是为了修复一个缓冲区溢出漏洞。<br /><img src="https://img-blog.csdnimg.cn/20210717152359704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzcwNjc2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" /></p><h3 id="54-sensitivity-analysis-for-features"><a class="markdownIt-Anchor" href="#54-sensitivity-analysis-for-features"></a> 5.4 Sensitivity Analysis for Features</h3><p>下表展示了不同特征对漏洞分类的效果影响。涉及名词有</p><ul><li>sequence of sub-tokens (SST)</li><li>sequence of tokens (ST)</li><li>control dependency（CD）</li><li>data dependency（DD）<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619883.png" alt="在这里插入图片描述" /></li></ul><p>可以看到作者对比的特征是ST，ST+SST，ST+SST+AST等等。逐级递增，但并没有单独测试AST,VAR等等。</p><h3 id="55-sensitivity-analysis-on-training-data"><a class="markdownIt-Anchor" href="#55-sensitivity-analysis-on-training-data"></a> 5.5 Sensitivity Analysis on Training Data</h3><p>数据集切分方式的影响<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061619877.png" alt="在这里插入图片描述" /></p><h2 id="六参考文献"><a class="markdownIt-Anchor" href="#六参考文献"></a> 六.参考文献</h2><blockquote><p>[<a href="https://dl.acm.org/doi/10.1145/1595696.1595767">1] Tung Thanh Nguyen, Hoan Anh Nguyen, Nam H. Pham, Jafar M. Al-Kofahi, and Tien N. Nguyen. 2009. Graph-Based Mining of Multiple Object Usage Patterns.</a><br />[<a href="https://arxiv.org/abs/2106.10478">2] Li Y , Wang S , Nguyen T N . Vulnerability Detection with Fine-grained Interpretations. 2021.</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LineVD_Statement-level Vulnerability Detection using Graph Neural Networks</title>
      <link href="/2023/12/18/Papers/Vul/LineVD-Statement-level-Vulnerability-Detection-using-Graph-Neural-Networks/"/>
      <url>/2023/12/18/Papers/Vul/LineVD-Statement-level-Vulnerability-Detection-using-Graph-Neural-Networks/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>当前基于机器学习的软件漏洞检测方法主要在功能级别进行。然而，这些方法的一个关键限制是，它们没有指示导致漏洞的特定代码行。这限制了开发人员有效检查和解释学习模型预测的能力，这对于将基于机器学习的工具集成到软件开发工作流中至关重要。基于图的模型在功能级漏洞检测方面表现出了良好的性能，但其在语句级漏洞检测中的能力尚未得到广泛探索。**虽然通过可解释的人工智能解释功能级预测是一个很有前途的方向，但我们在这里从完全监督学习的角度来考虑语句级软件漏洞检测任务。**我们提出了一种新的深度学习框架LineVD，它将语句级漏洞检测定义为节点分类任务。**LineVD利用图神经网络和基于转换器的模型对原始源代码标记进行编码，从而利用语句之间的控制和数据依赖性。**特别是，通过解决函数级和语句级信息之间的冲突输出，LineVD显著提高了函数代码在没有漏洞状态的情况下的预测性能。我们针对从多个真实世界项目中获得的大量真实世界C/C++漏洞进行了广泛的实验，并证明F1分数比当前最先进的技术提高了105%.</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><p>自动化SVD大致可分为两类：</p><p>（1）传统方法，包括静态和动态分析；</p><p>（2）数据驱动解决方案，利用数据挖掘和机器学习来预测软件漏洞；</p><p>尽管当前的数据驱动方法在识别软件漏洞方面取得了成功，但它们往往局限于粗粒度水平。模型输出通常为开发人员提供有限的预测结果验证和解释信息，导致在评估和缓解软件漏洞时付出额外努力。</p><p>许多SVD解决方案已经从文件级过渡到函数级或切片级预测，其他一些工作进一步利用补充信息，如提交级别的代码更改以及附带的日志消息，来构建预测模型。虽然目标是帮助从业者对有缺陷的代码进行优先级排序，但漏洞通常可以局限于几个关键行。因此，审查大型函数仍然可能是一个相当大的负担。</p><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312182057555.png" alt="image-20231218205705483" style="zoom:67%;" /><p>为了节省空间，我们从一个较小的函数中选择一个漏洞，该函数包含Linux内核（CVE-2018-12896）中的整数溢出漏洞，该漏洞最终可能被利用来导致拒绝服务。通过显式语句级别的预测，可以更容易地解释为什么函数被预测为易受攻击（或者，验证预测是否错误）。语句级SVD模型将第22行上的加法赋值操作标记为最可疑的，该操作包含易受攻击的整数强制转换操作，使开发人员能够更有效地验证和减轻该漏洞。</p><p>先前的工作利用GNNExplainer来导出易受攻击的语句作为模型的解释，以展示在语句级的工作。然而，在我们的工作中，我们发现在对潜在的脆弱性语句进行分类和排序时，性能是不充分和有效的。或者，我们旨在探索在语句级别直接训练和预测漏洞以进行SVD粒度细化的可行性和有效性，这将允许数据驱动的解决方案以完全监督的方式直接利用任何可用的语句级别信息。</p><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><ul><li>提出了一种新颖有效的语句级SVD方法，LineVD实现了显著的改进，F1得分增加了105%；</li><li>研究了构建基于GNN的语句级SVD模型的每个阶段的性能影响，包括节点嵌入方法和GNN模型选择。根据研究结果，开发LineVD是为了通过同时学习功能和语句级别的信息，在很大程度上提高性能。</li><li>LineVD是第一种通过图神经网络联合学习函数级和语句级信息以提高SVD性能的方法，在经验评估中，它显著优于仅使用一种类型信息的传统模型。</li><li>发布了数据集、源代码和带有支持脚本的模型，这为未来的基准测试和比较工作提供了一个现成的实现解决方案。<a href="https://github.com/davidhin/linevd">https://github.com/davidhin/linevd</a></li></ul><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312182110490.png" alt="image-20231218211008424" /></p><p>首先将问题定义为，节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">V\rightarrow Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>的映射，也就是语句是否易受攻击。</p><p>通过学习最小化损失loss:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>L</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>G</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>Y</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">min\sum_{i=1}^nL(f(G_i, Y_i|V_i))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p><strong>Feature Extraction</strong></p><p>LineVD将源代码的单个函数作为原始输入。通过处理函数并将其拆分为单独的语句Vi，首先通过CodeBERT的预训练BPE标记器对每个样本进行标记。在V＝{V1，V2，…，Vn}的集合之后，整个函数和包括该函数的各个语句被传递到CodeBERT中。因此，可以获得函数级和语句级的代码表示。</p><p>具体而言，LineVD分别嵌入了函数级和语句级代码，而不是为函数级嵌入聚合语句级嵌入。CodeBERT是一个双峰模型，这意味着除了函数代码本身之外，它还基于函数的自然语言描述进行了训练。作为输入，它使用一个特殊的分隔符标记来区分自然语言描述和函数代码。虽然函数的自然语言描述是不可访问的，但在这项工作中应用了文献中规定的一般操作，在每个输入前添加一个额外的分隔符标记，使描述为空白。对于CodeBERT的输出，我们使用了分类标记的嵌入，这适用于代码摘要任务。这使我们能够更好地利用CodeBERT模型强大的预训练源代码摘要功能。</p><p>总体而言，使用CodeBERT的LineVD的特征提取组件产生n+1个特征嵌入：一个嵌入用于整个函数，n个嵌入用于每个语句，我们分别表示为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mi>v</mi><mo>=</mo><mrow><msubsup><mi>x</mi><mn>1</mn><mi>v</mi></msubsup><mo separator="true">,</mo><msubsup><mi>x</mi><mn>2</mn><mi>v</mi></msubsup><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msubsup><mi>x</mi><mi>n</mi><mi>v</mi></msubsup></mrow></mrow><annotation encoding="application/x-tex">Xv={x^v_1,x^v_2,…,x^v_n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9125em;vertical-align:-0.24810799999999997em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span>。</p><p><strong>Graph Construction</strong></p><p>在LineVD中，我们专注于数据和控制相关性信息，为此我们引入了图注意力网络（GAT）模型。如第2.2节所述，图神经网络（GNN）基于信息扩散机制学习图结构数据，而不是将信息压缩成平面向量，平面向量根据图的连通性更新节点状态，以保留重要信息，即拓扑依赖信息。</p><p><strong>Classifier Learning</strong></p><p>目标是训练一个可以同时从函数级和语句级代码中联合学习的模型。为了实现这一点，我们认为函数级和语句级代码片段对预测结果的贡献相等。因此，我们利用函数级CodeBERT嵌入的输入和从GAT层获得的语句嵌入，构建了一组共享的线性层和dropout层。</p><p>虽然易受攻击的语句可能足以指示函数易受攻击，但我们使用元素乘法构建LineVD，以进一步利用函数级别的信息进行训练。此外，这种操作和谐地平衡了函数级和语句级嵌入之间的冲突输出，并将证明某些场景的决策是合理的，即，如果函数级嵌入的输出类为零，那么所有语句级输出也为零。对此的直觉是，非易受攻击的函数不可能具有易受攻击的代码行。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><p>最近的研究表明，SVD模型应该根据能够代表真实世界漏洞不同特征的数据进行评估[10]。这意味着评估从真实世界项目中提取的源代码（即非合成的），同时保持不平衡的比率，这是软件项目中漏洞固有的。在现实世界场景中应用时，使用不满足这些条件的数据集会导致模型性能的不一致。另一个数据集要求是足够多的样本，理想情况下跨越多个项目，以便获得一个可以很好地推广到看不见的代码的模型。最后一个要求是在语句级别访问基本事实标签，或可追溯到修复前代码，即原始gitcommit。</p><p><strong>Ground-Truth labels</strong></p><p>为了获得易受攻击和非易受攻击线路的基本事实标签，我们遵循文献[19，32]中的断言，而不是提出我们自己的启发式方法：（1）漏洞修复提交中删除的线路用作易受攻击的线路的指标，以及（2）所有依赖于添加线路的控制或数据的线路也被视为易受攻击。第二点的理由是，在漏洞修复提交中添加的任何行都是为了帮助修补漏洞。因此，在漏洞修复提交中未修改但与这些添加的行相关的行可以被视为与漏洞相关。为了获得与依赖于添加行的行相对应的标签，我们首先获得样本前后版本的代码变化，其中Big Vul中的样本指的是函数级代码片段。对于之前的版本，我们删除所有添加的行，对于之后的版本，删除所有删除的行。在这两种情况下，我们都保留空白占位符行，以确保行号的一致性。从后版本中提取的代码图可用于查找所有依赖于添加行的控制或数据行，这些行的行号对应于前版本。这组线可以与删除的线组合，以获得单个样本的最终脆弱线集。注释行被排除在代码图中，因此不用于训练或预测。这可以从图1和图2中看出；在这种情况下，只有一个修改的行，它被视为删除的行（22）和添加的行（23）。在这种情况下，前后版本的控制和数据依赖边恰好相同，因此我们可以使用图2来识别依赖于第23行的控制/数据的行，即第3、19和21行。</p><p><strong>Cleaning</strong></p><p>原始数据集中的一些样本被错误地截断，导致代码样本无法解析且无效。例如，一个原本是50行的函数可能会因为没有明显原因而被错误地截断为40行。原因可能是数据集最初是如何构建的错误；然而，在整个数据集中只有30个这样的样本。我们使用80:10:10的随机训练/验证/测试分割比。对于训练集，我们对不可破坏样本的数量进行了不足采样，以在函数级别生成近似平衡的数据集，而测试和验证集保持原始的不平衡比例。我们选择在函数级别上平衡样本，因为在语句级别上进行平衡，同时保持函数中语句之间的上下文依赖关系是非常重要的。</p><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><ul><li><p>RQ1：与最先进的基于解释的SVD模型相比，LineVD可以实现多大的性能提升？</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190937348.png" alt="image-20231219093737314" /></p></li><li><p>RQ2：不同的代码嵌入方法如何影响语句级漏洞检测？与其他粒度级别的SVD相比，语句级SVD的代码嵌入方法尚未得到探索。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190940483.png" alt="" /></p></li><li><p>RQ3：图神经网络和函数级信息如何对LineVD性能做出贡献？使用图神经网络的信息传播对语句级SVD的影响还有待探索。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190942923.png" alt="" /></p></li><li><p>RQ4：LineVD在跨项目分类场景中的表现如何？虽然在包含多个项目的数据集上进行训练已经减少了对模型通用性的歪曲，但来自同一项目的样本仍然有可能出现在训练集和测试集中。使用跨项目场景可以更好地表示模型在完全看不见的项目上的表现，而不仅仅是看不到的样本。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190943968.png" alt="image-20231219094311928" /></p></li><li><p>RQ5：对于真实世界的数据，LineVD最能区分哪些语句类型？从语句类型的角度研究模型预测结果，特别是对于真实世界的数据，可以帮助了解模型在哪里表现最好，在哪里失败，这可以指导未来的工作和语句级SVD的改进。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312190943357.png" alt="image-20231219094343320" /></p></li></ul><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><p>LineVD，一种用于语句级漏洞检测的新型深度学习方法，它可以让开发人员更有效地评估潜在的漏洞功能。LineVD通过在训练过程中利用图神经网络和语句级信息，在真实世界的开源项目中实现了最先进的语句级漏洞检测。与最新的基于细粒度机器学习的模型相比，这一显著改进表明了直接利用语句级信息进行语句级SVD的有效性。最后，LineVD实现了合理的跨项目性能，表明即使对于完全看不见的软件项目，它也具有有效性和泛化能力。未来的方向将包括探索替代的预训练特征嵌入方法和新的GNN架构，这些架构可以更好地适应软件源代码的底层性质和漏洞。</p><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
            <tag> 代码行级检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Detecting Vulnerabilities using Patch-Enhanced Vulnerability Signatures</title>
      <link href="/2023/12/18/Papers/Vul/MVP/"/>
      <url>/2023/12/18/Papers/Vul/MVP/</url>
      
        <content type="html"><![CDATA[<h3 id="paper"><a class="markdownIt-Anchor" href="#paper"></a> Paper</h3><p>MVP: Detecting Vulnerabilities using Patch-Enhanced Vulnerability Signatures：USENIX 2020，Yang Xiao et al.</p><h3 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h3><p>重复漏洞（Recurring Vulnerability）广泛存在于真实的系统中，这些漏洞通常由可重用的代码库或共享的代码逻辑导致，因此同样的漏洞很可能在其他地方也存在而未被发现。本文提出了一种新的方法<strong>MVP</strong>来检测具有低假阳性和低假阴性的重复漏洞，首先利用新的程序切片技术从漏洞函数及其补丁函数中提取漏洞和补丁的语法和语义特征。如果目标函数匹配漏洞特征，但不匹配补丁特征，则该目标函数会被识别为存在漏洞。</p><p>本文在10个开源系统上对MVP方法进行实验，结果表明，MVP显著优于目前的基于克隆和基于功能匹配的重复漏洞检测的SOTA方法；MVP检测到了通用的漏洞检测方法无法检测到的重复漏洞；MVP检测到97个新的漏洞，并获得了23个CVE认证。</p><h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3><p>由于软件系统中代码库的重用或代码逻辑的共享(对不同用途的相似对象使用相似的处理逻辑)，使得具有相似特征的重复漏洞广泛存在，但在现实程序中却无法检测到，因此，重复漏洞检测得到了广泛的普及。本文的目的就是检测重复出现的漏洞，也即给定一个在程序中以一种特定的方式运行的漏洞，检测其他程序是否可能存在这种同样形式的漏洞。</p><p>现有的检测重复漏洞的方法可以分为两种：</p><ul><li>一种是基于代码克隆的方法，该方法将重复漏洞的检测问题视为代码克隆的检测问题，从已知的漏洞中提取token或语法级的signature，并将该signature的克隆代码视作漏洞。</li><li>另一种是基于函数匹配的方法，该方法不考虑任何漏洞特征，直接将已知的漏洞函数作为signature，检测是否存在这些signature的克隆函数。</li></ul><p>该领域目前存在的两个主要挑战是如何区分已经修补完成的漏洞，减少假阳性率；以及如何精确的生成一个已知漏洞的signature，来减少假阳性和假阴性。</p><p>本文提出了一个针对重复漏洞的漏洞检测方法MVP，<strong>为了解决第一个挑战，MVP不仅生成漏洞的signature，还同时生成补丁的signature</strong>。利用漏洞特征来检测可能存在的漏洞，并利用补丁特征来区分这些漏洞是否已经打过补丁。<strong>为了解决第二个挑战，我们提出了一种新的切片方法，只提取与漏洞和补丁相关的语句，在语法和语义级别生成更加精确的漏洞和补丁的signature</strong>。此外，我们采用语句抽象和基于熵的语句选择来进一步提高MVP的准确性。</p><p>本文在10个C/C++开源项目上对MVP方法进行了实验，发现了97个尚未被发现的安全漏洞，并获得了23个CVE认证。同时，将MVP与四种现有的SOTA方法进行比较，发现MVP在准确率上明显更胜一筹。</p><h3 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h3><p>本文在10个项目的34019对漏洞和补丁函数上进行了实验，使用SourcerCC同一对漏洞函数和补丁函数的相似度，发现有91.3%的样本对二者相似度均超过了70%，而实验证明有35.1%的真实漏洞目标函数与原漏洞函数的相似度小于70%，所以很难通过仅仅计算目标函数与漏洞函数的相似度来判断是否有漏洞，还要计算目标函数与补丁函数的相似度来综合判断。</p><h3 id="method"><a class="markdownIt-Anchor" href="#method"></a> Method</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958816.jpeg" alt="img" /></p><p>上图是本文MVP模型的Framework架构图，一个以函数为检测粒度的重复漏洞检测框架，主要包含以下3个步骤：(以下用“sig”代指“signature”)</p><ul><li>生成目标函数的sig：输入待检测的目标系统，为系统中的每个目标函数生成sig。</li><li>生成漏洞代码和补丁代码的sig：输入安全补丁程序，生成漏洞和补丁的sig，从漏洞产生和漏洞修复的角度反映漏洞，得到一个具有众多漏洞和补丁sig的待匹配集合。</li><li>将目标系统中的每个函数的sig与漏洞和补丁sig进行匹配：如果在待匹配集合中发现了与目标函数sig相匹配的漏洞sig，但不存在相匹配的补丁sig，则认为目标函数存在重复漏洞。</li></ul><p>接下来进行详细解读。</p><p>首先，定义函数签名，给定一个C/C++函数f，将f的签名定义为一个元组(fsyn，fsem)，其中fsyn是函数中所有语句的哈希值的集合；fsem是由一系列3元组(h1，h2，type)构成的集合，h1和h2表示任意两个语句的哈希值，type ∈\in\in {data，control}表示哈希值为h1的语句和哈希值为h2的语句具有数据依赖或控制依赖关系。<strong>fsyn捕获目标函数的语句作为语法签名；fsem捕获目标函数语句之间的数据依赖和控制依赖关系，作为语义签名</strong>。二者提供了一个函数的补充信息，以帮助提高匹配精度。</p><p>其次，使用(fv,pv)来代表一对漏洞函数和对应的补丁函数。给定一对(fv,pv)，函数Patch Pv由一个或多个hunk（块）组成。hunk是Patch中的一个基本单元，它由上下文行、已删除的代码行和已添加的代码行组成。删除的行在fv中，但不再pv中；添加的行不在fv中，但在pv中。</p><ul><li><strong>生成目标函数的signature</strong></li></ul><p>该过程有3个步骤，首先是parsing过程，使用Joern来parse代码生成代码属性图（一个AST、PDG、CFG联合的数据结构），以获取目标系统的所有函数，对每个目标函数生成AST和PDG。然后对函数做规范化处理，对形参、局部变量和字符串常量替换为同一形式，删除所有注释、大括号、tab、空白。</p><p>最后，进行函数签名的生成，首先对规范化后的函数中的每个语句计算hash值，得到fsyn。接着从函数的PDG中提取两个语句之间的数据和控制依赖关系，每一组关系表示成一个三元组的形式(h1，h2，type)，下图展示了一个从原始目标函数到生成sig的完整过程。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958827.jpeg" alt="img" /></p><ul><li><strong>生成漏洞代码和补丁代码的signature</strong></li></ul><p>给定一对(fv,pv)和Patch Pv，下面阐述如何生成sig来捕获与漏洞相关的关键语句，而不是将fv和pv中的所有语句都包含在内，以此获得小而准确的sig来进行有效匹配。</p><p>首先识别代码变化，通过解析安全补丁的头文件（diff文件）来识别更改的文件，通过解析diff文件来查找已删除和添加的语句及其行号。同时找到所有函数的起始和结束地址，如果一个语句包括一个或多个已删除（已添加）的代码行，则认为该语句已删除(已添加)，通过比较语句行号和函数行号的关系来确定哪些函数被更改。以此可以获得已添加的语句集合 SaddS_{add}S_{add} ，已删除的语句集合 SdelS_{del}S_{del} ，漏洞函数语句 SvulS_{vul}S_{vul} ，补丁函数语句SpatS_{pat}S_{pat} 。</p><p>利用切片技术可以提取相关的语句并排除无关的语句，本文在PDG上执行前向和后向切片，使用SaddS_{add}S_{add}和 SdelS_{del}S_{del} 作为切片的标准。传统的程序切片方法存在一定的问题，比如下图的例子，如果将第18行的条件语句作为切片标准，那么前向切片包含了太多的语句(19-40)，其中会包含很多与该漏洞无关的噪声语句，而如果将标准严格到与18行直接相关的前向切片，则只有23和24行，真正的漏洞行28行又没有包含在内。也就是说<strong>如果要求直接相关，则切片可能不包含漏洞语句，而如果允许间接相关，切片又存在太多的噪声</strong>。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958834.jpeg" alt="img" /></p><p>再比如说下图的例子，如果以第3行的函数调用作为切片标准，由于其没有返回值，因此只能得到后向切片而无法得到前向切片。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958824.jpeg" alt="img" /></p><p>基于以上的问题，本文提出了一种新的切片方法，将SaddS_{add}S_{add}和 SdelS_{del}S_{del} 中的每个语句作为切片的标准。对于后向切片，正常的基于PDG进行后向切片，获取与标准句相数据依赖和控制依赖的所有语句。对于前向切片，根据不同的语句类型执行不同的切片准则：</p><ul><li>赋值语句：正常按照数据流进行前向切片即可</li><li>条件语句：前向切片过程中只针对条件语句中使用的变量或参数切片（只考虑数据依赖），只有当这样产生的切片为空时，才考虑控制依赖</li><li>返回语句：不需要进行前向切片，因为返回值和返回语句与后面的语句无依赖关系</li><li>其他：包括未使用返回值的函数调用语句，对变量和参数的数据依赖语句切片</li></ul><p>（注：上面条件语句和其他语句指的数据依赖并不是严格意义上的数据依赖，而是先回溯到变量和参数的定义语句再求数据依赖，比如上图正常来说第4行和第3行不存在数据依赖，但在上面的语境下是存在的，第4行在第3行的前向切片中）</p><p>将SdelS_{del}S_{del}以及其对应的前向后向切片放在一起，构成了 SdelsemS_{del}<sup>{sem}S_{del}</sup>{sem} 蕴含着该函数已删除的语句的语义信息， SaddsemS_{add}<sup>{sem}S_{add}</sup>{sem} 同理。</p><p>接下来分别从语法和语义级别上计算漏洞sig和补丁sig，即(Vsyn,Vsem)和(Psyn,Psem)，漏洞sig与漏洞的产生相关，补丁sig与漏洞的修补相关。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958801.jpeg" alt="img" /></p><p>首先是计算Vsyn，SdelsemS_{del}<sup>{sem}S_{del}</sup>{sem}包含了漏洞产生的语义信息，但有漏洞的修改过程不涉及删除语句，只有增加语句，因此还要补上与增加的语句数据或控制依赖的原漏洞函数语句，也就是(1)式，然后根据PDG图由Vsyn得到Vsem，由SdelsemS_{del}<sup>{sem}S_{del}</sup>{sem}得到Tsem。接着将 SaddsemS_{add}<sup>{sem}S_{add}</sup>{sem} 和 SvulS_{vul}S_{vul} 做差集找到只存在于补丁函数中的语句即为Psyn，然后先根据PDG图计算漏洞函数的三元组集F，用T和F做差集就可以得到只存在于补丁函数中的语句（新加的语句）的三元组集Psem。</p><p>然而按照上述方式生成Vsyn还是会发现存在噪声，而且发现Vsyn这与删除(添加)语句远的语句更有可能是噪声。因此本文提出了一种基于信息熵的漏洞语句选择方法。</p><p>设目标系统中语句的总个数为N，Vsyn中某个语句s在目标系统中出现的次数为n，则信息熵为</p><p>Is=−log§=−log(nN)∝1nI_s=-log§=-log(\frac{n}{N}) \propto \frac{1}{n}I_s=-log§=-log(\frac{n}{N}) \propto \frac{1}{n}</p><p>对Vsyn中的所有语句的信息熵求和，得到总信息熵 III ，如果 III 高于某一阈值就不断的删除离删除(添加)语句最远的语句，直到低于该阈值，或者直到剩余的语句均为与改动代码直接数据或控制依赖的语句。</p><p>接着对Sdel，(Vsyn,Vsem)和 (Psyn,Psem)进行如上文所述的规范化处理和计算hash值，得到漏洞sig和补丁sig，对所有的漏洞补丁代码对处理后得到待检测集合。</p><ul><li><strong>将目标系统中的每个函数的signature与漏洞和补丁signature进行匹配</strong></li></ul><p>那么有了目标系统中每个目标函数的sig(fsyn,fsem)，以及删除的语句Sdel，漏洞的sig(Vsyn, Vsem)，补丁的sig(Psyn,Psem)，根据以下原则判断目标函数是否具有漏洞（与漏洞sig匹配但与补丁sig不匹配），规则有以下5条：</p><ul><li>目标函数必须包含所有已删除的语句</li><li>目标函数的签名与漏洞签名在语法层次上匹配（Vsyn和fsyn的交集大于某一阈值）</li><li>目标函数的签名与补丁签名在语法层次上不匹配（Psyn和fsyn的交集小于某一阈值）</li><li>目标函数的签名与漏洞签名在语义层次上匹配（Vsem和fsem的交集大于某一阈值）</li><li>目标函数的签名与补丁签名在语义层次上不匹配（Psem和fsem的交集小于某一阈值）</li></ul><h3 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h3><p>实验回答以下五个问题：</p><ul><li>Q1：与最先进的方法相比，MVP在检测重复漏洞方面的准确性如何？</li><li>Q2：与最先进的方法相比，MVP在检测重复漏洞方面的开销程度如何？</li><li>Q3：在MVP的匹配过程中，如何配置阈值？</li><li>Q4：语句抽象和语句信息的采样对结果的影响有多大？</li><li>Q5：其他漏洞检测方法检测重复漏洞的性能如何？</li></ul><p>本文作者对10个开源的C/C++项目代码进行测试，包含了25377个patch和34,378个有变动的函数，具体数据集如下表所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958794.jpeg" alt="img" /></p><p>本文将MVP模型与两类SOTA方法进行对比，一类是基于代码克隆的重复漏洞检测方法，比如Redebug和VUDDY。另一类是基于函数匹配的方法，比如SourcererCC和CCAligner。最后还对比了VulDeepecker和Devign这两种方法，都是目前漏洞检测领域非常优秀的方法。</p><ul><li>Q1：与最先进的方法相比，MVP在检测重复漏洞方面的准确性如何？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958242.jpeg" alt="img" /></p><p>由上图可见，在10个开源系统上MVP模型的准确率和召回率都大幅领先。</p><ul><li>Q2：与最先进的方法相比，MVP在检测重复漏洞方面的开销程度如何？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958250.jpeg" alt="img" /></p><p>由上图可见，该类方法都可以分为系统分析、补丁分析、匹配三部分，简单来说，时间花销与方法的规模是成比例的，ReDeBug是基于token的，VUDDY是基于语法的，MVP是基于语义的，因此所花费的时间也是以此递增。</p><ul><li>Q3：在MVP的匹配过程中，如何配置阈值？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958358.jpeg" alt="img" /></p><p>由上图可见，当匹配的漏洞sig大于0.8且补丁sig小于0.2时，MVP可以达到较高的准确率。当匹配的漏洞sig大于0.8时，召回率会大幅下降，而匹配的补丁sig比例不影响召回率（因为其实相当于不考虑补丁sig的话，主要问题是假阳性率，对召回率影响不大）。</p><ul><li>Q4：语句抽象和语句信息的采样对结果的影响有多大？</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290958341.jpeg" alt="img" /></p><p>如上图所示，其含义是Vsyn采样时信息熵阈值的大小对结果的影响。有图可见，该采样的效果还是非常明显的，阈值在5时，准确率和召回率最高。</p><ul><li>Q5：其他漏洞检测方法检测重复漏洞的性能如何？</li></ul><p>本文还对比了VulDeepecker和Devign这两种方法，发现MVP的结果远远好于这两种方法，VulDeePecker召回率仅为7.2%，Devign召回率为36.0%。</p><h3 id="limitation"><a class="markdownIt-Anchor" href="#limitation"></a> Limitation</h3><ul><li>MVP只专注于重复漏洞</li><li>使用joern生成代码属性图，只适用于C/C++</li><li>通过宏来修复的漏洞代码无法进行检测</li><li>对形式参数、局部变量和字符串进行抽象，无法发现有相似函数调用或相似数据类型的漏洞</li></ul><h3 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h3><p>本文提出了一个重复漏洞检测模型MVP，该模型通过同时生成漏洞signature和补丁signature的方式来区分漏洞函数是否打过补丁；同时提出了一种新的函数切片方法，只提取与漏洞和补丁相关的语句，在语法和语义级别生成更加精确的漏洞和补丁的signature。方法过程如下：首先对于待检测的目标系统，为系统中的每个目标函数生成signature；接着生成安全补丁数据集中每一个（漏洞，补丁）对对应的漏洞signature和补丁signature；最后将目标系统中的每个目标函数的signature与漏洞和补丁signature进行匹配，如果在待匹配集合中发现了与目标函数signature相匹配的漏洞signature，但不存在相匹配的补丁signature，则认为目标函数存在重复漏洞。该方法以函数为检测粒度，针对C/C++代码。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Modeling and Discovering Vulnerabilities with Code Property Graphs</title>
      <link href="/2023/12/18/Papers/Vul/Modeling%20and%20Discovering%20Vulnerabilities%20with%20Code%20Property%20Graphs/"/>
      <url>/2023/12/18/Papers/Vul/Modeling%20and%20Discovering%20Vulnerabilities%20with%20Code%20Property%20Graphs/</url>
      
        <content type="html"><![CDATA[<h2 id="modeling-and-discovering-vulnerabilities-with-code-property-graphsspa-2014-fabian-yamaguchi-et-al"><a class="markdownIt-Anchor" href="#modeling-and-discovering-vulnerabilities-with-code-property-graphsspa-2014-fabian-yamaguchi-et-al"></a> Modeling and Discovering Vulnerabilities with Code Property Graphs：S&amp;P(A) 2014, Fabian Yamaguchi et al.</h2><h3 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h3><p>本文提出了一种基于代码属性图CPG的源代码漏洞检测方法。代码属性图是包括抽象语法树AST、控制流图CFG和程序依赖图PDG的一个联合数据结构。本文通过图的遍历（graph traversals）来进行漏洞检测，检测的漏洞类别包括缓冲区溢出（buffer overflows），整数溢出（integer overflows），内存泄漏（memory disclosures），格式化字符串漏洞（format string vulnerabilities）。本文使用一个图数据库来实现该方案，并在Linux内核源代码中识别了18个以前未知的漏洞，证明了该方案的有效性。</p><h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148238.jpeg" alt="img" /></p><p>以上图为示例代码，介绍一下AST、CFG、PDG的含义。</p><ul><li>AST</li></ul><p>AST的全名为抽象语法树，是代码解析器或者编译器产生的一种代码的中间表示形式，是很多其它代码表示基础。AST非叶子节点表示运算或赋值操作，叶子节点表示常量或标识符，表达了代码的表达式和语句嵌套生成程序的方式。AST蕴含着丰富的代码语法信息，但缺乏控制流和数据依赖等信息，示例代码的AST如下图(a)所示。</p><ul><li>CFG</li></ul><p>CFG的全名为控制流图，表示了每条代码语句的执行顺序以及需要满足的条件分支，CFG的每个结点表示1条代码语句，结点之间通过有向边连接表示执行的顺序和分支。AST可以经过2个步骤变成CFG：首先用if, while, for等控制语句建立初步的CFG，然后用goto，break等语句来对CFG图进行修正。CFG可以用在许多安全应用上，比如检测已知恶意代码的变种以及指导模糊测试的工具，示例代码的CFG如下图(b)所示。</p><ul><li>PDG</li></ul><p>PDG的全名为程序依赖图，最初用于程序切片任务中，PDG同时包含数据依赖和控制依赖，数据依赖指的是变量的使用语句与变量的定义或赋值语句存在数据依赖；控制依赖指的是一条语句的执行与否依赖于另一条语句执行的结果，则称这两条语句控制依赖。示例代码的PDG如下图©所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148300.jpeg" alt="img" /></p><p>上文所述每种程序表示（AST，CFG，PDG）都是从不同的角度表示程序，而CPG就是要结合这几种表示，属性图在许多图数据库（ArangoDB，Neo4J，OrientDB）中是结构化数据的基础表示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148279.jpeg" alt="img" /></p><p>一个简单的属性图如上图所示，每个节点的属性key均为k，而属性value有x和w两个值，获取属性图的特征信息的主要方式是graph traversals（图的遍历）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148241.jpeg" alt="img" /></p><p>图的遍历有以上3种方式，分别是获取邻接节点，获取类别为l的边的可达节点，以及获取类别为l的边且属性为k和s的可达节点。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148245.jpeg" alt="img" /></p><p>上图就是一个CFG的完整实例，其中包括AST,CFG,PDG的边，包含语法和语义信息，控制依赖和数据依赖</p><ul><li>与AST对比，整个函数的AST被切分成4个语句的AST，并用CFG和PDG的边串起</li><li>与CFG对比，每个语句用它的AST来表示而不仅仅是token序列，并且多了PDG的边</li><li>与PDG对比,  每个语句用它的AST来表示而不仅仅是token序列，并且多了CFG的边</li></ul><p>本文的贡献点：</p><ul><li>CPG：一种结合了AST,CFG,PDG三种程序表示的综合图表示</li><li>CPG遍历检测漏洞：常见类型的漏洞可以被建模为代码属性图的遍历，并生成有效的漏洞检测模板</li><li>高效执行：将CPG导入到图数据库中后，可以高效的处理大型代码库</li></ul><h3 id="method"><a class="markdownIt-Anchor" href="#method"></a> Method</h3><p>下面，使用下图的C代码举例，展示本文是如何通过CPG图的遍历来检测4种代码漏洞的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148251.jpeg" alt="img" /></p><p>channelp-&gt;exit_signal =LIBSSH2_ALLOC(session, namelen +1);这行代码种namelen是用户输入的变量，所以可能会导致漏洞，本文从以下几个方面分析漏洞：</p><ul><li>Sensitive operations：敏感操作包括调用受保护的函数，缓冲区复制数据，比如示例中的算数表达式就需要特别关注，需要检查AST</li><li>Type usage：同时变量类型也需要进行关注，如果namelen是16位而不是32位变量就不会出现漏洞，该类型也需要检查AST</li><li>Attacker control：检测哪些data source处于用户控制之下很重要，这个示例中，_libssh2_ntohu32的返回值就是用户可控的，可以借助PDG中的数据依赖来建模</li><li>Sanitization：许多程序由于缺乏数据校验而导致漏洞，在示例中，如果对namelen进行校验，确保它的值在合适范围内，那么漏洞不会发生，此时需要检查CFG</li></ul><p>下面以3种漏洞为例，介绍分析代码属性图提供的不同视图如何有助于构建成功的图遍历以发现漏洞。</p><ol><li>Syntax-Only Vulnerability：在CPG中，语句内部的问题可以通过AST解决，而语句之间的依赖关系则需要CFG和PDG来处理。AST层面主要有如下问题：</li></ol><ul><li><p>Insecure arguments：不安全的参数，主要出自函数调用参数，比如格式化字符串漏洞(printf)，其中格式化字符串的一个必须满足的条件就是传递的第一个参数不是常量（比如%s）。</p></li><li><p>Integer overflows：整数溢出常常发生在内存分配（malloc）的算术运算中（+，*），比如LIBSSH2_ALLOC (session, namelen + 1);的第二个参数。所以在遍历AST时需重点访问malloc类函数调用中的算术运算结点。</p></li><li><p>Integer type issues：问题主要出现在赋值操作中，左边的数据类型宽度要小于右边的宽度（比如左边short，右边int），这在遍历AST的时候可能分别需要遍历赋值运算符的左右子树。</p></li><li><p>Control-Flow Vulnerability：引入CFG可以对更多的漏洞类型建模，通过使用代码属性图的控制流边，可以建模语句的执行顺序，从而可以访问更大范围的漏洞，比如：</p></li><li><p>Resource leaks：当资源被分配（allocate）但并没有被释放的时候，会导致系统爆内存，进而使得无法被外部访问。在CFG中，从分配内存空间的函数调用（malloc）开始，到释放这个指针的函数（free）构成一个路径，如果只有malloc没有free，则说明出现了内存泄露。</p></li><li><p>Failure to release locks：虽然在一般情况下并发问题很难检测到，但可以使用简单的控制流分析来检测在错误路径上没有释放锁的情况。</p></li><li><p>Use-after-free vulnerabilities：内存被释放后没有置为NULL，导致可能被再次利用，简单的控制流分析就足以在一个函数中识别这类漏洞。</p></li><li><p>Taint-Style Vulnerability：结合语法、控制和数据流信息对漏洞进行建模，与只使用语法和控制流的漏洞分析相比，加上PDG可以使用数据流边建模额外的代码漏洞，比如：</p></li><li><p>Buffer overflow vulnerabilities：缓冲区溢出漏洞大多由没有对输入数据进行校验导致，在许多linux内核代码中，当系统从get_user读取外部输入数据作为第3个参数传递给copy_from_user或者memcpy函数时会触发该漏洞。所以遍历的时候需要检查get_user的第一个参数和copy_from_user(memcpy)的第3个参数。</p></li><li><p>Code injection vulnerabilities：在C语言中，注入类漏洞通常在CPG中存在从recv第2个参数到system第1个参数的路径，并且中间没有对字符串进行校验和检查。</p></li><li><p>Missing permission checks：web应用程序和内核代码通常都需要在执行操作之前检查用户权限，这类漏洞没有对用户可控数据进行检查，确保他们有足够的权限。</p></li></ul><h3 id="experiment"><a class="markdownIt-Anchor" href="#experiment"></a> Experiment</h3><p>为了进行评估，我们基于代码属性图的遍历过程实现了一个静态代码漏洞检测系统。针对不同的漏洞类型使用不同的代码表示来处理，如下图所示。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148630.jpeg" alt="img" /></p><p>本文使用对CPG图遍历的方式在Linux内核源代码中识别了18个以前未知的漏洞，证明了该方案的有效性。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291148698.jpeg" alt="img" /></p><h3 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h3><p>本文提出了一种基于代码属性图CPG的源代码漏洞检测方法，基于一种新颖的源代码表示形式，即代码属性图CPG，通过对图的遍历来对常见漏洞进行建模于检测。使用CPG图遍历的方式，本文对缓冲区溢出、格式字符串漏洞和内存地址泄漏等漏洞进行了建模与分析检测。此外，本文还审计了一个Linux内核代码库，并在源代码中确定了18个以前未知的漏洞，这些漏洞由供应商确认并修复。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Path-Sensitive Code Embedding via Contrastive Learning for Software Vulnerability Detection</title>
      <link href="/2023/12/18/Papers/Vul/Path-Sensitive%20Code%20Embedding%20via%20Contrastive%20Learning%20for%20Software%20Vulnerability%20Detection/"/>
      <url>/2023/12/18/Papers/Vul/Path-Sensitive%20Code%20Embedding%20via%20Contrastive%20Learning%20for%20Software%20Vulnerability%20Detection/</url>
      
        <content type="html"><![CDATA[<h1 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h1><p>为了获得代码的结构信息，当前的学习方法通常将程序抽象成图的形式（例如，数据流图，抽象语法树），然后基于安全和易受攻击的代码片段的（子）图来训练底层分类模型以进行漏洞预测。然而，这些模型仍然不足以精确检测缺陷，因为这些模型的目标是产生分类结果，而不是理解漏洞的语义，例如，关键的漏洞触发路径，这对于静态漏洞检测至关重要。本文提出了ContraFlow，这是一种选择性但精确的对比值流嵌入方法，用于静态检测软件漏洞。**ContraFlow的新颖之处在于使用自监督对比学习从预训练的路径嵌入模型中选择和保留可行的值流（也称为程序依赖）路径，从而显著减少了训练昂贵的下游模型进行基于路径的漏洞检测所需的标记数据量。**我们使用288个真实项目评估了ContraFlow，比较了八种最近的基于学习的方法。ContraFlow在信息度、标记度和F1得分方面的表现优于这八个基线方法，最高分别提高了334.1％、317.9％和58.3％，而在定位有缺陷的语句方面，ContraFlow的平均语句召回率、平均语句精度和平均IoU方面的改进分别最高提高了450.0％、192.3％和450.0％。</p><h1 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h1><h2 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h2><p>Existing Efforts and Limitations. 最近提出了代码嵌入，旨在通过分布式向量表示来表示代码语义，用于源代码分析和错误检测。</p><ul><li>最初，嵌入方法将程序视为文本标记[49-51]，通过应用自然语言处理技术来学习代码语义，而不需要代码结构信息。后来，几种方法[7, 10, 48, 81]通过保留结构信息（例如，通过程序依赖图）改进了嵌入结果，然后使用图神经网络（GNNs）[41, 47]来分类代码片段的（子）图是否易受攻击。</li><li>尽管学习代码的图表示可以用于代码分类或摘要任务，但对于基于路径的漏洞检测仍然不足。 这是因为输入图表示不区分程序路径，而后端GNNs无法识别程序路径。 图特征是从GNNs中所有连接节点对之间的消息传递中学习的，但不幸的是，缺乏任何可行/不可行的值流（程序依赖）路径的知识。but unfortunately, without the knowledge of any feasible/infeasible value-flow (program dependence) paths.</li><li>因此，这些预测模型并不知道潜在的错误路径，这些路径显示了错误的产生和触发方式。这是静态错误检测的主要目标之一：帮助从业者快速定位并修复报告的漏洞。</li></ul><p>Insights and Challenges. 为了解决上述限制，检测方法需要基于精确的学习模型，该模型能够保留价值流路径，而不是整个图，该图无法区分可行/不可行的程序依赖路径。受到词嵌入中令牌袋的概念的启发，一些最近的代码嵌入方法对抽象语法树（ASTs）或值流图（VFGs）上的路径进行了嵌入以进行代码分类和摘要 [62]。这些方法随机抽样一小部分路径以产生它们的嵌入向量，然后聚合它们形成代码片段的最终表示。然而，这些方法不能直接用于诸如基于路径的错误检测等复杂任务，因为可能存在需要嵌入的无界程序路径的数量。</p><p>基于路径的模型的有效性在于路径选择策略。**识别和保留个别可行路径而不是通过随机抽样聚合不可行或与错误无关的路径是具有挑战性但重要的，**以避免在嵌入过程中出现不精确。这需要在模型训练过程中选择性地学习具有判别特征的路径，这些特征在 bug 语义中起作用，以产生用于基于路径的漏洞检测的精确嵌入。</p><h2 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h2><p>图2通过使用从真实项目POCO（一个用于网络应用程序的库）[31]提取的业务逻辑错误（CWE840）[55]，沿着图1中的三个阶段，阐明了ContraFlow的关键思想。漏洞是由于在rebuild_list(&amp;hd)之后调用set_status(&amp;hd)时API误用引起的，其中hd首先在第2行定义，然后在第6行修改，并在第13行使用。hd的这种错误的值流路径可能导致意外行为并导致服务拒绝。</p><p>注意，从原始代码片段中提取的不同变量的值流路径很大，并且包含许多路径，包括用于可行性检查和嵌入的不可行或与错误无关的路径。我们在阶段（a）中的对比值流嵌入首先对VPE进行预训练，以在潜在空间中保留路径（例如，π1 − π4）的语义，然后使用主动学习在阶段（b）中选择最具代表性的路径，然后进行可行性检查，通过稀疏和受控的值流分析移除不可行的路径π2和π3。阶段（c）进一步微调并解释π1作为训练模型的排名注意分数（π1的90%）中可能存在错误的路径。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221117563.png" alt="image-20240422104749835" /></p><h4 id="a-contrastive-value-flow-embedding"><a class="markdownIt-Anchor" href="#a-contrastive-value-flow-embedding"></a> (a) Contrastive Value-Flow Embedding.</h4><p>如图2（a）所示，该阶段的输入是从代码片段中提取的一组值流路径袋，例如，π1（○2 → ○6 → 1○3），π2（○3 → ○9 → 1○3），π3（2○ → ○6 → 1○5）和π4（○3 → ○9 → 1○5）。我们将它们两次馈送到值流路径编码器（VPE）中，使用VPE中的不同dropout掩码[61]，以获得它们的向量表示，例如，vπ1，vπ2，vπ3和vπ4，以及它们的对应对比表示[26]，例如，v+π1，v+π2，v+π3和v+π4。VPE是使用对比学习进行预训练的，以捕获价值流路径的语义，使得预训练的相似嵌入向量（例如，vπ1和v+π1）彼此保持接近，而不相似的对（例如，vπ1和v+π3）则相距较远，如图2(a)所示的二维特征空间。</p><p>VPE的参数在反向传播过程中通过最小化NCE损失[9]来自动更新[33]，该损失编码了价值流嵌入向量之间的相似性。</p><h4 id="b-value-flow-path-selection"><a class="markdownIt-Anchor" href="#b-value-flow-path-selection"></a> (b) Value-Flow Path Selection.</h4><p>对value-flow path抽样，路径可行检查</p><p>该阶段使用从阶段（a）预训练的 VPE 将价值流路径转换为嵌入向量。之后，我们根据从自监督主动学习中学到的排名，对代表性的价值流路径进行抽样，例如，π1 − π4。这些路径进一步被输入到路径可行性检查中，以删除不可行的价值流路径。例如，路径 3○→○9 → 1○3 是不可行的，因为在 3○→ 9○ 和 ○9 → 1○3 处的控制流保护符 !FLG 和 FLG 相互矛盾。同样，○2 →○6 → 1○5 也是不可行的。最后，只有可行的价值流路径 π1 和 π4 被保留用于训练阶段（c）的检测模型。</p><h4 id="detection-model-training"><a class="markdownIt-Anchor" href="#detection-model-training"></a> © Detection Model Training.</h4><p>该阶段的输入是由阶段（b）产生的选择的可行且具有代表性的值流路径，这些路径首先使用从阶段（a）转移的VPE模型转换为向量。然后，这些嵌入向量通过一个transformer架构[69]生成每个值流路径的上下文向量。例如，通过与其他向量（例如，π4）进行关注来计算π1的上下文向量，以增加它们对π1的影响。之后，应用软注意力层[1]将这些上下文向量合并为一个向量，用于训练检测模型。</p><p>排名注意力权重指示了不同值流路径对模型输出的贡献。例如，值流路径π1（○2→6○→1○3）的注意力权重最高（90％），而其他路径可以忽略不计，表明该值流路径可能是一个有错误的路径。</p><h2 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h2><h1 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h1><h2 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h2><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221053254.png" alt="image-20240422105310211" style="zoom:50%;" /><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221047923.png" alt="image-20240422104749835" /></p><h3 id="a-contrastive-value-flow-embedding-2"><a class="markdownIt-Anchor" href="#a-contrastive-value-flow-embedding-2"></a> (a) Contrastive Value-Flow Embedding.</h3><p>该阶段旨在使用对比学习训练价值流嵌入模型，值流路径编码器（VPE）。</p><ul><li>给定一组从未标记的源代码中使用现有静态分析器SVF提取的值流路径。</li><li>首先执行数据增强以生成对比值流表示[26]，</li><li>然后利用标准的噪声对比估计（NCE）损失函数[9]来最大化语义上相似的值流路径向量之间的一致性。</li></ul><p>这更新了我们的VPE参数，以促使其保留价值流路径的深层语义。<strong>预训练的VPE在接下来的两个阶段中使用。</strong></p><h3 id="b-value-flow-path-selection-2"><a class="markdownIt-Anchor" href="#b-value-flow-path-selection-2"></a> (b) Value-Flow Path Selection.</h3><p>该阶段旨在精确选择可行且代表性的值流路径，以代表代码片段以支持基于路径的检测模型的快速训练。</p><ul><li>首先使用来自阶段（a）的预训练VPE生成输入路径的特征向量，并使用自监督主动学习[45]对路径进行采样，以捕获最具代表性的路径并使嵌入多样化且信息丰富。</li><li>然后，我们通过对带有注释的值流图（VFG）[12, 64]上的可达性问题进行路径敏感的代码嵌入来执行路径敏感的代码嵌入。</li><li>VFG以稀疏的方式捕获def-use关系，并使用描述控制流传输条件的注释保护边缘。然后，可行性检查被简化为在受保护的VFG上的可达性问题，以仅在低维嵌入空间中嵌入可行路径。</li></ul><h3 id="detection-model-training-2"><a class="markdownIt-Anchor" href="#detection-model-training-2"></a> © Detection Model Training.</h3><p>给定由阶段（b）产生的选定路径和从阶段（a）转移的VPE模型，本阶段将通过仅使用程序的选定路径及其标签（即易受攻击或安全）来训练精确的检测模型。我们首先为每个选定的值流路径获取来自VPE的嵌入向量，然后利用transformer架构[69]为每个路径生成上下文向量以捕获路径之间的交互。然后，这些向量被馈送到软注意力层[1]以对它们进行评分和聚合，形成最终的检测模型训练的一个向量。该模型还可以根据它们对模型输出的贡献来解释重要的值流路径和语句，这些贡献是由学习到的注意力分数排名的。</p><h4 id="contrastive-value-flow-embedding"><a class="markdownIt-Anchor" href="#contrastive-value-flow-embedding"></a> Contrastive Value-Flow Embedding.</h4><p>对比性值流嵌入旨在通过预训练 VPE 从未标记的代码片段中学习相似/不相似的受保护值流路径 π 的区分性向量表示 vπ。受保护值流路径 π 包括一系列程序语句，表示变量之间的 def-use 链，每个语句之间的边上的guard用于指示控制流转移条件 [12, 64]。这些guard将在阶段 (b) 中的路径可行性求解过程中使用。算法 1 总结了学习算法。对于每个学习时期，我们生成对比向量表示（第 2 行），并计算对比值流路径之间的对比损失（第 3 行）。VPE 的参数将在训练过程中自动更新（第 4 行）。以下段落描述了对比性值流表示和对比损失函数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404221149879.png" alt="image-20240422114932815" /></p><h1 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h1><h2 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h2><h2 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h2><h1 id="4-discusion"><a class="markdownIt-Anchor" href="#4-discusion"></a> 4 Discusion</h1><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Reveal</title>
      <link href="/2023/12/18/Papers/Vul/Reveal/"/>
      <url>/2023/12/18/Papers/Vul/Reveal/</url>
      
        <content type="html"><![CDATA[<h2 id="一背景"><a class="markdownIt-Anchor" href="#一背景"></a> 一.背景</h2><p>漏洞检测具有重大的意义，针对DLVP（Deep Learning Vulnerability detection）任务，作者在对现有的漏洞检测方法（VulDeepecker, SyScVR）等测试时发现了一些问题。</p><ul><li>在sard等合成数据集训练的模型用在真实场景下（FFMPeg, Qemu, Linux等）效果很差</li><li>在用解释方法（LEMNA等）来解释漏洞检测方法时经常发现模型学习到了无关的特征</li><li>训练/测试数据包含了许多重复</li><li>现有的方法没有解决样本类别不平衡问题</li></ul><p>论文贡献</p><ul><li>提出了新的漏洞检测方法Reveal</li><li>利用Chromium和Debian的修复commit构造数据集</li></ul><h2 id="二数据集"><a class="markdownIt-Anchor" href="#二数据集"></a> 二.数据集</h2><h3 id="21-现有数据集"><a class="markdownIt-Anchor" href="#21-现有数据集"></a> 2.1 现有数据集</h3><p>针对数据集，作者统计的一些结果<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657318.png" alt="在这里插入图片描述" /><br />有合成，半合成，真实 &amp; 类别平衡， 真实 &amp; 类别不平衡</p><ul><li>合成类：包括<a href="https://www.nist.gov/publications/report-static-analysis-tool-exposition-sate-iv">Juliet</a>。使用已知漏洞pattern构造。</li><li>半合成：包括<a href="https://samate.nist.gov/SRD/index.php">SARD</a>和<a href="https://www.nist.gov/publications/national-vulnerability-database-nvd-overview">NVD</a>。它们是从软件产品中提取，并做了一定修改。</li><li>真实：从代码仓库（github）的commit中提取，来自一些bug fix版本。</li></ul><h3 id="22-reveal数据集"><a class="markdownIt-Anchor" href="#22-reveal数据集"></a> 2.2 Reveal数据集</h3><p>从<a href="https://so.csdn.net/so/search?q=Linux&amp;spm=1001.2101.3001.7020">Linux</a> Debian Kernel 和Chromium的vulnerabilitiy fixed patches中构造。</p><ul><li>对于Chromium，从<a href="https://bugs.chromium.org/p/chromium/issues/list">Bugzilla</a>中提取。</li><li>对于Linux Debian Kernel， 从<a href="https://security-tracker.debian.org/tracker/">Debian security tracker</a>中提取。</li></ul><p>该数据集是针对function（单个函数）进行分类的，构造过程如下：</p><ul><li>对于每个patch，从选取其vulnerable版本到fixed版本中被修改过源文件（.c, .cpp）和头文件（.h）。</li><li>对于被修改过的function，将该function修改前的标注为<code>vulnerable</code>。fix之后的标注为clean，其余未在patch中出现的function均标注为<code>clean</code>。</li></ul><p>示例如图<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657344.png" alt="在这里插入图片描述" /><br />v e r s i o n k − 1 version_{k-1}versionk−1​ 表示有漏洞的源文件，v e r s i o n k version_kversionk​ 表示fix版本。<code>ham_0</code>会被标注为vulnerable，<code>ham_1</code>，<code>egg</code>，<code>spam</code>会被标注为<code>clean</code>。</p><p>数据集统计信息如下：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657348.png" alt="在这里插入图片描述" /></p><h2 id="三现有方法"><a class="markdownIt-Anchor" href="#三现有方法"></a> 三.现有方法</h2><p>现有的方法大致可分为token-based和graph-based</p><h3 id="31-token-based"><a class="markdownIt-Anchor" href="#31-token-based"></a> 3.1 token-based</h3><p>token-based模型将源代码当成一个简单的token序列。而序列长度则会很大程度上影响模型发挥，因为源代码token序列可能相当长。所以就有了code slicing（VulDeepecker, SySeVR）。slicing的初衷是不考虑每个代码行，预处理的时候忽略掉许多无关行。slicing技术上从一些interesting points（API调用，数组索引，指针使用）出发。尽管如此，token-based方法将源代码视为序列，容易丢失语义信息。做过slice也会丢失一些依赖。</p><h3 id="32-graph-based"><a class="markdownIt-Anchor" href="#32-graph-based"></a> 3.2 graph-based</h3><p>graph-based模型将代码视为一个基于句法和语义依赖的图。句法依赖包括AST（抽象语法树），语义依赖包括CFG（控制流图），DFG（数据流图），PDG（程序依赖图），Def-Use chain graph。比如<a href="https://blog.csdn.net/qq_44370676/article/details/115326040">Devign</a>使用了CPG（代码依赖图）。一般来说，使用的依赖信息越多，检出率越高，但是本身消耗的资源也会更多。</p><h3 id="33-存在的问题"><a class="markdownIt-Anchor" href="#33-存在的问题"></a> 3.3 存在的问题</h3><p>都存在vocabulary explosion（词表爆炸）问题。词表主要包括一些identifier（变量名，函数名，常量值等）。比如<code>int count = 0;</code>中包括了变量名<code>count</code>。而实际应用中变量名有无限种可能，如果简单粗暴的添加进词表那么100%要爆炸，有一种解决方案（VulDeepecker, SySeVR中采用的）是<strong>符号化</strong>。比如对于变量名<code>count</code>，将其用<code>VAR1</code>替代，对于自定义函数名<code>function</code>，将其用<code>FUNC1</code>替代，以此类推。</p><p>将代码转化为token序列后就是要向量化了，向量化主流的方案就是用embedding layer。这个embedding layer可以采用直接用下游任务（预测代码是否有漏洞）来训练，也可以用Word2Vec甚至Bert来先预训练。VulDeePecker和SySeVR用Word2Vec来将每个token向量化。Devign直接用Word2Vec来向量化一个statement的所有token（有点没搞懂Word2Vec是怎么对序列向量化的）。</p><p>向量化之后就是训练了，训练就需要损失函数，现有的方案采用交叉熵（cross entropy）或者带正则化的交叉熵损失函数。但仅仅靠交叉熵损失函数只能区分是否包含漏洞，并不能让模型学习到有漏洞和没有漏洞的代码的区别。</p><p>此外还有一个问题就是数据不平衡，因为数据集中包含漏洞和不包含漏洞的代码比例非常不协调。</p><h2 id="四reveal"><a class="markdownIt-Anchor" href="#四reveal"></a> 四.ReVeal</h2><p>总体过程如下图所示<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657355.png" alt="在这里插入图片描述" /><br />需要注意的是作者这里进行了2个阶段的训练</p><ul><li>第一个阶段是pre-train（Phase-I）。主要是训练GGNN，目标是能获得良好的graph embedding。</li><li>第二个阶段是train（Phase-II）。主要是训练MLP，目标是获得良好分类结果，SMOTE过采样也主要是应用在Phase-II。</li></ul><h3 id="41-feature-extraction-phase-i"><a class="markdownIt-Anchor" href="#41-feature-extraction-phase-i"></a> 4.1 Feature Extraction (Phase-I)</h3><p>这个阶段的目标是将源代码转化成一个向量，这个向量保存了代码的语义（semantic）和句法（syntactic）信息。因此作者用到了CPG（代码属性图）。</p><p>通常，CPG表示为 G = ( V , E ) G = (V,E)G=(V,E)。V是结点（英文vertices或者nodes）和边集合（edges）。与Devign不同的是，这里每个结点不仅包含原始的一行代码（statement或者code fragment）。还包括statement类型（即这一行代码大概是什么语句，ArithmeticExpression或者CallStatement等等）。</p><p>所以对于一个node v vv的向量化包括2部分</p><ul><li>用one-hot将其类型向量化，得到向量 T v T_vTv</li><li>用word2vec向量化code fragment内容，得到向量 C v C_vCv</li><li>拼接（concat）C v C_vCv 和 T v T_vTv 得到结点向量 x v x_vxv</li></ul><p>对于用Word2Vec向量化，代码里如下：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">node_split = nltk.word_tokenize(node_content)</span><br><span class="line">nrp = np.zeros(<span class="number">100</span>)</span><br><span class="line"><span class="keyword">for</span> token in node_split:</span><br><span class="line">try:</span><br><span class="line">   embedding = wv.wv[token]</span><br><span class="line">except:</span><br><span class="line">   embedding = np.zeros(<span class="number">100</span>)</span><br><span class="line">nrp = np.add(nrp, embedding)</span><br><span class="line"><span class="keyword">if</span> len(node_split) &gt; <span class="number">0</span>:</span><br><span class="line">   fNrp = np.divide(nrp, len(node_split))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   fNrp = nrp</span><br></pre></td></tr></table></figure><p>从<code>node_split = nltk.word_tokenize(node_content)</code>和<code>fNrp = np.divide(nrp, len(node_split))</code>可知对于一行代码（以<code>int a = 10</code>）为例。会将statement先解析成一个token序列，之后用Word2Vec对每个token向量化，然后取所有token向量的<strong>均值</strong>。</p><p>之后便用GGNN来进行结点向量的聚合，GGNN的计算过程前面总结过：<a href="https://blog.csdn.net/qq_44370676/article/details/115701325">图神经网络的计算过程</a></p><p>简单来说，经过GGNN的处理，每个结点的向量由 x v x_vxv 变成 x v ′ x_v^{’}xv′<br />x v ′ = G R U ( x v , ∑ ( u , v ) ∈ E g ( x u ) ) x_v^{’} = GRU(x_v, \sum\limits_{(u,v) \in E} g(x_u) )xv′​=GRU(xv​,(u,v)∈E∑​g(xu​))</p><p>GRU内部公式就不展开了，在RNN序列任务种 h t = G R U ( i n p u t i , h t − 1 ) h_t = GRU(input_i, h_{t-1})ht=GRU(inputi,ht−1) 。u uu 是 v vv 邻居结点，g ( ⋅ ) g(·)g(⋅) 是一个 transformation function。</p><p>最后一步就是用聚合函数（aggregate function）将每个结点的向量聚合成一个向量 x g x_gxg，作为整个CPG，也就是源代码的向量表示。</p><p>x g = ∑ v ∈ V x v ′ x_g = \sum\limits_{v \in V} x_v^{’}xg=v∈V∑xv′</p><p>这里在论文中，作者用向量总和（element-wise summation）作为聚合函数，而实际上在代码里，聚合函数是一个可配置参数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061709378.png" alt="image-20240406170926341" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657330.png" alt="在这里插入图片描述" /></p><h3 id="42-training-phase-ii"><a class="markdownIt-Anchor" href="#42-training-phase-ii"></a> 4.2 Training (Phase-II)</h3><p>现实数据集中的样本不平衡问题非常严重，不包含漏洞的代码数量远超过包括漏洞的。</p><p>因此作者将训练阶段分为2部分</p><ul><li>Reducing Class Imbalance：采用re-sampling（不知道该如何翻译）平衡训练集vulnerable和non-vulnerable的样本。</li><li>Representation Learning Model：基于平衡后的数据集训练一个可以很好的区分vulnerable和non-vulnerable样本的representation learning model。</li></ul><h4 id="421-reducing-class-imbalance"><a class="markdownIt-Anchor" href="#421-reducing-class-imbalance"></a> 4.2.1 Reducing Class Imbalance</h4><p>在处理样本不平衡问题上用到了SMOTE算法。对于样本中的多数类（non-vulnerable），SMOTE会进行sub-sampling（随机删除一些样本），对于少数类（vulnerable），SMOTE会进行super-sampling（新合成一些样本）。直到每个类别的出现频率相等。算法如下图表示</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657366.png" alt="在这里插入图片描述" /></p><h4 id="422-representation-learning-model"><a class="markdownIt-Anchor" href="#422-representation-learning-model"></a> 4.2.2 Representation Learning Model</h4><p>一个code fragment（一个method）的CPG（用 G GG 表示）经过graph embedding（phase-I）后得到向量 x g x_gxg， 作为 G GG 的最终向量表示。但是vulnerable codes 和 non-vulnerable codes的向量在特征空间上有很大重合。</p><p>codes的特征向量经过TSNE降维后如下表示，一个点代表一个code fragment，红色部分为vulnerable codes，绿色为non-vulnerable codes。可以看到一个好的embedding是需要能够在特征空间区分开它们的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657895.png" alt="在这里插入图片描述" /><br />分类函数如下所示<br />y = σ ( W . h ( x g ) + b ) y = \sigma(W .h(x_g) +b)y=σ(W.h(xg​)+b)</p><ul><li>σ \sigmaσ 为softmax</li><li>W WW 和 b bb 为最后一层全连接层的参数</li></ul><p>其中 h ( x g ) h(x_g)h(xg) 为一个全连接层，将 x g x_gxg 投影到新的向量平面 h g h_ghg。</p><p>为了将non-vulnerable和vulnerable特征向量区别最大化。作者在训练模型时用到了triplet loss而不是softmax，记为 L t r p L_{trp}Ltrp。每次训练需要用到的一个数据为一个3元组，记为 ( g , s a m e , d i f f ) (g, same, diff)(g,same,diff) 对应 ( a , p , n ) (a, p, n)(a,p,n)。s a m e samesame 和 g gg 为同属一个类的样本， d i f f diffdiff 则相反。</p><p>L t r p = L C E + α . L p + β ∗ L r e g L_{trp} = L_{CE} + \alpha .L_{p} + \beta * L_{reg}Ltrp=LCE+α.Lp+β∗Lreg</p><ul><li><p>α \alphaα 和 β \betaβ 为超参数</p></li><li><p>L C E L_{CE}LCE 为交叉熵损失<br />L C E = − ∑ y ^ ⋅ l o g ( y ) + ( 1 − y ^ ) ⋅ l o g ( 1 − y ) L_{CE} = - \sum \hat y·log(y) + (1−\hat y)·log(1−y)LCE​=−∑y<sup>​⋅log(y)+(1−y</sup>​)⋅log(1−y) ，y yy 和 y ^ \hat yy^​ 分别表示 g gg 的标签和预测结果</p></li><li><p>L r e g L_{reg}Lreg 为正则化损失<br />L r e g = ∣ ∣ h ( x g ) ∣ ∣ + ∣ ∣ h ( x s a m e ) ∣ ∣ + ∣ ∣ h ( x d i f f ) ∣ ∣ L_{reg} = ||h(x_g)||+||h(x_{same})|| + ||h(x_{diff})||Lreg​=∣∣h(xg​)∣∣+∣∣h(xsame​)∣∣+∣∣h(xdiff​)∣∣ 。这里正则化损失主要用来限制 h hh 即投影空间向量大小。</p></li><li><p>L p = ∣ D ( h ( x g ) , h ( x s a m e ) ) − D ( h ( x g ) , h ( x d i f f ) ) + γ ∣ L_{p} = | D(h(x_g), h(x_{same}))−D(h(x_g),h(x_{diff})) + \gamma|Lp=∣D(h(xg),h(xsame))−D(h(xg),h(xdiff))+γ∣<br />L p L_{p}Lp​ 为投影损失，是为了最大区分正类和负类样本在投影空间的差异。<br />D ( v 1 , v 2 ) = 1 − ∣ v 1 . v 2 ∣ ∣ v 1 ∣ ∣ ∗ ∣ ∣ v 2 ∣ ∣ ∣ D(v_1,v_2) = 1−|\frac{v_1.v_2}{||v1||∗||v2||}|D(v1​,v2​)=1−∣∣∣v1∣∣∗∣∣v2∣∣v1​.v2​​∣</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061710663.png" alt="image-20240406171004625" /></p></li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657836.png" alt="在这里插入图片描述" /></p><h2 id="五-实验设置"><a class="markdownIt-Anchor" href="#五-实验设置"></a> 五. 实验设置</h2><p>模型超参数大小<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657849.png" alt="在这里插入图片描述" /><br />评估指标:</p><ul><li>跟Devign一样，这是个针对function的二分类问题。</li><li>Accuracy, Precision, Recall, F1-score这4个指标用来评估模型。</li></ul><h2 id="六实验结果"><a class="markdownIt-Anchor" href="#六实验结果"></a> 六.实验结果</h2><h3 id="61-现有方法的有效性"><a class="markdownIt-Anchor" href="#61-现有方法的有效性"></a> 6.1 现有方法的有效性</h3><p>作者在评估其它模型（vuldeepecker等）的性能时统一使用真实数据集，针对现有的模型训练数据的问题，作者给出了2个场景</p><ul><li>Scenario-A (pre-trained models)<br />该模型在它本身的数据集上训练（比如VulDeepecker在sard数据集上训练），然后在真实数据集上测试</li><li>Scenario-B (re-trained models)<br />真实数据集上训练 + 真实数据集测试</li></ul><p>Scenario-A的测试结果如下：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657888.png" alt="在这里插入图片描述" /><br />Scenario-B的测试结果如下：<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657917.png" alt="在这里插入图片描述" />同时，作者自己实现了一个Devign，并开源到<a href="https://github.com/saikat107/Devign">github</a>了。</p><p>可以看到，现有的方法泛化能力不强，在应用到真实数据集时效果有一定程度下降。</p><h3 id="62-现有方法的局限性"><a class="markdownIt-Anchor" href="#62-现有方法的局限性"></a> 6.2 现有方法的局限性</h3><h4 id="621-数据重复"><a class="markdownIt-Anchor" href="#621-数据重复"></a> 6.2.1 数据重复</h4><p>用slice和token-based方法都可能造成在训练集和测试集造成数据重复。作者做了一个统计，结果如下<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657046.png" alt="在这里插入图片描述" />可以看到合成数据集比真实数据集多了很多重复。虽然重复会有利于漏洞分类任务，但不利于模型提取漏洞特征。</p><h4 id="622-数据不平衡"><a class="markdownIt-Anchor" href="#622-数据不平衡"></a> 6.2.2 数据不平衡</h4><p>数据集的情况再粘贴以下，看看Vul这一列，可以看到很多数据集中，正负样本比例不均。所以会造成模型分类时倾向于多数类。<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657244.png" alt="在这里插入图片描述" /></p><h4 id="623-学到不相关特征"><a class="markdownIt-Anchor" href="#623-学到不相关特征"></a> 6.2.3 学到不相关特征</h4><p>为了选择好的DL模型来做漏洞分类，非常有必要理解模型是基于什么特征来做的分类。好的模型应该分配更多的权重给漏洞相关的特征。</p><p>作者通过LEMNA（一种解释方法）来解释token-based模型的分类结果。结果如下<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657302.png" alt="在这里插入图片描述" /><br />对于graph-based模型，作者则用每个结点的激活值来表示，激活值越大，结点越关键。对一个被token-based方法错误分类而被graph-based方法正确方法分类的样本解释， 结果如下</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657290.png" alt="在这里插入图片描述" /></p><h4 id="624-模型选择缺乏区分度"><a class="markdownIt-Anchor" href="#624-模型选择缺乏区分度"></a> 6.2.4 模型选择：缺乏区分度</h4><p>这里主要展示不同的方法提取到的代码的特征向量对正类负类样本的区分度，即特征向量空间中两类代码是否很容易被区分开。作者用TSNE对不同方法提取的特征向量进行研究，并用centroid distance来衡量它们的效果， 结果如下（再粘贴一次）</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657356.png" alt="在这里插入图片描述" /><br />绿色为负类（无漏洞）的样本，红色为正类（有漏洞）。</p><h3 id="63-解决上述问题"><a class="markdownIt-Anchor" href="#63-解决上述问题"></a> 6.3 解决上述问题</h3><p>作者分别用SMOTE解决样本不均衡问题，而REVEAL本身就能解决其它的问题。</p><p>为了分别研究re-sampling和GGNN的效果，作者做了几组实验。不过实验结果里作者并未提到用什么模型替代了GGNN。</p><p>Re-balance的效果</p><p>实验结果如下（主要看F1-score），W/O表示without<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657298.png" alt="在这里插入图片描述" /><br />跟其它模型（token-based + MLP,RF,SVM）的对比<br /><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404061657371.png" alt="在这里插入图片描述" /></p><h2 id="七预训练word2vec"><a class="markdownIt-Anchor" href="#七预训练word2vec"></a> 七.预训练Word2Vec</h2><p>代码如下：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">def <span class="title function_">train</span><span class="params">(args)</span>:</span><br><span class="line">    files = args.data_paths</span><br><span class="line">    sentences = []</span><br><span class="line">    <span class="keyword">for</span> f in files:</span><br><span class="line">        data = json.load(open(f))</span><br><span class="line">        <span class="keyword">for</span> e in data:</span><br><span class="line">            code = e[<span class="string">&#x27;code&#x27;</span>]</span><br><span class="line">            sentences.append([token.strip() <span class="keyword">for</span> token in code.split()])</span><br><span class="line">    wvmodel = Word2Vec(sentences, min_count=args.min_occ, workers=<span class="number">8</span>, size=args.embedding_size)</span><br><span class="line">    print(<span class="string">&#x27;Embedding Size : &#x27;</span>, wvmodel.vector_size)</span><br><span class="line">    <span class="keyword">for</span> i in range(args.epochs):</span><br><span class="line">        wvmodel.train(sentences, total_examples=len(sentences), epochs=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> not os.path.exists(args.save_model_dir):</span><br><span class="line">        os.mkdir(args.save_model_dir)</span><br><span class="line">    save_file_path = os.path.join(args.save_model_dir, args.model_name)</span><br><span class="line">    wvmodel.save(save_file_path)</span><br><span class="line"><span class="number">12345678910111213141516</span></span><br></pre></td></tr></table></figure><p>这里大概就是将一个function的所有代码<code>split</code>成一个token序列当作一个sentence训练Word2Vec模型。</p><h2 id="八参考文献"><a class="markdownIt-Anchor" href="#八参考文献"></a> 八.参考文献</h2><blockquote><p><a href="https://arxiv.org/abs/2009.07235">Chakraborty, S. , Krishna, R. , Ding, Y. , &amp; Ray, B. . (2020). Deep<br />Learning based Vulnerability Detection: Are We There Yet?.</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SySeVR</title>
      <link href="/2023/12/18/Papers/Vul/SySeVR/"/>
      <url>/2023/12/18/Papers/Vul/SySeVR/</url>
      
        <content type="html"><![CDATA[<h3 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h3><p>软件漏洞检测目前为止还是一个待被解决的重要问题，因为每天都有很多新的漏洞被发现。使用深度学习方法进行代码漏洞检测是非常有效的，这种方式减轻了对于人为定义特征的要求。尽管深度学习在各个领域取得了巨大的成功，但在漏洞检测领域并没有被研究透彻。为了填补这一空白，本文提出了第一个使用深度学习在C/C++源代码上进行漏洞检测的系统性框架，框架名称叫做SySeVR，全称是“基于语法语义的向量表征”，该框架聚焦于如何获取包含语法和语义信息的代码表征以应用于漏洞检测。该方法检测出了15个没有在NVD中报告过的漏洞，验证了模型的有效性。</p><h3 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h3><p>假设软件漏洞是不可避免的，那关键的问题是如何更早的发现这些漏洞。基于源代码的静态检测方法包含有基于代码相似性的方法和基于模式的方法，基于代码相似性的方法只能检测与代码克隆相关的漏洞，而基于模式的方法则需要耗费大量的人力去定义模式。因此，最有效的方法是使用深度学习。</p><p>之前的<a href="https://zhuanlan.zhihu.com/p/265616085">VulDeepecker</a>方法是在代码切片层级上进行漏洞检测的，这个方法有4个缺点：1）只能检测与API调用相关的漏洞；2）只包含了语义信息中的数据依赖；3）特征提取模块只用了BLSTM来实现；4）没有解释假阳性和假阴性的原因。本文的SySeVR框架则克服了以上4个缺点。</p><p>本文提出SySeVR框架核心是为了解答这个问题——“如何提取代码的向量化表征，该表征包含着适用于漏洞检测的语法和语义信息？”为了回答该问题，本文引入SyVCs(语法漏洞候选)和SeVCs(语义漏洞候选)两个概念，分别表示漏洞的语法特征和语义特征(数据依赖和控制依赖)。同时，本文设计了自动化提取SyVCs和SeVCs的算法。</p><p>为了评估SySeVR有效性，本文给出了一个从NVD和SARD中提取出来的包含126种漏洞的数据集，数据集的地址为<a href="https://link.zhihu.com/?target=https%3A//github.com/SySeVR/SySeVR">SySeVR</a>。有了新数据集，SySeVR可以实现以下功能：</p><ul><li>SySeVR验证了多种神经网络模型来进行漏洞检测。BRNN，BGRU比RNN，CNN模型更有效，也比DBN和浅层学习模型更有效。</li><li>BGRU的有效性依赖于训练数据，如果某些语法元素经常出现在代码的漏洞(非漏洞)片段中，那这些语法元素就会导致高的假阳(阴)性率，解释了假阳性率和假阴性率的原因。</li><li>考虑更多的语义信息(比如控制依赖和数据依赖)可以减少30.4％的假阴性率。</li><li>在4个软件产品上应用 SySeVR-enabled BGRU模型，检测出了15个没有在NVD中报告过的漏洞。</li></ul><h3 id="模型结构"><a class="markdownIt-Anchor" href="#模型结构"></a> 模型结构</h3><p>在图像处理领域有一个非常经典的概念叫做region proposal（候选区域），研究者可以从图像中提取出很多的proposal然后向量化，使用深度学习训练检测。对于程序代码而言，我们也可以模仿图像中的操作，利用proposal的思想来完成漏洞检测。</p><p>如果使用函数作为proposal，则粒度太高，无法定位具体漏洞位置；如果使用语句作为proposal则会导致正负样本不均衡，且分割了代码语句之间的语义信息。因此，本文采用语句的集合作为proposal，以其为单位进行代码漏洞检测。</p><p>首先，我们定义表示漏洞语法特征的SyVCs。下图展示了由region proposal的灵感产生的SySeVR的框架。简而言之，本文依次生成了SyVCs，SeVCs，对SeVCs向量化后使用深度学习进行训练和检测。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945931.jpeg" alt="img" /></p><p>总体而言，SyVCs包含了符合某种漏洞语法特征的代码元素（比如函数调用、指针使用）。SeVCs是由SyVCs生成的，在SyVCs的基础上增加了代码的语义信息，它是一部分相互数据依赖和控制依赖的代码语句的集合。下图是一个直观的示例，SyVCs中的每一个红框代表一个SyVC，不同的SyVC可以相互包含，因为其代表不同的漏洞，比如第18行。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945958.jpeg" alt="img" /></p><p>首先说说生成SyVCs。SyVCs包含了符合漏洞语法特征的代码元素，比如上图中18行的data就是一次指针使用，因为第9行出现了’*'号说明了data是指针类型。本文借助抽象语法树来实现SyVCs的生成。对于每一个函数，首先生成函数的抽象语法树，抽象语法树的根节点表示函数，叶子节点表示token，中间节点表示语句或者说连续的token。</p><p>可用于漏洞检测的代码元素可能是AST的叶子节点或中间节点，因此遍历抽象语法树的节点，如果该节点满足某一条漏洞规则，则该节点对应的一个或多个token将作为code element加入到SyVCs中，具体的伪代码如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945978.jpeg" alt="img" /></p><p>接下来是将SyVCs转化为SeVCs。本文借助代码切片技术去定义与SyVCs语义相关的语句，在介绍该过程前首先要了解几个概念。</p><ul><li>CFG：表示控制流图，它的点是函数语句，边为有向边，表示相邻语句间的运行先后关系。</li><li>数据依赖：如果控制流图中有一条A-&gt;B的路径，且在A语句中计算得到的值会在B语句中使用，则称B数据依赖A。</li><li>控制依赖：如果控制流图中有一条A-&gt;B的路径，且B是否执行需要看A执行的结果(即B不是post-dominate A), 则称B控制依赖A。</li><li>PDG：表示程序依赖图，它的点是函数语句，边为有向边，表示相邻语句间的数据依赖或控制依赖。</li><li>前向切片：一个(SyVC)代码元素的前向切片是由一些语句组成的，这些语句包含了在PDG上从该代码元素出发所有可达的点。</li><li>过程间前向切片：过程间前向切片比前向切片多了一些语句，多的语句是在PDG中代码元素可以通过函数调用到达的点。</li><li>后向切片：一个(SyVC)代码元素的后向切片是由一些语句组成的，这些语句包含了在PDG上所有与该代码元素可达的、且以该代码元素为终点的点。</li><li>过程间后向切片：过程间后向切片比后向切片多了一些语句，多的语句是在PDG中可以通过函数调用到达代码元素的点。</li><li>程序切片：由过程间前向切片和过程间后向切片的语句融合构成，删掉了其中重复的部分。</li></ul><p>有了这些概念后，就可以开始生成SeVCs了，SeVCs其实就是与SyVCs中的代码元素相控制依赖和数据依赖的语句的集合，其具体生成的伪代码如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945940.jpeg" alt="img" /></p><p>首先生成源代码的PDG图，对于PDG中一个的代码元素，生成前向切片和后向切片。然后，融合前向切片和被该函数调用的函数的前向切片，得到过程间前向切片。融合后向切片、被该函数调用的函数的后向切片、以及调用该函数的函数的后向切片，得到过程间后向切片。融合过程间前向切片和过程间后向切片得到程序切片，至此，对于PDG中的该代码元素，生成了其对应的程序切片。</p><p>程序切片中的所有函数语句构成一个集合。对于不同的函数的语句而言，调用者的语句在被调用者的语句之前。调整好顺序后，该集合就是该代码元素(SyVC)对应的SeVC了，对SyVCs中的每一个SyVC这样处理，就可以生成SeVCs。下图是一个以25行的data为SyVC的一个转换示例，体现了从PDG到切片到SeVC的完整过程。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945964.jpeg" alt="img" /></p><p>有了SeVCs，之后就是对SeVCs的向量化编码操作了。下图为该过程的详细伪代码，在此不一一赘述。简单来说，对于每个SeVC，首先删除不合法字符，对函数和变量名进行映射标准化(V1,V2,F1,F2之类的)。之后，将每个SeVC的每个单词embedding成固定长度的向量，将单词concate到一起。</p><p>此时要求concate后的SeVC的向量长度为固定值theta，如果不够就补全；如果超过theta就看SeVC向量两端到SyVC元素有没有小于 1/21/21/2 theta的，有则删去另一端至总长度为theta。如果都没有小于 1/21/21/2 theta的，则两端一起删到两端到SyVC元素都为1/21/21/2 theta。这样就将SeVCs编码为了长度为theta的向量的集合，此时给该集合加上标记，有漏洞的SeVC标签为1，没有漏洞则为0，之后使用双向GRU网络训练检测即可。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945970.jpeg" alt="img" /></p><h3 id="实验部分"><a class="markdownIt-Anchor" href="#实验部分"></a> 实验部分</h3><p>本文在NVD和SARD两个数据集上进行实验。对于NVD，本文收集了1591个开源C/C<ins>程序，其中874个是有漏洞的。对于SARD，本文收集了14000个C/C</ins>程序，其中13906个是有漏洞的，这里的有漏洞包含bad和mix，bad指的是有漏洞，mix指的是漏洞版本和修复好的版本都有。合计，本文收集了15591个程序，其中14780个是有漏洞的，对应126种CWE漏洞类型。</p><p>实验过程大体上和前文模型结构讲的类似，其中值得注意的是提取SyVCs的时候如何获取漏洞的语法特征并进行匹配。本文通过checkmarx工具提取出了4中类型的漏洞语法规则。</p><ul><li>API/库函数调用(FC)：包含了811个函数调用，对应于106种CWE漏洞。</li><li>数组使用(AU)：包含87种CWE漏洞，比如数组元素访问，地址计算等等。</li><li>指针使用(PU)：包含103种CWE漏洞，比如不合法的指针计算、引用、传参。</li><li>算术表达式(AE)：包含45种CWE漏洞，不合法的算术表达式，比如整数溢出等。</li></ul><p>下图为这4类漏洞覆盖的CWE漏洞类型。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945424.jpeg" alt="img" /></p><p>有了漏洞特征后重点是如何讲代码元素与漏洞特征进行匹配，下图是一个匹配SyVC的示例。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945457.jpeg" alt="img" /></p><ul><li>FC判定需要满足该代码元素是一个函数调用，且属于811种函数调用之中。</li><li>AU判定需要满足这是一个标识符声明语句且包含’[‘和’]’。</li><li>PU判定需要满足这是一个标识符声明语句且包含’*’。</li><li>AE判定需要满足这是一个表达式语句且包含’=’，并且等号右端有两个以上的元素。</li></ul><p>从SyVCs转化为SeVCs按算法做就好，本文最终生成SeVCs的结果如下表所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945468.jpeg" alt="img" /></p><p>在编码阶段使用word2vec进行编码(gensim)，每个单词向量长度为30，一个SeVC最多500个单词，theta为15000。</p><p>最后说说生成标签，该过程分为两步。第一步是生成初始的标签，针对NVD数据集，如果一个SeVC包含的删除或修改的语句前面有’-’，则被标记为1(有漏洞)；而如果一个SeVC包含的移动的语句前面有’-’，且这个文件包含一个已知的漏洞，则被标记为1；其他情况都标记为0。针对SARD数据集，如果一个SeVC提取自一个good程序，则被标记为0；如果提取自bad或mix程序，则分情况，若该SeVC包含至少一个漏洞语句则标记为1，否则标记为0。</p><p>接下来第二步，使用交叉验证的方式来修正标签。比如将数据集分为5份，4份训练，1份测试。在测试过程中发现的假阴性样本（有漏洞的样本检测为无漏洞）将会被考虑是否标错了，对于这类样本手动检查修正标签。</p><p>接下来就是最后的模型结果。本文的实验结果旨在说明四个问题：</p><ul><li>1：SySeVR搭配BLSTM可以检测多种类型的漏洞吗？</li><li>2：SySeVR可以搭配各种各样的神经网络来进行漏洞检测吗，检测效果如何？</li><li>3：考虑控制依赖是否使得SySeVR更加有效，结果好了多少？</li><li>4：SySeVR相比现有的SOTA方法如何？</li></ul><p>对于第一个问题，作者将SySeVR-BLSTM模型分别检测4种类型的漏洞，于VulDeepecker模型的结果进行比较，结果如下图所示，可见SySeVR-BLSTM模型的结果明显优于VulDeepecker模型，证明了该模型可以有效的检测多种不同类型的漏洞。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945484.jpeg" alt="img" /></p><p>对于第二个问题，本文比较了使用LR,MLP,DBN,CNN,LSTM,GRU,BLSTM,BGRU等神经网络进行训练和检测的效果，发现使用BGRU对SeVCs进行训练检测的效果最好。RNNs比CNN更好，CNN比浅层网络更好，假阴性率高于假阳性率(没检测出来的偏多)。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945496.jpeg" alt="img" /></p><p>对于第三个问题，本文分别列举了在各个模型上只使用数据依赖(DD)和同时使用数据依赖控制依赖(DDCD)的模型结果，结果如下所示，可见控制依赖可以很大程度上提升模型的效果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945558.jpeg" alt="img" /></p><p>对于第四个问题，将本文的SySeVR-BGRU模型与Flawfinder,RATS,checkmarx,VUDDY，VulDeepecker进行比较，可见SySeVR-BGRU模型显著强于之前的所有模型。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403290945707.jpeg" alt="img" /></p><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>本文提出了一个叫做SySeVR的基于深度学习的代码漏洞检测框架，该模型提取待检测代码的语法和语义特征并应用于漏洞检测。大量的实验证明了SySeVR模型的有效性，本文使用SySeVR模型检测出NVD中15个未被报道过的漏洞。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VulDeePecke</title>
      <link href="/2023/12/18/Papers/Vul/VulDeepecker/"/>
      <url>/2023/12/18/Papers/Vul/VulDeepecker/</url>
      
        <content type="html"><![CDATA[<h2 id="vuldeepecker基于深度学习的漏洞检测系统"><a class="markdownIt-Anchor" href="#vuldeepecker基于深度学习的漏洞检测系统"></a> <a href="https://zhuanlan.zhihu.com/p/265616085">VulDeePecker：基于深度学习的漏洞检测系统</a></h2>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The Vulnerability Is in the Details Locating Fine-grained Information of Vulnerable Code Identified by Graph-based Detectors</title>
      <link href="/2023/12/18/Papers/Vul/VULEXPLAINER/"/>
      <url>/2023/12/18/Papers/Vul/VULEXPLAINER/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>漏洞检测是软件开发生命周期中的关键组成部分。现有的漏洞检测器，尤其是基于深度学习（DL）模型的检测器，已经取得了很高的效果。尽管它们能够从给定的代码片段中检测到易受攻击的代码片段，但通常无法进一步定位与漏洞相关的精细信息，比如精确的漏洞触发位置。在本文中，我们提出了VULEXPLAINER，这是一个用于自动定位由DL-based检测器报告的粗略级易受攻击代码片段中的漏洞关键代码行的工具。我们的方法利用了代码结构和漏洞的语义。具体来说，我们利用程序切片来获得一组包含漏洞触发和漏洞依赖语句的关键程序路径，并对它们进行排名，以确定最重要的一个（即子图），作为与漏洞相关联的数据流。我们证明了VULEXPLAINER在四个最先进的基于图表示（GP）的漏洞检测器上表现一致良好，即它可以针对八种常见的C/C++漏洞以约90％的准确率标记漏洞触发代码语句，优于五种广泛使用的基于GNN的解释方法。实验结果证明了VULEXPLAINER的有效性，它提供了一个有前景的研究线索：整合程序切片和深度学习来解释易受攻击的代码片段。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h3 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h3><p>To counteract the potential exploitation, both academia and industrial communities have proposed numerous techniques for identifying and locating those vulnerabilities.</p><ul><li><p>传统方法，例如基于规则的分析技术利用预定义的签名或规则来识别漏洞。问题是，通常报告高误报和漏报率。</p></li><li><p>基于 DL 的检测技术通常在提取的代码特征表示上运行，已经显示出在标记包含漏洞的代码片段（即函数或片段）方面的巨大效果。然而，分析的粗粒度和黑盒性质使得检测结果的可解释性较差。<strong>例如，一个函数或代码片段可能包含十几行代码，这对开发人员来说仍然是一个具有挑战性的任务，以理解漏洞的根本原因并进一步采取行动来修复它们</strong>。解决这个问题的一种有希望的方法是利用解释方法来选择 DL-based 检测器的重要特征，然后将它们映射到相应的代码行。</p></li><li><p>最近图形解释技术的快速发展显示出了解决这个问题的巨大潜力。现有的图解释方法通常从三个角度促进模型的可解释性：为图边分配数值 [10]，[11]，计算节点的重要性分数 [12]，以及在通过 GNN 时计算图遍历的分数 [13]。</p></li></ul><p>尽管它们在诸如子图分类之类的任务中取得了成功，但现有的基于 GNN 的解释技术仍然存在固有的不足，这些不足阻碍了直接应用以获得有关漏洞的细粒度信息，例如触发代码行。</p><p>**第一个不足之处在于捕捉潜藏在良性和脆弱代码库中的微妙但丰富的语义能力有限。**程序的功能由提取的代码图中的语句（即节点）及其信息流（即边）定义。因此，针对程序的特定语义对于解释方法至关重要。然而，现有的解释方法无法定位到这种细粒度的信息，因为它们通常忽视了程序图中丰富的语义信息。</p><p>这可能归因于程序漏洞检测的复杂性相对于现有任务（即，较简单的拓扑结构）而言。<mark>例如，由边表示的两个语句之间的控制流或程序依赖关系几乎没有反映出来。此外，节点中包含的语义信息难以编码到潜在空间中。</mark></p><p>**第二个不足之处源于对关键漏洞检测语句的不足考虑。**大多数易受攻击的程序及其修补版本通常具有类似的拓扑结构，因为它们都包含触发漏洞的语句，如图1所示。唯一的区别可能在于一些修复漏洞的语句，涉及与漏洞触发相关的控制流和程序相关信息。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404190957908.png" alt="image-20240419095734769" style="zoom:50%;" /><h3 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h3><p>提出了VULEXPLAINER，这是一种新颖的方法，用于从GNN-based漏洞检测器报告的脆弱代码中识别细粒度信息。给定一个检测到的脆弱代码片段，VULEXPLAINER首先从中提取程序切片，然后构造控制和数据依赖信息。与先前的工作（例如，DEEPWUKONG[6]）相比，VULEXPLAINER仅保留脆弱性触发和脆弱性依赖的程序路径级信息，而不是完整程序的信息。这显着提高了分析效率，因为程序路径包含较少的代码行。利用程序切片方法，VULEXPLAINER捕获了更多包含在代码行中的语义信息。因此，它可以提供比仅关注拓扑特征的方法更准确的解释结果。</p><p><strong>VULEXPLAINER的目标是识别漏洞的根本原因。 最近的工作[14]表明，错误触发路径是定位和修复漏洞的关键。</strong> 因此，为了评估我们方法的有效性，我们提出了一个新的评估指标，漏洞触发代码行覆盖率（以下简称LC，在第V-B节中详细说明）。 我们对VULEXPLAINER的有效性进行多维评估。 在第一个比较维度中，我们将VULEXPLAINER应用于解释四种基于图代码表示的最新漏洞检测器的输出，包括DEEPWUKONG [6]，REVEAL [7]，IVDETECT [8]和DEVIGN [9]。 这四个检测器都使用程序依赖图（PDGs，DEVIGN仅使用数据依赖图，不使用控制依赖图）作为代码图表示。</p><h3 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h3><p>总之，我们做出以下主要贡献：</p><p>• 一种新颖的基于 GNN 的漏洞检测器的漏洞细粒度信息定位技术。鉴于现有的基于 GNN 的漏洞检测器的解释能力不足，我们提出了 VULEXPLAINER 框架作为解决方案。它可以识别程序中包含漏洞触发语句的重要流路径，为识别出的漏洞提供更细粒度的语义上下文。我们在匿名仓库 [16] 上发布了本文中使用的源代码和数据集。</p><p>• 方法效果。通过对全面基准数据集的多维评估，我们展示了 VULEXPLAINER 在 LC 方面优于现有的解释方法，LC 是影响漏洞定位和修复的关键因素。平均而言，VULEXPLAINER 对本研究中使用的所有漏洞检测器的 LC 均高于 85%，显示出对不同基于 GNN 的漏洞检测器的良好泛化能力。</p><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h3 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h3><h4 id="an-example-of-locating-vulnerability"><a class="markdownIt-Anchor" href="#an-example-of-locating-vulnerability"></a> AN EXAMPLE OF LOCATING VULNERABILITY</h4><p>如图 3 所示。它包含一个缓冲区溢出漏洞，该漏洞通过复制更多数据（即代码片段第 11 行定义的 100 字节）来触发，而数组的最大容量为（即代码片段第 2 行定义的 50 字节）。基于 GNN 的漏洞检测器只输出检测结果为 1，表明代码片段是易受攻击的（或反之为 0）。漏洞定位任务的目标是构建一个包含漏洞触发代码行和漏洞相关变量的关键赋值的控制和数据依赖路径，或者此后称为流路径。为此，我们首先通过将语句映射到节点并根据节点之间的依赖信息构造流路径将源代码转换为图形表示。从路径中，我们选择满足我们漏洞定位目标的路径。具体来说，在图 3 中我们的示例中，从原始代码片段中提取了多条流路径，<strong>例如“8-11”、“2-6-7-13”等。其中，“2-6-7-11”被认为是最关键的路径，因为既包括第 2 行（关键变量赋值）又包括第 11 行（漏洞触发）。</strong><br />技术挑战。根据这个漏洞定位示例，对于一般和自动定位检测到的漏洞代码，技术挑战至少有两个方面：<br />• 挑战#1 <strong>通过基于 GNN 的检测器正确检测到易受攻击的代码后，缺乏一种有效的漏洞定位方法，该方法生成覆盖漏洞触发和相关关键变量赋值的流路径。</strong><br />• 挑战#2 <strong>给定生成的流路径，缺乏一种有效的路径选择机制，该机制识别最合适的路径作为检测到的漏洞的最合理最终数据流</strong>。为了解决这两个挑战，我们提出了 VULEXPLAINER，它可以从代码片段中导出的 PDG 中自动生成可行的流路径，并对它们进行排名以选择最合理的路径。该框架的技术细节将在第四节中介绍。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191945690.png" alt="image-20240419194551637" style="zoom:67%;" /><h4 id="locating-vulnerability-statements-using-gnn-based-detectors"><a class="markdownIt-Anchor" href="#locating-vulnerability-statements-using-gnn-based-detectors"></a> LOCATING VULNERABILITY STATEMENTS USING GNN-BASED DETECTORS</h4><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191959536.png" alt="image-20240419195905435" style="zoom:67%;" /><ul><li>流路径生成。</li></ul><p>给定一个以图形表示的脆弱代码片段，其控制和数据依赖已计算（见图4(a)），VULEXPLAINER 首先识别程序中可能触发漏洞的语句（即节点），表示为潜在汇点（potential sink points，PSPs）。接下来，VULEXPLAINER 在程序图中沿着从 PSP 开始的流路径迭代遍历，直到到达 PSP 的源（例如，表示关键变量赋值的节点）。类似地，VULEXPLAINER 生成图中所有符合条件的流路径，每个流路径以一个 PSP 结束。</p><ul><li>流程路径选择。</li></ul><p>VULEXPLAINER首先对每个流程路径进行向量化，并计算与漏洞概率相关的重要性分数（见图4(b)）。接下来，VULEXPLAINER选择具有最高重要性分数的流程路径作为漏洞数据流。请注意，我们不会直接针对路径选择训练分类器，因为每个路径被视为数据流而不是代码片段。</p><h4 id="流路径生成"><a class="markdownIt-Anchor" href="#流路径生成"></a> 流路径生成</h4><p>从原始代码图（即PDG）生成流路径，我们利用基于DLVD方法的程序切片，这种方法已被之前的作品广泛采用，例如DEEPWUKONG，REVEAL，IVDETECT，DEVIGN。切片原理基于PDG的控制依赖和数据依赖。更具体地，详细的流路径生成方法由算法1中的“GENERATESLICE”函数描述。它以代码图G和路径长度限制k（即，为了有效地移除后续搜索中的冗长路径）作为输入。我们将算法详细描述如下。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192022921.png" alt="image-20240419202206854" style="zoom:67%;" /><h4 id="流路径选择"><a class="markdownIt-Anchor" href="#流路径选择"></a> 流路径选择</h4><p><strong>在流程路径中，我们的目标是根据预测结果选择一个可以最好地定位触发漏洞的语句的路径。</strong></p><p>关键直觉是，如果一条路径包含了PSP及其源节点，则应选择该路径。例如，第III节中的示例中的路径“2 - 6 - 7 - 11”。如果有多条符合条件的路径，我们进一步根据路径重要性对它们进行排名，并选择具有最高重要性得分的路径。更正式地说，给定一个代码图G，我们从中提取流程路径并对每个流程路径进行向量化。</p><p>向量化一个流程路径的过程与检测器向量化相应代码图的过程相同。然后，我们通过将每个向量化的流程路径视为原始代码图的子图并将其输入经过良好训练的基于GNN的漏洞检测器来计算每个流程路径的重要性得分。这个过程可以正式描述为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192040306.png" alt="image-20240419204002233" /></p><p>在这里，g 是从 G 中提取的流路径，Φ 是基于 GNN 的漏洞检测器之一。最后，我们计算每条路径的重要性分数 ISg，衡量它们对于检测器预测相应代码片段的贡献。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192040633.png" alt="image-20240419204044559" /></p><p>假设在对G进行切片后有n个流路径，表示为{g1, …, gi, …gn}。漏洞数据流g∗表示为：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192041488.png" alt="image-20240419204114457" /></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192030658.png" alt="image-20240419203043537" style="zoom:67%;" /><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><p>评估了VULEXPLAINER在DEEPWUKONG、REVEAL、IVDETECT和DEVIGN的预测结果中定位漏洞语句的有效性。评估是为了检测CWE中排名前30位的8个漏洞，与GNN的五种最先进的解释器进行比较。为此，我们概述了本研究中使用的数据集以及涉及其标记过程（第V-A节）。接下来，我们详细阐述了实验设置。</p><h3 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h3><p>目标漏洞：此处使用的数据集必须支持细粒度检测，这需要明确的有关易受攻击代码行的信息。许多实际数据集中的缺陷行，如DEVIGN [9]，REVEAL，Fan [26]，都标有从提交的版本修补程序中提取的代码更改信息。如图7所示，包含CVE-2015-2029漏洞ID的示例代码包括标记为绿色的漏洞修复代码行。<strong>然而，这种标记方法只能检测到漏洞修复行，而未检测到漏洞触发行。</strong></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404192212129.png" alt="image-20240419221207069" style="zoom:67%;" /><p>在图7中的同一示例中，受污染流程中的语句被标记为粉红色，这并未涵盖触发漏洞的代码行。此外，fA函数处修复的漏洞可能会在fB函数处触发。在这种情况下，fA将被标记为易受攻击，而fB则为非易受攻击。更糟糕的是，Roland Croft等人[27]报告了真实数据集中约20-71%的假阳性漏洞样本的存在。由上可见，在实际数据集中准确标记易受攻击的代码行可能具有挑战性。由于噪声数据集可能会影响深度学习模型的性能[28]，我们从SARD [24]，一个合成漏洞数据库中组装我们的数据集。在SARD数据集中，每个程序（即测试用例）可能与一个或多个CWE ID相关联，因为一个程序可能包含不同类型的漏洞。更重要的是，每个易受攻击程序的触发漏洞语句已经被正确标记。我们的目标是检查2021年C/C++中30种最危险的软件缺陷中的八种，具体关注CWE20，CWE22，CWE78，CWE119，CWE125，CWE190，CWE400和CWE787。我们使用与DEEPWUKONG [6]相同的网络爬虫来收集所有可用程序。</p><p><strong>基准数据集处理：从 SARD 收集的数据按以下步骤进行处理。首先，我们将 SARD 程序的功能解析为供 REVEAL 和 IVDETECT 使用的 CPGs。我们直接利用由 DEEPWUKONG 生成的切片级别 XFGs（PDG 的子图），因为它们在其存储库中可用。然后，我们按照先前的工作对这些 CPGs 和 XFGs 进行标记和去重。任何包含一个或多个易受攻击语句的 CPG 或 XFG 将被标记为易受攻击，反之亦然。除此之外，我们将易受攻击样本中的关键语句标记为节点索引。</strong></p><p>基准数据集分布：经过处理阶段，我们从 SARD 数据集中收集了 82,243 个易受攻击的 CPGs 和 164,736 个非易受攻击的 CPGs，如表 I 所示。我们从 DEEPWUKONG 下载了 XFGs 数据集。重新标记后，我们总共组装了 151,774 个易受攻击的 XFGs 和 384,062 个非易受攻击的 XFGs。</p><h3 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h3><p>评估指标：我们首先使用六个常用的指标评估四种漏洞检测工具的有效性，包括准确率（ACC）、误报率（FPR）、漏报率（FNR）、召回率（R）、精确率（P）、F1分数（F1）。简化结果总结在表II中，详细结果可在我们的存储库[16]中找到。</p><p>评估解释方法以及VULEXPLAINER的有效性，我们提出度量<strong>行覆盖率</strong>，即LC。请注意，评估指标仅适用于真正阳性样本，即标记并检测为易受攻击的样本。**LC的定义如下：给定包含n个易受攻击代码行的代码片段C的流路径g，则LC = n/m，其中m（m ≥ n）表示数据集中标记为易受攻击的代码行的总数。**如果g包含数据集中标记的所有易受攻击语句，则LC为1；如果g不包含标记的易受攻击语句，则LC为0。</p><p>请注意，我们考虑使用忠实度[36]来衡量解释器和VULEXPLAINER的性能。然而，目前缺乏一种通用且标准的计算忠实度的方法，导致不同方法得出的结果差异巨大。这使得将忠实度作为评估指标之一变得不可靠。此外，我们的目标是定位和解释检测到的漏洞的原因，并不一定需要构建一个最大程度保留原始图属性的子图。</p><h4 id="rq1-vulexplainer能否准确定位触发漏洞的代码行"><a class="markdownIt-Anchor" href="#rq1-vulexplainer能否准确定位触发漏洞的代码行"></a> RQ1 VULEXPLAINER能否准确定位触发漏洞的代码行？</h4><p>设置两个参数，sparsity和k，用来控制flow path的节点数量，参数稀疏度由 1 − n/m 计算，其中 m 和 n 分别是图中和路径中的节点总数。直观地说，稀疏度控制着图中节点的分布均匀程度。更多节点集中在较少的路径中（即相对较长的路径）会导致较低的稀疏度。参数 k 指定了路径中的节点最大数量，如算法 1 所述。考虑这两个参数，流路径中的最大节点数 MaxN 由 min(k, (1 − 稀疏度) ∗ m) 给出。</p><p><strong>RQ1.1：VULEXPLAINER在各种类型的漏洞中能否表现一致？</strong></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201003834.png" alt="image-20240420100351781" /></p><p>如表III所示，VULEXPLAINER在定位不同类型的漏洞时表现出不同的性能。对于CWE-78漏洞，它取得了最高的LC分数（98％），对于CWE-20（84％）和CWE-119（87％）则相对较低。为了更好地理解这种差异背后的原因，我们对几个特殊案例进行了手动审查，并确认了以下三个可能的原因。</p><p>首先，所选的PSPs可能是不完整的。各种类型的语句可能会触发漏洞。某些漏洞，比如CWE-78，只能通过与系统命令相关的API触发，使得漏洞模式相对比较简单。然而，其他类型的漏洞（例如缓冲区溢出）可能会被各种语句触发，包括与内存相关的API、数组操作和指针操作。这导致代码图中出现更多的PSPs，随后在路径生成和选择过程中产生更多的干扰，这对我们的方法构成挑战。此外，我们目标的PSP模式可能不完整，可能会在解释过程中排除某些漏洞类型。</p><p>我们利用程序切片生成流程路径，以保留漏洞语义。在这个过程中，我们会筛选掉一些与漏洞有关的控制和数据依赖关系，而不包含变量。然而，使用我们的方法分析大量路径可能会变得困难，考虑到要探索和解析的指数级扩展可能性。</p><p>基于深度学习的检测器并不像我们期望的那样可靠。在某些情况下，检测器的输出分数显著低于预期，即使路径与漏洞强相关。这种不可靠性可能会影响到VULEXPLAINER的测量有效性。这也表明传统评估指标可能无法完全捕捉这些检测器的有效性。</p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201011857.png" alt="image-20240420101118758" style="zoom:50%;" /><p><strong>RQ1.2：VULEXPLAINER在不同基于图的漏洞检测器上能否表现一致？换句话说，VULEXPLAINER的性能是否受到检测器选择的影响？</strong></p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201011256.png" alt="image-20240420101152223" style="zoom:50%;" /><h4 id="rq2-vulexplainer能否超越现有的gnn漏洞检测解释方法"><a class="markdownIt-Anchor" href="#rq2-vulexplainer能否超越现有的gnn漏洞检测解释方法"></a> RQ2 VULEXPLAINER能否超越现有的GNN漏洞检测解释方法？</h4><p>结果：在使用评估指标LC对八种漏洞进行评估时，VE在比较中超越了所有五种解释方法。由于当k的值变化时可以观察到解释器表现的相同趋势，我们基于页面约束使用k = 7呈现和分析最终结果。以CWE-20为例，基于DEEPWUKONG的预测定位易受攻击行时，VE在LC方面比GL大约30%。至于CWE-125，用于REVEAL的定位易受攻击行时，GR仅获得51%的LC，而我们的方法达到96%。对于IVDETECT，DL仅获得4%的LC，而VE达到97%。与GE相比，在CWE-787上为DEVIGN定位易受攻击行时，VE达到91%的LC，几乎比GE高出33%。对于PE也观察到类似的模式，仅实现33%的LC。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201020607.png" alt="image-20240420102009538" /></p><p>分析：实验结果表明，仅依赖节点嵌入和代码图的拓扑结构来定位易受攻击代码片段的根本原因是不足够的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404201018628.png" alt="image-20240420101815581" /></p><h2 id="4-discussion"><a class="markdownIt-Anchor" href="#4-discussion"></a> 4 Discussion</h2><p>首先，我们只在SARD数据集上进行实验，该数据集包含合成和学术程序，但可能不代表真实世界的软件产品。我们在第V-A节中讨论了现有真实世界数据集中的问题。生成可靠的细粒度数据集仍然是一个悬而未决的问题。其次，我们的框架使用关键库API调用、数组或指针操作和操作符语句来执行程序切片作为PSPs。如第VI-A1节所述，这意味着某些边缘情况可能被忽视。此外，它还可能引入无关的语句作为汇点。增强我们的方法的一种方式是检测附加的补充类型的PSP模式，随后筛选出多余的汇点以减少潜在的不准确性。这需要对触发真实世界漏洞以及如何修复这些漏洞有额外的见解。我们只考虑分析PSPs，虽然进一步分析与漏洞相关数据输入到程序的潜在源点是一个有希望的对角线研究方向。第三，我们的实验仅限于C/C++程序中的八种漏洞类型。尽管如此，我们的方法可以轻松扩展到包括其他源-汇漏洞和其他编程语言。第四，我们的方法仅考虑基于四种基于图的漏洞检测器定位脆弱语句。然而，我们的方法很容易适用于其他检测器，并有可能用于其他程序分析任务。</p><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><aside> 💡 Others<hr /><h4 id="基于gnn的漏洞检测器"><a class="markdownIt-Anchor" href="#基于gnn的漏洞检测器"></a> 基于GNN的漏洞检测器</h4><p>最近，安全分析师和研究人员在漏洞检测任务中已经开始利用GNNs [9]，[7]，[8]，[6]，[17]，[18]。他们假设代码的图表示相对于传统的基于序列的表示方式，可以更好地保留与漏洞相关的程序的关键语义信息。通常，最常用的图表示是代码属性图（CPG），它与抽象语法树（AST）、控制流图（CFG）、控制依赖图（CDG）和数据依赖图（DDG）相结合。此外，另一种图表示程序依赖图（PDG）由CDG和DDG组成，可以被视为CPG的子结构，在程序切片中被广泛使用。在本研究中，我们主要利用PDG进行切片。通常，基于GNN的检测器的检测阶段通常包括三个步骤，如图2所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404191939483.png" alt="image-20240419193946385" /></p><ul><li>将源代码解析为图形表示。</li></ul><p>目标源代码片段通常是函数或片段。在这里，我们利用Joern [20]来转储代码片段的图形表示，以支持那些基于GNN的检测器（DEEPWUKONG [6]，REVEAL [7]，IVDETECT）。</p><ul><li>将代码图嵌入到向量化表示中。</li></ul><p>在代码图中，一个节点通常代表一个程序语句，而一条边表示两个语句之间的关系（执行顺序或 def-use）。在这里，每个节点可以通过 DOC2VEC [21] 或 WORD2VEC [22] 进行向量化。然后，通过顺序向量化所有包含的节点生成向量化图数据。</p><ul><li>使用训练良好的 GNN 模型对向量化代码图进行分类。</li></ul><p>通过代码片段的向量化图和它们的标签，可以训练 GNN 模型，如图卷积网络（GCN）和门控图神经网络（GGNN），来检测目标程序的向量化图数据。</p><h4 id="控制和数据依赖关系"><a class="markdownIt-Anchor" href="#控制和数据依赖关系"></a> 控制和数据依赖关系</h4><p>在一个PDG中，控制依赖边Si → Sj表示Sj语句是否会根据Si中的约束条件执行。数据依赖边S′ i → S′ j意味着在S′ j中使用了在S′ i中定义的值。并且在从S′ i到S′ j的路径上没有其他语句重新定义相应的值。程序的控制依赖图可以通过Cytron R等人提出的算法确定。而数据依赖关系可以通过到达定义分析计算。</p><h4 id="potential-sink-pointspsps"><a class="markdownIt-Anchor" href="#potential-sink-pointspsps"></a> Potential Sink Points（PSPs）</h4><p>PSPs是与漏洞关系密切的语句。在算法1中，它们由函数“ExtractSinkNode”（第3行）提取，该函数考虑了我们程序切片中以下四种类型的PSPs。我们采用了李等人提出的相同定义[25]。</p><p>函数库/API函数调用（FC）</p><p>这种类型的PSP几乎涵盖了除整数溢出之外的所有漏洞类型。不同类型的漏洞由各种类型的API调用触发。例如，操作系统命令注入通常由诸如system和execl之类的API触发，而缓冲区溢出通常由类似memcpy的数据复制函数触发。</p><p>数组使用（AU）。</p><p>这种类型的PSP通常出现在内存错误中。在本研究中，AU仅涵盖缓冲区溢出漏洞。例如，“data[i] = 1;”可能导致缓冲区溢出。请注意，我们在这项工作中不考虑诸如带有常量索引的数组访问等微不足道的情况。</p><p>指针使用（PU）。</p><p>与AU类似，PU通常出现在内存错误中。本研究仅涵盖缓冲区溢出漏洞。</p><p>算术表达式（AE）。</p><p>这种类型的PSP通常是像“a + 1”或“a++”这样的算术表达式。AE通常与整数溢出和除零漏洞有关。在这里，我们主要关注前者。请注意，在这项工作中我们不考虑诸如带有条件检查的自增和自减操作等微不足道的情况。</p><h4 id="dependent-statement"><a class="markdownIt-Anchor" href="#dependent-statement"></a> Dependent Statement</h4><p>算法1中的函数“ExtractPrecNodes”（第19行）建立了节点“n”的依赖关系（即识别节点“n”依赖的节点）。我们发现，并非每个节点“n”的依赖关系都与漏洞有关，因为源代码语句可能包含多个表达式，其中仅有一个可能触发漏洞。因此，在提取依赖节点时，我们只关注涉及每个PSP相关关键变量的控制和数据依赖。在图5中进行说明，我们的工具识别了可能触发语句S3中整数下溢的算术操作“CHAR ARRAY SIZE - 1”。虽然S3通过变量“connectSocket”与S1存在数据依赖，但它们不出现在算术操作中。因此，在进行切片时，我们不考虑数据依赖边“S1 - S3”。对于其他节点，我们考虑当前节点的所有依赖语句。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VDSimilar</title>
      <link href="/2023/12/18/Papers/Vul/VDSimilar/"/>
      <url>/2023/12/18/Papers/Vul/VDSimilar/</url>
      
        <content type="html"><![CDATA[<h3 id="paper"><a class="markdownIt-Anchor" href="#paper"></a> Paper</h3><p>VDSimilar: Vulnerability detection based on code similarity of vulnerabilities and patches，Hao Sun, Lei Cui，C&amp;S(B)。</p><h3 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h3><p>现有的研究将漏洞检测视为一个分类问题，在捕获语义和语法相似性的同时需要大量的标记数据。本研究认为漏洞的相似性是漏洞检测的关键，本文准备了一个由漏洞和相关补丁组成的相对较小的数据集，并尝试比较漏洞之间的相似性、漏洞补丁之间的差异性来实现漏洞检测。为此，使用Siamese网络+BiLSTM+Attention作为检测模型。在OpenSSL和Linux的876个漏洞和补丁的数据集上，提出了模型VDSimilar，在OpenSSL的AUC值上达到了约97.17%，优于目前基于深度学习的漏洞检测SOTA方法。</p><h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3><p>现有的基于代码相似性的漏洞检测方法普遍是基于代码段语法和语义的相似性来进行的，但是两份语法语义相似的代码很可能因为一丁点差别而一个有漏洞一个没有漏洞，因此，本文希望找到一个能从漏洞角度捕获相似性的方法。另外，基于深度学习的方法总是需要大量的数据，比如VulDeepecker需要61638个code gadget，准备这样的数据集需要花费巨大的人力资源，本文希望找到一个可以在小数据集上使用的深度学习检测方法。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000651.jpeg" alt="img" /></p><p>本文提出了一个基于度量学习的代码漏洞检测方法，学习了一个应用于漏洞和补丁数据集上的代码相似性检测器。首先，准备一个CVE brunch的数据集，每个CVE brunch包含与一个CVE相关的多个漏洞函数和补丁函数，如上图所示，这些CVE函数可以从不同版本的软件中获得，它们遵循两个规则：</p><ul><li>对于同一个CVE中两个版本的漏洞函数，漏洞片段保持不变</li><li>对于一个漏洞函数和一个补丁函数，漏洞片段一定消失</li></ul><p>因此，每个CVE brunch都可能提供一个CVE漏洞特征。其次，从漏洞的角度来看，不同版本的两个漏洞函数应该被视为相似的，即使版本迭代过程中存在代码更改；另一方面，由于补丁代码中漏洞片段已经消除，因此即使漏洞函数与补丁函数语法和语义相似，也应视为不同。本研究在本文提出的数据集上与之前的方法比较，证明了VDSimilar的有效性。</p><p>本文认为，相比整个漏洞函数，漏洞代码片段是漏洞检测的关键，如下图所示，显示了t1_lib.c 的 tls_decrypt_ticket函数的代码片段，该函数在OpenSSL的三个版本中演进。该功能被报告为一个漏洞(CVE-2014-3567)，影响0.9.8zb和1.0.1i，然后在更高版本的1.0.1l中修复，下图中第二个函数应该是1.0.1i。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000691.jpeg" alt="img" /></p><p>可见，相比第一版，第二版增加了4行，改变了一行，都是漏洞函数。第三版相比第二版只增加了一行，和第一版相比更接近于第二版，但第三版确是补丁函数。OpenSSL程序不断发展，其中一个函数可能会由于诸多原因修改，如修复bug、优化性能或重构代码。两个版本的相同函数在语法和语义上可能会有很大的差异，而对于需要修复的漏洞，补丁可能只涉及几行甚至一行代码，因此跨连续版本的漏洞函数和补丁函数在语法上是高度相似的。</p><p>因此，一种好的基于代码相似度的漏洞检测方法应该更多地关注漏洞片段的相似度，而不是整个函数的代码语法和语义的相似度。</p><h3 id="method"><a class="markdownIt-Anchor" href="#method"></a> Method</h3><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000615.jpeg" alt="img" /></p><p>上图是VDSimilar的整体framework，数据集包含了很多的CVE漏洞，每个CVE漏洞由几个版本的漏洞函数和补丁函数组成。由于训练样本过少，本文采用度量学习的方式训练计算相似性的分类器，对于漏洞-漏洞函数对，标记为相似label为1，对于漏洞-补丁函数对，标记为不相似label为0，训练Siamese网络，训练过程中引入Attention，最终计算测试函数和漏洞库函数的相似性，相似性高于一定阈值被认为存在漏洞。</p><ul><li><strong>数据准备</strong></li></ul><p>为了准备数据集，本文从CVE Details数据库中收集了一组CVE，如下图所示，漏洞一般可以通过两种途径得到。一种是直接下载product，然后根据漏洞详细信息中描述的文件名和函数名提取漏洞函数；另一种是直接从外部链接中引用的补丁中提取漏洞；由于有些外部链接并不可用，因此本文采用第一种方式。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000621.jpeg" alt="img" /></p><p>为了获得补丁，假设最新的有漏洞版本之后的Linux和OpenSSL版本漏洞已经修复，通过从多个版本的程序中提取漏洞和补丁函数，生成一组相似对({V, V, 1})和差异对({V, P, 0})。使用网络爬虫Scrapy框架爬取CVE Details中的程序版本、漏洞函数名、文件名和补丁等等信息，可以为每个CVE获取一个元组，即(CVE、软件、漏洞版本、补丁版本、文件名、函数名)。</p><p>对于每一个CVE，根据上文提取的详细信息，使用LLVM解析源代码，提取出一组漏洞函数和补丁函数。使用hash的方式去除重复函数、修正可能出现的漏洞标签错误信息。然后生成相似对和差异对，在该过程中扩大数据集，方便训练。</p><ul><li><strong>检测模型</strong></li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000648.jpeg" alt="img" /></p><p>本文的检测模型Siamese架构如上图所示，首先进行embedding，然后输入BiLSTM中得到输出，经过一层Attention后计算相似度即可。值得一提的是该Attention是self-attention，类似transformer一样，由H成参数矩阵生成Q,K,V，然后进行Attention计算，该Attention过程的作用是将注意力聚集在漏洞代码片段而不是整个函数上。</p><p>Siamese网络是一个共享权重的孪生网络，模型训练过程中最大化漏洞函数之间的相似度，最小化漏洞函数和补丁函数的相似度。在测试过程中计算每个目标函数与已有漏洞函数的相似度，如果接近1则有漏洞，如果接近0则没有漏洞，算法伪代码如下。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000618.jpeg" alt="img" /></p><h3 id="evaluation"><a class="markdownIt-Anchor" href="#evaluation"></a> Evaluation</h3><p>与Simian，Nicad，ReDeBug，PMD-CPD，SyseVR，VulDeePecker这几个方法做比较，本文的Siamese模型在Linux和OpenSSL数据集上取得了更高的检测准确率和F1值。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000002.jpeg" alt="img" /></p><p>本文将VDSimilar和几个之前的深度学习模型做比较，发现Siamese+BiLSTM+Attention的VDSimilar模型具有最好的泛化性能。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403291000010.jpeg" alt="img" /></p><h3 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h3><p>本文提出了一个基于代码相似性的源代码漏洞检测方法，准备了一个由漏洞和相关补丁组成的相对较小的数据集，并尝试比较漏洞之间的相似性、漏洞补丁之间的差异性来实现漏洞检测。为此，使用Siamese网络+BiLSTM+Attention作为检测模型。在OpenSSL和Linux的876个漏洞和补丁的数据集上取得了良好的实验效果，证明了模型的有效性。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vulnerability Detection by Learning From Syntax-Based Execution Paths of Code</title>
      <link href="/2023/12/18/Papers/Vul/Vulnerability%20Detection%20by%20Learning%20From%20Syntax-Based%20Execution%20Paths%20of%20Code/"/>
      <url>/2023/12/18/Papers/Vul/Vulnerability%20Detection%20by%20Learning%20From%20Syntax-Based%20Execution%20Paths%20of%20Code/</url>
      
        <content type="html"><![CDATA[<h2 id="0-abstract"><a class="markdownIt-Anchor" href="#0-abstract"></a> 0 Abstract</h2><p>在这项工作中，我们提出将代码片段的基于语法的控制流图（CFG）分解为多个执行路径来检测漏洞。具体来说，给定一个代码片段，我们首先基于它的抽象语法树（AST）构建它的CFG，将这种CFG称为基于语法的CFG，并将CFG分解为从入口节点到出口节点的多个路径。接下来，我们采用预先训练的代码模型和卷积神经网络来学习具有路径内和路径间注意力的路径表示。路径的特征向量被组合为代码片段的表示，并被输入分类器以检测漏洞。将代码片段分解为多个路径可以过滤掉一些与漏洞无关的冗余信息，并帮助模型关注漏洞特征。此外，由于分解的路径通常比代码片段短，位于长代码尾部的信息更有可能被处理和学习。为了评估我们模型的有效性，我们构建了一个包含超过231k个代码片段的数据集，其中有24k个漏洞。实验结果表明，所提出的方法在精度、召回率和F1分数方面分别优于最先进的基线至少22.30%、42.92%和32.58%。我们的进一步分析调查了所提出的方法优越性的原因。</p><h2 id="1-intro-or-overview"><a class="markdownIt-Anchor" href="#1-intro-or-overview"></a> 1 Intro or Overview</h2><h4 id="11-problem-and-challenge"><a class="markdownIt-Anchor" href="#11-problem-and-challenge"></a> 1.1 Problem and Challenge</h4><p>漏洞检测对于保护软件系统至关重要。已经提出了基于深度学习的各种方法来学习漏洞模式并识别它们。尽管这些方法在这项任务中显示出了巨大的潜力，但它们仍然存在以下问题：<mark>（1）它们很难将与漏洞相关的信息与大量无关的信息区分开来，这阻碍了它们捕捉漏洞特征的有效性。</mark>（2） <mark>它们在处理长代码方面效果较差，因为许多神经模型会限制输入长度，这阻碍了它们表示长时间易受攻击的代码片段的能力。</mark></p><h4 id="12-motivation"><a class="markdownIt-Anchor" href="#12-motivation"></a> 1.2 Motivation</h4><p>Observation 1: A vulnerable function may contain a vast of statements unrelated to vulnerabilities.</p><p>Observation 2: Truncating the statements in the tail of a long code snippet may negatively affect the effectiveness of vulnerability detection.</p><h4 id="13-contribution"><a class="markdownIt-Anchor" href="#13-contribution"></a> 1.3 Contribution</h4><h2 id="2-architecture-method"><a class="markdownIt-Anchor" href="#2-architecture-method"></a> 2 Architecture &amp; Method</h2><h4 id="21-system-overview"><a class="markdownIt-Anchor" href="#21-system-overview"></a> 2.1 System Overview</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403151148919.png" alt="image-20240315114845862" /></p><p>形式上，我们采用Gi=（Vi，Ei）来表示代码片段ci的基于语法的CFG，其中Vi=（v1 i，v2 i，…v|Vi|i）是包含|Vi|语句的节点集。Ei是表示语句之间的控制流的边集。每条边都是ci中两个语句之间的关系，因此一个语句可以在另一个语句之后执行。Gi中的路径是节点序列p=（n1，n2，…，nk），其中节点nk是ci的陈述k。对于任何一对相邻节点np和nq，存在从np到nq的边。如果起始节点等于结束节点，则路径将是一个循环。</p><p>首先将每个代码片段解析为AST，并根据AST构建基于语法的CFG。接下来，我们提出了一种基于贪婪的路径选择算法，从基于语法的CFG中选择多个执行路径，即将代码片段分解为几个执行路径。然后，通过CodeBERT[24]将所选路径编码为具有路径内注意力的向量，然后将其馈送到CNN中以捕获路径间注意力。最后，我们利用MLP分类器来执行检测。</p><h4 id="22-method"><a class="markdownIt-Anchor" href="#22-method"></a> 2.2 Method</h4><p>Construction of Control Flow Graph From AST</p><p>该阶段以代码片段为输入，使用tree-sitter[50]将其解析为AST，并从AST构建基于语法的CFG。在本节中，我们使用图3中的示例来说明我们如何从代码片段的AST构建基于语法的CFG。在构造CFG之前，我们使用正则表达式删除代码段中的空行和注释。我们还在代码中标记每条语句的行号。由于基于语法的CFG中的每个节点代表一个单独的语句，因此在构造CFG时，我们只考虑AST中的语句节点。为了简化演示，我们做出以下定义：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403151615419.png" alt="image-20240315114834197" /></p><p>简单语句：在AST中不包含其他语句的语句。</p><p>Next语句：节点的Next语句是指在执行节点后可能执行的语句。一个节点可能有多个Next语句。</p><p>非子Next语句：节点的非子Next声明是指该节点的Next语句，不包含在以该节点为根的子树中。</p><p>Normal语句：不是break_语句、continue_Statement、return_Statement和throw_Statement的语句。</p><p>为了构造代码段的基于语法的CFG，我们首先将代码段的所有语句添加到CFG中作为其节点，并将第一个语句视为入口节点，将所有return_statement、assert_statement和throw_statement视为出口节点。如果代码片段的最后一条语句不是出口节点，我们将在代码末尾添加一个伪出口节点。然后，我们以广度优先的方式遍历AST，并为每个语句类型设计规则，以在CFG中构建边。</p><p>1） 对于每个既是简单语句又是普通语句的语句，如果AST中存在其下一个同级语句，我们将其连接到此同级语句。例如，在图3中，我们将节点2连接到节点3，将节点3连接到节点4。</p><p>2） 对于每个循环语句，即For_statement和while_statement，如果存在这样的语句，我们将其与第一个子语句和下一个同级语句连接起来。如果它的最后一个子语句是Normal语句，我们将此语句连接到循环语句。例如，在图3中，我们将节点4连接到节点5，将节点4与节点10连接，将节点5与节点4连接。</p><p>3） 对于每个break_statement，我们首先找到它的第一个祖先，它是沿着AST的循环语句或switch_statement。然后，我们将其连接到祖先的非子下一个语句。</p><p>4） 对于每个continue_statement，我们首先找到它的第一个祖先，即沿着AST的循环语句。然后，我们把它和这个祖先联系起来。</p><p>5） 对于每个if_statement，如果存在这样的语句，我们首先将其连接到其下一个同级语句，如果最后一个子语句是Normal语句，则将其then_block的最后一个子声明连接到其当前next语句。例如，在图3中，我们将节点6连接到节点4，将节点7连接到节点4.将节点10连接到节点12，将节点11连接到节点12。然后，如果它的子级包含else_statement，我们将else_Statements连接到它的每个Next Statements，将if_statement中的边移除到它的Next Statements中，并将if_sttatement中的边缘添加到else_statement。对于图3，我们将节点8连接到节点4，移除从节点6到节点4的边，并将节点6连接到节点8。接下来，我们遍历else_语句。我们将其最后一个子语句连接到当前的Next语句。如果它的最后一个子语句是Normal语句，我们会将其边缘移除到Next语句，并将其连接到第一个子语句。对于图3，我们将节点9连接到节点4，将节点8移除到节点4并将节点8连接到节点9。最后，我们将if_statement连接到它的then_block的第一个子语句。对于图3，我们将节点5连接到节点6，将节点6连接到节点7，将节点10连接到节点11。</p><p>6） 对于每个switch_statement，我们将其连接到其第一个case_statement。对于每个case_statement，我们首先将其连接到下一个case_statementor default_statement。然后，如果这个case_statement的最后一个子语句是Normal语句，我们将其连接到这个case_statement的当前Next语句。最后，我们将case_statement连接到它的第一个子语句。对于每个default_statement，如果其最后一个子语句不是Normal语句，我们将其连接到其第一个子语句，并将其最后一个子语句连接到switch_statement的Non-child-Next语句。</p><p>7） 对于每个try_statement，我们将其catch_clauses视为语句。我们不能为try_statement构造一个“声音”CFG，因为我们不能知道每个函数调用只能从调用方的AST抛出哪些异常。此外，构建一个“完整”的CFG需要将try_block中的每个语句连接到每个catch_clause，这可能会引入太多的死路径，并对以下阶段产生负面影响。因此，我们选择只将try_block中的最后一个Normal语句连接到catch_clauses。具体来说，我们将try_statement连接到其try_block中的第一个语句，将其try_bock中的最后一个Normal语句连接到其第一个catch_clause。对于每个catch_clause，我们将其连接到它的第一个语句和下一个catch_clause。此外，对于try_block和每个catch_clause中的最后一个语句，即Normal语句，我们将其连接到try_statement的Non-Child Next语句。</p><p><strong>Path Selection</strong><br />一个代码片段可以被视为其所有执行路径的组合。但是，如果代码段包含循环，则它可能具有无限的执行路径。它可能需要许多计算资源来编码代码片段的所有执行路径。**因此，我们认为，在CFG中对所有执行路径进行编码以学习相应代码片段的表示是不切实际的。我们将基于语法的CFG中的执行路径定义为从CFG的入口节点到出口节点的路径，并从此将其称为执行路径。此外，在看不见的代码片段中准确定位易受攻击的语句是非常重要的。**如果我们只提取一个执行路径来表示代码片段，那么很可能会错过易受攻击的语句，并对漏洞检测的性能产生负面影响。幸运的是，根据我们对现实世界漏洞的观察和第三节中给出的激励性示例，我们发现一些执行路径通常可以涵盖漏洞的根本原因。因此，我们选择并编码几个具有代表性的执行路径来表示相应的代码片段，而不是对CFG中的所有或仅一个执行路径进行编码。Alon等人也使用了类似的策略。[51]在将代码片段表示为AST路径时。该阶段负责从先前阶段构建的CFG中选择几个具有代表性的执行路径。</p><p>选择执行路径有两个要求：首先，为了避免丢失代码片段中的重要信息，所选路径应覆盖尽可能多的代码行。其次，为了减轻模型训练的负担，我们希望选择的路径尽可能短。不幸的是，这两个要求在某种程度上是冲突的。为了在它们之间进行权衡，我们提出了一种基于贪婪的路径选择算法。</p><h2 id="3-experiment-and-evaluation"><a class="markdownIt-Anchor" href="#3-experiment-and-evaluation"></a> 3 Experiment and Evaluation</h2><h4 id="31-dataset-and-process"><a class="markdownIt-Anchor" href="#31-dataset-and-process"></a> 3.1 DataSet and Process</h4><h4 id="32-evaluation"><a class="markdownIt-Anchor" href="#32-evaluation"></a> 3.2 <strong>Evaluation</strong></h4><h2 id="4-conclusion"><a class="markdownIt-Anchor" href="#4-conclusion"></a> 4 Conclusion</h2><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><aside> 💡 Others<hr />]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
          <category> Vulnerabilities </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> Vulnerabilities </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/12/16/hello-world/"/>
      <url>/2023/12/16/hello-world/</url>
      
        <content type="html"><![CDATA[<p>这是一个指南</p><p><a href="https://gavinblog.github.io/anzhiyu-docs/">安知鱼主题指南 (gavinblog.github.io)</a></p><h3 id="布局layout"><a class="markdownIt-Anchor" href="#布局layout"></a> 布局（Layout）</h3><p>Hexo 有三种默认布局：<code>post</code>、<code>page</code> 和 <code>draft</code>。在创建这三种不同类型的文件时，它们将会被保存到不同的路径；而您自定义的其他布局和 <code>post</code> 相同，都将储存到 <code>source/_posts</code> 文件夹。</p><table><thead><tr><th style="text-align:left">布局</th><th style="text-align:left">路径</th></tr></thead><tbody><tr><td style="text-align:left"><code>post</code></td><td style="text-align:left"><code>source/_posts</code></td></tr><tr><td style="text-align:left"><code>page</code></td><td style="text-align:left"><code>source</code></td></tr><tr><td style="text-align:left"><code>draft</code></td><td style="text-align:left"><code>source/_drafts</code></td></tr></tbody></table><h1 id="1-常用命令"><a class="markdownIt-Anchor" href="#1-常用命令"></a> 1 常用命令</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># draft</span><br><span class="line">hexo new draft &quot;test&quot;</span><br><span class="line"></span><br><span class="line">hexo publish draft &quot;test&quot;</span><br></pre></td></tr></table></figure><h1 id="2-公式"><a class="markdownIt-Anchor" href="#2-公式"></a> 2 公式</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm un hexo-renderer-marked --save</span><br><span class="line"># or</span><br><span class="line">npm un hexo-renderer-kramed --save</span><br><span class="line"># 安装 `hexo-renderer-markdown-it-plus`</span><br><span class="line">npm i @upupming/hexo-renderer-markdown-it-plus --save</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在根目录的 _config.yml 中使用下面的配置将 strict 设置为 false</span></span><br><span class="line"><span class="attr">markdown_it_plus:</span></span><br><span class="line">  <span class="attr">plugins:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">plugin:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">&#x27;@neilsustc/markdown-it-katex&#x27;</span></span><br><span class="line">      <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">options:</span></span><br><span class="line">        <span class="attr">strict:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 指南 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo bug</title>
      <link href="/2023/12/16/hello-bug/"/>
      <url>/2023/12/16/hello-bug/</url>
      
        <content type="html"><![CDATA[<p>这是一个bug指南，在使用Hexo的时候遇到了一些bug，自己在这里对解决过的bug做以记录。</p><h4 id="nunjucks-error-line-26-column-109-parseaggregate-expected-comma-after-expression"><a class="markdownIt-Anchor" href="#nunjucks-error-line-26-column-109-parseaggregate-expected-comma-after-expression"></a> Nunjucks Error: [Line 26, Column 109] parseAggregate: expected comma after expression</h4><p>这个自己是hexo在render公式的时候产生的问题，不能两个”{“紧接着放在一起，应该{ {…} }在<strong>之间加空格</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 指南 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Basic terms and concepts</title>
      <link href="/2023/12/16/Security/%E5%9F%BA%E6%9C%AC%E6%9C%AF%E8%AF%AD/"/>
      <url>/2023/12/16/Security/%E5%9F%BA%E6%9C%AC%E6%9C%AF%E8%AF%AD/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Basic terms and concepts</p></blockquote><h2 id="vulnerability"><a class="markdownIt-Anchor" href="#vulnerability"></a> Vulnerability</h2><h4 id="vulnerability-2"><a class="markdownIt-Anchor" href="#vulnerability-2"></a> Vulnerability</h4><p><code>VUL</code>，Vulnerability的缩写，泛指<code>漏洞</code>。漏洞是指计算机系统中存在可能被攻击者利用的弱点、缺陷或安全漏洞。这些漏洞允许未经授权的访问，如窃取敏感数据，或允许攻击者在目标计算机系统上执行任意操作，如安装恶意软件。此类漏洞可能表现在不同方面，包括软件代码、硬件组件、配置或设计。</p><h4 id="cwe"><a class="markdownIt-Anchor" href="#cwe"></a> CWE</h4><p>CWE是社区开发的漏洞列表。它提供了一种标准化和结构化的方法来识别和分类这些漏洞，并为每个漏洞分配一个唯一的标识符。例如，CWE-119提到了臭名昭著的“缓冲区溢出”。遵循不同级别的概念抽象，CWE将漏洞组织在树状层次结构中，其中低级CWE ID与高级CWE ID相关联。例如，表示“越界写入”的CWE-787和表示“越界读取”的CWE-125都是属于CWE-119的较低级别类型。</p><h4 id="poc"><a class="markdownIt-Anchor" href="#poc"></a> <strong>POC</strong></h4><p><code>POC，Proof of Concept</code>，中文意思是“<code>概念证明</code>”。这个短语会在漏洞报告中使用，漏洞报告中的POC则是<code>一段说明或者一个攻击的样</code>例，使得读者能够确认这个漏洞是真实存在的。</p><h4 id="exp"><a class="markdownIt-Anchor" href="#exp"></a> <strong>EXP</strong></h4><p><code>EXP</code>，Exploit，中文意思是“<code>漏洞利用</code>”。意思是一段对漏洞<code>如何利用的详细说明或者一个演示的漏洞攻击代码</code>，可以使得读者完全了解漏洞的机理以及利用的方法。</p><h4 id="cve漏洞编号"><a class="markdownIt-Anchor" href="#cve漏洞编号"></a> <strong>CVE漏洞编号</strong></h4><p><code>CVE</code> 的英文全称是“Common Vulnerabilities &amp; Exposures”公共漏洞和暴露，例如CVE-2015-0057、CVE-1999-0001等等。CVE就好像是一个字典表，为广泛认同的<a href="https://so.csdn.net/so/search?q=%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8&amp;spm=1001.2101.3001.7020">信息安全</a>漏洞或者已经暴露出来的弱点给出一个公共的名称。如果在一个漏洞报告中指明的一个漏洞，如果有CVE名称，你就可以快速地在任何其它CVE兼容的数据库中找到相应修补的信息，解决安全问题。</p><p>可以在https://cve.mitre.org/网站根据漏洞的CVE编号搜索该漏洞的介绍。</p><p>也可以在中文社区http://www.scap.org.cn/上搜索关于漏洞的介绍</p><h4 id="0day漏洞和0day攻击"><a class="markdownIt-Anchor" href="#0day漏洞和0day攻击"></a> <strong>0DAY漏洞和0DAY攻击</strong></h4><p>在计算机领域中，零日漏洞或零时差漏洞（英语：Zero-dayexploit）通常是指还没有补丁的安全漏洞，而零日攻击或零时差攻击（英语：Zero-dayattack）则是指利用这种漏洞进行的攻击。提供该漏洞细节或者利用程序的人通常是该漏洞的发现者。零日漏洞的利用程序对网络安全具有巨大威胁，因此零日漏洞不但是黑客的最爱，掌握多少零日漏洞也成为评价黑客技术水平的一个重要参数。<br />零日漏洞及其利用代码不仅对犯罪黑客而言，具有极高的利用价值，一些国家间谍和网军部队，例如美国国家安全局和美国网战司令部也非常重视这些信息。据路透社报告称美国政府是零日漏洞黑市的最大买家。</p><h4 id="can"><a class="markdownIt-Anchor" href="#can"></a> CAN</h4><p>CAN和CVE的唯一区别是前者代表了候选条目，还未经CVE编辑委员会认可，而后者则是经过认可的条目。 然后，两种类型的条目都对公众可见，条目的编号不会随着认可而改变—仅仅是“CAN”前缀替换成了“CVE”。</p><h4 id="bugtraq"><a class="markdownIt-Anchor" href="#bugtraq"></a> BUGTRAQ</h4><p>一个完整的对计算机安全漏洞（它们是什么，如何利用它们，以及如何修补它们）的公告及详细论述进行适度披露的邮件列表</p><h4 id="cncve"><a class="markdownIt-Anchor" href="#cncve"></a> CNCVE</h4><p>中国（CN）的 CVE ，是CNCERT/CC（国家计算机网络应急处理协调中心）为漏洞进行编号的一个自己的标准。CNCVE不但包含漏洞的描述予以统一定义，还将包括漏洞的补丁、验证等措施，更方便、有用。</p><h4 id="cnvd"><a class="markdownIt-Anchor" href="#cnvd"></a> CNVD</h4><p>国家信息安全漏洞共享平台。是由国家计算机网络应急技术处理协调中心（简称CNCERT）联合国内重要信息系统单位、基础电信运营商、网络安全厂商、软件厂商和互联网企业建立的信息安全漏洞信息共享知识库。</p><h4 id="cnnvd"><a class="markdownIt-Anchor" href="#cnnvd"></a> CNNVD</h4><p>中国国家信息安全漏洞库。是中国信息安全测评中心为切实履行漏洞分析和风险评估的职能，负责建设运维的国家信息安全漏洞库，为我国信息安全保障提供基础服务</p><h4 id="cvsscommon-vulnerability-scoring-system"><a class="markdownIt-Anchor" href="#cvsscommon-vulnerability-scoring-system"></a> CVSS(Common Vulnerability Scoring System)</h4><p>通用漏洞评分系统，行业公开标准，用来评测漏洞的严重程度，0-10分值越高越严重,美国国家漏洞数据库官网：<a href="https://nvd.nist.gov/vuln/search%E5%8F%AF%E6%9F%A5%E8%AF%A2CVE%E5%AF%B9%E5%BA%94CVSS%E5%88%86%E5%80%BC">https://nvd.nist.gov/vuln/search可查询CVE对应CVSS分值</a></p><p>PS：评分会受时间和空间影响，如随着时间推移，漏洞相关补丁越多，可被利用性越低；漏洞存在不同的环境，也会影响漏洞的威胁程度</p><h4 id="cpecommon-platform-enumeration"><a class="markdownIt-Anchor" href="#cpecommon-platform-enumeration"></a> CPE（Common Platform Enumeration）</h4><p>以标准化方式为软件应用程序、操作系统及硬件命名的方法</p><h2 id="code-representation"><a class="markdownIt-Anchor" href="#code-representation"></a> Code Representation</h2><h4 id="code-tokens"><a class="markdownIt-Anchor" href="#code-tokens"></a> Code Tokens</h4><p>代码标记是指程序中带有特定语义的词法标记。它们包括标识符（例如变量和函数名）、关键字、分隔符（例如标点符号和分隔符）和运算符（例如算术运算符和逻辑运算符）。通过词法解析，代码片段可以直接表示为一个序列或一组标记。</p><h4 id="ast"><a class="markdownIt-Anchor" href="#ast"></a> AST</h4><p>抽象语法树，是将代码元素组织成树结构的基本代码表示。树叶对应于主代码元素，如变量类型、符号和运算符，而非叶节点表示一组受限的代码结构，如表达式和循环。与词汇解析的代码标记相比，AST除了词汇信息外，还自然地体现了源代码的句法结构。</p><p>AST 是源代码的有序树表示结构。 通常，它是代码解析器用来理解程序的基本结构并检查语法错误的第一步表示。 因此，它构成了生成许多其他代码表示的基础，并且 AST V ast 的节点集包括本文使用的其余三种代码表示的所有节点。 从根节点开始，代码被分解为代码块、语句、声明、表达式等，最后分解为形成叶节点的主标记。 主要的AST节点如图所示。所有方框都是AST节点，第一行有具体代码，并注释了节点类型。 蓝色框是 AST 的叶节点，紫色箭头表示子父 AST 关系。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202403062143171.png" alt="image-20240306214316124" /></p><h4 id="cfg"><a class="markdownIt-Anchor" href="#cfg"></a> CFG</h4><p>CFG或控制流图是一个有向图，其中每个节点表示语句的基本块，每条边表示函数内块之间的控制流。CFG是通过识别AST中的控制相关性来构建的。通常要求代码在功能上是完整的和可编译的，以精确地生成CFG。</p><p>CFG 描述了程序在执行期间可能遍历的所有路径。 路径选择由条件语句确定，例如 if、for 和 switch 语句。 在CFG中，节点表示语句和条件，它们通过有向边连接以指示控制的转移。  CFG 边缘在图 2 中用绿色虚线箭头突出显示。特别是，流程从入口开始并在出口结束，并且在 if 语句处派生出两条不同的路径。</p><h4 id="pdg"><a class="markdownIt-Anchor" href="#pdg"></a> PDG</h4><p>程序依赖图，是代码的另一种图形表示，强调代码元素之间的数据和控制依赖关系。与CFG类似，它可以在AST的基础上构建。在构建过程中，某些代码细节被抽象，以更明确地揭示控制和数据依赖关系。</p><h4 id="cpg"><a class="markdownIt-Anchor" href="#cpg"></a> CPG</h4><p>代码属性图，提出了一种更为综合的代码混合图表示，它集成了从AST、CFG和PDG导出的信息。</p><h4 id="数据流图-dfg"><a class="markdownIt-Anchor" href="#数据流图-dfg"></a> 数据流图 (DFG)</h4><p>DFG 跟踪整个 CFG 中变量的使用情况。 数据流是面向变量的，任何数据流都涉及某些变量的访问或修改。 DFG 边表示对相同变量的后续访问或修改。 它在图 2 中用橙色双箭头表示，并在边缘标注了所涉及的变量。 例如，参数b既用在if条件中，又用在赋值语句中。 自然代码序列（NCS） 为了对源代码的自然顺序进行编码，我们使用 NCS 边来连接 AST 中的相邻代码标记。 这种编码的主要好处是保留源代码序列反映的编程逻辑。 NCS 边在图 2 中用红色箭头表示，连接 AST 的所有叶节点。</p><h4 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h4><p>[1]Zhenzhou T ,Binhui T ,Jiajun L , et al.Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding[J].Expert Systems With Applications,2024,238(PB):</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> 基本术语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>挑战与问题</title>
      <link href="/2023/12/16/Security/%E6%8C%91%E6%88%98%E4%B8%8E%E9%97%AE%E9%A2%98/"/>
      <url>/2023/12/16/Security/%E6%8C%91%E6%88%98%E4%B8%8E%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>已经开发了各种方法来检测漏洞（Cui et al.，2022），包括静态、动态、一致性分析和模糊方法。正如我们将在相关工作部分进一步深入研究的那样，TrVD属于静态检测系列中基于学习的范式。在这种范式中，漏洞检测任务被公式化为一个分类问题。具体来说，在训练阶段，分类器 通过代码表示构建、特征提取和模型训练，从一组带有基本事实标签的训练样本中学习。在检测阶段，当出现一段可能看不见的源代码时, 执行代码表示构造和特征提取的相同过程。经过训练的分类器预测漏洞的存在，或者进一步精确定位特定的漏洞类型。</p><h2 id="可用性"><a class="markdownIt-Anchor" href="#可用性"></a> 可用性</h2><p>其他被广泛采用的代码表示包括CFG、PDG和各种基于图形的变体。这些表示更明确地描述了代码元素之间的控制或数据依赖关系，然而，当面对不可执行或不完整的代码片段时，很难精确推导出这些依赖关系。因此，它们可能并不总是适用于漏洞检测。按照约定，AST可以很容易地为任何代码片段构建，例如文件、函数或单个语句。</p><h2 id="效率"><a class="markdownIt-Anchor" href="#效率"></a> 效率</h2><p>与需要相对复杂和耗时的控制或依赖性分析的代码表示（例如CFG、PDG和代码小工具）相比，从代码构建AST要简单得多，重量轻，从而有助于提高整个检测方法的效率。</p><h2 id="语义综合性"><a class="markdownIt-Anchor" href="#语义综合性"></a> 语义综合性</h2><p>那些人工创建的代码表示（例如，PDG和XFG）倾向于强调代码的特定方面，例如控制流或数据依赖关系。然而，它们经常在转换过程中丢失一些重要信息，这会导致语义损失，尤其是在表示不完整的代码片段时。不同的是，AST使源代码具有高度结构化的性质，其中关于语句和表达式的底层语法是直接可用的；也就是说，AST提供了更全面、更丰富、更精确的代码语义，使TrVD不遗漏任何可疑的漏洞含义，提高了检测的准确性。</p><p>[1]Zhenzhou T ,Binhui T ,Jiajun L , et al.Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding[J].Expert Systems With Applications,2024,238(PB):</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的审稿意见</title>
      <link href="/2023/12/16/Manuscripts/review/"/>
      <url>/2023/12/16/Manuscripts/review/</url>
      
        <content type="html"><![CDATA[<h2 id="intelligent-vulnerability-detector-using-deep-sequence-and-graph-based-hybrid-feature-extraction"><a class="markdownIt-Anchor" href="#intelligent-vulnerability-detector-using-deep-sequence-and-graph-based-hybrid-feature-extraction"></a> Intelligent Vulnerability Detector using deep sequence and graph based Hybrid Feature Extraction</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191506692.png" alt="image-20231210113010116" /></p><p>This manuscript proposed a graph-based and sequence-based neural network model for detecting vulnerabilities in Java code, utilizing multiple program features，which addresses the detection problem of a range of vulnerabilities collected from the Common Weakness Enumeration (CWE) . It introduces GCN-RFEMLP for extracting graph-based features and employs CodeBERT for extracting sequence-based features. However, there are some critical issues outlined in the manuscript making the referee has to reject it.</p><p>Comments：</p><ol><li>The COVID-19 pandemic, which is unrelated to the research and should not have been mentioned.</li><li>The manuscript presents a list of seven contributions; however, they lack conciseness and do not effectively emphasize the primary contributions.</li><li>Certain figures in the manuscript are not appropriate. Figure 1 appears to be more focused on the classification of machine learning methods and lacks contextual relevance, considering that the manuscript is specifically about vulnerability detection. Other figures also suffer from similar issues, as they seem to be detached from vulnerability detection and lack any meaningful connection. Figures 3 and 4 depict the node2vec process and GCN, respectively. However, these figures are not relevant to the vulnerability detection discussed in the paper and do not contribute to the study. Instead, the figures should focus on illustrating the transformation process from source code to code property graph, highlighting the comprehensive model proposed in the manuscript.</li><li>In the experimental section, the formatting of the tables presenting the experimental results lacks consistency. And, it is customary to report experimental results with two decimal places, such as 98.90. It is important to ensure that other result comparison data follow the same formatting convention.</li><li>The dataset description in the manuscript lacks clarity, and there is no mention of the labeling process for the data. Additionally, the comparison with other benchmarks does not indicate the dataset that was utilized.</li><li>Moreover, the manuscript lacks relevant explanations and approaches for addressing data imbalance, which can pose a risk of overfitting.</li></ol><h2 id="vuldet-bc-binary-software-vulnerability-detection-based-on-bigru-and-cnn"><a class="markdownIt-Anchor" href="#vuldet-bc-binary-software-vulnerability-detection-based-on-bigru-and-cnn"></a> VulDet-BC: Binary Software Vulnerability Detection Based on BiGRU and CNN</h2><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191506699.png" alt="image-20231210113205646" /></p><p>this manuscript 提出了一种二进制漏洞检测方法VulDet-BC，从二进制机器指令级别，结合BiGRU与CNN构建二进制漏洞检测模型，其中利用了注意力机制，并且通过与一些基线的对比在一些指标上优于基线，However, there are some critical issues outlined in the manuscript making the referee has to reject it.</p><p>Comments:</p><ol><li>文章在相关工作部分对漏洞检测这一研究领域的介绍不够充分，近期的许多新颖的工作并没有被提及。</li><li>深度学习方法常常基于一定的漏洞模式，来实现漏洞检测。文稿中的方法将二进制机器指令转换为数字形式，再转换过程中并没有提出任何与漏洞模式相关的概念，无论在语义或是语法上；</li><li>文中提到的BiGRU结合注意力模块并不新颖，且文中实验部分所提出的一系列RQ，缺乏对漏洞成因的思考，仅仅是从深度学习的角度在进行消融实验；</li><li>BinVulDet，在文稿中是第40个引用，是比较新的工作，在伪代码级别检测二进制软件的漏洞，文稿既没有对其工作进行介绍（related work)也没有与其进行对比研究。源代码漏洞检测方法VulDeePecker使用了code-gadget结合BiLSTM构建漏洞检测模型，但是文中似乎使用后半部分的BiLSTM进行对比，这样的对比实验设计已经不是同VulDeePecker工作进行对比了，这显然是错误的；</li><li>文稿中缺乏对漏洞检测任务的误报和漏报的分析，即FNR和FPR，这在漏洞检测的工作中非常重要，且缺乏对真实世界的软件漏洞进行检测的实验研究，使实验中提出的RQ变得更加单薄，对论文的研究缺乏支撑度；</li></ol><p>This manuscript proposed a binary software vulnerability detection method called VulDet-BC, which operates at the binary machine instruction level. It employs a combination of BiGRU and CNN along with attention mechanisms to build a vulnerability detection model. The manuscript claims superiority over baselines in certain metrics. However, the manuscript has several critical issues outlined below, which led the referee to reject it.</p><ol><li>The related work of the paper lacks a comprehensive review of the research field of vulnerability detection. Many recent and innovative works in the field have not been mentioned.</li></ol><p>2.Deep learning methods often rely on some vulnerability patterns to achieve effective vulnerability detection. The proposed method in the manuscript converts binary machine instructions into numeric representations without introducing any concepts related to vulnerability patterns, either semantically or syntactically.</p><p>3.The combination of BiGRU and attention mechanisms mentioned in the paper is not novel. Additionally, the series of research questions(RQ) proposed in the experimental section lacks contemplation on the causes of vulnerabilities. The experiments conducted only focus on the impact of deep learning techniques.</p><p>4.“BinVulDet” is referenced as the 40th citation in the manuscript and represents a relatively recent work that focuses on detecting vulnerabilities in binary software at the pseudo code level. However, the manuscript fails to provide an introduction to this work in the related work section and does not compare it with the proposed method. The source code vulnerability detection method “VulDeePecker” utilizes code-gadgets combined with BiLSTM to build a vulnerability detection model. However, it seems that the manuscript incorrectly compares its method with only the latter part, BiLSTM, which is not a valid comparison to the original VulDeePecker work. This discrepancy in the experimental design is evidently an error.</p><p>5.The manuscript lacks an analysis of false negatives (FNR) and false positives (FPR), which are crucial in vulnerability detection. Furthermore, there is a lack of experiments on detecting real-world software vulnerabilities, making the proposed research questions less substantiated.</p>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 审稿 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>c语言混淆技术</title>
      <link href="/2023/12/16/Security/c%E8%AF%AD%E8%A8%80%E6%B7%B7%E6%B7%86%E6%8A%80%E6%9C%AF/"/>
      <url>/2023/12/16/Security/c%E8%AF%AD%E8%A8%80%E6%B7%B7%E6%B7%86%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<h4 id="代码混淆定义"><a class="markdownIt-Anchor" href="#代码混淆定义"></a> 代码混淆定义：</h4><p>原代码 P 通过某种变换变成代码 P’，若 P 和 P’运行结果与过程行为保持一致，该种变换就称之为混淆变换。</p><p>具体来说，当混淆转换满足以下两种情况时，这种混淆变化称之为合法的转换：</p><ul><li>（1）如果源程序 P 无法停止运行或报错结束运行，则变换后的程序 P’可以结束运行也可以继续运行。</li><li>（2）否则，目标程序 P’也结束运行并且输出与源程序相同的结果。</li><li><mark>两个程序之间操作并不一定完全相同，且不一定有相同的效率。</mark></li></ul><p>实际上，混淆工具预先设定若干混淆规则，并使用其它更为复杂的代码取代源代码中符合条件的代码语句，<strong>虽然源代码语义并未改变但混淆后的程序运行过程中空间复杂度往往更高，执行时间也更长，甚至有可能改变系统环境</strong>等。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/imgs202312171007669.png" alt="image-20231217100733637" /></p><p>图 2.1 展示了混淆编译的整体流程，</p><ul><li>首先混淆工具会对输入的源代码进行代码预处理得到<mark>程序控制流图 CFG、抽象语法树 AST</mark> 等信息，</li><li>然后对<mark>数据流、控制流</mark>等进行分析，并根据输入的混淆参数选择对应的混淆算法处理源代码，</li><li>最后输出混淆编译后的程序。</li></ul><p>尽管混淆策略多种多样，但通常按 Collberg 提出的方法将其大致分为四类[16]：</p><ul><li>布局混淆</li><li>数据流混淆</li><li>控制流混淆</li><li>预防混淆</li></ul><p>接下来将对这几类混淆策略进行详细分析。</p><h4 id="布局混淆"><a class="markdownIt-Anchor" href="#布局混淆"></a> 布局混淆</h4><p>布局混淆是一种在不影响源程序正常运行的情况下，即<strong>不修改程序核心控制流和数据流</strong>，对程序包含有用信息的非核心代码做出修改的一种混淆策略；此处的非核心代码一般包括注释语句、多余代码片段、用于调试的代码语句以及自定义的变量名。</p>]]></content>
      
      
      <categories>
          
          <category> 软件安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件安全 </tag>
            
            <tag> C/C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>overleaf 葵花宝典</title>
      <link href="/2023/12/16/Manuscripts/overleaf/overleaf%E7%BB%8F%E9%AA%8C/"/>
      <url>/2023/12/16/Manuscripts/overleaf/overleaf%E7%BB%8F%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="1列表"><a class="markdownIt-Anchor" href="#1列表"></a> 1.列表</h1><h2 id="itemize命令无序列表"><a class="markdownIt-Anchor" href="#itemize命令无序列表"></a> <strong>{itemize}命令【无序列表】</strong></h2><blockquote><p>{itemize}命令对文本进行简单的排列，不是采用序号，默认是用实心圆点符号进行排列。这个命令需要和\item配合使用。</p></blockquote><p>默认为实心圆点符号</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;itemize&#125;</span><br><span class="line">    <span class="keyword">\item</span> one</span><br><span class="line">    <span class="keyword">\item</span> two</span><br><span class="line">    <span class="keyword">\item</span> ...</span><br><span class="line"><span class="keyword">\end</span>&#123;itemize&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191508804.png" alt="image-20231210154216456" /></p><p>使用其他符号进行排列</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;itemize&#125;</span><br><span class="line">    <span class="keyword">\item</span>[*] one</span><br><span class="line">    <span class="keyword">\item</span>[*] two</span><br><span class="line">    <span class="keyword">\item</span>[*] ...</span><br><span class="line"><span class="keyword">\end</span>&#123;itemize&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191508806.png" alt="image-20231210155010036" /></p><h2 id="enumerate命令有序列表"><a class="markdownIt-Anchor" href="#enumerate命令有序列表"></a> <strong>{enumerate}命令【有序列表】</strong></h2><blockquote><p>{enumerate}命令采用序号对文本进行简单的排列，默认是用1，2，3进行排列。这个命令需要和\item配合使用。</p></blockquote><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;enumerate&#125;</span><br><span class="line">    <span class="keyword">\item</span> one</span><br><span class="line">    <span class="keyword">\item</span> two</span><br><span class="line">    <span class="keyword">\item</span> ...</span><br><span class="line"><span class="keyword">\end</span>&#123;enumerate&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191508812.png" alt="image-20231210155244000" /></p><p><strong>使用其他形式的编号</strong>：</p><blockquote><p>{enumerate}产生所需要的编号，默认是采用数字1,2,3……进行排列。</p><p><strong>使用命令\usepackage{enumerate}</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;enumerate&#125;[i)]</span><br><span class="line">    \item one</span><br><span class="line">    \item two</span><br><span class="line">    \item ...</span><br><span class="line">\end&#123;enumerate&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;enumerate&#125;[1)]</span><br><span class="line">    \item one</span><br><span class="line">    \item two</span><br><span class="line">    \item ...</span><br><span class="line">\end&#123;enumerate&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 自定义编号形式</span><br><span class="line"></span><br><span class="line">\begin&#123;description&#125;</span><br><span class="line">    \item[Step1] one</span><br><span class="line">    \item[Step2] two</span><br><span class="line">    \item[Step3] ...</span><br><span class="line">\end&#123;description&#125;</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191509540.png" alt="image-20231219150916511" /></p><h1 id="2三线表"><a class="markdownIt-Anchor" href="#2三线表"></a> 2.三线表</h1><p>使用方法1或者2都可以，两种latex编辑器WinEdt和TexStudio各有优点，看你选择，我用的是方法1，使用WinEdt。</p><p>直接显示latex 代码，然后你们根据自己的情况进行修改即可</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">\begin&#123;table&#125;[h] %h表示三线表在当前位置插入</span><br><span class="line">\setlength&#123;\abovecaptionskip&#125;&#123;<span class="number">0.</span>05cm&#125; %设置三线表标题与第一条线间距</span><br><span class="line">\centering</span><br><span class="line">\caption&#123;\textbf&#123;The characteristics of various methods&#125;&#125;</span><br><span class="line">%表头文本加黑，但不加黑Table <span class="number">1.</span>字样，引入包即可：\usepackage[labelfont=bf]&#123;caption&#125;</span><br><span class="line">\arrayrulecolor&#123;black&#125; %设置三线表线条颜色：黑色</span><br><span class="line">\begin&#123;tabular*&#125;&#123;\hsize&#125;&#123;@&#123;\extracolsep&#123;\fill&#125;&#125;c c c c&#125; %&#123;\hsize&#125;使三线表自适应宽度，c表示文本居中</span><br><span class="line">  \hline</span><br><span class="line">  <span class="number">1</span> &amp; <span class="number">2</span> &amp; <span class="number">3</span> &amp; <span class="number">4</span>\\</span><br><span class="line">  \hline</span><br><span class="line">  <span class="number">11</span> &amp; <span class="number">22</span> &amp; <span class="number">33</span> &amp; <span class="number">44</span> \\</span><br><span class="line">  <span class="number">111</span> &amp; <span class="number">222</span> &amp; <span class="number">333</span> &amp; <span class="number">444</span> \\</span><br><span class="line">  <span class="number">1111</span> &amp; <span class="number">2222</span> &amp; <span class="number">3333</span> &amp; <span class="number">4444</span> \\</span><br><span class="line">  <span class="number">11111</span> &amp; <span class="number">22222</span> &amp; <span class="number">33333</span> &amp; <span class="number">44444</span> \\</span><br><span class="line">  <span class="number">111111</span> &amp; <span class="number">222222</span> &amp; <span class="number">333333</span> &amp; <span class="number">444444</span> \\</span><br><span class="line">  \hline</span><br><span class="line">\end&#123;tabular*&#125;</span><br><span class="line">\end&#123;table&#125;</span><br></pre></td></tr></table></figure><p>添加包：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">\usepackage&#123;booktabs&#125;</span><br><span class="line">\usepackage&#123;amsmath&#125;</span><br><span class="line">\usepackage&#123;setspace&#125;</span><br><span class="line">\usepackage&#123;array,caption&#125;</span><br><span class="line">\usepackage[labelfont=bf]&#123;caption&#125;</span><br></pre></td></tr></table></figure><h1 id="3图片过大处理"><a class="markdownIt-Anchor" href="#3图片过大处理"></a> 3.图片过大处理</h1><p>在<a href="https://so.csdn.net/so/search?q=LaTeX%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87&amp;spm=1001.2101.3001.7020">LaTeX插入图片</a>的时候，经常需要调整图片的大小。我们可以通过如下代码来完成：</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[htb]</span><br><span class="line">  <span class="keyword">\centering</span></span><br><span class="line">  <span class="keyword">\includegraphics</span>[width=0.5<span class="keyword">\linewidth</span>]&#123;fig2.png&#125;</span><br><span class="line">  <span class="keyword">\caption</span>&#123;图片的解释&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure><p>其中，width=0.5[linewidth](<a href="https://so.csdn.net/so/search?q=linewidth&amp;spm=1001.2101.3001.7020">https://so.csdn.net/so/search?q=linewidth&amp;spm=1001.2101.3001.7020</a>) 表明将插入的图像等比例缩小至0.6倍。经验证，调整比例后图像成功地缩小了。</p><p>这样可以适应模板 自动地调整大小 不用手动去调整长宽 非常好用</p><h1 id="4空格"><a class="markdownIt-Anchor" href="#4空格"></a> 4.空格</h1><p>quad空格a \quad b一个m的宽度<br />大空格a\ b1/3m宽度<br />中等空格a;b2/7m宽度<br />小空格a,b1/6m宽度<br />没有空格ab<br />紧贴a!b缩进1/6m宽度</p><h1 id="5latex的粗体"><a class="markdownIt-Anchor" href="#5latex的粗体"></a> 5.latex的粗体</h1><p>latTx的粗体一般用以下命令：</p><p>\textbf{}：文本环境加粗。在数学环境使用的话，会使斜体效果消失。并且无法输出加粗的希腊字母。</p><p>\mathbf{}：会变为粗体，但同样会导致数学字母斜体形式的丢失。 \boldmath{}：数学环境里可以加粗且不会使斜体消失。需要添加amsmath宏包。 \boldsymbol{}：可以对希腊字母加粗。需要添加amsmath宏包。 在数学环境中，比较推荐的方式是添加宏包\usepackage{bm}, 使用\bm{}命令加粗。</p><p>但是在xelatex或Luatex引擎的unicode-math环境中中，\bm{}会报错。此时，可以使用以下命令：</p><p>\symbfit{}：加粗，且有斜体效果 \symbf{}：加粗，没有斜体效果 \mathbfcal{}：加粗的\mathcal字体</p><p>[<a href="https://blog.csdn.net/xovee/article/details/106325136">翻译] [Overleaf] LaTeX 中的粗体、斜体、下划线_latex 斜体-CSDN博客</a></p><h1 id="6图片与引用"><a class="markdownIt-Anchor" href="#6图片与引用"></a> 6.图片与引用</h1><p>示例：</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure*&#125;</span><br><span class="line"><span class="keyword">\centering</span></span><br><span class="line"><span class="keyword">\includegraphics</span>[scale=0.45]&#123;double<span class="built_in">_</span>single.eps&#125; <span class="comment">%scale=缩小比例，或者用width=2in</span></span><br><span class="line"><span class="keyword">\caption</span>&#123;Search&#125;     <span class="keyword">\label</span>&#123;fig:ss&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure*&#125;</span><br></pre></td></tr></table></figure><p>引用注意</p><p>\label{} 必须写在 \caption{} 的后面。</p><p>\ref{}:引用</p><p>\ref{fig:ss}, 即\ref{}, {}内为标签名称,我这里的标签名称是：fig:ss</p><h1 id="7宽度问题"><a class="markdownIt-Anchor" href="#7宽度问题"></a> 7.宽度问题</h1><p>\hsize: 是 Latex中定义的长度，是一种叫做水平盒子的长度，它的主要作用是告诉TeX系统什么时候换行。所以大部分时候和\textwidth是一致的，但是在分栏状况下，\hsize只是栏的宽度；</p><p>\textwidth: 是 Latex中定义的长度，等效于\hsize，并且是固定不变的，可以理解为一行文字的宽度。</p><p>\pagewidth: 包含了页边的宽度，比\textwidth要大</p><p>\linewidth: 这指得是目前环境的宽度，是依赖于上下文的一个宽度值，例如新建了一个box，在这个box中，</p><p>\linewidth是box中文字的宽度。再例如minipage环境中，\linewidth就和这个minipage的大小有关.</p><p>\columnwidth: 如果文章分栏的话，这个宽度就是每一栏的宽度。</p>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> overleaf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>overleaf 问题</title>
      <link href="/2023/12/16/Manuscripts/overleaf/overleaf%E9%97%AE%E9%A2%98%20/"/>
      <url>/2023/12/16/Manuscripts/overleaf/overleaf%E9%97%AE%E9%A2%98%20/</url>
      
        <content type="html"><![CDATA[<h1 id="algorithm最后出现0"><a class="markdownIt-Anchor" href="#algorithm最后出现0"></a> algorithm最后出现=0</h1><p><strong>解决方法：</strong></p><p>注释掉&quot;\usepackage{algpseudocode}&quot;</p><p>因为<code>\usepackage&#123;algpseudocode&#125; %This introduces extra zero at the end of algorithm</code></p><h1 id="table位置问题"><a class="markdownIt-Anchor" href="#table位置问题"></a> table位置问题</h1><p>如果table默认置顶，在.sty文件中定义了table环境，那么可尝试将</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;table&#125;[h] </span><br></pre></td></tr></table></figure><p>改为</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;table&#125;[pos=h] </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> overleaf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Computers&amp;Security</title>
      <link href="/2023/12/16/Manuscripts/sci/Computers&amp;Security/"/>
      <url>/2023/12/16/Manuscripts/sci/Computers&amp;Security/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www2.cloud.editorialmanager.com/cose/default2.aspx">Editorial Manager®</a></p>]]></content>
      
      
      <categories>
          
          <category> Manuscripts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sci投稿 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++ lamda表达式</title>
      <link href="/2023/12/16/Programmer/c-c++/lambda/"/>
      <url>/2023/12/16/Programmer/c-c++/lambda/</url>
      
        <content type="html"><![CDATA[<p>创建一个匿名函数并执行。Objective-C采用的是上尖号^，而C++ 11采用的是配对的方括号[]。实例如下：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    []&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;Hello,Worldn&quot;</span>; </span><br><span class="line">    &#125;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们也可以方便的将这个创建的匿名函数赋值出来调用：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> func = [](<span class="type">int</span> i) &#123; <span class="comment">// (int i) 是指传入改匿名函数的参数</span></span><br><span class="line">        cout &lt;&lt; i;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">func</span>(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="捕获选项"><a class="markdownIt-Anchor" href="#捕获选项"></a> 捕获选项</h1><ul><li>[] Capture nothing (or, a scorched earth strategy?)</li><li>[&amp;] Capture any referenced variable by reference</li><li>[=] Capture any referenced variable by making a copy</li><li>[=, &amp;foo] Capture any referenced variable by making a copy, but capture variable foo by reference</li><li>[bar] Capture bar by making a copy; don’t copy anything else</li><li>[this] Capture the this pointer of the enclosing class</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-[]不捕获任何变量</span><br><span class="line"></span><br><span class="line">-[&amp;]通过引用捕获任何引用变量</span><br><span class="line"></span><br><span class="line">-[=]通过复制捕获任何引用变量</span><br><span class="line"></span><br><span class="line">-[=，&amp;foo]通过复制捕获任何引用的变量，但通过引用捕获变量foo</span><br><span class="line"></span><br><span class="line">-[bar]通过复制来捕获bar；不要复制其他任何东西</span><br><span class="line"></span><br><span class="line">-[this]捕获封闭类的this指针</span><br></pre></td></tr></table></figure><h1 id="不捕获任何变量"><a class="markdownIt-Anchor" href="#不捕获任何变量"></a> [] 不捕获任何变量</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> func = [] &#123; cout &lt;&lt; i; &#125;;</span><br><span class="line">    <span class="built_in">func</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>vs 报错<br />error C3493: 无法隐式捕获“i”，因为尚未指定默认捕获模式<br />error C2064: 项不会计算为接受 0 个参数的函数</p><p>g++ 报错：<br />error: ‘i’ is not captured</p><p>要直接沿用外部的变量需要在 [] 中指名捕获。</p><h1 id="拷贝捕获"><a class="markdownIt-Anchor" href="#拷贝捕获"></a> [=] 拷贝捕获</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> func = [=]&#123;  <span class="comment">// [=] 表明将外部的所有变量拷贝一份到该函数内部</span></span><br><span class="line">        cout &lt;&lt; i;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">func</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br />1024</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [=]&#123;</span><br><span class="line">        <span class="comment">// fun1 内存在 i</span></span><br><span class="line">        cout &lt;&lt; i; <span class="comment">// 1024</span></span><br><span class="line">        <span class="keyword">auto</span> fun2 = []&#123; <span class="comment">// 未指名捕获， i 不存在</span></span><br><span class="line">            cout &lt;&lt; i;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="built_in">fun2</span>();</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="引用捕获"><a class="markdownIt-Anchor" href="#引用捕获"></a> [&amp;] 引用捕获</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>;</span><br><span class="line">    cout &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [&amp;]&#123;</span><br><span class="line">        cout &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果:<br />0x28ff0c<br />0x28ff0c</p><h1 id="拷贝与引用混合"><a class="markdownIt-Anchor" href="#拷贝与引用混合"></a> [=, &amp;] 拷贝与引用混合</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [=, &amp;i]&#123; <span class="comment">// 默认拷贝外部所有变量，但引用变量 i</span></span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果<br />outside i:0x28ff0c<br />outside j:0x28ff08<br />inside i:0x28ff0c<br />inside j:0x28ff04</p><h1 id="bar-指定引用或拷贝"><a class="markdownIt-Anchor" href="#bar-指定引用或拷贝"></a> [bar] 指定引用或拷贝</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [i]&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        <span class="comment">// cout &lt;&lt; j &lt;&lt; endl; // j 未捕获</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br />outside i value:1024 addr:0x28ff08<br />inside i value:1024 addr:0x28ff04</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [&amp;i]&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  i value:&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; addr:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        <span class="comment">// cout &lt;&lt; j &lt;&lt; endl; // j 未捕获</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br />outside i value:1024 addr:0x28ff08<br />inside i value:1024 addr:0x28ff08</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">1024</span>, j = <span class="number">2048</span>, k;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;outside j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">auto</span> fun1 = [i, &amp;j]&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  i:&quot;</span> &lt;&lt; &amp;i &lt;&lt; endl;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;inside  j:&quot;</span> &lt;&lt; &amp;j &lt;&lt; endl;</span><br><span class="line">        <span class="comment">// cout &lt;&lt; k; // k 未捕获</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">fun1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：<br />outside i:0x28ff0c<br />outside j:0x28ff08<br />inside i:0x28ff00<br />inside j:0x28ff08</p><h1 id="this-捕获-this-指针"><a class="markdownIt-Anchor" href="#this-捕获-this-指针"></a> [this] 捕获 this 指针</h1><figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="title">std</span>;</span><br><span class="line"><span class="keyword">class</span> <span class="title">test</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">hello</span>()</span> &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;test hello!n&quot;</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lambda</span>()</span> &#123;</span><br><span class="line">        auto fun = [<span class="keyword">this</span>]&#123; <span class="comment">// 捕获了 this 指针</span></span><br><span class="line">            <span class="keyword">this</span>-&gt;hello(); <span class="comment">// 这里 this 调用的就是 class test 的对象了</span></span><br><span class="line">        &#125;;</span><br><span class="line">        fun();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">int</span> <span class="title">main</span>()</span></span><br><span class="line">&#123;</span><br><span class="line">    test t;</span><br><span class="line">    t.lambda();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> C/C++ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>低秩分解</title>
      <link href="/2023/12/16/AILearning/DL/%E7%9F%A5%E8%AF%86%E7%82%B9/%E4%BD%8E%E7%A7%A9%E5%88%86%E8%A7%A3/"/>
      <url>/2023/12/16/AILearning/DL/%E7%9F%A5%E8%AF%86%E7%82%B9/%E4%BD%8E%E7%A7%A9%E5%88%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="低秩分解的几何解释"><a class="markdownIt-Anchor" href="#低秩分解的几何解释"></a> 低秩分解的几何解释</h1><p>低秩分解（Low-rank factorization）也可以通过几何的方式来解释，帮助我们理解其含义和应用。</p><p>假设我们有一个m×n的矩阵A，我们希望对其进行低秩分解，即将其分解为两个低秩矩阵的乘积：A ≈ UV^T。其中，U是一个m×k的矩阵，V是一个n×k的矩阵，k远远小于m和n。</p><p>几何上，可以将矩阵A视为描述一个向量空间中的点集。每一列可以看作是一个向量，而这些向量组成了一个n维的向量空间。低秩分解可以理解为通过两个低维的向量空间的点集的线性组合来近似表示原始向量空间中的点集。</p><p>具体地说，U矩阵的列向量可以看作是原始向量空间的基向量，它们将原始向量空间中的点集映射到一个低维的子空间。V矩阵的列向量则表示这个低维子空间中的基向量。通过对这两个子空间的基向量的线性组合，我们可以近似表示原始向量空间中的点集。</p><p>这个分解可以理解为以下几个几何步骤：</p><ol><li>U矩阵的列向量将原始向量空间中的点集映射到一个低维的子空间。这个子空间具有较低的维度k。</li><li>V矩阵的列向量表示这个低维子空间中的基向量，用于描述子空间中的点集。</li><li>通过对U和V的线性组合，将低维子空间中的点集映射回原始向量空间，近似重构出原始的点集。</li></ol><p>通过低秩分解，我们可以利用较低维度的向量空间来近似表示原始向量空间中的点集。这种近似表示可以在降低存储和计算成本的同时，尽可能地保留原始数据的主要结构和特征。</p><p>综上所述，几何视角可以帮助我们将低秩分解理解为通过两个低维子空间的基向量的线性组合来近似表示原始向量空间中的点集，从而实现对原始数据的降维和近似表示。这种几何解释有助于我们理解低秩分解的概念和原理。</p><h1 id="奇异值分解的几何理解"><a class="markdownIt-Anchor" href="#奇异值分解的几何理解"></a> <a href="https://www.cnblogs.com/lukairui/p/17475145.html">奇异值分解的几何理解</a></h1><p>奇异值分解（SVD）可以通过几何的方式来解释，从而帮助我们理解其含义和应用。</p><p>首先，我们可以将一个矩阵视为对向量空间的一种变换。假设有一个m×n的矩阵A，其中每一列可以看作是一个向量，而这些向量组成了一个n维的向量空间。奇异值分解可以将这个向量空间的变换分解为三个基本的几何操作：旋转、缩放和再次旋转。</p><p>具体地说，奇异值分解将矩阵A分解为三个矩阵的乘积：A = UΣVT。其中，U是一个正交矩阵，表示一个旋转操作；Σ是一个对角矩阵，对角线上的元素是奇异值，表示一个缩放操作；VT是另一个正交矩阵，表示另一个旋转操作。</p><p>这个分解可以理解为以下几个几何步骤：</p><ol><li>U对应的旋转矩阵将原始向量空间进行旋转操作，使其与新的基向量相对应。</li><li>Σ对应的对角矩阵进行缩放操作，将每个基向量的长度进行缩放，即改变了向量空间的比例关系。</li><li>V^T对应的旋转矩阵将缩放后的向量空间进行进一步旋转操作，以使其与原始向量空间对齐。</li></ol><p>通过奇异值分解，我们可以将原始矩阵A分解为这三个操作的组合，从而更好地理解和描述原始矩阵A的结构和特征。</p><p>此外，奇异值分解还提供了一种基于奇异值的重要性排序。奇异值的大小表示了每个基向量在变换中的重要性。较大的奇异值对应的基向量在变换中具有更大的影响力，而较小的奇异值对应的基向量在变换中贡献较小。</p><p>综上所述，几何视角可以帮助我们将奇异值分解理解为对向量空间的旋转、缩放和再次旋转等几何操作的组合，从而更好地理解和应用奇异值分解的概念和原理。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Siamese Network</title>
      <link href="/2023/12/16/AILearning/DL/%E7%9F%A5%E8%AF%86%E7%82%B9/siamese/"/>
      <url>/2023/12/16/AILearning/DL/%E7%9F%A5%E8%AF%86%E7%82%B9/siamese/</url>
      
        <content type="html"><![CDATA[<h2 id="siamese网络"><a class="markdownIt-Anchor" href="#siamese网络"></a> Siamese网络</h2><h4 id="问题背景"><a class="markdownIt-Anchor" href="#问题背景"></a> 问题背景</h4><p>分类问题：</p><ul><li><p>分类数量较少，每一类的数据量较多，比如ImageNet、VOC等。这种分类问题可以使用神经网络或者SVM解决，只要事先知道了所有的类。</p></li><li><p>分类数量较多（或者说无法确认具体数量），每一类的数据量较少，比如人脸识别、人脸验证任务。</p></li></ul><p>解决方法：</p><ul><li>提出一种思路：将输入映射为一个特征向量，使用两个向量之间的距离来表示输入之间的差异，如图像语义上的差异。</li><li>Siamese网络，每次需要输入两个样本作为一个sample对计算损失函数。</li><li>提出Contrastive Loss用于训练。</li></ul><h4 id="应用场景"><a class="markdownIt-Anchor" href="#应用场景"></a> 应用场景</h4><p>孪生神经网络用于处理两个输入&quot;比较类似&quot;的情况。伪孪生神经网络适用于处理两个输入&quot;有一定差别&quot;的情况。比如，我们要计算两个句子或者词汇的语义相似度，使用siamese network比较适合；如果验证标题与正文的描述是否一致（标题和正文长度差别很大），或者文字是否描述了一幅图片（一个是图片，一个是文字），就应该使用pseudo-siamese network。也就是说，要根据具体的应用，判断应该使用哪一种结构，哪一种Loss。</p><h4 id="siamese创新点"><a class="markdownIt-Anchor" href="#siamese创新点"></a> Siamese创新点</h4><p>网络的创新点是淡化了标签，是的网络具有很好的扩展性，可以对那些没有训练过的类别进行分类，这一点优于很多算法。</p><p>该算法对一些小数据量的数据集也适用，变相地增加了整个数据集的大小，使得数据量相对较小的数据集也能用深度神经网络训练出不错的效果。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528397.png" alt="image-20220104195309340" /></p><p>不同输入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>通过统一<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">G_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>得到两个向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo stretchy="false">)</mo><msub><mi>G</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G_W(X_1)G_W(X_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，计算两个向量之间的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">L1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mord">1</span></span></span></span>距离获得<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">E_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<br />其中，两个network是两个共享权值的网络，实际上就是两个完全相同的网络。孪生神经网络有两个输入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">X1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord">1</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">X2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord">2</span></span></span></span>,将两个输入feed进入两个神经网络（Network1 and Network2），这两个神经网络分别将输入映射到新的空间，形成输入在新的空间中的表示。通过<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">Loss</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span>的计算，评价两个输入的相似度。</p><p>如果左右两边不共享权值，而是两个不同的神经网络，叫做<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mi>s</mi><mi>e</mi><mi>u</mi><mi>d</mi><mi>o</mi><mo>−</mo><mi>s</mi><mi>i</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>t</mi><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">pseudo-siamese network</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault">d</span><span class="mord mathdefault">o</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>，伪孪生神经网络。对于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mi>s</mi><mi>e</mi><mi>u</mi><mi>d</mi><mi>o</mi><mo>−</mo><mi>s</mi><mi>i</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>t</mi><mi>w</mi><mi>o</mi><mi>r</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">pseudo-siamese network</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault">d</span><span class="mord mathdefault">o</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>，两边可以是不同的神经网络（如一个是lstm，一个是cnn），也可以是相同类型的神经网络。</p><h2 id="siamese的损失函数"><a class="markdownIt-Anchor" href="#siamese的损失函数"></a> Siamese的损失函数</h2><blockquote><p>Contrastive Loss</p></blockquote><h4 id="损失函数的选择"><a class="markdownIt-Anchor" href="#损失函数的选择"></a> 损失函数的选择</h4><p>Softmax当然是一种好的选择，但不一定是最优选择，即使是在分类问题中。传统的siamese network使用Contrastive Loss。损失函数还有更多的选择，siamese network的初衷是计算两个输入的相似度,。左右两个神经网络分别将输入转换成一个&quot;向量&quot;，在新的空间中，通过判断cosine距离就能得到相似度了。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Cosine</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span></span></span></span>是一个选择，<code>exp function</code>也是一种选择，欧式距离什么的都可以，<strong>训练的目标是让两个相似的输入距离尽可能的小，两个不同类别的输入距离尽可能的大。</strong></p><h4 id="论文中contrastive-loss"><a class="markdownIt-Anchor" href="#论文中contrastive-loss"></a> 论文中Contrastive Loss</h4><p>论文中的损失函数定义如下：<br />Y代表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是否属于同一类别。输入同一类别为0，不属于同一类别为1。<br />P代表输入数据数量。<br />i表示当前输入数据下标。<br /><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>G</mi></msub></mrow><annotation encoding="application/x-tex">L_G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表两个输入数据属于同一类别时的损失函数（G，genuine）。<br /><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>I</mi></msub></mrow><annotation encoding="application/x-tex">L_I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>代表两个输入数据不属于同一类别的损失函数（I，imposter）。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>P</mi></munderover><mi>L</mi><mo stretchy="false">(</mo><mi>W</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>Y</mi><mo separator="true">,</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}(W)=\sum_{i=1}^{P}L(W,(Y,X_{1},X_{2})^{i})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.15999999999999992em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>W</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>Y</mi><mo stretchy="false">)</mo><msub><mi>L</mi><mi>G</mi></msub><mrow><mo fence="true">(</mo><msub><mi>E</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mrow></mrow><mrow><mo>+</mo><mi>Y</mi><msub><mi>L</mi><mi>I</mi></msub><mrow><mo fence="true">(</mo><msub><mi>E</mi><mi>W</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>i</mi></msup><mo fence="true">)</mo></mrow></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array} {c}{ {L(W,(X_{1},X_{1},X_{2})^{i})=(1-Y)L_{G}\left(E_{W}(X_{1},X_{2})^{i}\right)} }\\ { { } } { {+ {Y}L_{I}\left(E_{W}(X_{1},{ { {X} } }_{2})^{i}\right)} }\end{array}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.42em;vertical-align:-0.96em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.46em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span><span style="top:-2.4em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"></span></span><span class="mord"><span class="mord"><span class="mord">+</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.96em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p><p>根据我们对两个向量间举例的定义，可以得到以下条件：<br />即不同类别向量间的距离比相同类别向量间距离大。<br />两个向量之间距离越小，属于同一类别的可能性就越大。</p><h4 id="目前的contrastive-loss"><a class="markdownIt-Anchor" href="#目前的contrastive-loss"></a> 目前的Contrastive Loss</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528403.png" alt="img" /></p><p>其中：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528406.png" alt="img" /></p><p>代表两个样本特征X1和X2 的欧氏距离（二范数）P 表示样本的特征维数，Y 为两个样本是否匹配的标签，Y=1 代表两个样本相似或者匹配，Y=0 则代表不匹配，m 为设定的阈值，N 为样本个数。</p><p>观察上述的contrastive loss的表达式可以发现，这种损失函数可以很好</p><p>的表达成对样本的匹配程度，也能够很好用于训练提取特征的模型。</p><p>当 Y=1（即样本相似时），损失函数只剩下</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528402.png" alt="在这里插入图片描述" /></p><p>当 Y=0 (即样本不相似时），损失函数为</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528405.png" alt="在这里插入图片描述" /></p><p>即当样本不相似时，其特征空间的欧式距离反而小的话，损失值会变大，这也正好符号我们的要求。<br /><strong>注意：</strong><br />这里设置了一个阈值<strong>ｍargin</strong>，表示我们只考虑不相似特征欧式距离在<strong>０～ｍargin</strong>之间的，当距离超过ｍargin的，则把其loss看做为０**(即不相似的特征离的很远，其loss应该是很低的；而对于相似的特征反而离的很远，我们就需要增加其loss，从而不断更新成对样本的匹配程度)**</p><h2 id="siamese的思想总结"><a class="markdownIt-Anchor" href="#siamese的思想总结"></a> Siamese的思想总结</h2><p>其实讲了这么多，主要思想就是三点：</p><ul><li>输入不再是单个样本，而是一对样本，不再给单个的样本确切的标签，而且给定一对样本是否来自同一个类的标签，是就是0，不是就是1</li><li>设计了两个一模一样的网络，网络共享权值W，对输出进行了距离度量，可以说l1、l2等。</li><li>针对输入的样本对是否来自同一个类别设计了损失函数，损失函数形式有点类似交叉熵损失：<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202312191528415.png" alt="" /></li></ul><p>最后使用获得的损失函数，使用反向传播梯度下降去更新两个网络共享的权值W。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>可解释机器学习</title>
      <link href="/2023/12/16/AILearning/DL/%E7%9F%A5%E8%AF%86%E7%82%B9/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2023/12/16/AILearning/DL/%E7%9F%A5%E8%AF%86%E7%82%B9/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="可解释机器学习"><a class="markdownIt-Anchor" href="#可解释机器学习"></a> 可解释机器学习</h1><p>作者：SkylaSun</p><p>链接：<a href="https://zhuanlan.zhihu.com/p/570926717">https://zhuanlan.zhihu.com/p/570926717</a></p><p>来源：知乎</p><p>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h2 id="可解释机器学习-2"><a class="markdownIt-Anchor" href="#可解释机器学习-2"></a> 可解释机器学习</h2><p>可解释性方法将机器学习模型的决策过程转变成人类更能理解的结果。通用可解释性方法一般仅基于特征进行解释，无法处理图结构信息，在处理漏洞发掘场景下的图数据时，作者将边的相关性分数传递到<a href="https://www.zhihu.com/search?q=%E9%82%BB%E6%8E%A5%E8%8A%82%E7%82%B9&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">邻接节点</a>中，从而产生一个节点级别的解释。</p><ul><li>CAM（<a href="https://www.zhihu.com/search?q=%E7%B1%BB%E5%88%AB%E6%BF%80%E6%B4%BB%E6%98%A0%E5%B0%84%E5%9B%BE&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">类别激活映射图</a>），一种特征<a href="https://www.zhihu.com/search?q=%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8A%80%E6%9C%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">可视化技术</a>，最初为解释CNN模型而设计，将深层网络中学习到的<a href="https://www.zhihu.com/search?q=%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">语义信息</a>，通过权重与输出节点联系起来。</li><li><a href="https://www.zhihu.com/search?q=%E7%BA%BF%E6%80%A7%E8%BF%91%E4%BC%BC&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">线性近似</a>，通过梯度与输入，计算每个特征对分类输出的线性化贡献。</li><li>GradCAM，将<a href="https://www.zhihu.com/search?q=%E7%BA%BF%E6%80%A7%E8%BF%91%E4%BC%BC%E6%96%B9%E6%B3%95&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">线性近似方法</a>应用于GNN层的中间<a href="https://www.zhihu.com/search?q=%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">激活函数</a>，而非输入激活，产生了类似CAM的优势。</li><li>SmoothGrad，对多个噪声输入进行节点特征梯度平均，并且产生了抗噪声的解释。</li><li>IG（<a href="https://www.zhihu.com/search?q=%E7%A7%AF%E5%88%86%E6%A2%AF%E5%BA%A6&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">积分梯度</a>），改进了线性近似，过程中参考了反事实基线输入G‘，并且使用延实际输入G的<a href="https://www.zhihu.com/search?q=%E7%9B%B4%E7%BA%BF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">直线</a>路径平均的梯度，以及G和G’之间的输入激活。</li><li>Gradient or Saliency Method，通过梯度衡量预测结果相对不同输入的变化情况。</li><li>GB（导向反向传播），对普通的<a href="https://www.zhihu.com/search?q=%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">反向传播</a>加了指导，限制了小于0的梯度的回传。</li><li>LRP（逐层相关性传播），将预测结果反向传递会输入，创建相关性映射。</li><li>EB（<a href="https://www.zhihu.com/search?q=%E6%BF%80%E5%8A%B1%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">激励反向传播</a>），使用反向传播计算l-1层到第1层中<a href="https://www.zhihu.com/search?q=%E7%A5%9E%E7%BB%8F%E5%85%83&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">神经元</a>激活的相对影响，而且仅考虑<a href="https://www.zhihu.com/search?q=%E6%AD%A3%E6%9D%83%E9%87%8D&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">正权重</a>。</li></ul><p>另外，本文关注的三种针对<a href="https://www.zhihu.com/search?q=GNN%E6%A8%A1%E5%9E%8B&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">GNN模型</a>的可解释性方法概述如下：</p><p><strong>GNNExplainer</strong>，<a href="https://www.zhihu.com/search?q=%E9%BB%91%E7%9B%92%E5%89%8D%E5%90%91%E8%A7%A3%E9%87%8A%E6%8A%80%E6%9C%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">黑盒前向解释技术</a>，最大化整体预测结果和可判别子图S以及节点特征子集的<a href="https://www.zhihu.com/search?q=%E4%BA%92%E4%BF%A1%E6%81%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">互信息</a>。</p><p><strong>PGExplainer</strong>，解决了GNNExplainer需要针对每个单独的图实例进行计算的问题，同样也是通过提取相关子图S进行全局解释，但支持归纳式学习方法。</p><p><strong>Graph-LRP</strong>使用<a href="https://www.zhihu.com/search?q=%E9%AB%98%E9%98%B6%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22570926717%22%7D">高阶泰勒展开</a>处理多层GNN上节点之间的消息传递。</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习专业术语</title>
      <link href="/2023/12/16/AILearning/DL/%E7%9F%A5%E8%AF%86%E7%82%B9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/"/>
      <url>/2023/12/16/AILearning/DL/%E7%9F%A5%E8%AF%86%E7%82%B9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/</url>
      
        <content type="html"><![CDATA[<h4 id="激活函数activation-function"><a class="markdownIt-Anchor" href="#激活函数activation-function"></a> 激活函数（Activation Function）</h4><p>为了让神经网络能够学习复杂的决策边界（decision boundary），我们在其一些层应用一个非线性激活函数。最常用的函数包括 sigmoid、tanh、ReLU（Rectified Linear Unit 线性修正单元） 以及这些函数的变体。</p><h4 id="adadelta"><a class="markdownIt-Anchor" href="#adadelta"></a> Adadelta</h4><p>Adadelta 是一个基于梯度下降的学习算法，可以随时间调整适应每个参数的学习率。它是作为 Adagrad 的改进版提出的，它比超参数（hyperparameter）更敏感而且可能会太过严重地降低学习率。Adadelta 类似于 rmsprop，而且可被用来替代 vanilla SGD。</p><p>论文：Adadelta：一种自适应学习率方法（ADADELTA: An Adaptive Learning Rate Method）<br />技术博客：斯坦福 CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br />技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="adagrad"><a class="markdownIt-Anchor" href="#adagrad"></a> Adagrad</h4><p>Adagrad 是一种自适应学习率算法，能够随时间跟踪平方梯度并自动适应每个参数的学习率。它可被用来替代vanilla SGD (<a href="http://www.wildml.com/deep-learning-glossary/#sgd">http://www.wildml.com/deep-learning-glossary/#sgd</a>)；而且在稀疏数据上更是特别有用，在其中它可以将更高的学习率分配给更新不频繁的参数。</p><p>论文：用于在线学习和随机优化的自适应次梯度方法（Adaptive Subgradient Methods for Online Learning and Stochastic Optimization）<br />技术博客：斯坦福 CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br />技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="adam"><a class="markdownIt-Anchor" href="#adam"></a> Adam</h4><p>Adam 是一种类似于 rmsprop 的自适应学习率算法，但它的更新是通过使用梯度的第一和第二时刻的运行平均值（running average）直接估计的，而且还包括一个偏差校正项。</p><p>论文：Adam：一种随机优化方法（Adam: A Method for Stochastic Optimization）<br />技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="仿射层affine-layer"><a class="markdownIt-Anchor" href="#仿射层affine-layer"></a> 仿射层（Affine Layer）</h4><p>神经网络中的一个全连接层。仿射（Affine）的意思是前面一层中的每一个神经元都连接到当前层中的每一个神经元。在许多方面，这是神经网络的「标准」层。仿射层通常被加在卷积神经网络或循环神经网络做出最终预测前的输出的顶层。仿射层的一般形式为 y = f(Wx + b)，其中 x 是层输入，w 是参数，b 是一个偏差矢量，f 是一个非线性激活函数。</p><h4 id="注意机制attention-mechanism"><a class="markdownIt-Anchor" href="#注意机制attention-mechanism"></a> 注意机制（Attention Mechanism）</h4><p>注意机制是由人类视觉注意所启发的，是一种关注图像中特定部分的能力。注意机制可被整合到语言处理和图像识别的架构中以帮助网络学习在做出预测时应该「关注」什么。</p><p>技术博客：深度学习和自然语言处理中的注意和记忆（<a href="http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/%EF%BC%89">http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/）</a></p><h4 id="alexnet"><a class="markdownIt-Anchor" href="#alexnet"></a> Alexnet</h4><p>Alexnet 是一种卷积神经网络架构的名字，这种架构曾在 2012 年 ILSVRC 挑战赛中以巨大优势获胜，而且它还导致了人们对用于图像识别的卷积神经网络（CNN）的兴趣的复苏。它由 5 个卷积层组成。其中一些后面跟随着最大池化（max-pooling）层和带有最终 1000 条路径的 softmax (1000-way softmax)的 3个全连接层。Alexnet 被引入到了使用深度卷积神经网络的 ImageNet 分类中。</p><h4 id="自编码器autoencoder"><a class="markdownIt-Anchor" href="#自编码器autoencoder"></a> 自编码器（Autoencoder）</h4><p>自编码器是一种神经网络模型，它的目标是预测输入自身，这通常通过网络中某个地方的「瓶颈（bottleneck）」实现。通过引入瓶颈，我们迫使网络学习输入更低维度的表征，从而有效地将输入压缩成一个好的表征。自编码器和 PCA 等降维技术相关，但因为它们的非线性本质，它们可以学习更为复杂的映射。目前已有一些范围涵盖较广的自编码器存在，包括 降噪自编码器（Denoising Autoencoders）、变自编码器（Variational Autoencoders）和序列自编码器（Sequence Autoencoders）。</p><p>降噪自编码器论文：Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion<br />变自编码器论文：Auto-Encoding Variational Bayes<br />序列自编码器论文：Semi-supervised Sequence Learning</p><h4 id="平均池化average-pooling"><a class="markdownIt-Anchor" href="#平均池化average-pooling"></a> 平均池化（Average-Pooling）</h4><p>平均池化是一种在卷积神经网络中用于图像识别的池化（Pooling）技术。它的工作原理是在特征的局部区域上滑动窗口，比如像素，然后再取窗口中所有值的平均。它将输入表征压缩成一种更低维度的表征。</p><h4 id="反向传播backpropagation"><a class="markdownIt-Anchor" href="#反向传播backpropagation"></a> 反向传播（Backpropagation）</h4><p>反向传播是一种在神经网络中用来有效地计算梯度的算法，或更一般而言，是一种前馈计算图（feedforward computational graph）。其可以归结成从网络输出开始应用分化的链式法则，然后向后传播梯度。反向传播的第一个应用可以追溯到 1960 年代的 Vapnik 等人，但论文 Learning representations by back-propagating errors常常被作为引用源。</p><p>技术博客：计算图上的微积分学：反向传播（<a href="http://colah.github.io/posts/2015-08-Backprop/%EF%BC%89">http://colah.github.io/posts/2015-08-Backprop/）</a></p><h4 id="通过时间的反向传播bpttbackpropagation-through-time"><a class="markdownIt-Anchor" href="#通过时间的反向传播bpttbackpropagation-through-time"></a> 通过时间的反向传播（BPTT：Backpropagation Through Time）</h4><p>通过时间的反向传播是应用于循环神经网络（RNN）的反向传播算法。BPTT 可被看作是应用于 RNN 的标准反向传播算法，其中的每一个时间步骤（time step）都代表一个计算层，而且它的参数是跨计算层共享的。因为 RNN 在所有的时间步骤中都共享了同样的参数，一个时间步骤的错误必然能「通过时间」反向到之前所有的时间步骤，该算法也因而得名。当处理长序列（数百个输入）时，为降低计算成本常常使用一种删节版的 BPTT。删节的 BPTT 会在固定数量的步骤之后停止反向传播错误。</p><p>论文：Backpropagation Through Time: What It Does and How to Do It</p><h4 id="分批标准化bnbatch-normalization"><a class="markdownIt-Anchor" href="#分批标准化bnbatch-normalization"></a> 分批标准化（BN：Batch Normalization）</h4><p>分批标准化是一种按小批量的方式标准化层输入的技术。它能加速训练过程，允许使用更高的学习率，还可用作规范器（regularizer）。人们发现，分批标准化在卷积和前馈神经网络中应用时非常高效，但尚未被成功应用到循环神经网络上。</p><p>论文：分批标准化：通过减少内部协变量位移（Covariate Shift）加速深度网络训练（Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift）<br />论文：使用分批标准化的循环神经网络（Batch Normalized Recurrent Neural Networks）</p><h4 id="双向循环神经网络bidirectional-rnn"><a class="markdownIt-Anchor" href="#双向循环神经网络bidirectional-rnn"></a> 双向循环神经网络（Bidirectional RNN）</h4><p>双向循环神经网络是一类包含两个方向不同的 RNN 的神经网络。其中的前向 RNN 从起点向终点读取输入序列，而反向 RNN 则从终点向起点读取。这两个 RNN 互相彼此堆叠，它们的状态通常通过附加两个矢量的方式进行组合。双向 RNN 常被用在自然语言问题中，因为在自然语言中我们需要同时考虑话语的前后上下文以做出预测。</p><p>论文：双向循环神经网络（Bidirectional Recurrent Neural Networks）</p><h4 id="caffe"><a class="markdownIt-Anchor" href="#caffe"></a> Caffe</h4><p>Caffe 是由伯克利大学视觉和学习中心开发的一种深度学习框架。在视觉任务和卷积神经网络模型中，Caffe 格外受欢迎且性能优异。</p><h4 id="分类交叉熵损失categorical-cross-entropy-loss"><a class="markdownIt-Anchor" href="#分类交叉熵损失categorical-cross-entropy-loss"></a> 分类交叉熵损失（Categorical Cross-Entropy Loss）</h4><p>分类交叉熵损失也被称为负对数似然（negative log likelihood）。这是一种用于解决分类问题的流行的损失函数，可用于测量两种概率分布（通常是真实标签和预测标签）之间的相似性。它可用 L = -sum(y * log(y_prediction)) 表示，其中 y 是真实标签的概率分布（通常是一个one-hot vector），y_prediction 是预测标签的概率分布，通常来自于一个 softmax。</p><h4 id="信道channel"><a class="markdownIt-Anchor" href="#信道channel"></a> 信道（Channel）</h4><p>深度学习模型的输入数据可以有多个信道。图像就是个典型的例子，它有红、绿和蓝三个颜色信道。一个图像可以被表示成一个三维的张量（Tensor），其中的维度对应于信道、高度和宽度。自然语言数据也可以有多个信道，比如在不同类型的嵌入（embedding）形式中。</p><h4 id="卷积神经网络cnnconvnetconvolutional-neural-network"><a class="markdownIt-Anchor" href="#卷积神经网络cnnconvnetconvolutional-neural-network"></a> 卷积神经网络（CNN/ConvNet：Convolutional Neural Network）</h4><p>CNN 使用卷积连接从输入的局部区域中提取的特征。大部分 CNN 都包含了卷积层、池化层和仿射层的组合。CNN 尤其凭借其在视觉识别任务的卓越性能表现而获得了普及，它已经在该领域保持了好几年的领先。</p><p>技术博客：斯坦福CS231n类——用于视觉识别的卷积神经网络（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br />技术博客：理解用于自然语言处理的卷积神经网络（<a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/%EF%BC%89">http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/）</a></p><h4 id="深度信念网络dbndeep-belief-network"><a class="markdownIt-Anchor" href="#深度信念网络dbndeep-belief-network"></a> 深度信念网络（DBN：Deep Belief Network）</h4><p>DBN 是一类以无监督的方式学习数据的分层表征的概率图形模型。DBN 由多个隐藏层组成，这些隐藏层的每一对连续层之间的神经元是相互连接的。DBN 通过彼此堆叠多个 RBN（限制波尔兹曼机）并一个接一个地训练而创建。</p><p>论文：深度信念网络的一种快速学习算法（A fast learning algorithm for deep belief nets）</p><h4 id="deep-dream"><a class="markdownIt-Anchor" href="#deep-dream"></a> Deep Dream</h4><p>这是谷歌发明的一种试图用来提炼深度卷积神经网络获取的知识的技术。这种技术可以生成新的图像或转换已有的图片从而给它们一种幻梦般的感觉，尤其是递归地应用时。</p><p>代码：Github 上的 Deep Dream（<a href="https://github.com/google/deepdream%EF%BC%89">https://github.com/google/deepdream）</a><br />技术博客：Inceptionism：向神经网络掘进更深（<a href="https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html%EF%BC%89">https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html）</a></p><h4 id="dropout"><a class="markdownIt-Anchor" href="#dropout"></a> Dropout</h4><p>Dropout(随机失活) 是一种用于神经网络防止过拟合的正则化技术。它通过在每次训练迭代中随机地设置神经元中的一小部分为 0 来阻止神经元共适应（co-adapting），Dropout 可以通过多种方式进行解读，比如从不同网络的指数数字中随机取样。Dropout 层首先通过它们在卷积神经网络中的应用而得到普及，但自那以后也被应用到了其它层上，包括输入嵌入或循环网络。</p><p>通俗讲随机失活（Dropout）在训练的过程中以一定比例随机失活神经元来达到提高模型泛化能力的效果。</p><p>论文：Dropout: 一种防止神经网络过拟合的简单方法（Dropout: A Simple Way to Prevent Neural Networks from Overfitting）<br />论文：循环神经网络正则化（Recurrent Neural Network Regularization）</p><h4 id="嵌入embedding"><a class="markdownIt-Anchor" href="#嵌入embedding"></a> 嵌入（Embedding）</h4><p>一个嵌入映射到一个输入表征，比如一个词或一句话映射到一个矢量。一种流行的嵌入是词语嵌入（word embedding，国内常用的说法是：词向量），如 word2vec 或 GloVe。我们也可以嵌入句子、段落或图像。比如说，通过将图像和他们的文本描述映射到一个共同的嵌入空间中并最小化它们之间的距离，我们可以将标签和图像进行匹配。嵌入可以被明确地学习到，比如在 word2vec 中；嵌入也可作为监督任务的一部分例如情感分析（Sentiment Analysis）。通常一个网络的输入层是通过预先训练的嵌入进行初始化，然后再根据当前任务进行微调（fine-tuned）。</p><h4 id="梯度爆炸问题exploding-gradient-problem"><a class="markdownIt-Anchor" href="#梯度爆炸问题exploding-gradient-problem"></a> 梯度爆炸问题（Exploding Gradient Problem）</h4><p>梯度爆炸问题是梯度消失问题（Vanishing Gradient Problem）的对立面。在深度神经网络中，梯度可能会在反向传播过程中爆炸，导致数字溢出。解决梯度爆炸的一个常见技术是执行梯度裁剪（Gradient Clipping）。</p><p>论文：训练循环神经网络的困难之处（On the difficulty of training Recurrent Neural Networks）</p><h4 id="微调fine-tuning"><a class="markdownIt-Anchor" href="#微调fine-tuning"></a> 微调（Fine-Tuning）</h4><p>Fine-Tuning 这种技术是指使用来自另一个任务（例如一个无监督训练网络）的参数初始化网络，然后再基于当前任务更新这些参数。比如，自然语言处理架构通常使用 word2vec 这样的预训练的词向量（word embeddings），然后这些词向量会在训练过程中基于特定的任务（如情感分析）进行更新。</p><h4 id="梯度裁剪gradient-clipping"><a class="markdownIt-Anchor" href="#梯度裁剪gradient-clipping"></a> 梯度裁剪（Gradient Clipping）</h4><p>梯度裁剪是一种在非常深度的网络（通常是循环神经网络）中用于防止梯度爆炸（exploding gradient）的技术。执行梯度裁剪的方法有很多，但常见的一种是当参数矢量的 L2 范数（L2 norm）超过一个特定阈值时对参数矢量的梯度进行标准化，这个特定阈值根据函数：新梯度=梯度*阈值/L2范数（梯度）{new_gradients = gradients * threshold / l2_norm(gradients)}确定。</p><p>论文：训练循环神经网络的困难之处（On the difficulty of training Recurrent Neural Networks）</p><h4 id="glove"><a class="markdownIt-Anchor" href="#glove"></a> GloVe</h4><p>Glove 是一种为话语获取矢量表征（嵌入）的无监督学习算法。GloVe 的使用目的和 word2vec 一样，但 GloVe 具有不同的矢量表征，因为它是在共现（co-occurrence）统计数据上训练的。</p><p>论文：GloVe：用于词汇表征（Word Representation）的全局矢量（Global Vector）（GloVe: Global Vectors for Word Representation ）</p><h4 id="googlelenet"><a class="markdownIt-Anchor" href="#googlelenet"></a> GoogleLeNet</h4><p>GoogleLeNet 是曾赢得了 2014 年 ILSVRC 挑战赛的一种卷积神经网络架构。这种网络使用 Inception 模块（Inception Module）以减少参数和提高网络中计算资源的利用率。</p><p>论文：使用卷积获得更深（Going Deeper with Convolutions）</p><h4 id="gru"><a class="markdownIt-Anchor" href="#gru"></a> GRU</h4><p>GRU（Gated Recurrent Unit：门控循环单元）是一种 LSTM 单元的简化版本，拥有更少的参数。和 LSTM 细胞（LSTM cell）一样，它使用门控机制，通过防止梯度消失问题（vanishing gradient problem）让循环神经网络可以有效学习长程依赖（long-range dependency）。GRU 包含一个复位和更新门，它们可以根据当前时间步骤的新值决定旧记忆中哪些部分需要保留或更新。</p><p>论文：为统计机器翻译使用 RNN 编码器-解码器学习短语表征（Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation）<br />技术博客：循环神经网络教程，第 4 部分：用 Python 和 Theano 实现 GRU/LSTM RNN（<a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/%EF%BC%89">http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/）</a></p><h4 id="ground-truth"><a class="markdownIt-Anchor" href="#ground-truth"></a> ground truth</h4><p>在机器学习中， ground truth表示监督学习的训练集的分类准确性，用于证明或者推翻某个假设。有监督的机器学习会对训练数据打标记，试想一下如果训练标记错误，那么将会对测试数据的预测产生影响，因此这里将那些正确打标记的数据成为ground truth。</p><h4 id="highway-layer"><a class="markdownIt-Anchor" href="#highway-layer"></a> Highway Layer</h4><p>Highway Layer　是使用门控机制控制通过层的信息流的一种神经网络层。堆叠多个 Highway Layer 层可让训练非常深的网络成为可能。Highway Layer 的工作原理是通过学习一个选择输入的哪部分通过和哪部分通过一个变换函数（如标准的仿射层）的门控函数来进行学习。Highway Layer 的基本公式是 T * h(x) + (1 - T) * x；其中 T 是学习过的门控函数，取值在 0 到 1 之间；h(x) 是一个任意的输入变换，x 是输入。注意所有这些都必须具有相同的大小。</p><p>论文：Highway Networks</p><h4 id="icml"><a class="markdownIt-Anchor" href="#icml"></a> ICML</h4><p>即国际机器学习大会（International Conference for Machine Learning），一个顶级的机器学习会议。</p><h4 id="ilsvrc"><a class="markdownIt-Anchor" href="#ilsvrc"></a> ILSVRC</h4><p>即 ImageNet 大型视觉识别挑战赛（ImageNet Large Scale Visual Recognition Challenge），该比赛用于评估大规模对象检测和图像分类的算法。它是计算机视觉领域最受欢迎的学术挑战赛。过去几年中，深度学习让错误率出现了显著下降，从 30% 降到了不到 5%，在许多分类任务中击败了人类。</p><h4 id="inception模块inception-module"><a class="markdownIt-Anchor" href="#inception模块inception-module"></a> Inception模块（Inception Module）</h4><p>Inception模块被用在卷积神经网络中，通过堆叠 1×1 卷积的降维（dimensionality reduction）带来更高效的计算和更深度的网络。</p><p>论文：使用卷积获得更深（Going Deeper with Convolutions）</p><h4 id="keras"><a class="markdownIt-Anchor" href="#keras"></a> Keras</h4><p>Kears 是一个基于 Python 的深度学习库，其中包括许多用于深度神经网络的高层次构建模块。它可以运行在 TensorFlow 或 Theano 上。</p><h4 id="lstm"><a class="markdownIt-Anchor" href="#lstm"></a> LSTM</h4><p>长短期记忆（Long Short-Term Memory）网络通过使用内存门控机制防止循环神经网络（RNN）中的梯度消失问题（vanishing gradient problem）。使用 LSTM 单元计算 RNN 中的隐藏状态可以帮助该网络有效地传播梯度和学习长程依赖（long-range dependency）。</p><p>论文：长短期记忆（LONG SHORT-TERM MEMORY）<br />技术博客：理解 LSTM 网络（<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/%EF%BC%89">http://colah.github.io/posts/2015-08-Understanding-LSTMs/）</a><br />技术博客：循环神经网络教程，第 4 部分：用 Python 和 Theano 实现 GRU/LSTM RNN（<a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/%EF%BC%89">http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/）</a></p><h4 id="最大池化max-pooling"><a class="markdownIt-Anchor" href="#最大池化max-pooling"></a> 最大池化（Max-Pooling）</h4><p>池化（Pooling）操作通常被用在卷积神经网络中。一个最大池化层从一块特征中选取最大值。和卷积层一样，池化层也是通过窗口（块）大小和步幅尺寸进行参数化。比如，我们可能在一个 10×10 特征矩阵上以 2 的步幅滑动一个 2×2 的窗口，然后选取每个窗口的 4 个值中的最大值，得到一个 5×5 特征矩阵。池化层通过只保留最突出的信息来减少表征的维度；在这个图像输入的例子中，它们为转译提供了基本的不变性（即使图像偏移了几个像素，仍可选出同样的最大值）。池化层通常被安插在连续卷积层之间。</p><h4 id="mnist"><a class="markdownIt-Anchor" href="#mnist"></a> MNIST</h4><p>MNIST数据集可能是最常用的一个图像识别数据集。它包含 60,000 个手写数字的训练样本和 10,000 个测试样本。每一张图像的尺寸为 28×28像素。目前最先进的模型通常能在该测试集中达到 99.5% 或更高的准确度。</p><h4 id="动量momentum"><a class="markdownIt-Anchor" href="#动量momentum"></a> 动量（Momentum）</h4><p>动量是梯度下降算法（Gradient Descent Algorithm）的扩展，可以加速和阻抑参数更新。在实际应用中，在梯度下降更新中包含一个动量项可在深度网络中得到更好的收敛速度（convergence rate）。</p><p>论文：通过反向传播（back-propagating error）错误学习表征</p><h4 id="多层感知器mlpmultilayer-perceptron"><a class="markdownIt-Anchor" href="#多层感知器mlpmultilayer-perceptron"></a> 多层感知器（MLP：Multilayer Perceptron）</h4><p>多层感知器是一种带有多个全连接层的前馈神经网络，这些全连接层使用非线性激活函数（activation function）处理非线性可分的数据。MLP 是多层神经网络或有两层以上的深度神经网络的最基本形式。</p><p>负对数似然（NLL：Negative Log Likelihood）</p><p>参见分类交叉熵损失（Categorical Cross-Entropy Loss）。</p><h4 id="神经网络机器翻译nmtneural-machine-translation"><a class="markdownIt-Anchor" href="#神经网络机器翻译nmtneural-machine-translation"></a> 神经网络机器翻译（NMT：Neural Machine Translation）</h4><p>NMT 系统使用神经网络实现语言（如英语和法语）之间的翻译。NMT 系统可以使用双语语料库进行端到端的训练，这有别于需要手工打造特征和开发的传统机器翻译系统。NMT 系统通常使用编码器和解码器循环神经网络实现，它可以分别编码源句和生成目标句。</p><p>论文：使用神经网络的序列到序列学习（Sequence to Sequence Learning with Neural Networks）<br />论文：为统计机器翻译使用 RNN 编码器-解码器学习短语表征（Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation）</p><h4 id="神经图灵机ntmneural-turing-machine"><a class="markdownIt-Anchor" href="#神经图灵机ntmneural-turing-machine"></a> 神经图灵机（NTM：Neural Turing Machine）</h4><p>NTM 是可以从案例中推导简单算法的神经网络架构。比如，NTM 可以通过案例的输入和输出学习排序算法。NTM 通常学习记忆和注意机制的某些形式以处理程序执行过程中的状态。</p><p>论文：神经图灵机（Neural Turing Machines）</p><p>非线性（Nonlinearity）</p><p>参见激活函数（Activation Function）。</p><h4 id="噪音对比估计ncenoise-contrastive-estimation"><a class="markdownIt-Anchor" href="#噪音对比估计ncenoise-contrastive-estimation"></a> 噪音对比估计（NCE：noise-contrastive estimation）</h4><p>噪音对比估计是一种通常被用于训练带有大输出词汇的分类器的采样损失（sampling loss）。在大量的可能的类上计算 softmax 是异常昂贵的。使用 NCE，我们可以将问题降低成二元分类问题，这可以通过训练分类器区别对待取样和「真实」分布以及人工生成的噪声分布来实现。</p><p>论文：噪音对比估计：一种用于非标准化统计模型的新估计原理（Noise-contrastive estimation: A new estimation principle for unnormalized statistical models ）<br />论文：使用噪音对比估计有效地学习词向量（Learning word embeddings efficiently with noise-contrastive estimation）</p><h4 id="池化"><a class="markdownIt-Anchor" href="#池化"></a> 池化</h4><p>参见最大池化（Max-Pooling）或平均池化（Average-Pooling）。</p><h4 id="受限玻尔兹曼机rbnrestricted-boltzmann-machine"><a class="markdownIt-Anchor" href="#受限玻尔兹曼机rbnrestricted-boltzmann-machine"></a> 受限玻尔兹曼机（RBN：Restricted Boltzmann Machine）</h4><p>RBN 是一种可被解释为一个随机人工神经网络的概率图形模型。RBN 以无监督的形式学习数据的表征。RBN 由可见层和隐藏层以及每一个这些层中的二元神经元的连接所构成。RBN 可以使用对比散度（contrastive divergence）进行有效的训练，这是梯度下降的一种近似。</p><p>第六章：动态系统中的信息处理：和谐理论基础<br />论文：受限玻尔兹曼机简介（An Introduction to Restricted Boltzmann Machines）</p><h4 id="循环神经网络rnnrecurrent-neural-network"><a class="markdownIt-Anchor" href="#循环神经网络rnnrecurrent-neural-network"></a> 循环神经网络（RNN：Recurrent Neural Network）</h4><p>RNN 模型通过隐藏状态（或称记忆）连续进行相互作用。它可以使用最多 N 个输入，并产生最多 N 个输出。比如，一个输入序列可能是一个句子，其输出为每个单词的词性标注（part-of-speech tag）（N 到 N）；一个输入可能是一个句子，其输出为该句子的情感分类（N 到 1）；一个输入可能是单个图像，其输出为描述该图像所对应一系列词语（1 到 N）。在每一个时间步骤中，RNN 会基于当前输入和之前的隐藏状态计算新的隐藏状态「记忆」。其中「循环（recurrent）」这个术语来自这个事实：在每一步中都是用了同样的参数，该网络根据不同的输入执行同样的计算。</p><p>技术博客：了解 LSTM 网络（<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/%EF%BC%89">http://colah.github.io/posts/2015-08-Understanding-LSTMs/）</a><br />技术博客：循环神经网络教程第1部分——介绍 RNN （<a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/%EF%BC%89">http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/）</a></p><h4 id="递归神经网络recursive-neural-network"><a class="markdownIt-Anchor" href="#递归神经网络recursive-neural-network"></a> 递归神经网络（Recursive Neural Network）</h4><p>递归神经网络是循环神经网络的树状结构的一种泛化（generalization）。每一次递归都使用相同的权重。就像 RNN 一样，递归神经网络可以使用向后传播（backpropagation）进行端到端的训练。尽管可以学习树结构以将其用作优化问题的一部分，但递归神经网络通常被用在已有预定义结构的问题中，如自然语言处理的解析树中。</p><p>论文：使用递归神经网络解析自然场景和自然语言（Parsing Natural Scenes and Natural Language with Recursive Neural Networks ）</p><h4 id="relu"><a class="markdownIt-Anchor" href="#relu"></a> ReLU</h4><p>即线性修正单元（Rectified Linear Unit）。ReLU 常在深度神经网络中被用作激活函数。它们的定义是 f(x) = max(0, x) 。ReLU 相对于 tanh 等函数的优势包括它们往往很稀疏（它们的活化可以很容易设置为 0），而且它们受到梯度消失问题的影响也更小。ReLU 主要被用在卷积神经网络中用作激活函数。ReLU 存在几种变体，如Leaky ReLUs、Parametric ReLU (PReLU) 或更为流畅的 softplus近似。</p><p>论文：深入研究修正器（Rectifiers）：在 ImageNet 分类上超越人类水平的性能（Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification）<br />论文：修正非线性改进神经网络声学模型（Rectifier Nonlinearities Improve Neural Network Acoustic Models ）<br />论文：线性修正单元改进受限玻尔兹曼机（Rectified Linear Units Improve Restricted Boltzmann Machines ）</p><h4 id="残差网络resnet"><a class="markdownIt-Anchor" href="#残差网络resnet"></a> 残差网络（ResNet）</h4><p>深度残差网络（Deep Residual Network）赢得了 2015 年的 ILSVRC 挑战赛。这些网络的工作方式是引入跨层堆栈的快捷连接，让优化器可以学习更「容易」的残差映射（residual mapping）而非更为复杂的原映射（original mapping）。这些快捷连接和 Highway Layer 类似，但它们与数据无关且不会引入额外的参数或训练复杂度。ResNet 在 ImageNet 测试集中实现了 3.57% 的错误率。</p><p>论文：用于图像识别的深度残差网络（Deep Residual Learning for Image Recognition）</p><h4 id="rmsprop"><a class="markdownIt-Anchor" href="#rmsprop"></a> RMSProp</h4><p>RMSProp 是一种基于梯度的优化算法。它与 Adagrad 类似，但引入了一个额外的衰减项抵消 Adagrad 在学习率上的快速下降。</p><p>PPT：用于机器学习的神经网络 讲座6a<br />技术博客：斯坦福CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br />技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="序列到序列seq2seq"><a class="markdownIt-Anchor" href="#序列到序列seq2seq"></a> 序列到序列（Seq2Seq）</h4><p>序列到序列（Sequence-to-Sequence）模型读取一个序列（如一个句子）作为输入，然后产生另一个序列作为输出。它和标准的 RNN 不同；在标准的 RNN 中，输入序列会在网络开始产生任何输出之前被完整地读取。通常而言，Seq2Seq 通过两个分别作为编码器和解码器的 RNN 实现。神经网络机器翻译是一类典型的 Seq2Seq 模型。</p><p>论文：使用神经网络的序列到序列学习（Sequence to Sequence Learning with Neural Networks）</p><h4 id="随机梯度下降sgdstochastic-gradient-descent"><a class="markdownIt-Anchor" href="#随机梯度下降sgdstochastic-gradient-descent"></a> 随机梯度下降（SGD：Stochastic Gradient Descent）</h4><p>随机梯度下降是一种被用在训练阶段学习网络参数的基于梯度的优化算法。梯度通常使用反向传播算法计算。在实际应用中，人们使用微小批量版本的 SGD，其中的参数更新基于批案例而非单个案例进行执行，这能增加计算效率。vanilla SGD 存在许多扩展，包括动量（Momentum）、Adagrad、rmsprop、Adadelta 或 Adam。</p><p>论文：用于在线学习和随机优化的自适应次梯度方法（Adaptive Subgradient Methods for Online Learning and Stochastic Optimization）<br />技术博客：斯坦福CS231n：优化算法（<a href="http://cs231n.github.io/neural-networks-3/%EF%BC%89">http://cs231n.github.io/neural-networks-3/）</a><br />技术博客：梯度下降优化算法概述（<a href="http://sebastianruder.com/optimizing-gradient-descent/%EF%BC%89">http://sebastianruder.com/optimizing-gradient-descent/）</a></p><h4 id="softmax"><a class="markdownIt-Anchor" href="#softmax"></a> Softmax</h4><p>Softmax 函数通常被用于将原始分数（raw score）的矢量转换成用于分类的神经网络的输出层上的类概率（class probability）。它通过对归一化常数（normalization constant）进行指数化和相除运算而对分数进行规范化。如果我们正在处理大量的类，例如机器翻译中的大量词汇，计算归一化常数是很昂贵的。有许多种可以让计算更高效的替代选择，包括分层 Softmax（Hierarchical Softmax）或使用基于取样的损失函数，如 NCE。</p><h4 id="tensorflow"><a class="markdownIt-Anchor" href="#tensorflow"></a> TensorFlow</h4><p>TensorFlow是一个开源 C ++ / Python 软件库，用于使用数据流图的数值计算，尤其是深度神经网络。它是由谷歌创建的。在设计方面，它最类似于 Theano，但比 Caffe 或 Keras 更低级。</p><h4 id="theano"><a class="markdownIt-Anchor" href="#theano"></a> Theano</h4><p>Theano 是一个让你可以定义、优化和评估数学表达式的 Python 库。它包含许多用于深度神经网络的构造模块。Theano 是类似于 TensorFlow 的低级别库。更高级别的库包括Keras 和 Caffe。</p><h4 id="梯度消失问题vanishing-gradient-problem"><a class="markdownIt-Anchor" href="#梯度消失问题vanishing-gradient-problem"></a> 梯度消失问题（Vanishing Gradient Problem）</h4><p>梯度消失问题出现在使用梯度很小（在 0 到 1 的范围内）的激活函数的非常深的神经网络中，通常是循环神经网络。因为这些小梯度会在反向传播中相乘，它们往往在这些层中传播时「消失」，从而让网络无法学习长程依赖。解决这一问题的常用方法是使用 ReLU 这样的不受小梯度影响的激活函数，或使用明确针对消失梯度问题的架构，如LSTM。这个问题的反面被称为梯度爆炸问题（exploding gradient problem）。</p><p>论文：训练循环神经网络的困难之处（On the difficulty of training Recurrent Neural Networks）</p><h4 id="vgg"><a class="markdownIt-Anchor" href="#vgg"></a> VGG</h4><p>VGG 是在 2014 年 ImageNet 定位和分类比赛中分别斩获第一和第二位置的卷积神经网络模型。这个 VGG 模型包含 16-19 个权重层，并使用了大小为 3×3 和 1×1 的小型卷积过滤器。</p><p>论文：用于大规模图像识别的非常深度的卷积网络（Very Deep Convolutional Networks for Large-Scale Image Recognition）</p><h4 id="word2vec"><a class="markdownIt-Anchor" href="#word2vec"></a> word2vec</h4><p>word2vec 是一种试图通过预测文档中话语的上下文来学习词向量（word embedding）的算法和工具 (<a href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a>)。最终得到的词矢量（word vector）有一些有趣的性质，例如vector(‘queen’) ~= vector(‘king’) - vector(‘man’) + vector(‘woman’) （女王~=国王-男人+女人）。两个不同的目标函数可以用来学习这些嵌入：Skip-Gram 目标函数尝试预测一个词的上下文，CBOW 目标函数则尝试从词上下文预测这个词。</p><p>论文：向量空间中词汇表征的有效评估（Efficient Estimation of Word Representations in Vector Space）<br />论文：分布式词汇和短语表征以及他们的组合性（Distributed Representations of Words and Phrases and their Compositionality）<br />论文：解释 word2vec 参数学习（word2vec Parameter Learning Explained）</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL知识点 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DGL计算中心性</title>
      <link href="/2022/12/18/AILearning/DGL/DGL%E8%AE%A1%E7%AE%97%E4%B8%AD%E5%BF%83%E6%80%A7/"/>
      <url>/2022/12/18/AILearning/DGL/DGL%E8%AE%A1%E7%AE%97%E4%B8%AD%E5%BF%83%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<p>在DGL中，可以使用<code>dgl.degree</code>、<code>dgl.in_degree</code>和<code>dgl.out_degree</code>函数来计算图的度、入度和出度。此外，DGL还提供了一些其他库和函数来计算不同类型的中心性度量。以下是几种常见的中心性度量及其计算方法：</p><ul><li>度中心性（Degree Centrality）：度中心性衡量一个节点与图中其他节点之间的连接数量。可以使用<code>dgl.degree</code>函数计算节点的度。</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="comment"># 计算节点的度中心性</span></span><br><span class="line">degree_centrality = dgl.degree(g).<span class="built_in">float</span>() / (g.number_of_nodes() - <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Degree Centrality:&quot;</span>, degree_centrality)</span><br></pre></td></tr></table></figure><ul><li>介数中心性（Betweenness Centrality）：介数中心性衡量一个节点在图中的最短路径中充当桥梁的频率。可以使用<code>dgl.contrib.sampling.sampler.BetweennessCentrality</code>类来计算介数中心性。</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> dgl.contrib.sampling.sampler <span class="keyword">as</span> sampler</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"><span class="comment"># 计算节点的介数中心性</span></span><br><span class="line">betweenness_centrality = sampler.BetweennessCentrality()(g)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Betweenness Centrality:&quot;</span>, betweenness_centrality)</span><br></pre></td></tr></table></figure><ul><li>接近中心性（Closeness Centrality）：接近中心性衡量一个节点与图中其他节点之间的平均最短路径长度。可以使用<code>dgl.contrib.sampling.sampler.ClosenessCentrality</code>类来计算接近中心性。</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> dgl.contrib.sampling.sampler <span class="keyword">as</span> sampler</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"><span class="comment"># 计算节点的接近中心性</span></span><br><span class="line">closeness_centrality = sampler.ClosenessCentrality()(g)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Closeness Centrality:&quot;</span>, closeness_centrality)</span><br></pre></td></tr></table></figure><ul><li>特征向量中心性（Eigenvector Centrality）：特征向量中心性衡量一个节点在图中的重要性，取决于它与其他重要节点的连接程度。可以使用<code>torch.eig</code>函数计算特征值和特征向量，然后提取特征值中的实部作为特征向量中心性的度量。</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 创建图</span></span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"><span class="comment"># 计算节点的特征向量中心性</span></span><br><span class="line">eigenvalues, eigenvectors = torch.eig(g.adjacency_matrix().to_dense(), eigenvectors=<span class="literal">True</span>)</span><br><span class="line">eigenvector_centrality = eigenvalues[:, <span class="number">0</span>].real</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Eigenvector Centrality:&quot;</span>, eigenvector_centrality)</span><br></pre></td></tr></table></figure><p>请注意，在计算特征向量中心性时，我们将图的邻接矩阵转换为稠密矩阵，然后使用<code>torch.eig</code>函数计算特征值和特征向量。这可能在处理大型图时导致内存问题，因此需要根据具体情况进行调整。</p>]]></content>
      
      
      <categories>
          
          <category> AILearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DGL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IR分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-IR/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-IR/</url>
      
        <content type="html"><![CDATA[<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>编译器和静态分析的关系</li><li>AST vs IR</li><li>IR:3-地址代码（3AC）</li><li>实际静态分析器的3AC—Soot（Java）</li><li>SSA-静态单赋值</li><li>基本块（BB）</li><li>控制流图（CFG）</li></ol><h2 id="1编译器和静态分析的关系"><a class="markdownIt-Anchor" href="#1编译器和静态分析的关系"></a> 1.编译器和静态分析的关系</h2><p>源码-&gt;（Scanner - 词法Lexical分析-Regular Expression）-&gt;（Parser- 语法Syntax分析-Context-Free Grammar）， 生成AST -&gt;（Type Checker - 语义Semantic分析 - Attribute Grammar），生成 Decorated AST  -&gt; Translator，生成IR，进行静态分析 -&gt; Code Generator</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015129.webp" alt="img" /></p><p>1-1-编译器原理.png</p><h2 id="2ast-vs-ir"><a class="markdownIt-Anchor" href="#2ast-vs-ir"></a> 2.AST vs IR</h2><p><strong>AST</strong> ：高级，更接近于语法结构，依赖于语言种类，适用于快速类型检查，缺少控制流信息</p><p><strong>IR</strong>：低级，更接近于机器码，不依赖语言种类，压缩且简洁，包含控制流信息。是静态分析的基础</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015072.webp" alt="img" /></p><p>1-2-AST&amp;IR.png</p><h2 id="3ir3-地址代码3ac"><a class="markdownIt-Anchor" href="#3ir3-地址代码3ac"></a> 3.IR:3-地址代码（3AC）</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 最多1个操作符</span></span><br><span class="line">a+b+<span class="number">3</span>  -&gt;  t1 = a+b</span><br><span class="line">                 t2 = t1+<span class="number">3</span></span><br><span class="line">Address：</span><br><span class="line">    Name:a、b</span><br><span class="line">    Constant: <span class="number">3</span></span><br><span class="line">    编译器的临时变量：t1、t2</span><br></pre></td></tr></table></figure><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015124.webp" alt="img" /></p><p>1-3-常用3地址码.png</p><h2 id="4实际静态分析器的3acsootjava"><a class="markdownIt-Anchor" href="#4实际静态分析器的3acsootjava"></a> 4.实际静态分析器的3AC—Soot（Java）</h2><p>Soot-常用的Java静态分析框架</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// java IR（Jimple）基本知识</span></span><br><span class="line">invokespecial：call constructor, call superclass methods, call <span class="keyword">private</span> methods</span><br><span class="line">invokevirtual: instance methods <span class="title function_">call</span> <span class="params">(virtual dispatch)</span></span><br><span class="line">invokeinterface: cannot optimization, checking <span class="keyword">interface</span> <span class="title class_">implementation</span></span><br><span class="line">invokestation:call <span class="keyword">static</span> methods</span><br><span class="line"></span><br><span class="line">Java <span class="number">7</span>: invokedynamic -&gt; Java <span class="keyword">static</span> typing, dynamic language runs on JVM</span><br><span class="line"></span><br><span class="line">method signature: <span class="keyword">class</span> <span class="title class_">name</span>, <span class="keyword">return</span> type, method <span class="title function_">name</span><span class="params">(parameter1 type, parameter2 type)</span></span><br></pre></td></tr></table></figure><h2 id="5ssa-静态单赋值"><a class="markdownIt-Anchor" href="#5ssa-静态单赋值"></a> 5.SSA-静态单赋值</h2><p><strong>定义</strong>：给每一个定义变量一个新的名字，传递到接下来的使用当中，每个变量有1个定义（赋值的目标变量）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015273.webp" alt="img" /></p><p>1-4-SSA.png</p><p><strong>优点</strong>：唯一的变量名可以间接体现程序流信息，简化分析过程；清楚的Define-Use信息。</p><p><strong>缺点</strong>：引入很多变量和phi-function；转换为机器码时效率变低（引入很多拷贝操作）。</p><h2 id="6基本块bb"><a class="markdownIt-Anchor" href="#6基本块bb"></a> 6.基本块（BB）</h2><p><strong>定义</strong>：只有1个开头入口和1个结尾出口的最长3-地址指令序列。</p><p><strong>识别基本块的算法</strong>：首先确定入口指令，第一条指令是入口；任何跳转指令的目标地址是入口；任何跟在跳转指令之后的指令是入口。然后构造基本块，任何基本块包含1个入口指令和其接下来的指令。</p><p><strong>我的想法</strong>：对于下1条指令，若该指令不是入口，则可以加入；若该指令有多个出口，则停止加入，否则继续判断下一条指令。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015127.webp" alt="img" /></p><p>1-5-基本块算法.png</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015902.png" alt="image-20210507093627625" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015392.png" alt="image-20210507094011702" /></p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015444.png" alt="image-20210507093932573" /></p><h2 id="7控制流图cfg"><a class="markdownIt-Anchor" href="#7控制流图cfg"></a> 7.控制流图（CFG）</h2><p><strong>控制流边</strong>：基本块A的结尾有跳转指令跳转到基本块B；原始指令序列中，B紧跟着A，且A的结尾不是无条件跳转。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015647.webp" alt="img" /></p><p>1-6-控制流边.png</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241015485.png" alt="image-20210507094447334" /></p><p>添加Entry / Exit：没有块跳转到该块 / 没有跳转到其他块。</p><p>作者：bsauce<br />链接：<a href="https://www.jianshu.com/p/acb73f72cf46">https://www.jianshu.com/p/acb73f72cf46</a><br />来源：简书<br />著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>指针分析基础</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>指针分析规则</li><li>如何实现指针分析</li><li>指针分析算法</li><li>指针分析如何处理函数调用（过程间指针分析）</li></ol><h3 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点：</h3><p>理解指针分析的规则、指针流图PFG、指针分析算法。</p><p>理解指针分析调用函数的规则、过程间指针分析算法、实时调用图构建。</p><hr /><h1 id="1指针分析规则"><a class="markdownIt-Anchor" href="#1指针分析规则"></a> 1.指针分析规则</h1><p><strong>首先分析前4种语句</strong>：New / Assign / Store / Load。</p><p><strong>指针分析的域和相应的记法</strong>：变量/函数/对象/实例域/指针，用pt表示程序中的指向关系（映射）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012464.webp" alt="img" /></p><p>7-1-1-标记方法.png</p><p><strong>规则</strong>：采用推导形式，横线上面是条件，横线下面是结论。</p><ul><li><p>New：创建对象，将<code>new T()</code>对应的对象oi加入到x的指针集。</p></li><li><p>Assign：将y的指针集加入到x对应的指针集。</p></li><li><p>Store：让oi的field指向oj。</p></li><li><p>Load：Store的反操作。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012461.webp" alt="img" /></p><p>7-1-2-规则.png</p></li></ul><hr /><h1 id="2如何实现指针分析"><a class="markdownIt-Anchor" href="#2如何实现指针分析"></a> 2.如何实现指针分析</h1><p><strong>算法要求</strong>：全程序指针分析，要容易理解和实现。</p><p><strong>本质</strong>：在指针（变量/域）之间传递指向信息。Andersen-style分析（很普遍）——很多solving system把指针分析看作是一种包含关系，eg，<code>x = y</code>，x包含y。</p><p><strong>问题</strong>：当一个指针的指向集发生变化，必须更新与它相关的其他指针。如何表示这种传递关系？PFG。</p><p><strong>PFG</strong>：用指针流图PFG来表示指针之间的关系，PFG是<strong>有向图</strong>。</p><ul><li>Nodes：Pointer = V U (O x F)    节点n表示一个变量或抽象对象的域。</li><li>Edges：Pointer X Pointer   边x -&gt; y 表示指针x指向的对象may会流入指针y。</li></ul><p><strong>Edges添加规则</strong>：根据程序语句 + 对应的规则。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012456.webp" alt="img" /></p><p>7-2-1-PFG边规则.png</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012467.webp" alt="img" /></p><p>7-2-2-PFG示例.png</p><p><strong>PTA步骤</strong>：</p><ol><li>构造PFG（根据以上示例，PFG也受指向关系影响）</li><li>根据PFG传播指向信息</li></ol><hr /><h1 id="3指针分析算法"><a class="markdownIt-Anchor" href="#3指针分析算法"></a> 3.指针分析算法</h1><h4 id="1过程内pta算法"><a class="markdownIt-Anchor" href="#1过程内pta算法"></a> （1）过程内PTA算法</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012472.webp" alt="img" /></p><p>7-3-0-PTA算法_过程内.png</p><p><strong>符号</strong>：</p><ul><li>S：程序语句的集合。</li><li>WL：Work list，待合并的指针信息，二元组的集合，&lt;指针n，指向的对象集合pts&gt;。pts将被加入到n的指向集pt(n)中。</li><li>PFG：指针流图。</li></ul><p><strong>步骤</strong>：对每种语句都是基于第1小节的规则来实现。</p><ol><li>对S中所有类似**New <code>x = new T()</code>**的语句，将&lt;x, {oi}&gt;加入到WL。</li><li>对S中所有类似**Assign <code>x = y</code>**的语句，调用<code>AddEdge()</code>将<code>y -&gt; x</code>加入到PFG，&lt;x, pt(y)&gt;加入到WL（传播指向信息）。</li><li>遍历WL，取一个元素&lt;n, pts&gt;，除去pts中与pt(n)重复的对象得到<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012374.svg" alt="\Delta" />，调用Propagate(n,<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />)将<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />加入到pt(n)，且取出PFG中所有n指向的边<code>n-&gt;s</code>，将&lt;s, pts&gt;加入到WL（根据PFG将指向信息传递给同名指针）。</li><li>如果n表示一个变量x（x跟Store/Load指令相关），对<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />中的每个对象oi。对S中所有类似**Store <code>x.f = y</code><strong>的语句，调用<code>AddEdge()</code>将<code>y -&gt; oi.f</code>加入到PFG，&lt;oi.f, pt(y)&gt;加入到WL（传播指向信息）；对S中所有类似</strong>Load <code>y = x.f</code>**的语句，调用<code>AddEdge()</code>将<code>oi.f -&gt; y</code>加入到PFG，&lt;y, pt(oi.f)&gt;加入到WL（传播指向信息）。</li></ol><p><strong>问题</strong>：</p><ol><li>为什么要去重？避免冗余，英文叫做Differential propagation差异传播。</li><li>指针集用什么数据结构存储？混合集 Hibra-set，集合元素小于16个用hash set，大于16个用big-rector 位存储。</li><li>开源项目有哪些？<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fsable.github.io%2Fsoot%2F">Soot</a>、<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fwala.sourceforge.net%2Fwiki%2Findex.php%2FMain_Page">WALA</a>、<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fpag-www.gtisc.gatech.edu%2Fchord%2Fuser_guide%2F">Chord</a>。</li></ol><h4 id="2示例"><a class="markdownIt-Anchor" href="#2示例"></a> （2）示例</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span> b = new C(); </span><br><span class="line"><span class="number">2</span> a = b;</span><br><span class="line"><span class="number">3</span> c = new C(); </span><br><span class="line"><span class="number">4</span> c.f = a;</span><br><span class="line"><span class="number">5</span> d = c;</span><br><span class="line"><span class="number">6</span> c.f = d; </span><br><span class="line"><span class="number">7</span> e = d.f;</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">WL</th><th style="text-align:center">正处理</th><th style="text-align:center">PFG</th><th>指针集</th><th>处理语句</th><th>算法语句</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">[&lt;b, {o1}&gt;, &lt;c, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td>1，3</td><td>处理New</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">[&lt;b, {o1}&gt;, &lt;c, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td></td><td>2，4</td><td>处理Assign</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">[&lt;c, {o3}&gt;]</td><td style="text-align:center">&lt;b, {o1}&gt;</td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td>pt(b)={o1}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">[&lt;c, {o3}&gt;], &lt;a, {o1}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td></td><td></td><td>Propagate()传递，没有b.f语句</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">[&lt;a, {o1}&gt;]</td><td style="text-align:center">&lt;c, {o3}&gt;</td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td>pt©={o3}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">[&lt;a, {o1}&gt;, &lt;d, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；</td><td></td><td></td><td>Propagate()传递，有c.f语句</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">[&lt;a, {o1}&gt;, &lt;d, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；o3.f&lt;-a；o3.f&lt;-d；  <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012907.webp" alt="img" /> 7-3-1-PFG.png</td><td></td><td>4，6</td><td>处理Store/Load，添加边</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">[&lt;d, {o3}&gt;]</td><td style="text-align:center">&lt;a, {o1}&gt;</td><td style="text-align:center"></td><td>pt(a)={o1}；</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">[&lt;d, {o3}&gt;,&lt;o3.f, {o1}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递</td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">[&lt;o3.f, {o1}&gt;]</td><td style="text-align:center">&lt;d, {o3}&gt;</td><td style="text-align:center"></td><td>pt(d)={o3}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">11</td><td style="text-align:center">[&lt;o3.f, {o1}&gt;, &lt;o3.f, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递，有d.f语句</td></tr><tr><td style="text-align:center">12</td><td style="text-align:center">[&lt;o3.f, {o1}&gt;, &lt;o3.f, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">a&lt;-b；d&lt;-c；o3.f&lt;-a；o3.f&lt;-d；e&lt;-o3.f；  <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012751.webp" alt="img" /> 7-3-2-PFG.png</td><td></td><td>7</td><td>处理Load，添加边</td></tr><tr><td style="text-align:center">13</td><td style="text-align:center">[&lt;o3.f, {o3}&gt;]</td><td style="text-align:center">&lt;o3.f, {o1}&gt;</td><td style="text-align:center"></td><td>pt(o3.f)={o1}；</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">14</td><td style="text-align:center">[&lt;o3.f, {o3}&gt;, &lt;e, {o1}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递</td></tr><tr><td style="text-align:center">15</td><td style="text-align:center">[&lt;e, {o1}&gt;]</td><td style="text-align:center">&lt;o3.f, {o3}&gt;</td><td style="text-align:center"></td><td>pt(o3.f)={o1, o3}</td><td></td><td>while开头</td></tr><tr><td style="text-align:center">16</td><td style="text-align:center">[&lt;e, {o1}&gt;, &lt;e, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td></td><td></td><td>Propagate()传递</td></tr><tr><td style="text-align:center">17</td><td style="text-align:center"></td><td style="text-align:center">&lt;e, {o1}&gt;；&lt;e, {o3}&gt;</td><td style="text-align:center"><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012778.webp" alt="img" /> 7-3-3-PFG.png</td><td>pt(e)={o1, o3}</td><td></td><td>while开头</td></tr></tbody></table><hr /><h1 id="4指针分析如何处理函数调用"><a class="markdownIt-Anchor" href="#4指针分析如何处理函数调用"></a> 4.指针分析如何处理函数调用</h1><p><strong>构造调用图技术对比</strong>：</p><ul><li>CHA：基于声明类型，不精确，引入错误的调用边和指针关系。</li><li>指针分析：基于pt(a)，即a指向的类型，更精确，构造更准的CG并对指针分析有正反馈（所以过程间指针分析和CG构造同时进行，很复杂）。</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">(A a)</span> &#123;   <span class="comment">// pt(a) = ???</span></span><br><span class="line">  ...</span><br><span class="line">    b = a.bar();    <span class="comment">// pt(b) = ???  把a的指向分析清楚了，就能确定a.bar()到底调用哪个对象的bar()函数，那么b的指向也明确了。</span></span><br><span class="line">    ... </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="1调用语句规则"><a class="markdownIt-Anchor" href="#1调用语句规则"></a> （1）调用语句规则</h4><p><strong>call语句规则</strong>：主要分为4步。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012806.webp" alt="img" /></p><p>7-4-1-call规则.png</p><ol><li><strong>找目标函数m</strong>：Dispatch(oi, k)——找出pt(x)，也即oi类型对象中的k函数。</li><li><strong>receiver object</strong>：把x指向的对象（<code>pt(x)</code>）传到m函数的this变量，即mthis</li><li><strong>传参数</strong>：pt(aj), 1&lt;=j&lt;=n  传给m函数，即p(mpj), 1&lt;=j&lt;=n。<strong>建立PFG边</strong>，a1-&gt;mp1，…，an-&gt;mpn。</li><li><strong>传返回值</strong>：pt(mret)传给pt®。<strong>建立PFG边</strong>，r&lt;-mret。</li></ol><p><strong>问题</strong>：为什么PFG中不添加x-&gt;mthis边？因为mthis只和自己这个对象相关，而可能有pt(x)={new A, new B, new C}，指定对象的x只流向对应的对象，是无法跨对象传递的。</p><h4 id="2过程间pta算法"><a class="markdownIt-Anchor" href="#2过程间pta算法"></a> （2）过程间PTA算法</h4><p><strong>问题</strong>：由于指针分析和CG构造互相影响，所以每次迭代只分析可达的函数和语句。然后不断发现和分析新的可达函数。</p><p><strong>可达示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012783.webp" alt="img" /></p><p>7-4-2-可达示例.png</p><p><strong>算法</strong>：黄色背景的代码是和过程内分析不同的地方。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012835.webp" alt="img" /></p><p>7-4-3-PTA算法_过程间.png</p><p><strong>符号</strong>：</p><ul><li>mentry：入口main函数</li><li>Sm：函数m中的语句</li><li>S：可达语句的集合（就是RM中的语句）</li><li>RM：可达函数的集合</li><li>CG：调用图的边</li></ul><p><strong>步骤</strong>：基于调用规则来实现。</p><ol><li>首先调用<strong>AddReachable(mentry)</strong>，将入口函数mentry的语句加到S中。处理**New <code>x = new T()</code><strong>语句，把&lt;x, {oi}&gt;加入到WL；处理</strong>Assign <code>x = y</code>**语句，调用<code>AddEdge(y, x)</code>加入边到PFG。</li><li>跟过程内指针分析一样，遍历WL，取一个元素&lt;n, pts&gt;，除去pts中与pt(n)重复的对象得到<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />，调用Propagate(n,<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />)将<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />加入到pt(n)，且取出PFG中所有n指向的边<code>n-&gt;s</code>，将&lt;s, pts&gt;加入到WL（根据PFG将指向信息传递给同名指针）。</li><li>如果n表示一个变量x（x跟Store/Load指令相关），对<img src="https://math.jianshu.com/math?formula=%5CDelta" alt="\Delta" />中的每个对象oi。对S中所有类似**Store <code>x.f = y</code><strong>的语句，调用<code>AddEdge()</code>将<code>y -&gt; oi.f</code>加入到PFG，&lt;oi.f, pt(y)&gt;加入到WL（传播指向信息）；对S中所有类似</strong>Load <code>y = x.f</code>**的语句，调用<code>AddEdge()</code>将<code>oi.f -&gt; y</code>加入到PFG，&lt;y, pt(oi.f)&gt;加入到WL（传播指向信息）。</li><li>最后调用<strong>ProcessCall(x, oi)</strong>，处理与x相关的<strong>call指令</strong>。取出S中类似<code>r = x.k(a1,...,an)</code>的调用语句L，首先调用Dispatch(oi, k)解出调用的目标函数m，把&lt;mthis, {oi}&gt;加入到WL（传递接收对象，上下文敏感分析将用到），将<code>L-&gt;m</code>这条调用边加入到CG；调用**AddReachable(m)**将新的语句加入到S，并处理New/Assign语句；调用AddEdge()将<code>实参-&gt;形参</code>、<code>返回值-&gt;r</code>边加入到PFG（传递参数、返回值），并将<code>&lt;形参,pt(实参)&gt;</code>、<code>&lt;r,pt(返回值)&gt;</code>加入到WL。</li></ol><p><strong>问题</strong>：为什么ProcessCall(x, oi)中，要判断<code>L-&gt;m</code>这条边是否已经加入到CG？因为x可能指向多个对象，就会多次处理L这个调用指令，可能x中别的对象oj早就已经将这条边加入进去了。</p><h4 id="3示例"><a class="markdownIt-Anchor" href="#3示例"></a> （3）示例</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span> &#123;</span></span><br><span class="line"><span class="number">2</span>   <span class="type">static</span> <span class="type">void</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="number">3</span>       A a = new A();</span><br><span class="line"><span class="number">4</span>       A b = new B();</span><br><span class="line"><span class="number">5</span>       A c = b.foo(a);</span><br><span class="line"><span class="number">6</span>   &#125;</span><br><span class="line"><span class="number">7</span>   A <span class="title function_">foo</span><span class="params">(Ax)</span>&#123;...&#125;</span><br><span class="line"><span class="number">8</span> &#125;</span><br><span class="line"><span class="number">9</span> <span class="class"><span class="keyword">class</span> <span class="title">B</span> <span class="title">extends</span> <span class="title">A</span> &#123;</span>  </span><br><span class="line"><span class="number">10</span>  A <span class="title function_">foo</span><span class="params">(A y)</span> &#123;</span><br><span class="line"><span class="number">11</span>      A r=newA();</span><br><span class="line"><span class="number">12</span>      <span class="keyword">return</span> r;</span><br><span class="line"><span class="number">13</span>      &#125;</span><br><span class="line"><span class="number">14</span>  &#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">WL</th><th style="text-align:center">正处理</th><th style="text-align:center">PFG</th><th style="text-align:center">指针集</th><th style="text-align:center">RM</th><th style="text-align:center">CG</th><th style="text-align:center">语句</th><th>算法语句</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">[]</td><td style="text-align:center"></td><td style="text-align:center">{}</td><td style="text-align:center"></td><td style="text-align:center">{}</td><td style="text-align:center">{}</td><td style="text-align:center"></td><td>初始化</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">[]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">{A.main()}</td><td style="text-align:center"></td><td style="text-align:center">1，2</td><td>AddReachable(mentry)</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">[&lt;a,{o3}&gt;, &lt;b,{o4}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">3，4</td><td></td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">[&lt;b,{o4}&gt;]</td><td style="text-align:center">&lt;a,{o3}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(a)={o3}；</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">[]</td><td style="text-align:center">&lt;b,{o4}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(b)={o4}</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">[]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">5</td><td>ProcessCall(b, o4)</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">[&lt;B.foothis, {o4}&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">{5-&gt;B.foo(A)}</td><td style="text-align:center"></td><td>m=Dispatch(o4, foo())=B.foo()；添加到调用图</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">[&lt;B.foothis, {o4}&gt;, &lt;r, o11&gt;]</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">{A.main(), B.foo()}</td><td style="text-align:center"></td><td style="text-align:center"></td><td>AddReachable(B.foo())；添加到可达函数</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">[&lt;B.foothis, {o4}&gt;, &lt;r, o11&gt;, &lt;y, {o3}&gt;]</td><td style="text-align:center"></td><td style="text-align:center">{a-&gt;y, r-&gt;c}    <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012987.webp" alt="img" /></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>AddEdge()；添加参数边、返回值边</td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">[&lt;r, o11&gt;, &lt;y, {o3}&gt;]</td><td style="text-align:center">&lt;B.foothis, {o4}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(B.foothis)={o4}；</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头，B.foothis没有调用任何函数</td></tr><tr><td style="text-align:center">11</td><td style="text-align:center">[&lt;y, {o3}&gt;, &lt;c, {o11}&gt;]</td><td style="text-align:center">&lt;r, o11&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt®={o11}；</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr><tr><td style="text-align:center">12</td><td style="text-align:center"></td><td style="text-align:center">&lt;y, {o3}&gt;, &lt;c, {o11}&gt;</td><td style="text-align:center"></td><td style="text-align:center">pt(y)={o3}；pt©={o11}</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td>while开头</td></tr></tbody></table><p>如果是CHA的话，CG={5-&gt;B.foo(A), <strong>5-&gt;A.foo(A)</strong>}，错误识别为调用边。</p><p><strong>结果</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012023.webp" alt="img" /></p><p>7-4-5-result.png</p><p><strong>问题</strong>：没有入口函数的？如对库函数处理，生成调用库函数的程序。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>指针分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%8C%87%E9%92%88%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>Motivation</li><li>指针分析介绍</li><li>影响指针分析的关键要素</li><li>分析哪些语句</li></ol><h3 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点：</h3><p>什么是指针分析？影响指针分析的关键因素是什么？指针分析要分析哪些指令？</p><hr /><h1 id="1motivation"><a class="markdownIt-Anchor" href="#1motivation"></a> 1.Motivation</h1><p><strong>指针分析必要性</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012597.webp" alt="img" /></p><p>6-1-PTA-motivation.png</p><hr /><h1 id="2指针分析"><a class="markdownIt-Anchor" href="#2指针分析"></a> 2.指针分析</h1><p><strong>目标</strong>：分析程序指针可以指向哪些内存。对于Java等面向对象语言，主要分析指针指向哪个对象。</p><p><strong>说明</strong>：指针分析属于<mark>may analysis</mark>，分析的结果是某指针所有可能指向哪些对象，是个<mark>over-approximation</mark>集合。</p><p><strong>示例</strong>：面向对象语言中的指针指向问题。对于setB()函数，this指向<code>new A()</code>，因为是调用者是a.setB()；setB()中的b是x传过来的，所以b指向new B()，A.b指向 new B()。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012589.webp" alt="img" /></p><p>6-2-1-PTA示例.png</p><p><strong>区别</strong>：</p><ul><li>指针分析：<strong>分析指针所有可能指向的对象</strong>。</li><li>别名分析：<strong>分析两个指针是否指向相同的对象</strong>，可通过指针分析来推导得到。</li></ul><p><strong>应用</strong>：基本信息（别名分析/调用图），编译优化（嵌入虚拟调用），漏洞（空指针），安全分析（信息流）。</p><hr /><h1 id="3影响指针分析的关键要素"><a class="markdownIt-Anchor" href="#3影响指针分析的关键要素"></a> 3.影响指针分析的关键要素</h1><p><strong>指标</strong>：精度（precision）&amp; 效率（efficiency）。</p><p><strong>影响因素</strong>：本课程，我们主要分析分配点的堆抽象技术、上下文敏感/不敏感、流敏感/不敏感、全程序分析。</p><table><thead><tr><th>因素</th><th>问题</th><th>选项</th></tr></thead><tbody><tr><td>Heap abstraction</td><td>如何建模堆内存？</td><td>• <strong>Allocation-site</strong>        • Storeless</td></tr><tr><td>Context sensitivity</td><td>如何建模调用上下文？</td><td>• <strong>Context-sensitive</strong>     • <strong>Context-insensitive</strong></td></tr><tr><td>Flow sensitivity</td><td>如何建模控制流？</td><td>• Flow-sensitive     • <strong>Flow-insensitive</strong></td></tr><tr><td>Analysis scope</td><td>分析哪部分程序？</td><td>• <strong>Whole-program</strong>    • Demand-driven</td></tr></tbody></table><h4 id="1堆抽象内存建模"><a class="markdownIt-Anchor" href="#1堆抽象内存建模"></a> （1）堆抽象（内存建模）</h4><p><strong>问题</strong>：程序动态执行时，堆对象个数理论上是无穷无尽的，但静态分析无法处理这个问题。所以为保证指针分析可以终止，我们采用堆抽象技术，将无穷的具体对象抽象成有限的抽象对象。也即，将有共性的对象抽象成1个静态对象，从而限制静态分析对象的个数。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 示例</span></span><br><span class="line"><span class="keyword">for</span> (...) &#123;</span><br><span class="line">    A a = new A();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>技术概览</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012594.webp" alt="img" /></p><p>6-3-1-堆抽象技术概览.png</p><p>我们只学习<code>Allocation-Site</code>(分配，定位点)技术，最常见也最常被使用。</p><p><strong><code>Allocation-Site</code>原理</strong>：将动态对象抽象成它们的创建点（<code>Allocation-Site</code>），来表示在该点创建的所有动态对象。<code>Allocation-Site</code>个数是有限的。</p><p><strong>示例</strong>：循环创建了3个对象，我们用O2来抽象表示这3个动态对象。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012580.webp" alt="img" /></p><p>6-3-2-堆抽象示例.png</p><h4 id="2上下文敏感-context-sensitivity"><a class="markdownIt-Anchor" href="#2上下文敏感-context-sensitivity"></a> （2）上下文敏感 Context Sensitivity</h4><p><strong>问题</strong>：考虑是否区分不同call-site对同一函数的调用。</p><ul><li><p>Context-sensitive：根据某函数调用上下文的不同，多次分析同一函数。</p></li><li><p>Context-insensitive：每个函数只分析一次。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012569.webp" alt="img" /></p><p>6-3-3-上下文敏感示例.png</p></li></ul><h4 id="3流敏感-flow-sensitivity"><a class="markdownIt-Anchor" href="#3流敏感-flow-sensitivity"></a> （3）流敏感 Flow Sensitivity</h4><p><strong>问题</strong>：考虑语句顺序（控制流）的影响  vs 把程序当做无序语句的集合。</p><p><strong>方法</strong>：<strong>流敏感会在每个程序点都保存一份指针指向关系映射，而流不敏感则对整个程序保存一份指向关系映射。</strong></p><p><strong>说明</strong>：目前流敏感对Java提升不大，不过在C中很有效，本课程分析的是Java，所以重点讨论流不敏感技术。</p><p><strong>指针分析示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012567.webp" alt="img" /></p><p>6-3-4-流敏感示例.png</p><h4 id="4分析范围-analysis-scope"><a class="markdownIt-Anchor" href="#4分析范围-analysis-scope"></a> （4）分析范围 Analysis Scope</h4><p><strong>问题</strong>：分析程序的哪一部分？</p><ul><li>Whole-program 全程序：分析全程序的指向关系。</li><li>Demand-driven 需求驱动：只分析影响特定域的指针的指向关系。</li></ul><hr /><h1 id="4分析哪些语句"><a class="markdownIt-Anchor" href="#4分析哪些语句"></a> 4.分析哪些语句</h1><p><strong>问题</strong>：哪些语句会影响指针指向，那就只分析这些语句。</p><p><strong>Java指针类型</strong>：</p><ol><li><p><strong>Lacal variable: x</strong></p></li><li><p>Static field:C.f   （有时称为全局变量）——不分析</p></li><li><p><strong>Instance field: x.f</strong>    （对象的field）</p></li><li><p>Array element: array[i]  ——不分析，因为静态分析无法确定下标，所以将array中所有成员映射到一个field中，等价于<strong>Instance field</strong>，所以不重复分析。如下图所示：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241012902.webp" alt="img" /></p><p>6-4-1-数组处理.png</p></li></ol><p><strong>影响指针指向的语句</strong>：</p><ol><li>New:      x = new T()</li><li>Assign：x = y</li><li>Store：  x.f = y</li><li>Load：   y = x.f</li><li>Call：     r = x.k(a,…)<ul><li>Static call：    C.foo()</li><li>Special call： super.foo() / x.<init>() / this.privateFoo()</li><li><strong>Virtual call</strong>：x.foo()</li></ul></li></ol><p>复杂的内存访问可以通过引入临时变量，转化为三地址代码：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">x.f.g.h = y;</span><br><span class="line"><span class="comment">// 转化为</span></span><br><span class="line">t1 = x.f;</span><br><span class="line">t2 = t1.g;</span><br><span class="line">t2.h = y;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据流分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>数据流分析总览</li><li>预备知识</li><li>Reaching Definitions Analysis (may analysis)</li><li>Live Variables Analysis (may analysis)</li><li>Available Expressions Analysis (must analysis)</li></ol><h3 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点：</h3><ul><li>理解3种数据流分析的含义，如何设计类似的算法，如何优化</li><li>理解3种数据流分析的共性与区别</li><li>理解迭代算法并弄懂算法为什么能停止</li></ul><hr /><h2 id="1数据流分析总览"><a class="markdownIt-Anchor" href="#1数据流分析总览"></a> 1.数据流分析总览</h2><blockquote><p>may analysis：输出可能正确的信息（需做over-approximation优化，才能成为Safe-approximation安全的近似，可以有误报-completeness），注意大多数静态分析都是may analysis</p><p>must analysis：输出必须正确的信息（需做under-approximation优化，才能成为Safe-approximation安全的近似，可以有漏报-soundness）</p></blockquote><p>Nodes (BBs/statements)、Edges (control flows)、CFG (a program)</p><p><strong>例如</strong>：</p><blockquote><p>application-specific Data &lt;- <code>abstraction</code> (+/-/0)</p><p>Nodes &lt;- <code>Transfer function</code></p><p>Edges &lt;- <code>Control-flow handling</code></p></blockquote><p>不同的数据流分析 有 不同的数据<strong>抽象表达</strong> 和 不同的<strong>安全近似策略</strong>，如 不同的 <strong>转换规则</strong> 和 <strong>控制流</strong>处理。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000785.webp" alt="img" /></p><p>2-1-数据流分析总览.png</p><hr /><h2 id="2预备知识"><a class="markdownIt-Anchor" href="#2预备知识"></a> 2.预备知识</h2><p><strong>输入/输出状态</strong>：程序执行前/执行后的状态（本质就是抽象表达的数据的状态，如变量的状态）。</p><p><strong>数据流分析的结果</strong>：最终得到，每一个程序点对应一个数据流值(data-flow value)，表示该点所有可能程序状态的一个抽象。例如，我只关心x、y的值，我就用抽象来表示x、y所有可能的值的集合（输入/输出的值域/约束），就代表了该程序点的程序状态。</p><blockquote><p>Forward Analysis前向分析：按程序执行顺序的分析。OUT[s]=fs(IN[s])，s-statement</p><p>Backward Analysis反向分析：逆向分析。IN[s]=fs(OUT[s])</p></blockquote><p><strong>控制流约束</strong>：约束求解做的事情，推断计算输入到输出，或反向分析。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000769.webp" alt="img" /></p><p>2-2-控制流约束.png</p><hr /><h2 id="3reaching-definitions-analysis-may-analysis"><a class="markdownIt-Anchor" href="#3reaching-definitions-analysis-may-analysis"></a> 3.Reaching Definitions Analysis (may analysis)</h2><p><strong>问题定义</strong>：给变量v一个定义d（赋值），存在一条路径使得程序点p能够到达q，且在这个过程中不能改变v的赋值。</p><p><strong>应用举例</strong>：检测未定义的变量，若v可达p且v没有被定义，则为未定义的变量。</p><p><strong>抽象表示</strong>：设程序有n条赋值语句，用n位向量来表示能reach与不能reach。</p><h4 id="1公式分析"><a class="markdownIt-Anchor" href="#1公式分析"></a> （1）公式分析</h4><p>什么是definition？ <code>D: v = x op y</code>    类似于赋值。</p><p><strong>Transfer Function</strong>：OUT[B] = genB U (IN[B] - killB) ——怎么理解，就是基于转换规则而得到。</p><p><strong>解释</strong>：基本块B的输出 = 块B内的所有变量v的定义（赋值/修改）语句  U （块B的输入 - 程序中其它所有定义了变量v的语句）。本质就是本块与前驱修改变量的语句 作用之和（去掉前驱的重复修改语句）。</p><p><strong>Control Flow</strong>：IN[B] = Up a_predecesso_of_B Out[P] ——怎么理解，就是基于控制流而得到。</p><p><strong>解释</strong>：基本块B的输入 = 块B所有前驱块P的输出的并集。注意，所有前驱块意味着只要有一条路径能够到达块B，就是它的前驱，包括条件跳转与无条件跳转。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000762.webp" alt="img" /></p><p>2-3-1-Reaching_Definition.png</p><h4 id="2算法"><a class="markdownIt-Anchor" href="#2算法"></a> （2）算法</h4><p><strong>目的</strong>：输入CFG，计算好每个基本块的killB（程序中其它块中定义了变量v的语句）和genB（块B内的所有变量v的定义语句），输出每个基本块的IN[B]和OUT[B]。</p><p><strong>方法</strong>：首先所有基本块的OUT[B]初始化为空。遍历每一个基本块B，按以上两个公式计算块B的IN[B]和OUT[B]，只要这次遍历时有某个块的OUT[B]发生变化，则重新遍历一次（因为程序中有循环存在，只要某块的OUT[B]变了，就意味着后继块的IN[B]变了）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000773.webp" alt="img" /></p><p>2-3-2-可达性分析算法.png</p><h4 id="3实例"><a class="markdownIt-Anchor" href="#3实例"></a> （3）实例：</h4><p><strong>抽象表示</strong>：设程序有n条赋值语句，用n位向量来表示能reach与不能reach。</p><p><strong>说明</strong>：红色-第1次遍历；蓝色-第2次遍历；绿色-第3次遍历。</p><p><strong>结果</strong>：3次遍历之后，每个基本块的OUT[B]都不再变化。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000780.webp" alt="img" /></p><p>2-3-3遍历实例.png</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000686.png" alt="image-20210507134806554" /></p><p>现在，我们可以回想一下，数据流分析的目标是，最后得到了，每个程序点关联一个数据流值（该点所有可能的程序状态的一个抽象表示，也就是这个n位向量）。在这个过程中，我们对个基本块，不断利用基于转换规则的语义（也就是transfer functions，构成基本块的语句集）-<code>OUT[B]</code>、控制流的约束-<code>IN[B]</code>，最终得到一个稳定的安全的近似约束集。</p><h4 id="4算法会停止吗"><a class="markdownIt-Anchor" href="#4算法会停止吗"></a> （4）算法会停止吗？</h4><p>OUT[B] = genB U (IN[B] - killB)</p><p><strong>大致理解</strong>：genB和 killB是不变的，只有IN[B]在变化，所以说OUT[B]只会增加不会减少，n向量长度是有限的，所以最终肯定会停止。具体涉及到不动点证明，后续课程会讲解。</p><hr /><h2 id="4live-variables-analysis-may-analysis"><a class="markdownIt-Anchor" href="#4live-variables-analysis-may-analysis"></a> 4.Live Variables Analysis (may analysis)</h2><p><strong>问题定义</strong>：某程序点p处的变量v，从p开始到exit块的CFG中是否有某条路径用到了v，如果用到了v，则v在p点为live，否则为dead。其中有一个隐含条件，在点p和引用点之间不能重定义v。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000030.webp" alt="img" /></p><p>2-4-1-live_variables定义.png</p><p><strong>应用场景</strong>：可用于寄存器分配，如果寄存器满了，就需要替换掉不会被用到的变量。</p><p><strong>抽象表示</strong>：程序中的n个变量用长度为n bit的向量来表示，对应bit为1，则该变量为live，反之为0则为dead。</p><h4 id="1公式分析-2"><a class="markdownIt-Anchor" href="#1公式分析-2"></a> （1）公式分析</h4><p><strong>Control Flow</strong>：OUT[B] = US a_successor_of_BIN[S]</p><p><strong>理解</strong>：我们是前向分析，只要有一条子路是live，父节点就是live。</p><p><strong>Transfer Function</strong>：IN[B] = useB U (OUT[B] - defB)</p><p><strong>理解</strong>：IN[B] = 本块中use出现在define之前的变量 U （OUT[B]出口的live情况 - 本块中出现了define的变量）。define指的是定义/赋值。</p><p><strong>特例分析</strong>：如以下图所示，第4种情况，v=v-1，实际上use出现在define之前，v是使用的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000096.webp" alt="img" /></p><p>2-4-2-公式推导.png</p><h4 id="2算法-2"><a class="markdownIt-Anchor" href="#2算法-2"></a> （2）算法</h4><p><strong>目的</strong>：输入CFG，计算好每个基本块中的defB（重定义）和useB（出现在重定义之前的使用）。输出每个基本块的IN[B]和OUT[B]。</p><p><strong>方法</strong>：首先初始化每个基本块的IN[B]为空集。遍历每一个基本块B，按以上两个公式计算块B的OUT[B]和IN[B]，只要这次遍历时有某个块的IN[B]发生变化，则重新遍历一次（因为有循环，只要某块的IN[B]变了，就意味前驱块的OUT[B]变了）。</p><p><strong>问题</strong>：遍历基本块的顺序有要求吗？ 没有要求，但是会影响遍历的次数。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000117.webp" alt="img" /></p><p>2-4-3-live_variables算法.png</p><p><strong>初始化规律</strong>：一般情况下，may analysis 全部初始化为空，must analysis全部初始化为all。</p><h4 id="3实例-2"><a class="markdownIt-Anchor" href="#3实例-2"></a> （3）实例</h4><p><strong>抽象表示</strong>：程序中的n个变量用长度为n bit的向量来表示，对应bit为1，则该变量为live，反之为0则为dead。</p><p><strong>说明</strong>：从下往上遍历基本块，黑色-初始化；红色-第1次；蓝色-第2次；绿色-第3次。</p><p><strong>结果</strong>：3次遍历后，IN[B]不再变化，遍历结束。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000125.webp" alt="img" /></p><p>2-4-4-算法运行示例.png</p><hr /><h2 id="5available-expressions-analysis-must-analysis"><a class="markdownIt-Anchor" href="#5available-expressions-analysis-must-analysis"></a> 5.Available Expressions Analysis (must analysis)</h2><p><strong>问题定义</strong>：程序点p处的表达式<code>x op y</code>可用需满足2个条件，一是从entry到p点必须经过<code>x op y</code>，二是最后一次使用<code>x op y</code>之后，没有重定义操作数x、y。（如果重定义了x 或 y，如x = <code>a op2 b</code>，则原来的表达式<code>x op y</code>中的x或y就会被替代）。</p><p><strong>应用场景</strong>：用于优化，检测全局公共子表达式。</p><p><strong>抽象表示</strong>：程序中的n个表达式，用长度为n bit的向量来表示，1表示可用，0表示不可用。</p><p><strong>说明</strong>：属于forward分析。</p><h4 id="1公式分析-3"><a class="markdownIt-Anchor" href="#1公式分析-3"></a> （1）公式分析</h4><p><strong>Transfer Function</strong>：OUT[B] = genB U (IN[B] - killB)</p><p><strong>理解</strong>：genB—基本块B中所有新的表达式（并且在这个表达式之后，不能对表达式中出现的变量进行重定义）–&gt;加入到OUT；killB—从IN中删除变量被重新定义的表达式。</p><p><strong>Control Flow</strong>：IN[B] = <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000045.svg" alt="\cap" />P a_predecessor_of_B OUT[P]</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000045.svg" alt="IN[B] = \cap_{P}\ _{a\ predecessor\ of\ B}OUT[P]" /></p><p><strong>理解</strong>：从entry到p点的所有路径都必须经过该表达式。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000140.webp" alt="img" /></p><p>2-5-1-可用表达式定义.png</p><p><strong>问题</strong>：该分析为什么属于must analysis呢？因为我们允许有漏报，不能有误报，比如以上示例中，改为x=3，去掉 b=e16*x，该公式会把该表达式识别为不可用。但事实是可用的，因为把x=3替换到表达式中并不影响该表达式的形式。这里虽然漏报了，但是不影响程序分析结果的正确性。</p><h4 id="2算法-3"><a class="markdownIt-Anchor" href="#2算法-3"></a> （2）算法</h4><p><strong>目的</strong>：输入CFG，提前计算好genB和killB。</p><p><strong>方法</strong>：首先将OUT[entry]初始化为空，所有基本块的OUT[B]<strong>初始化为1…1</strong>。遍历每一个基本块B，按以上两个公式计算块B的IN[B]和OUT[B]，只要这次遍历时有某个块的OUT[B]发生变化，则重新遍历一次（因为有循环，只要某块的OUT[B]变了，就意味后继块的IN[B]变了）。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000334.webp" alt="img" /></p><p>2-5-2-可用表达式算法.png</p><h4 id="3实例-3"><a class="markdownIt-Anchor" href="#3实例-3"></a> （3）实例</h4><p><strong>抽象表示</strong>：程序中的n个表达式，用长度为n bit的向量来表示，1表示可用，0表示不可用。</p><p><strong>说明</strong>：黑色-初始化；红色-第1次；蓝色-第2次。</p><p><strong>结果</strong>：2次遍历后，OUT[B]不再变化，遍历结束。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241000364.webp" alt="img" /></p><p>2-5-3-算法运行示例.png</p><hr /><h2 id="6三种分析技术对比"><a class="markdownIt-Anchor" href="#6三种分析技术对比"></a> 6.三种分析技术对比</h2><table><thead><tr><th></th><th>Reaching Definitions</th><th>Live Variables</th><th>Available Expressions</th></tr></thead><tbody><tr><td><strong>Domain</strong></td><td>赋值语句</td><td>变量</td><td>表达式</td></tr><tr><td><strong>Direction</strong></td><td>forward</td><td>backward</td><td>forward</td></tr><tr><td><strong>May/Must</strong></td><td>May</td><td>May</td><td>Must</td></tr><tr><td><strong>Boundary</strong></td><td>OUT[Entry]=Φ</td><td>IN[Exit]=Φ</td><td>OUT[Entry]=Φ</td></tr><tr><td><strong>Initialization</strong></td><td>OUT[B]=Φ</td><td>IN[B]=Φ</td><td>OUT[B]=Π</td></tr><tr><td><strong>Transfer function</strong></td><td>OUT=gen U (IN - kill)</td><td>same</td><td>same</td></tr><tr><td><strong>Meet</strong></td><td>U</td><td>U</td><td>Π</td></tr></tbody></table><p><strong>问题</strong>：怎样判断是May还是Must？</p><p>Reaching Definitions表示只要从赋值语句到点p<strong>存在1条路径</strong>，则为reaching，结果不一定正确；Live Variables表示只要从点p到Exit<strong>存在1条路径</strong>使用了变量v，则为live，结果不一定正确；Available Expressions表示从Entry到点p的<strong>每一条路径</strong>都经过了该表达式，则为available，结果肯定正确。</p><p>作者：bsauce<br />链接：<a href="https://www.jianshu.com/p/45eb5e5565d5">https://www.jianshu.com/p/45eb5e5565d5</a><br />来源：简书<br />著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据流分析2</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%902/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%902/</url>
      
        <content type="html"><![CDATA[<p>关于这一节<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Fhahahaqwe123">zcc</a>的笔记已经够完美了，我就直接在他基础上记录了。</p><h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>迭代算法-另一个角度</li><li>偏序（Partial Order）</li><li>上下界（Upper and Lower Bounds）</li><li>格（Lattice），半格（Semilattice），全格和格点积（Complete and Product Lattice）</li><li>数据流分析框架（via Lattice）</li><li>单调性与不动点定理（Monotonicity and Fixed Point Theorem）</li><li>迭代算法转化为不动点理论</li><li>从lattice的角度看may/must分析</li><li>分配性（Distributivity）和MOP</li><li>常量传播</li><li>Worklist算法</li></ol><h3 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点：</h3><p>上节课是介绍了3种数据流分析迭代算法，本节课将从数学理论的角度来讨论数据流分析，加深对数据流分析算法的理解。</p><hr /><h2 id="1迭代算法-另一个角度"><a class="markdownIt-Anchor" href="#1迭代算法-另一个角度"></a> 1.迭代算法-另一个角度</h2><p><strong>本质</strong>：常见的数据流迭代算法，目的是通过迭代计算，最终得到一个稳定的不变的解。</p><h4 id="1理论"><a class="markdownIt-Anchor" href="#1理论"></a> （1）理论</h4><p><strong>定义1</strong>：给定有k个节点（基本块）的CFG，迭代算法就是在每次迭代时，更新每个节点n的OUT[n]。</p><p><strong>定义2</strong>：设数据流分析的值域是V，可定义一个<strong>k-元组</strong>： (OUT[n1], OUT[n2], … , OUT[nk])。是集合 (V1 <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\times" /> V2 … <img src="https://math.jianshu.com/math?formula=%5Ctimes" alt="\times" /> Vk) （幂集，记为Vk）的一个元素，表示每次迭代后k个节点整体的值。</p><p><strong>定义3</strong>：每一次迭代可看作是Vk映射到新的Vk，通过转换规则和控制流来映射，记作函数F：Vk <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\rightarrow" /> Vk。</p><p><strong>迭代算法本质</strong>：通过不断迭代，直到相邻两次迭代的<strong>k-元组</strong>值一样，算法结束。</p><h4 id="2图示"><a class="markdownIt-Anchor" href="#2图示"></a> （2）图示</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002572.webp" alt="img" /></p><p>4-1-迭代算法数学化.png</p><p><strong>不动点</strong>：当Xi = F(Xi)时，就是不动点。</p><p><strong>问题</strong>：</p><ul><li>迭代算法是否一定会停止（到达不动点）？</li><li>迭代算法如果会终止，会得到几个解（几个不动点）？</li><li>迭代几次会得到解（到达不动点）？</li></ul><hr /><h2 id="2偏序partial-order"><a class="markdownIt-Anchor" href="#2偏序partial-order"></a> 2.偏序（Partial Order）</h2><p><strong>定义</strong>：给定偏序集(P, <img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\sqsubseteq" />)，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />是集合P上的二元关系，若满足以下性质则为偏序集：</p><ul><li>∀<em>x</em>∈<em>P</em>,<em>x</em>⊑<em>x</em>                          自反性Reflexivity</li><li>∀<em>x</em>,<em>y</em>∈<em>P</em>, <em>x</em>⊑<em>y</em>∧<em>y</em>⊑<em>x</em> ⇒ <em>x</em>=y     对称性Antisymmetry</li><li>∀<em>x</em>,<em>y</em>∈<em>P</em>, <em>x</em>⊑<em>y</em>∧<em>y</em>⊑<em>z</em> ⇒ <em>x</em>⊑<em>z</em>     传递性Transitivity</li></ul><p><strong>例子</strong>：</p><ul><li>P是整数集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\leq" />，是偏序集；若<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示&lt;，则显然不是偏序集。</li><li>P是英文单词集合，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示子串关系（可以存在两个元素不具有偏序关系，不可比性），是偏序集。</li></ul><hr /><h2 id="3上下界upper-and-lower-bounds"><a class="markdownIt-Anchor" href="#3上下界upper-and-lower-bounds"></a> 3.上下界（Upper and Lower Bounds）</h2><h5 id="1定义"><a class="markdownIt-Anchor" href="#1定义"></a> （1）定义</h5><p><strong>定义</strong>：给定偏序集(P, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />)，且有P的子集S⊆P：</p><ul><li>∀<em>x</em>∈<em>S</em>, <em>x</em>⊑<em>u</em>, 其中<em>u</em>∈<em>P</em>，则u是子集S的上界 （<strong>注意，u并不一定属于S集</strong>）</li><li>∀<em>x</em>∈<em>S</em>, <em>l</em>⊑<em>x</em>, 其中<em>l</em>∈<em>P</em>，则l是S的下界</li></ul><p><strong>最小上界</strong>：least upper bound（lub 或者称为join），用⊔S表示。上确界？</p><p>定义：对于子集S的任何一个上界u，均有⊔S⊑u。</p><p><strong>最大下界</strong>：greatest lower bound（glb 或者称为meet），用⊓S表示。下确界？</p><p>定义：对于子集S的任何一个下界l，均有l⊑⊓S。</p><h5 id="2示例"><a class="markdownIt-Anchor" href="#2示例"></a> （2）示例</h5><p>若S只包含两个元素，a、b（S = {a, b}）那么上界可以表示为a⊔b，下界可以表示为a⊓b。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002554.webp" alt="img" /></p><p>4-3-1-上下确界示例.png</p><h5 id="3特性"><a class="markdownIt-Anchor" href="#3特性"></a> （3）特性</h5><ul><li>并非每个偏序集都有上下确界。</li></ul><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002553.webp" alt="img" /></p><p>4-3-2-无下确界.png</p><ul><li><p>如果存在上下确界，则是唯一的。</p><p>利用传递性和反证法即可证明。</p></li></ul><hr /><h2 id="4格lattice半格semilattice全格格点积complete-and-product-lattice"><a class="markdownIt-Anchor" href="#4格lattice半格semilattice全格格点积complete-and-product-lattice"></a> 4.格（Lattice），（半格）Semilattice，全格，格点积（Complete and Product Lattice）</h2><p>都是基于上下确界来定义的。</p><h4 id="1格"><a class="markdownIt-Anchor" href="#1格"></a> （1）格</h4><p><strong>定义</strong>：给定一个偏序集(P,⊑)，∀a,b∈P，如果存在a⊔b和a⊓b，那么就称该偏序集为格。偏序集中的<strong>任意两个元素</strong>构成的集合均<strong>存在最小上界和最大下界</strong>，那么该偏序集就是格。</p><p><strong>例子</strong>：</p><ul><li>(S, ⊑)中S是整数子集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />是<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\leq" />，是格点；</li><li>(S, ⊑)中S是英文单词集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示子串关系，不是格点，因为单词pin和sin就没有上确界；</li><li>(S, ⊑)中S是{a, b, c}的幂集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\subseteq" />子集，是格点。</li></ul><h4 id="2半格"><a class="markdownIt-Anchor" href="#2半格"></a> （2）半格</h4><p><strong>定义</strong>：给定一个偏序集(P,⊑)，∀a,b∈P：<br />当且仅当a⊔b存在（上确界），该偏序集叫做 join semilatice；</p><p>当且仅当a⊓b存在（下确界），该偏序集叫做 meet semilatice</p><h4 id="3全格"><a class="markdownIt-Anchor" href="#3全格"></a> （3）全格</h4><p><strong>定义</strong>：对于格点 (S, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />) （前提是格点）的任意子集S，⊔<em>S</em>上确界和⊓S下确界都存在，则为全格complete lattice。</p><p><strong>例子</strong>：</p><ul><li>P是整数集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />是<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\leq" />，不是全格，因为P的子集正整数集没有上确界。</li><li>(S, ⊑)中S是{a, b, c}的幂集，<img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />表示<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\subseteq" />子集，是全格。</li></ul><p><strong>符号</strong>：<img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002462.svg" alt="\top" /> = <img src="mdPics/math" alt="\sqcup" />P ，叫做top；<img src="mdPics/math" alt="\perp" /> = <img src="mdPics/math" alt="\sqcap" />P，叫做bottom。</p><p><strong>性质</strong>：有穷的格点必然是complete lattice。全格一定有穷吗？ 不一定，如实数界[0, 1]。</p><h4 id="4格点积"><a class="markdownIt-Anchor" href="#4格点积"></a> （4）格点积</h4><p><strong>定义</strong>：给定一组格，L1=(P1, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />1)，L2=(P2, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />2)，… ，Ln=(Pn, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />n)，都有上确界<img src="mdPics/math" alt="\sqcup" />i和下确界<img src="mdPics/math" alt="\sqcap" />i，则定义格点积 Ln = (P, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />)：</p><ol><li>P = P1 <img src="https://math.jianshu.com/math?formula=%5Ctimes" alt="\times" /> … <img src="https://math.jianshu.com/math?formula=%5Ctimes" alt="\times" /> Pn</li><li>(x1, … xn) <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" /> (y1, … yn) <img src="mdPics/math" alt="\Leftrightarrow" /> (x1 <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" /> y1) <img src="mdPics/math" alt="\wedge" /> … <img src="https://math.jianshu.com/math?formula=%5Cwedge" alt="\wedge" /> (xn <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" /> yn)</li><li>(x1, … xn) <img src="mdPics/math" alt="\sqcup" /> (y1, … yn) = (x1 <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup" /> y1, …, xn <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup" /> yn)</li><li>(x1, … xn) <img src="mdPics/math" alt="\sqcap" /> (y1, … yn) = (x1 <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> y1, …, xn <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> yn)</li></ol><p><strong>性质</strong>：格点积也是格点；格点都是全格，则格点积也是全格。</p><hr /><h2 id="5数据流分析框架via-lattice"><a class="markdownIt-Anchor" href="#5数据流分析框架via-lattice"></a> 5.数据流分析框架（via Lattice）</h2><p>数据流分析框架(D, L, F) ：</p><ul><li>D—方向</li><li>L—格点（值域V，meet <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> 或 join <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup" /> 操作）</li><li>F—转换规则V <img src="mdPics/math" alt="\rightarrow" /> V。</li></ul><p>数据流分析可以看做是<strong>迭代算法</strong>对<strong>格点</strong> 利用<strong>转换规则</strong>和 <strong>meet/join操作</strong>。</p><hr /><h2 id="6单调性与不动点定理monotonicity-and-fixed-point-theorem"><a class="markdownIt-Anchor" href="#6单调性与不动点定理monotonicity-and-fixed-point-theorem"></a> 6.单调性与不动点定理（Monotonicity and Fixed Point Theorem）</h2><p>目标问题：迭代算法一定会停止（到达不动点）吗？</p><p>（1）单调性</p><p><strong>定义</strong>：函数f: L <img src="mdPics/math" alt="\rightarrow" /> L，满足∀x,y∈L，x⊑y⇒f(x)⊑f(y)，则为单调的。</p><p>（2）不动点理论</p><p><strong>定义</strong>：给定一个<strong>完全lattice(L,⊑)</strong>，如果f:L→L是<strong>单调</strong>的，并且<strong>L有限</strong></p><p>那么我们能得到最小不动点，通过迭代：f(⊥),f(f(⊥)),…,fk(⊥)直到找到最小的一个不动点。</p><p>同理 我们能得到最大不动点，通过迭代：f(⊤),f(f(⊤)),…,fk(⊤)直到找到最大的一个不动点。</p><p>（3）证明</p><p>不动点的存在性；</p><p>最小不动点证明。</p><hr /><h2 id="7迭代算法转化为不动点理论"><a class="markdownIt-Anchor" href="#7迭代算法转化为不动点理论"></a> 7.迭代算法转化为不动点理论</h2><p><strong>问题</strong>：我们如何在理论上证明<strong>迭代算法有解</strong>、<strong>有最优解</strong>、<strong>何时到达不动点</strong>？那就是将迭代算法转化为<strong>不动点理论</strong>。因为不动点理论已经证明了，单调、有限的完全lattice，存在不动点，且从⊤开始能找到最大不动点，从⊥开始能找到最小不动点。</p><p><strong>目标</strong>：证明迭代算法是一个<strong>完全lattice(L, <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" />)</strong>，是<strong>有限</strong>的，<strong>单调</strong>的。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002789.webp" alt="img" /></p><p>4-7-1-迭代算法.png</p><h4 id="1完全lattice证明"><a class="markdownIt-Anchor" href="#1完全lattice证明"></a> （1）完全lattice证明</h4><p>根据第5小节，迭代算法每个<strong>节点（基本块）的值域</strong>相当于一个<strong>lattice</strong>，每次迭代的<strong>k个基本块的值域</strong>就是一个<strong>k-元组</strong>。k-元组可看作<strong>lattice积</strong>，根据格点积性质：若Lk中每一个lattice都是完全的，则Lk也是<strong>完全</strong>的。</p><h4 id="2l是有限的"><a class="markdownIt-Anchor" href="#2l是有限的"></a> （2）L是有限的</h4><p>迭代算法中，值域是0/1，是有限的，则lattice有限，则Lk也有限。</p><h4 id="3f是单调的"><a class="markdownIt-Anchor" href="#3f是单调的"></a> （3）F是单调的</h4><p>函数F：BB中转换函数fi：L → L   +    BB分支之间的控制流影响（汇聚是join <img src="https://math.jianshu.com/math?formula=%5Csqcup" alt="\sqcup" /> / meet <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> 操作，分叉是拷贝操作）。</p><ol><li>转换函数：BB的gen、kill是固定的，值域一旦变成1，就不会变回0，显然单调。</li><li>join/meet操作：L × L → L 。证明：∀x,y,z∈L，且有x⊑y需要证明x⊔z⊑y⊔z。</li></ol><p><strong>总结</strong>：迭代算法是完全lattice，且是有限、单调的，所以一定有解、有最优解。</p><h4 id="4算法何时到达不动点"><a class="markdownIt-Anchor" href="#4算法何时到达不动点"></a> （4）算法何时到达不动点？</h4><p><strong>定义</strong>：<strong>lattice高度</strong>—从lattice的top到bottom之间最长的路径。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002813.webp" alt="img" /></p><p>4-7-3-lattice高度定义.png</p><p><strong>最坏情况迭代次数</strong>：设有n个块，每次迭代只有1个BB的OUT/IN值的其中1位发生变化（则从top→bottom这1位都变化），则最多迭 (<strong>n × h</strong>) 次。</p><hr /><h2 id="8从lattice的角度看maymust分析"><a class="markdownIt-Anchor" href="#8从lattice的角度看maymust分析"></a> 8.从lattice的角度看may/must分析</h2><p><strong>说明</strong>：may 和 must 分析算法都是从不安全到安全（是否安全取决于safe-aprroximate过程），从准确到不准确。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002848.webp" alt="img" /></p><p>4-8-1-must_may分析特点.png</p><h4 id="1may分析"><a class="markdownIt-Anchor" href="#1may分析"></a> （1）may分析</h4><p>以 Reaching Definitions分析为例：</p><ol><li>从<img src="mdPics/math" alt="\perp" /> 开始，<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" /> 表示所有定义都不可达，是<strong>不安全</strong>的结果（因为这个分析的应用目的是为了查错，查看变量是否需要初始化。首先在Entry中给每个变量一个假定义，标记所有变量为都为未初始化状态，<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" />表示所有的假定义都无法到达，说明所有变量在中间都进行了赋值，那就不需要对任何变量进行初始化，这是不安全的，可能导致未初始化错误）。</li><li><img src="mdPics/math" alt="\top" />表示所有Entry中的假定义都可达，从查错角度来说，需要对每个变量都进行初始化，非常<strong>安全</strong>！但是这句话没有用，我都要初始化的话还做这个分析干嘛？</li><li>Truth：表明最准确的验证结果，假设{a,c}是truth，那么包括其以上的都是safe的，以下的都是unsafe，就是上图的阴影和非阴影。</li></ol><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002864.webp" alt="img" /></p><p>4-8-2-Truth示例.png</p><ol><li>从<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" /> 到<img src="mdPics/math" alt="\top" /> ，得到的<strong>最小不动点</strong>最准确，离Truth最近。上面还有多个不动点，越往上越不准。</li></ol><h4 id="2must分析"><a class="markdownIt-Anchor" href="#2must分析"></a> （2）must分析</h4><p>以available expressions分析为例：</p><ol><li>从<img src="mdPics/math" alt="\top" />开始，表示所有表达式可用。如果用在表达式计算优化中，那么有很多已经被重定义的表达式也被优化了（实际上不能被优化），那么该优化就是错误的，<strong>不安全</strong>！</li><li><img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" />表示没有表达式可用，都不需要优化，很<strong>安全</strong>！但没有用。</li><li>从<img src="mdPics/math" alt="\top" />到<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" />，就是从不安全到安全，存在一个Truth，代表准确的结果。</li><li>从<img src="mdPics/math" alt="\top" />到<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" />，达到一个<strong>最大不动点</strong>，离truth最近的最优解。</li></ol><p>迭代算法转化到lattice上，may/must分析分别初始化为最小值<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" />和最大值<img src="mdPics/math" alt="\top" />，最后求最小上界/最大下界。</p><hr /><h2 id="9分配性distributivity和mop"><a class="markdownIt-Anchor" href="#9分配性distributivity和mop"></a> 9.分配性（Distributivity）和MOP</h2><p><strong>目的</strong>：MOP（meet-over-all-paths）衡量迭代算法的精度。</p><h4 id="1概念"><a class="markdownIt-Anchor" href="#1概念"></a> （1）概念</h4><p><strong>定义</strong>：最终将所有的路径一起来进行join/meet操作。</p><p><strong>路径P</strong> = 在cfg图上从entry到基本块si的一条路径（P = Entry → s1 → s2 → … → s~i ）。</p><p><strong>路径P上的转移函数Fp</strong>：该路径上所有语句的转移函数的组合fs1，fs2，… ，fsi-1，从而构成FP。</p><p><strong>MOP</strong>：从entry到si所有路径的FP的meet操作。本质—求这些值的最小上界/最大下界。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002877.webp" alt="img" /></p><p>4-9-1-MOP公式.png</p><p><strong>MOP准确性</strong>：有些路径不会被执行，所以不准确；若路径包含循环，或者路径爆炸，所以实操性不高，只能作为理论的一种衡量方式。</p><h4 id="2mop-vs-迭代算法"><a class="markdownIt-Anchor" href="#2mop-vs-迭代算法"></a> （2）MOP vs 迭代算法</h4><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002942.webp" alt="img" /></p><p>4-9-2-MOP与迭代算法比较.png</p><p>对于以上的CFG，抽象出itter和MOP公式。</p><p><strong>证明</strong>：</p><ol><li>根据最小上界的定义，有x⊑x⊔y和 y⊑x⊔y。</li><li>由于转换函数是单调的，则有F(x)⊑F(x⊔y)和F(y)⊑F(x⊔y)，所以F(x⊔y)就是F(x)和F(y)的上界。</li><li>根据定义，F(x)⊔F(y)是F(x)和F(y)的最小上界。</li><li>所以<em>F</em>(<em>x</em>)⊔<em>F</em>(<em>y</em>)⊑<em>F</em>(<em>x</em>⊔<em>y</em>)</li></ol><p><strong>结论</strong>：所以，MOP更准确。若F满足分配律，则迭代算法和MOP精确度一样 <em>F</em>(<em>x</em>⊔<em>y</em>)=<em>F</em>(<em>x</em>)⊔<em>F</em>(<em>y</em>)。一般，对于控制流的join/meet，是进行集合的交或并操作，则满足分配律。</p><hr /><h2 id="10常量传播-constant-propagation"><a class="markdownIt-Anchor" href="#10常量传播-constant-propagation"></a> 10.常量传播 (constant propagation)</h2><p><strong>问题描述</strong>：在程序点p处的变量x，判断x是否一定指向常量值。</p><p><strong>类别</strong>：<strong>must分析</strong>，因为要考虑经过p点所有路径上，x的值必须都一样，才算作一定指向常量。</p><p><strong>表示</strong>：CFG每个节点的OUT是pair（x, v）的集合，表示变量x是否指向常数v。</p><h4 id="数据流分析框架d-l-f"><a class="markdownIt-Anchor" href="#数据流分析框架d-l-f"></a> 数据流分析框架（D, L, F）</h4><p>（1）D：forward更直观</p><p>（2）L：lattice</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002090.webp" alt="img" /></p><p>4-10-1-UNDEF_NAC.png</p><p><strong>变量值域</strong>：所有实数。must分析，所以<img src="mdPics/math" alt="\top" />是UNDEF未定义（unsafe），<img src="https://math.jianshu.com/math?formula=%5Cperp" alt="\perp" /> 是NAC非常量（safe）。</p><p><strong>meet操作</strong>：must分析， <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" />。在每个路径汇聚点PC，对流入的所有变量进行meet操作，但并非常见的交和并，所以<strong>不满足分配律</strong>。</p><ul><li>NAC <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> v = NAC</li><li>UNDEF <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> v = v  未初始化的变量不是我们分析的目标。</li><li>c <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> v = ?                   c <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> c = c          c1 <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> c2 =NAC</li></ul><p>（3）<strong>F转换函数</strong></p><p>OUT[s] = gen U (IN[s] - {(x, _})</p><p>输出 = BB中新被赋值的 U 输入 - BB中相关变量值已经不是f常量的部分。</p><p>对所有的赋值语句进行分析（不是赋值语句则不管，用val(x)表示x指向的值）：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002116.webp" alt="img" /></p><p>4-10-2-赋值语句操作.png</p><p>（4）<strong>性质</strong>：不满足分配律</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002132.webp" alt="img" /></p><p>4-10-3-不满足分配律.png</p><p>可以发现，MOP更准确。F(X<img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" />Y) <img src="https://math.jianshu.com/math?formula=%5Csqsubseteq" alt="\sqsubseteq" /> F(X) <img src="https://math.jianshu.com/math?formula=%5Csqcap" alt="\sqcap" /> F(Y)，但是是单调的。</p><hr /><h2 id="11worklist算法"><a class="markdownIt-Anchor" href="#11worklist算法"></a> 11.Worklist算法</h2><p><strong>本质</strong>：对迭代算法进行优化，采用队列来存储需要处理的基本块，减少大量的冗余的计算。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404241002166.webp" alt="img" /></p><p>4-11-worklist.png</p><p>作者：bsauce<br />链接：<a href="https://www.jianshu.com/p/d314b316b332">https://www.jianshu.com/p/d314b316b332</a><br />来源：简书<br />著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>过程间分析</title>
      <link href="/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E8%BF%87%E7%A8%8B%E9%97%B4%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/18/Security/software%20analysis/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90-%E8%BF%87%E7%A8%8B%E9%97%B4%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录：</h3><ol><li>Motivation</li><li>调用图构建</li><li>过程间控制流分析</li><li>过程间数据流分析</li></ol><h3 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点：</h3><p>学习如何利用类层级分析来构建调用图；过程间控制流/数据流分析；过程间的常量传播。</p><hr /><h2 id="1motivation"><a class="markdownIt-Anchor" href="#1motivation"></a> 1.Motivation</h2><p><strong>问题</strong>：<mark>过程内的分析未考虑函数调用，导致分析不精确</mark>。</p><p><strong>过程间分析</strong>：Inter-procedural Analysis，考虑函数调用，又称为全程序分析（Whole Program Analysis），需要构建调用图，加入Call edges和Return edges。</p><hr /><h2 id="2调用图构建"><a class="markdownIt-Anchor" href="#2调用图构建"></a> 2.调用图构建</h2><h4 id="1调用图"><a class="markdownIt-Anchor" href="#1调用图"></a> （1）调用图</h4><p><strong>定义</strong>：本质是调用边的集合，从调用点（call-sites）到目标函数（target methods / callees）的边。</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953225.webp" alt="img" /></p><p>5-2-1-call_graph.png</p><p><strong>应用</strong>：是所有过程间分析（跨函数分析）的基础，程序优化，程序理解，程序调试。</p><h4 id="2面向对象语言的调用图构造java"><a class="markdownIt-Anchor" href="#2面向对象语言的调用图构造java"></a> （2）面向对象语言的调用图构造（Java）</h4><p><strong>代表性算法</strong>：从上往下精度变高，速度变慢，重点分析第1、4个算法。</p><ul><li>Class hierarchy analysis(CHA)</li><li>Rapid type analysis(RTA)</li><li>Variable type analysis(VTA)</li><li>Pointer analysis(k-CFA)</li></ul><p><strong>Java调用分类</strong>：</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:center"><strong>Static call</strong></th><th style="text-align:center"><strong>Special call</strong></th><th style="text-align:center"><strong>Virtual call</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>指令</strong></td><td style="text-align:center">invokestatic</td><td style="text-align:center">invokespecial</td><td style="text-align:center">invokeinterface、 invokevirtual</td></tr><tr><td style="text-align:left">Receiver objects（返回后赋值的目标对象）</td><td style="text-align:center">×</td><td style="text-align:center">✓</td><td style="text-align:center">✓</td></tr><tr><td style="text-align:left"><strong>目标函数</strong></td><td style="text-align:center">Static函数</td><td style="text-align:center">构造函数、 私有函数、父类的实例函数</td><td style="text-align:center">其他实例函数</td></tr><tr><td style="text-align:left"><strong>目标函数个数</strong></td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">≥1 (<strong>polymorphism</strong>多态性)</td></tr><tr><td style="text-align:left"><strong>何时确定</strong></td><td style="text-align:center">编译时</td><td style="text-align:center">编译时</td><td style="text-align:center">运行时</td></tr></tbody></table><p><strong>Method Dispatch</strong>：最难的是<strong>Virtual call</strong>，其中关键步骤是Method Dispatch，就是<strong>找到最终调用的实际函数</strong>。</p><p>virtual call在程序运行时才能得到，基于2个要素得到：</p><ol><li><p>reciever object的具体类型：<strong>c</strong></p></li><li><p>调用点的函数签名：<strong>m</strong>。（通过signature可以唯一确定一个函数）</p><ol><li>signature = 函数所在的类 + 函数名 + 描述符</li><li>描述符 = 返回类型 + 参数类型</li></ol><p>简记为C.foo(P, Q, R)</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953263.webp" alt="img" /></p><p>5-2-2-virtual_call.png</p></li></ol><h4 id="3method-dispatchvirtual-call"><a class="markdownIt-Anchor" href="#3method-dispatchvirtual-call"></a> （3）Method Dispatch（virtual call）</h4><p><strong>定义</strong>：用Dispatch(c, m)来模拟动态Method Dispatch过程，c表示reciever object，m表示函数签名。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953239.webp" alt="img" /></p><p>5-2-3-Method_Dispatch.png</p><p><strong>解释</strong>：若该类的非抽象方法（实际可执行的函数主体）中包含和m相同名字、传递/返回参数的m‘，则直接返回；否则到c的父类中找。</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953264.webp" alt="img" /></p><p>5-2-4-Dispatch示例.png</p><h4 id="4class-hirarchy-analysis-cha-类层级分析"><a class="markdownIt-Anchor" href="#4class-hirarchy-analysis-cha-类层级分析"></a> （4）Class Hirarchy Analysis (CHA)  类层级分析</h4><p><strong>目的</strong>：根据每个virtual call 的 receiver varible 的<strong>声明类型</strong>来求解所有可能调用的目标函数。如 <code>A a = ... ;</code>  <code>a.foo();</code> 这个a就是receiver varible，声明类型就是A。假定a可以指向A以及A所有子类对象，CHA的过程就是从A和子类中去找目标函数。</p><p><strong>算法</strong>：Resolve(cs)——利用CHA算法找到调用点所有可能的调用目标。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953362.webp" alt="img" /></p><p>5-2-5-CHA算法.png</p><p><strong>算法示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953350.webp" alt="img" /></p><p>5-2-6-CHA算法示例.png</p><p><strong>算法应用</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953907.webp" alt="img" /></p><p>5-2-7-CHA应用.png</p><p><strong>错误</strong>：以上b.foo()的调用目标 C.foo()和D.foo()是错误的，因为<strong>已经指定了是B类型</strong>，所以b.foo()根本不会调用C、D的foo()。因为CHA只考虑声明类型，也就是B，导致准确度下降。多态性就是说，父类可以引用子类的对象，如<code>B b=new C()</code>。</p><p>优缺点：CHA优点是速度快，只考虑声明类型，忽略数据流和控制流；缺点是准确度低。</p><p>总结：本类中有同名函数就在本类和子类找，没有就从父类找，接着找父类的子类中的同名函数（CHA分析）。</p><h4 id="5利用cha构造调用图"><a class="markdownIt-Anchor" href="#5利用cha构造调用图"></a> （5）利用CHA构造调用图</h4><p><strong>算法</strong>：<mark>遍历每个函数中的每个调用指令</mark>，调用CHA的Resolve()找到对应的目标函数和调用边，函数+调用边=调用图。</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953911.webp" alt="img" /></p><p>5-2-8-调用图构造算法.png</p><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953930.webp" alt="img" /></p><p>5-2-9-调用图算法示例.png</p><hr /><h2 id="3过程间控制流分析"><a class="markdownIt-Anchor" href="#3过程间控制流分析"></a> 3.过程间控制流分析</h2><p><strong>定义</strong>：过程间控制流图ICFG = CFG + (Call edges + Return edges)。</p><ul><li>Call edges：连接调用点和目标函数入口</li><li>Return edges：从return语句连到Return site（Call site后面一条语句）</li></ul><p><strong>示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953991.webp" alt="img" /></p><p>5-3-ICFG示例.png</p><hr /><h2 id="4过程间数据流分析"><a class="markdownIt-Anchor" href="#4过程间数据流分析"></a> 4.过程间数据流分析</h2><p><strong>说明</strong>：对ICFG进行数据流分析，没有标准的一套算法。</p><p><strong>对比</strong>：</p><table><thead><tr><th></th><th><strong>Intra</strong>procedural</th><th><strong>Inter</strong>procecdural</th></tr></thead><tbody><tr><td><strong>程序表示</strong></td><td>CFG</td><td>ICFG = CFGs + call &amp; return edges</td></tr><tr><td><strong>转换规则</strong></td><td>Node transfer</td><td>Node transfer + edge transfer</td></tr></tbody></table><p><strong>常量传播数据流分析</strong>：</p><ul><li>Node transfer：与过程内分析相同，对每个调用点，将等号左边部分去掉。</li><li>Call edge transfer：传参</li><li>Return edge transfer：传返回值</li></ul><p><strong>常量传播示例</strong>：</p><p><img src="https://foresta.oss-cn-beijing.aliyuncs.com/images/202404240953005.webp" alt="img" /></p><p>5-4-ICFG常量传播示例.png</p><p><strong>说明</strong>：黄色背景边必须有，从<code>b = addOne(a)</code>到<code>c=b-3</code>，a通过此边传递，b通过addOne()传递。若a也通过addOne()传递，会额外消耗系统资源。</p>]]></content>
      
      
      <categories>
          
          <category> 软件分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 过程间分析 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
